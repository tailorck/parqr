_id,body,course_id,followups,i_answer,num_unresolved_followups,num_views,post_id,s_answer,subject,tags
5ad7d09b0d63974e20c39043,"
Piazza is a Q&A; platform designed to get you great answers from classmates and instructors fast. We've put together this list of tips you might find handy as you get started:

 Ask questions!

The best way to get answers is to ask questions! Ask questions on Piazza rather than emailing your teaching staff so everyone can benefit from the response (and so you can get answers from classmates who are up as late as you are).

Edit questions and answers wiki-style.

Think of Piazza as a Q&A; wiki for your class. Every question has just a single students' answer that students can edit collectively (and a single instructors’ answer for instructors).

 Add a followup to comment or ask further questions.

To comment on or ask further questions about a post, start a followup discussion. Mark it resolved when the issue has been addressed, and add any relevant information back into the Q&A; above.

 Go anonymous.

Shy? No problem. You can always opt to post or edit anonymously.

 Tag your posts.

It's far more convenient to find all posts about your Homework 3 or Midterm 1 when the posts are tagged. Type a “#” before a key word to tag. Click a blue tag in a post or the question feed to filter for all posts that share that tag.

 Format code and equations.

Adding a code snippet? Click the pre or tt button in the question editor to add pre-formatted or inline teletype text. 
Mathematical equation? Click the Fx button to access the LaTeX editor to build a nicely formatted equation.

 View and download class details and resources. 

Click the Course Page button in your top bar to access the class syllabus, staff contact information, office hours details, and course resources—all in one place!


Contact the Piazza Team anytime with questions or comments at team@piazza.com. We love feedback!",j8rf9vx65vl23t,[],,,,1,,Welcome to Piazza!,[]
5ad7d09b0d63974e20c39044,"I'm a little bit frustrated.  I've implemented minimax with alpha-beta pruning, and I believe it is working correctly.  When I test it manually [whether I go first and make it open with a random move just for sake of the manual test, or go second], it almost always beats a random player....and Bonnie confirms that ---- my win ratios for my custom player against the random player are consistently 0.95 or 1.0 over a few submissions (one per ""about an hour"", of course).  So far, so good.  I'm rapidly growing accustomed to my 35 points.
 
However, my win ratio against the two minimax opponents in section A is always 0.5...showing 10 invalid_moves with no timeouts.  It's never budged.  It seems more than coincidental that I should always be losing exactly half the games played against one of the minimax opponents.  Is there any way to tell what is happening in more detail ?
 
My default search depth in the CustomPlayer constructor is 4, by the way, and I assume that Bonnie is always invoking it with the deafult value.
 
Probably I am tired and overlooking the obvious, or doing something stupid, but any and all suggestions, feedback, etc. would be very welcome.  Thank you in advance.",j8rf9vx65vl23t,"[{u'text': u'Hey Girish, I'm testing the follow up functionality. This is a follow up discussion.', u'responses': []}]",You can create your own CustomMinimax that mimic Bonnie's Minimax upto depth 3 since it uses the OpenEvalFn. Also if the win ratio is 0.5 it mostly means that you are only playing 2 different games in total. Since Minimax always chooses the best option given a starting position the rest of the moves will always be the same. Clearly the person playing first always wins and the player moving second will always lose since the moves will always be the same or vice versa. I am stuck with the same issue as well. I guess creating a better EvalFn or using symmetry might help.,,,6,,"Always beating random player quite handily, but win ratio for minimax opponents remains at 0.5",[hw1]
5ad7d09b0d63974e20c39045,"Part 2e states the following:

Given the same outcomes as in 2b, A beats B and A draws with C, you should now estimate the likelihood of different outcomes for the third match by running Gibbs sampling until it converges to a stationary distribution.

Currently I’m testing my Gibbs sampler by passing in known values for the initial state. But in the above problem, we don’t know the outcome of the matchup between C and A. How do I represent this unknown value in my initial state? If I just start it with a value of 0 (C wins), 1 (A wins), or 2 (Tie), won’t that impact the results? Or will it be irrelevant as long as I use the same assumption when testing my MH sampler?

I guess this also applies to skill levels (I’ve been passing in a skill level of 0 for all teams as the initial state for testing purposes), is that fine as well?",j8rf9vx65vl23t,[],"For non-observations in the initial states, set them randomly.

Edit: great answer.",,,7,,How should we handle unknown values in the initial state?,[hw1]
5ad7d09b0d63974e20c39046,"I have implemented iterative deepening with alpha beta pruning. In a 7x7 board against a mmax of depth 5, my AI with just alpha -beta pruning and depth of 7 wins 100% of the time as player1 but fails 90-100% of the time if it is the second player.

When I try the same with iterative deepening my AI only wins 60% of the games as player 1 and 40% of the time as player 2.

Did anyone face something like this? any suggestions?",j8rf9vx65vl23t,"[{u'text': u'hi this answer is great! Can you please explain more on how we can use node reordering to optimize this process?', u'responses': [u'Great follow up girish. Here is some feedback.']}, {u'text': u'New followup.', u'responses': []}]","check if the result is same by limiting depth of ID to the same as just AB, and set a large value for time. try it against a local mm opponent of depth 5.If result for both ID and AB is same, then you have a bad evaluation function. As the AB is allowing deeper search, you are evaluating good boards as bad and bad boards as good. Since you allow both to reach final depth, by giving the larger time, both should give you identical result on a correct implimentation. if the result is different, then you have made some mistake in the ID-AB",,,8,,alpha beta performing better than Iterative Deepening,[hw2]
5ad7d09c0d63974e20c39047,,j8rf9vx65vl23t,[],,,,9,,Test for parqr minimax,[hw5]
5ad7d4240d63974e20c3904a,"
Piazza is a Q&A; platform designed to get you great answers from classmates and instructors fast. We've put together this list of tips you might find handy as you get started:

 Ask questions!

The best way to get answers is to ask questions! Ask questions on Piazza rather than emailing your teaching staff so everyone can benefit from the response (and so you can get answers from classmates who are up as late as you are).

Edit questions and answers wiki-style.

Think of Piazza as a Q&A; wiki for your class. Every question has just a single students' answer that students can edit collectively (and a single instructors’ answer for instructors).

 Add a followup to comment or ask further questions.

To comment on or ask further questions about a post, start a followup discussion. Mark it resolved when the issue has been addressed, and add any relevant information back into the Q&A; above.

 Go anonymous.

Shy? No problem. You can always opt to post or edit anonymously.

 Tag your posts.

It's far more convenient to find all posts about your Homework 3 or Midterm 1 when the posts are tagged. Type a “#” before a key word to tag. Click a blue tag in a post or the question feed to filter for all posts that share that tag.

 Format code and equations.

Adding a code snippet? Click the pre or tt button in the question editor to add pre-formatted or inline teletype text. 
Mathematical equation? Click the Fx button to access the LaTeX editor to build a nicely formatted equation.

 View and download class details and resources. 

Click the Course Page button in your top bar to access the class syllabus, staff contact information, office hours details, and course resources—all in one place!


Contact the Piazza Team anytime with questions or comments at team@piazza.com. We love feedback!",jc6w44hrp9v2ki,[],,0.0,350.0,1,,Welcome to Piazza!,[]
5ad7d4250d63974e20c3904b,"Welcome to CS 6601: AI for Spring 2018!  We're still getting this semester's materials together and will post an official introduction announcement and teaching team introduction thread soon, but in the meantime, feel free to introduce yourselves in this thread. Please make sure your Piazza account is linked to your Georgia Tech email ID - we will be uploading the official roster to Piazza and you may get booted if you don't do this.
 
To get started, we'd like to get to know you. We've found in the past that our students have fascinatingly diverse backgrounds and experiences, and a lot of that came up quite often in the course. Below, you'll find a list of questions we'd like to ask you to get us started. We'd invite you to post a follow-up here and introduce yourself to us and the rest of the class -- you should see a box below offering you the chance to ""Compose a new follow-up discussion"". In general, when you post a follow-up that doesn't need to be answered, you should mark it ""Resolved"" - however, we'd like to say hi to each of you here, so please leave your intros Unresolved.
 
So, please introduce yourself here and answer the following questions (or whichever you feel like answering. Feel free to add anything additional!) :
What is your name?Where do you live? (or) Where are you from?Why are you taking AI?What other OMS/GT CS courses have you taken?What do you do when you're not working on classes? (Career, research, hobbies, etc.)What is something interesting about you?
 
If you haven't already, we'd encourage you to upload an avatar (click the gear in the top right, then Account/Email Settings, then Change Picture) as well -- the class feels much more alive with faces behind the messages! Please also feel free to link to videos, pictures, personal web sites, LinkedIn profiles, and more in your introductions. Just a couple of small requests: for videos, please make sure to link to them instead of embedding them, and for pictures, please only embed them if they're relatively small (around a couple hundred pixels in each dimension) to avoid radically slowing down the page's load time.

",jc6w44hrp9v2ki,"[{u'text': u'What is your name?
Chris Hellriegel
Where do you live? (or) Where are you from?
Melbourne, FL
Why are you taking AI?
I attempted this course last semester.  I got hit by a Hurricane Irma and had some house damage and related issues that I needed to resolve, so I withdrew for the semester.  Now I'm back to take another whack it at.  AI is quite fascinating and appears to be working its way into everything, so I think it is worth learning about.
What other OMS/GT CS courses have you taken?
Intro to OS and DB systems.
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Simple things, like exercise, watching movies, and hanging out with friends.  I have a pretty busy full-time work schedule so that combined with school eats up most of my time.
What is something interesting about you?
I know how to do Salsa Dancing!', u'responses': [u'Hey Chris,
Really hope everything's fine now, and that this semester goes well without any hiccups for you... and we're really glad to have you back!
Also, Salsa! Every attempt at anything remotely resembling dancing has ended in failure for me, so color me envious!
We look forward to working with you :)', u'Thanks!  I look forward to working with you guys too!  Learning to dance is just like everything else, you have to just keep practicing.']}, {u'text': u'Hi all,
 
What's your name?
Zenan Liu
 
Where do you live?
Singapore
 
What other OMS courses have you taken so far?
ML4T and KBAI
 
What do you do when you're not in the OMS? (Career, hobbies, etc.)
Travelling, swimming, my career is in UX design
 
Why are you taking CSE6242: Data & Visual Analytics? What do you hope to get out of this course?
Learn more about analytics which could help me with my work in UX.
 
What is something interesting about you?
I play the keyboard instrument', u'responses': [u'Hi Zenan, looks like you accidentally posted the intro for DVA! Haha. Nice to meet you still!
-Q.', u'Hey Zenan, welcome to the course! I'm a swimmer and keyboardist as well - looks like we have something in common!
Also, I believe there are a few people on-campus here in Tech who're working on marrying UX with AI and analytics - perhaps you could seek out their research?
We look forward to working with you!']}, {u'text': u'Christopher Jack NicholsonKnoxville, TennesseeIt's the last required course for my specialization.  It's also fascinating.AI4R, IOS, SDP, HCI, EdTech, ML4T, KBAI, IHI Board games, latelyAll but one of my grandparents were born in the 19th Century.', u'responses': [u'Hey Christopher,
Welcome to the course! Does this mean you're graduating soon? If so, best of luck!
Also, it's fascinating about your grandparents - I remember reading about a 117-year-old a few days ago, and a commenter had written about just how much this person would've seen in their lifetime. Really put things into perspective.
We look forward to working with you :)', u'Yes, I should graduate this semester given no mishaps.  Thanks for the good wishes!']}, {u'text': u'1. What is your name?
        Caleb McCreary

2. Where do you live? (or) Where are you from?
       I currently live in Kennesaw, GA, USA and I am originally from a microscopic town called Pine Log, GA, USA.

3. Why are you taking AI?
       Other than the course being part of my specialization, AI is one of the many courses I got into this program for. Other than being a fascinating topic, it is
       one of the major areas of building a great video game, which is my main passion in life. 

4. What other OMS/GT CS courses have you taken?
       Computational Photography and Computer Vision.

5. What do you do when you're not working on classes? 
        I currently work for a company doing research in applying AR to industrial automation. Outside of that, I've been a voracious learner/reader my whole life and I spend most of my time learning about various (if not unfocused)            topics. I enjoy tackling new programming languages and taking on small personal projects that challenge me to expand my horizons. In addition, I'm an avid biker, climber, hiker, and obsessed with both cooking and gaming            (board or digital). 

6. What is something interesting about you?
        My undergrad degree is in Biochemistry and I was a completely self-taught programmer before joining this program last semester.', u'responses': [u'Hi Caleb! Welcome to CS6601!

The first assignment is about game playing. Hopefully you enjoy tackling the problem!
I like you attitude of being a voracious learner. I hope I can do the same later in life. ']}, {u'text': u'1. What is your name?
Kenny Q. Vong, but please call me ""Q"" (like the alphabet)

2. Where do you live? (or) Where are you from?
Los Angeles, California

3. Why are you taking AI?
AI is a huge umbrella term and is ubiquitous across many disciplines these days. Becoming conversant with AI and perhaps being able to maneuver through a few of it subtopics would add depth and most likely provide great insights to implementation and application strategies.

4. What other OMS/GT CS courses have you taken?
SDP (Dr. A. Orso) and KBAI (Dr. A. Goel and Dr. D. Joyer). All great and highly recommended.

5. What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Exercise, sports, games, binge watch a show/anime, unapologetically cheer for the Lakers (even now....). All no longer available because of OMSCS, haha!

6. What is something interesting about you?
I've been training for the upcoming LA Marathon and every minute has been painful...

********* Slack: @q *********
 
Super excited to interact with everyone!!
 
-Q.', u'responses': [u'Hey Kenny!

Welcome to the course! We hope that you enjoy the course and recommend it to others at the end of the semester. 

Marathon! Good luck and keep fighting!']}, {u'text': u'What is your name?
Conor Cahill
Where do you live? (or) Where are you from?
Northern Virginia (though I spend half of my time out in Seattle, WA)
Why are you taking AI?
It's my last course in the program and I thought I'd have some fun!
What other OMS/GT CS courses have you taken?
IOS, AOS, CN, CP, SAAD, NS, IIS, CPS,  GA
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Work for AWS with a team in Seattle (hence my trip out there every other month).    Would like to play more with smart home stuff and my Mavic drone, but probably have to wait till the class is over...  
What is something interesting about you?
At one point in the far distant past, I was a Chinese linguist...  far, far distant past...
', u'responses': [u'Hey Conor,
That's a pretty wide set of courses you've taken - best of luck for graduation!
And it seems like there's an interesting story here - how'd you get from Chinese linguist to computer scientist?
We look forward to working with you :)', u'Well... Chinese ... C... both start with ""C"" and both are languages :-)...

On a more serious note, after 18 months of training, at my first duty station, we had a PDP-11 lying about running PWB UNIX (between v6 and v7) and I taught myself C and wrote some software that ended up being quite useful and they let me continue writing code...

30+ years later I decided to make my CS training more formal with an MS (I did my BS in EE graduating in '14 -- a very late bloomer).', u'Wow. That's... Quite a journey!
I've always thought one's life is set in stone pretty young. Naivete of youth, I guess :)']}, {u'text': u'What is your name?
Junwei Huang
Where do you live? (or) Where are you from?
Toronto, Canada
Why are you taking AI?
Apply AI or machine learning to my field which is to develop professional software for mining and oil/gas.
What other OMS/GT CS courses have you taken?
DB systems, SDP, CV. 
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Running, working on my drone.
What is something interesting about you?
I made myself a distributed parallel computing machine (10 nodes). What...you said this is not something interesting but rather boring. oh well...', u'responses': [u'I don't think we've had somebody in this course looking to apply AI to mining - seems pretty interesting!
And don't undersell yourself - a 10-node distributed system sounds pretty cool! Is there something in particular that you use it for?
Hope you find this course interesting. We look forward to working with you!']}, {u'text': u'What is your name?Lalitha GanesanWhere do you live? (or) Where are you from?I live in San Diego, CA and am originally from a small town in RI.Why are you taking AI?I'm doing the ML specialization and even though I don't need to take this class to get my specialization, I want to learn more about AI since it is so closely related to ML.What other OMS/GT CS courses have you taken?RL, ML, ML4T, KBAI, InfoSec, Intro to HPCWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)I'm an embedded software engineer. Outside of work, I like to entertain my creative side by knitting and designing knitwear. I also love to go hiking, do yoga, and hang out at breweries with friends.What is something interesting about you?I started an Etsy shop last year selling my handmade knits!', u'responses': [u'Hey Lalitha,
Welcome to the course! 

Looks like you are already familiar with a lot of GT courses and we hope you like AI as much as you like them, or maybe more :). Handmade knits are so cool and I would be interested in buying one! 
We look forward to working with you :)', u'Hey Lalitha,

It's really cool that you're selling your handmade knits! I just got around to knitting and crochet but unfortunately I just can't get the hang of knitting in the round (: Hope you enjoy the course!']}, {u'text': u'What is your name?

Officially, I'm Edward Daniels, but I use my middle name, so here on Piazza I show up as E. Scott Daniels. 

Where do you live? (or) Where are you from?
I currently reside in the Akron Ohio area (US East timezone)

Why are you taking AI?
First, after taking KBAI I wanted to continue to pursue the topic. Secondly it satisfies a specialisation requirement.

What other OMS/GT CS courses have you taken?
Computer networking, Computational photography, Intro to Operating Systems, Knowledge Based AI, Embedded Software, Software Analysis and Testing, Software Development Process, and Educational Technology. 

What do you do when you're not working on classes? (Career, research, hobbies, etc.)

I work for AT&T Labs -- Research, currently my work is focused on cloud, networking and distributed systems research. 

What is something interesting about you?
 For fun, I rock climb; both indoors and out. 
', u'responses': [u'Hey Scott,
That's a pretty wide breadth of courses you've taken! We hope you enjoy this course as well :)
I'm a bit afraid of heights, so I've never tried rock climbing even indoors - but I did come across this article a few months ago: https://www.dfki.de/web/research/publications/renameFileForDownload?filename=climbing-mixed-reality.pdf&file_id=uploads_3107
This, combined with a VR game called The Climb, makes me believe I can at least give it a virtual go.
We look forward to working with you!', u'
I love being up high, but have a horrible fear of falling. Turns out that falling isn't so bad, it's usually the landing that sucks!
']}, {u'text': u'What is your name?
Lu Lin, and I go by Irene sometimes.
Where do you live? (or) Where are you from?
San Diego, CA
Why are you taking AI?
I'm dying to learn about AI because it provides challenging problems and it's been a super buzzword during the entire past year.
What other OMS/GT CS courses have you taken?
SDP
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I love watching movies and am a huge Marvel fan. I did autonomous vehicle research as a civil engineer before I am a CS student.
What is something interesting about you?
I can simulate a perfect world consist of all self-driving cars and no traffic, or traffic signals. I became a CS student for the purpose of making my simulation come true. ', u'responses': [u'Hey Irene,
That is actually really interesting - when you talk about autonomous vehicle research from the Civil Engineering side of things, do you mean construction, planning and such to favour autonomous vehicles? Sounds so cool!We look forward to working with you!']}, {u'text': u'What is your name?

Mike Williamson

Where do you live? (or) Where are you from?

Columbia, SC, USA

Why are you taking AI?

I am working on the Computational Perception and Robotics track and this class is right in the middle as I understand it.  Looking forward to it.

What other OMS/GT CS courses have you taken?

CS6035, CS6040, CS6210, CS6290 and CS6310

What do you do when you're not working on classes? (Career, research, hobbies, etc.)

I work at BlueCross BlueShield of South Carolina as a Solution Designer.

What is something interesting about you?

I have been a Software Engineer  for the last 30 years having graduated from Purdue University in 1987.  I am so glad I was born when I was as this has been a truly interesting time to be an engineer.', u'responses': [u'Hey Michael,
Wow - 30 years is virtually a lifetime in the field! You've probably seen a ton of amazing change - can't imagine what it must be like :)
We hope we're able to make this course interesting for you - looking forward to it!', u'
Nice to know that I'm not the only 'old timer' here :)    Graduated with my BSCS in '82 -- wrote my first set of programmes on punch cards.  
']}, {u'text': u'What is your name?
Gurpreet Singh

Where do you live? (or) Where are you from?
Niskayuna, NY

Why are you taking AI?
I work with AI researchers and this course will help me prepare to contribute to the research activities (also it's the last required course for my II specialization)

What other OMS/GT CS courses have you taken?
SAAD, SAAT, KBAI, HCI, IHI, SDP, ET, NS, IIS

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Working as a Software Architect at GE Global Research. In my spare time - building a curated Digital Twin knowledge repository and drafting a book on Software Architectures

What is something interesting about you?
Learning about investment diversification - cryptos and domains (learning-by-doing) :-)', u'responses': [u'Hey Gurpreet,
Looking at your courses, I guess you're graduating soon? Best of luck!
You also seem to have a pretty diverse range of interests within Computer Science itself... We hope you can do a ton with what you learn from this course. We look forward to working with you :)', u'Yeah, this is my last course. Looking forward to this course and learnings which I can apply in my job and elsewhere!']}, {u'text': u'What is your name?
Diego F. Vacanti
Where do you live? (or) Where are you from?
Miami, FL (Born in Santos, São Paulo, Brazil)
Why are you taking AI?
I am in the healthcare field and we are beginning AI/ML related work and I will be at the head of it all. Also, it has always interested me.
What other OMS/GT CS courses have you taken?
Computer Vision and Introduction to Information Security. Also taking Computational Photography in Spring '18.
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Right now due to classes it's either work or spending time with my family, I hope after OMSCS that I am able to build a few projects I have in mind using Raspberry Pi and whatnot.
What is something interesting about you?
I love cooking and usually tend to go all out but I do it sparingly.', u'responses': [u'Hey Diego,
There's a Health Informatics course also available at Tech that I believe deals with exactly what you might be working with - although I reckon it might be stuff you already know :)
Hope we can make this course enjoyable for you - looking forward to it!', u'Yep I have worked my entire career up to this point in the healthcare industry, I am not sure if it would be worthwhile for me to take it. I deal with that stuff day in/out :D', u'
Hi Diego...
Health Informatics (6440) is an excellent course, imho.  I was pre-med in college so I enjoyed learning about HI and its impact on patient care.  It doesn't really get into AI/ML that much, but does go over the impact of intelligent systems in medicine.']}, {u'text': u'What is your name?
Richard Pace
Where do you live? (or) Where are you from?
Simi Valley, CA
Why are you taking AI?
Interest...
What other OMS/GT CS courses have you taken?
Concurrently taking GA.  Have taken IOS, HPCA, CN, IIS, NS, CCA, ML4T, SAAD, CPSS.
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Software developer with IBM.  Used to play guitar, but I haven't practiced in over a year now :-(  I still remember my scales though  :-)
What is something interesting about you?
If one defines the Bacon number very, very loosely, my Erdös/Einstein/Bacon number is 12.', u'responses': [u'AI with GA!!! Hats off to you...', u'Hey Richard, Bacon number 12 is definitely interesting! (Definitely defies the six degrees of Kevin Bacon theory) I think mine is about 5.Hope you enjoy the course :)', u'12 is the sum of the three numbers, each being 4.  Strictly speaking, one must be in a film to attain a Bacon number....My loose definition includes commercials and the derivation of my Bacon number of 4 using this loose definition is: Kevin Bacon was in Apollo 13 with Bill Paxton (1), Bill Paxton was in True Lies with Charlton Heston (2),  Charlton Heston was in Khartoum with my mother (3, a bit part, she's not an actress),  my mother and I (4) were in a commercial together (applying the loose definition here).', u'Ah I get it now! That's really cool, I didn't know about the other two. :) My friend's uncle happens to be an actor so that's how I calculated mine', u'The other two have to do with how close one is to co-authoring a published paper - i.e. if you are old enough to have co-authored a published paper with Paul Erdös or Albert Einstein, your Erdös or Einstein number, respectively, is 1.  I co-authored a paper that was published in Linear Algebra and its Applications with my graduate school thesis advisor, whose Erdös and Einstein numbers were both 3.

The Bacon number is actually a variation of the Erdös number,

https://en.wikipedia.org/wiki/Erd%C5%91s_number', u'That's pretty cool. I guess being a movie buff I knew the one that I could relate to!']}, {u'text': u'What is your name?     Nate CusterWhere do you live? (or) Where are you from?  Kansas City - USWhy are you taking AI?  - It interests me very muchWhat other OMS/GT CS courses have you taken?  IOS, SDP, ML, KBAI, NetworkingWhat do you do when you're not working on classes? sailing, tinkering with OS internals, small devices (rpi)What is something interesting about you?  I just started sailing after 30 years of kayaking or canoe only floating.', u'responses': [u'Hey Nate,
Where do you sail? My knowledge of sailing and US geography is extremely limited, but I assumed Kansas City was too far in the interior!
Best of luck for your sailing endeavors though :)We look forward to working with you!']}, {u'text': u'Hi,

What's your name?
Jim Winquist

Where do you live? (or) Where are you from?
Seattle, WA
Why are you taking AI?
I am really excited about the field of AI in general and am hoping to transition into a career in AI. I am taking this course to broaden my knowledge of AI algorithms and to get some more good AI projects under my belt.
What other OMS/GT CS courses have you taken?
SDP, KBAI, AI4R, ML4T, DB Systems, Computer Vision, Health Informatics, HCI, Ed Tech.
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Udacity SDCND, and personal projects.
What is something interesting about you?
I work in game development.', u'responses': [u'Hi Jim! Welcome to the course!

What kind of games do you develop? Are you interested in doing AI within games, or are your interests more general than that?']}, {u'text': u'1.What is your name?
My name is BoSuk Hong. I go by Ben.
2. Where do you live? (or) Where are you from?
I am in Chicago, Illinois.
3. Why are you taking AI?
Now there it's mentioned everywhere, I want to understand it.
4. What other OMS/GT CS courses have you taken?
DB systems and designs.
5. What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Netflix....
6. What is something interesting about you?
I was a math major, but I am terrible at it.', u'responses': [u'Welcome to AI BoSuk!

I'm curious, do you plan to do something AI related with your DB experience?']}, {u'text': u'What is your name?
Michael Bearss
Where do you live? (or) Where are you from?
Columbus, GA
Why are you taking AI?
I'm knocking out my last electives and thought this would be an interesting course. I'm really interested in AI and I think in the near future it will start to creep into almost every field of computer science. 

What other OMS/GT CS courses have you taken?
AOS. SDP, Computer Networks, IIS, Network Security, Software Analysis and Testing, DB Sys and Concepts
Tried to take CCA but had to drop (tried to take it along with AOS)
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Between OMSCS and work not too much free time left. I enjoy exercise (running, biking, BJJ) and family time.
What is something interesting about you?
I used to work as a professional chef( a long time ago)', u'responses': [u'As a veteran OMSCS student, perhaps you could help us improve the course and help the newbies find their way around?

Have you tried anything from the Watson cookbook yet?  I'm interested to hear your opinion!']}, {u'text': u'What is your Name? Rabah OuldnoughiWhere do you live? (or) Where are you from? Westfield, Indiana, USAWhy are you taking AI? Buzzword wherever I go, dying to know what's it all about. What other OMS/GT CS courses have you taken? AI4R, CP.What do you do when you're not working on classes? If I am not at work then I am either tinkering with stuff in my personal electronics lab or hiking in a national park. What is something interesting about you? Love cooking.', u'responses': [u'Welcome to AI, Rabah!

If you find AI and cooking both interesting, you might be quite taken by this: https://www.ibmchefwatson.com/community']}, {u'text': u'
What is your name? Chris SerranoWhere do you live? (or) Where are you from? Southern CaliforniaWhy are you taking AI? It's been recommended to me by several other studentsWhat other OMS/GT CS courses have you taken? AI4R, KBAI, ML, ML4T, RL, DVA, BD4H What do you do when you're not working on classes? (Career, research, hobbies, etc.) My background is in online publishing and I'm passionate about gaming of all typesWhat is something interesting about you? If you're taking RL I'm one of your TAs', u'responses': [u'Hello Chris, welcome to AI!

What do you plan to do after GaTech? Have you done any game development in the past?']}, {u'text': u'Hello everyone!

What's your name?
Ismail Kalimi 
Where do you live? (or) Where are you from?
Chicago, IL
Why are you taking AI?
Really interested in the topic of Artificial Intelligence, I've read some materials about it and excited for the class.
What other OMS/GT CS courses have you taken?
SDP, KBAI, AI4R, DVA
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I like to sketch in my spare time.
What is something interesting about you?
I was born and raised in UAE.', u'responses': [u'Hello Ismail, Welcome to AI!
You seem to have done a couple of courses in this field, that's good! 
We hope to further add to your understanding of AI through our course. 
Good luck!']}, {u'text': u'What is your name?
Jacob Dahleen
Where do you live? (or) Where are you from?
Elk Grove Village, IL
Why are you taking AI?
I don't have prior experience with AI and am still uncertain of the specialization I would like to pursue. AI seems central to 2 of the 4 and seemed like an interesting class to take if it ends up being and elective.
What other OMS/GT CS courses have you taken?
HPC
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work as an embedded software engineer designing and building custom hardware emulators. Between work and school, not much free time. I try to exercise when I can .
What is something interesting about you?
I was a collegiate rower in undergrad.', u'responses': [u'Welcome to AI Jacob!We hope we can make AI more interesting for you to pursue it ahead. The applications of AI are increasing in different domains and we hope you can link it up with your past experiences after he course. Good luck!']}, {u'text': u'What is your name?
Bernadette Bucher
Where do you live? (or) Where are you from?
Philadelphia, PA, USA
Why are you taking AI?
I am interested in intelligent robotics systems and specializing in Computational Perception and Robotics.
What other OMS/GT CS courses have you taken?
Operating Systems, Computer Vision, AI for Robotics, Computational Photography
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Career: signals and image processing, embedded software development for real time systems
Hobbies: hiking, running, playing piano, and reading
What is something interesting about you?
My longest hike so far was 8 days long in the Andes Mountains.', u'responses': [u'Welcome to AI Bernadette!We hope to supplement your knowledge of AI that you learned in your earlier class AI for Robotics. I hope that it was a good hike. :) ']}, {u'text': u'What is your name? - Ben NuttleWhere do you live? (or) Where are you from? - Detroit MI, though I frequently visit friends at GT (my girlfriend lives there)Why are you taking AI? - I work on AI systems for my career. Furthermore, I took the undergraduate AI course at Tech and really enjoyed it. I am looking forward to building on it as a foundation.What other OMS/GT CS courses have you taken? - CS6300 SDPWhat do you do when you're not working on classes? (Career, research, hobbies, etc.) - I work on autonomous vehicles for a tier-1 automotive supplier. We produce sensors and I get to play around with our demonstrator vehicles to showcase what we can do with data fusion and show off advanced functionality. In my spare time I try to stay active, training for races and playing various sports as well as lifting weights.What is something interesting about you? - There's a picture of me hanging in the third floor of the CoC at Georgia Tech. I regularly return to visit campus as I am an alum and get to recruit on behalf of my company. I ran the robotics team while I was in undergrad where we built robotic systems for a number of international competitions to represent GT.', u'responses': [u'Nice to meet you Ben! I also live in the Detroit area, feel free to reach out if you ever want to meet up.', u'Hi Ben, welcome to AI! It's so cool that you get to play around with autonomous cars. Hope you will enjoy the course and get the most out of it.']}, {u'text': u'What is your name?
Patrick Ho
Where do you live? (or) Where are you from?
Folsom, CA
Why are you taking AI?
Taking AI because interested in decision sciences, optimization, and predictive systems.

What other OMS/GT CS courses have you taken?
Computer Networks, Info. Sec., IOS
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Exercising, reading, snowboarding, playing with daughter, and playing tennis.  I also collect historical coins as a hobby.
What is something interesting about you?
I learned how to read music notes from the Internet and also drew inspiration by watching professionals play on YouTube.  Now, I can play a couple Chopin pieces and learning Fantasie Impromptu op 66.
', u'responses': [u'Wow! How long have you been learning? I consider Fantasie Impromptu to be my ultimate goal for playing piano, but the only Chopin piece I've attempted so far is Prelude in Em. ', u'Are you based out of Folsom? (wasn't sure if it was the answer to where you live or where you're from).  I'm currently based out of Folsom. Nice to have another classmate in the area!', u'@John - I've been learning the piano on and off for about 10 years now.  I've been learning Fantasie Impromptu for about a month. It's definitely a difficult piece. 

@Shubra - I moved to Folsom over the summer to take a job in the area.  I lived and worked in the east bay for a few years before heading to Folsom.  So far, I'm enjoying this area.  It's a quiet and nice place to raise a family.', u'Yes Fantasie Impromptu is hard. You've got the 3 against 4 polyrhythm. 

This young guy from Moscow is out of this world. Will be a Horowitz one day :)
', u'Hi Patrick, welcome to AI! I also tried to play Fantasie Impromptu op 66 but the first part was just too fast for me. Hope you will enjoy the course!']}, {u'text': u'What's your name?
Daniel Bernal 

Where do you live? (or) Where are you from?
Houston, Texas

Why are you taking AI?
I'm taking AI because I am also interested in video game development and AI techniques.

What other OMS/GT CS courses have you taken?
SAAD, SDP, ML, ML4T, DBS, Intro to OS, Health Informatics

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work full time as an IT Consultant.

What is something interesting about you?
I have a twin!', u'responses': [u'Is your twin brother also working/interested in IT field? Just curious.', u'He does! Although it was not initially his interest, he's a writer who works IT to pay the bills. :)', u'Hi Daniel, welcome to AI! Looks like you are already 2/3 through the program. It's very hard for me to imagine how it feels to have a twin. Hope you will enjoy the course!']}, {u'text': u'What is your name?
Sandy Davis
Where do you live? (or) Where are you from?
Herndon, VA (DC suburb)
Why are you taking AI?
I've always wanted to take a broad-ranging AI course. Really looking forward to implementing some of the concepts I've learned about in other classes. 
What other OMS/GT CS courses have you taken?
SDP, KBAI, EdTech, ML4T
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Most of my time is spent with my 3 kids, I am a stay-at-home mom right now. I also teach a NASA sponsored high school course online and have done some TAing for EdTech. Prior to kids I did software consulting and then taught high school math and CS for over 10 years. 
What is something interesting about you?
I can neither whistle nor snap my fingers. Countless people have tried to teach me but I simply can't figure it out.  ', u'responses': [u'Hi Sandy! I'm in Fairfax and work in Reston! ', u'Hi Sandy, welcome to AI! I can't whistle neither, no matter how hard I tried. Maybe we are just not gifted with the talent to do it. I also lived in Northern Virginia before moving to Atlanta for school. Hope you will enjoy the course. :)']}, {u'text': u'What is your name?Mengru LIWhere do you live? (or) Where are you from?Framingham, MAWhy are you taking AI?I am just interested in the modelings and algorithms that make machine intelligent and interactive and I also want to transfer my career to developing intelligent and interactive software applications.What other OMS/GT CS courses have you taken?Introduction to Operating SystemsWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)I work as software engineer now. But my work is primarily on enterprise application development, which is not quite fun.What is something interesting about you?I have a Japanese Akita, who is suck picky eater and I am trying my best to explore the food she loves.', u'responses': [u'Hi Mengru, Welcome to AI!
We hope we can make this an interesting course for you to pursue AI in the future. 
Good luck!']}, {u'text': u'What is your name? Chris ShafferWhere do you live? (or) Where are you from? Currently I live in Grand Rapids, Michigan, but I spent a number of years in Texas growing up (My dad was in the Air Force)Why are you taking AI? Specialization requirement of course - But also seems like AI (and somewhat related ML) is something that can be useful in a very large number of situations, I'd like to have an understanding of it so I can start to turn to it when I encounter those situations.What other OMS/GT CS courses have you taken? AOS, SAAD, CP, CVWhat do you do when you're not working on classes? (Career, research, hobbies, etc.) I'm a software developer at a small consultancy in Grand Rapids (CQL, Inc.) and I love learning new things and spending time with my wife and son (aka, re-experience childhood :) ).  If time is available, I also like to run and play chess.What is something interesting about you? I hope to run a marathon this year!', u'responses': [u'Welcome to AI! This course is great for getting a good understanding of the field of AI in general, and you'll get a chance to implement many of the algorithms that you learn about. Hope you enjoy the class and good luck on the marathon.']}, {u'text': u'What is your name?Adam PerettiWhere do you live? (or) Where are you from?North of Seattle in Everett, WA. I'm from the Washington area.Why are you taking AI?Looking to better interpret large sets of data, and act on those interpretations. I work for a utility and we're currently undergoing a reliability study. I would love to use what I learn here to optimize restoration times for our customers.What other OMS/GT CS courses have you taken?I've Database Design, Software Dev, Comp. Photography, HCI, Intro to Info Security, and KBAIWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)I'm an electrical engineer for a power utility in north washington.What is something interesting about you?I'm diving into the world of automatic trading and using social media to help form portfolios.', u'responses': [u'Hi Adam, Welcome to the course!
I hope the course contents help you in your study and make it interesting for you to pursue it further. 
In spite of being an Electrical Engineer, you have a good CS background! Hope that helps in this course. 
Good luck!']}, {u'text': u'What's your name?Nick SalerniWhere do you live? (or) Where are you from?Toronto, CanadaWhy are you taking AI?I am really excited to take this class as it’s one further step in learning about the topic I’m passionate about and that I currently work in. It will be really nice to get some more course projects under my belt!What other OMS/GT CS courses have you taken?DVA, Network Security, ML, RL, Computational Photography, KBAI, ML4T. What do you do when you're not working on classes? (Career, research, hobbies, etc.)I’m currently working as a software engineer at Amazon making everyone’s favourite assistant, Alexa, a lot smarter :)What is something interesting about you?I’ve been playing tennis since I was 4 and made it to a national ranking of the top 100. ', u'responses': [u'HI Nick,

Welcome to AI class! We hope that the things you learn in this course make Alexa even more fun to use! Top 100 national ranking in Tennis!! Kudos!

Good luck!']}, {u'text': u'Hi all... My so interesting info:

What is your name?
Chris Nolan

Where do you live? (or) Where are you from?
Raleigh, NC. A little bit of all over, but mostly Southeast US.

Why are you taking AI?
AI was my main focus in undergrad and a part of the work I do for my day job. Looking forward to the chance of getting a little more in-depth understanding and focus on it.

What other OMS/GT CS courses have you taken?
I've taken KBAI, AI for Robotics, Computational Photography, and SDE.

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
My day job is as a Software Engineer for IBM, working as an Algorithm Developer, and primarily focused on Information Retrieval. I also teach at a little club doing Historical Fencing which is pretty fun and my main hobby.

What is something interesting about you?
I'm an Iraq vet.', u'responses': [u'Hi Chris, Welcome to AI

Any chance you related to Nolan brothers? Jk. Looks like you have a lot of experience in Info Retrieval and this course definitely tackles some aspects of it. One of the Thad's best student is also ex-vet and he just finished his Ph.D. here at tech under Thad's supervision. 

Good luck!', u'Thanks. Yeah, I have a project coming up for work focused on applying HMMs to information retrieval and passage extraction of documents. Definitely looking forward to that section of the class and hoping it'll help with that work project.

And yeah, directing movies is my side job I do in my spare time, haha...']}, {u'text': u'What is your name?
Kai Ming, Choi
Where do you live? (or) Where are you from?
I'm from Hong Kong :)
Why are you taking AI?
I love AI & ML! And I do data science at work.
What other OMS/GT CS courses have you taken?
ML, AI4R, Computational Photography, Introduction to Information Security, SDP, DB Concepts & Design
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I'm working in a teleco, and I enjoy working interesting projects/assignments http://mingc.me/ 
What is something interesting about you?
I sleep a lot.', u'responses': [u'Hi Ming,

Welcome to AI! A lot of cool and AI related stuff on your site. I can't imagine how you manage to do that while sleeping a lot, haha. I guess I should sleep more too. In all seriousness, this course will definitely broaden you AI skill set and we look forward to interacting with you more. Good luck!']}, {u'text': u'Hello class,
My name is Brett Fincher, and Fort Worth, Texas, is where I call home. I'm married with three kids, all girls, ages 17, 5, and 1. I'm taking AI because I've always been interested in designing and developing software systems that enhance and enrich our lives. I believe that AI is a powerful tool that, despite all the fear-mongering surrounding it, can advance humanity for the better. Under OMSCS, I've taken Computational Photography, High-Performance Computer Architecture, Knowledge-Based AI, Software Development Process, Database System Concepts and Design, and Machine Learning for Trading. When I'm not studying at home, I'm spending time with my family or playing PC games, like Eve Online, Overwatch, or Divinity Original Sin 2. When I'm not at home, I'm working as an applications developer for an Internet advertising company. One interesting thing about me is that I'm a retired US Air Force Master Sergeant. I served 20 years, and in that time I traveled all over Europe, deployed to Iraq, and lived in places from coast to coast across the United States.', u'responses': [u'Wow man, You have done all this in one lifetime! First, kudos for juggling work and family and second, I just want to be as cool as you when I am as old as you are. High five for Overwatch!!
Looks like you have already taken a lot of courses and have experience with OMSCS and we hope you like what this course has to offer! Good luck!', u'Thanks for the kind words Sumeet!']}, {u'text': u'What is your name?
Parth Gaggar
Where do you live? (or) Where are you from?
Bengaluru, India
Why are you taking AI?
I took KBAI last fall and it has really made me excited about AI. I hope to learn about some of the algorithms that are used by AIs.
What other OMS/GT CS courses have you taken?
KBAI 
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I have a full time job which takes up a significant amount of my time, and also i enjoy watching movies and TV shows. I try to exercise, but haven't been much consistent :)
What is something interesting about you?
I have a good sense of humor. Just kidding!', u'responses': [u'', u'Hi Parth, 

Welcome to the AI course! Juggling between work and class can be taxing sometimes. A lot of previous working students have successfully completed this course and have used the principles taught in this class to implement some module in there work. 

Good luck!']}, {u'text': u'Hi everyone! Excited to be in this course. Here is my info:

I live in Santa Fe, NM. I recently moved here from Chicago.

I'm taking AI because I'd like to understand better some of that ""magic"" behind the implementations of this technology in our lives, and eventually apply it to my own projects.

This is my 2nd semester. The first semester I took Computer Networks.

Besides classes right now I work full time, I'm getting to know my new city, and trying to be semi-social (which is not my first inclination)

Something interesting: I recently started working at this company called Meow Wolf and I'm loving it. If you ever find yourself in Santa Fe, stop on by and check it out! https://meowwolf.com/

My linkedin: I'm down to connect with anybody from class: https://www.linkedin.com/in/brianduverneay/', u'responses': [u'Hi Brian, 

Welcome to the course and we are as excited as you are to make this course fun for you! I checked out the website for Meow Wolf and have to say, some pretty cool stuff going down there. One of my personal goal is to travel to NM before I graduate and would definitely stop by meowwolf if I make it. This class definitely reveals a lot of ""magic"" happening in the tech you see around. 

Good luck!', u'Thanks Sumeet and thanks for checking out the Meow Wolf site! Yes, come visit NM - I think it is a really unique state. Looking forward to the class :)']}, {u'text': u'What is your name?
Fangming Du
Where do you live? (or) Where are you from?
Bay area, CA US (just moved here this year)
Why are you taking AI?
I'm very interested in this topic and want to see the power of AI.
What other OMS/GT CS courses have you taken?
DB, Intro to Info Security,  HCI
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I have a full time job and 2 year old daughter :)
What is something interesting about you?
 I like watching movies', u'responses': [u'Hi Fangming, welcome to AI. Hope you can enjoy this course and maybe even teach some of what you learn to your daughter. Have fun!']}, {u'text': u'What is your name?
Peter Nicholson
Where do you live? (or) Where are you from?
Randolph, MA (almost Boston)
Why are you taking AI?
AI is where my ""passion"" is in computer science, especially when paired with robotics.
What other OMS/GT CS courses have you taken?
Advanced OS
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work full time, rock climb, and love to play board games.
What is something interesting about you?
I tend to do things the hard way.  I learned how to drive stick in Boston suburb rush hour.', u'responses': [u'Hey, cousin!  I've seen your name floating around the fora and Slack.(Just kidding, but you never know.  I've been doing amateur genealogy for a while and my own surname is my biggest brick wall - can't get past my great-grandfather.  Let me know if you ever do genealogy or DNA testing.)By the way, six of us played Twilight Imperium 4 last Saturday.', u'Hi Peter, welcome to AI. HW1 is about board game, hope you will enjoy working on it.']}, {u'text': u'Hi All,

What is your name?
Harmeet Bindra

Where do you live? (or) Where are you from?
I live in Suwanee, Georgia

Why are you taking AI?
AI is interesting 

What other OMS/GT CS courses have you taken?
This is my second semester in this program and I took Machine Learning for Trading and Introduction to information security last semester.

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work as a Software Developer at AT&T and I like working out and playing ping pong in my free time.

What is something interesting about you?
I learned how to swim by diving inside a 12ft swimming pool. ', u'responses': [u'Hello Harmeet! Welcome to AI! I hope this class provides you with a pool slightly less than 12 feet deep to dive into :)', u'haha. Thank you! Looking forward to it :)']}, {u'text': u'What is your name?     Rajesh ShettyWhere do you live? (or) Where are you from?  San Jose, CaliforniaWhy are you taking AI?  - AI is the reason I got into OMSCS. I believe, AI is going to change the way we work, live and play.What other OMS/GT CS courses have you taken?  KBAI, SDPWhat do you do when you're not working on classes? Software Engineering Manager in a networking company. Love spending time with my family and run half marathons when I get time.What is something interesting about you? ""something interesting"" :-) 
', u'responses': [u'Welcome to AI, Rajesh! I took KBAI last semester. What did you think about it?', u'Hello Rajesh,

Welcome to AI! Indeed AI is going to change the way we work, I would say it is already changing the way we work, live and play! 

Good luck with the course!', u'thanks Sumeet. Agree.

Noah, I quite liked the KBAI course. Unlike ML/DL, It provided a different perspective into AI from a knowledge based view. What did you think?

Look forward to working with you guys and the rest of the teaching team.', u'Hi Rajesh - I live in San Ramon and work in Sunnyvale. I am taking AI this semister. May be we can catch up sometime to exchange ideas. If you are interested, please send me a note Sehanuma@gmail.com']}, {u'text': u'Good evening!

What is your name?
Paul Morris

Where do you live? (or) Where are you from?
The greater Seattle area

Why are you taking AI?
I'm interested in learning algorithms. I like to automate things to get real work done. I believe in addition to getting me closer to graduating, I will learn a lot in this course and be able to apply it to projects I am working on.


What other OMS/GT CS courses have you taken?
ML4T

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Currently, work in aerospace but am looking to branch out. I have a background in lean and love to automate tasks. In my spare time, I learn new things (OMSCS), build gadgets (arduino), and spend time with my family. 

What is something interesting about you?
I machined copper yard lamps for a Christmas present. 

Feel free to add me on LinkedIn:
https://www.linkedin.com/in/morrispj/', u'responses': [u'Welcome to AI, Paul! Are you into home automation- if so, what kind of stuff have you done? Do you have any of your work hosted anywhere?', u'Hi Paul,

Thank you for enrolling and welcome to AI! I like to automate things too! It is just a pure pleasure to see a machine making perfect coffee for you! We hope you learn a lot from this course and make cool stuff to solve real-world problems.

Good Luck!']}, {u'text': u'What is your name?
Sudip Kafle
 
Where do you live? (or) Where are you from?
Kathmandu, Nepal
 
Why are you taking AI?
I am interested in algorithms and plan to specialize in ML.

 
What other OMS/GT CS courses have you taken?
KBAI, ML4t, DVA, Infosec, ML
 
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I am working as a remote full-stack developer. I love to travel and go for hiking.
 
What is something interesting about you?
I am the only vegetarian in my family. I have been following this diet since I was 3 years old and I don't know why I chose to be vegetarian at that age.', u'responses': [u'Hi Sudip,

Welcome to AI! I am the only non-vegetarian in my family, Don't worry, you don't need chicken to succeed in this class.

Good luck!', u':) ']}, {u'text': u'What is your name? 
Shubra Marwaha

Where do you live? 
Sacramento, CA

Why are you taking AI?
Think AI's the future. Took ML last semester and I'm developing a gradual liking for Algorithms, so figured this would be a great course to continue building on that.

What other OMS/GT CS courses have you taken?
ML, ML4T, CV and GIOS

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I am currently working as a Graphics Hardware Designer (How abt 'em pesky Intel hardware bugs in the news lately?) 
In my spare time, I like reading, exploring new music, plotting grand travel adventures and creating to-do lists that I will never get around too.

What is something interesting about you?
Grew up in Zambia. Currently on my third continent.', u'responses': [u'Hey Shubra,
We sure hope we can make this course interesting for you too!
I imagine you've seen quite a lot being on 3 continents - which one's your favourite?
We look forward to working with you :)']}, {u'text': u'Where do you live? (or) Where are you from?
I live in Melbourne Australia but I was born and grew up in Singapore
 
Why are you taking AI?
I'm interested in the topic, and thought a survey course would be fun.
 
What other OMS/GT CS courses have you taken?
ML, AI4R
 
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work in asset management and have a 4yo son. I am also active in the local ML/AI Meetup group.

What is something interesting about you?
I used to drive a tank for the Singapore Army.
', u'responses': [u'Hey Jonathan,
We sure hope we can make this course interesting for you :)And to me, this fact seems to be the most interesting - an actual tank driver? That's awesome!']}, {u'text': u'What is your name?Graeme McCrodanWhere do you live? (or) Where are you from?Vancouver, British Columbia, CanadaWhy are you taking AI?It's an interesting complement to the ML specialization which I am pursuing, and is a fascinating field of study.What other OMS/GT CS courses have you taken?ML, RL, ML4T, SDP, DVAWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)I work in quantitative investment management, like to hike, camp and play the odd video gameWhat is something interesting about you?Interestingly, I'm 30 and I struggle to answer this question.', u'responses': [u'Which firm are you with? I do quant equities myself.', u'CC&L Investment Management - ""boutique"" Canadian co.', u'I'm doing ML spec too. ', u'Cool, who are you with?', u'Hey Graeme,
Some would say quantitative investment management is interesting in itself :)
You seem to have taken quite a few courses within the realm of ML - we hope we're able to provide you with some insight you don't have already.
Welcome to the course!', u'Thanks Ravikiran. It can be very interesting! And judging by the syllabus (and the size of the textbook!), I'm certain this course will be valuable! There's always more to learn.']}, {u'text': u'What is your name?
William Wu
 
Where do you live? (or) Where are you from?
San Francisco, CA
 
Why are you taking AI?
I'm taking AI because I've always wanted to learn how we can program ""intelligence"". I believe in the (near) future computers will be learning and expressing emotions just like humans. I found watching OpenAI develop an AI bot defeat a human in DOTA 2 by using psychological techniques such as bluffing and feigning weakness very inspirational and shows how far AI has grown in the past decade. 

What other OMS/GT CS courses have you taken?
Software Architecture & Design, KBAI, Computational Photography, Databases, HCI
 
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Currently working full time as a software engineer at Uber. Love to play board games and go on motorcycle rides. 
 
What is something interesting about you?
Was born and raised in Germany', u'responses': [u'Hi William, Welcome to AI!
AI is developing at a fast pace these days and we see many applications as you mentioned. If you are interested in AI models in Games you might want to look at the Game AI course (CS7632) offered at Georgia Tech. 
Good luck!']}, {u'text': u'What is your name?

Omar Ramos

Where do you live? (or) Where are you from?

I live in El Centro, CA (about two hours East of San Diego...it's a more rural / agricultural community close to the Mexican border).

Why are you taking AI?

I'm definitely interested in AI and Machine Learning and would like to learn the fundamentals of both this semester and build on those skills so I can be comfortable applying those techniques in the future. 

What other OMS/GT CS courses have you taken?

I've taken quite a few of them but also had to withdraw from a number of them as well. So far I've completed:
CS 6035 Introduction to Information SecurityCS 6250 Computer NetworksCS 6300 Software Development Process CS 6400 Database Systems Concepts and DesignCS 6460 Educational Technology

But I've also tried taking these courses (in Spring 2017):
CSE 6242 Data and Visual AnalyticsCS 6475 Computational Photography (I had also tried taking this one in Spring 2016 too)CS 7646 Machine Learning for Trading

I took an extended break after needing to withdraw from my classes last Spring so I'm hoping starting up again with AI and the ML course this semester will better prepare me to do well in the Machine Learning related classes I tried to take last Spring.

What do you do when you're not working on classes? (Career, research, hobbies, etc.)

My job definitely does a decent job of occupying my time, and even without taking any classes I generally feel like I don't have enough free time to work on extra side projects, but generally it's either spent with my wife and kids or my family in some way :-).

What is something interesting about you?

Nowadays, (after just turning 30 last year and being a general workaholic sort of guy) it can be difficult to come up with recent things that make me feel interesting, but one thing from a long time ago was that I went to Okinawa, Japan when I was 12 to compete in a tournament and while I don't remember much anymore I left karate as a 2nd degree black belt when I was in high school (my mini dad belly is now encouraging thoughts for me to start going back to karate so I can work it off :-). Maybe once I'm done with the OMSCS program ;-).

Looking forward to the class and crossing my fingers I will have enough time and concentration this semester to do well in both AI and ML!
', u'responses': [u'Hi Omar! Welcome back, and welcome to AI! I'm also in ML this semester- Isbell is a pretty great guy ruthless dictator and I'm sure you'll find ML to be quite a fun class this class to be far superior, glory be to Starner.', u'Hi Omar,

Welcome to AI! With so many courses under your belly, I am sure you will excel this course too! Don't worry about the dad belly, AI will give you abs by the time you are done with the course! Then you can karate your way into work! On a serious note, I would encourage you to help students who are new to Piazza given your experience.

Have fun with the course and good luck!']}, {u'text': u'What is your name? 
Sijia Zhang

Where do you live? (or) Where are you from?
San Francisco, CA

Why are you taking AI?
I'm very interested in AI and machine learning. I would like to learn more about it and use the skills I gain here at work

What other OMS/GT CS courses have you taken?
Machine learning; machine learning for trading; big data for healthcare; computer photography; data and visual analytics; educational technology; computability, complexity & algorithms

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
perform science research and exercise

What is something interesting about you?
being creative with my healthy smoothie recipes ', u'responses': [u'Welcome to AI, Sijia!

What kind of scientific research are you doing?', u'Hi Noah, I do biomedical research. My current project involves using ML to perform phenotypic profiling on cells. ']}, {u'text': u'Hello everyone!
What is your name? John Fenske
Where do you live? (or) Where are you from?
Springfield, Missouri, US
Why are you taking AI?Ray Kurzweil tells us that the Singularity is coming whether or not we want it to, so I figure if I'm on this side of it, our eventual robot overlords may take pity on me.On a more serious note though, I find the field fascinating and think it has plenty of room for growth still. I am looking forward to a broad introduction to the topic.
What other OMS/GT CS courses have you taken?IHPC last semester
What do you do when you're not working on classes? (Career, research, hobbies, etc.)I work as a System Engineer for O'Reilly Auto Parts. In my shrinking spare time, I enjoy playing piano, watching and playing tennis with my wife, watching Star Trek, playing video games and tinkering with electronics with my 5 year old son.
What is something interesting about you?I have a published app that I like to come up with big ideas for and rarely get around to implementing. Maybe this class will help provide me with more motivation to work on it!https://play.google.com/store/apps/details?id=com.brunchware.android.eightbitlivewallpaper', u'responses': [u'Hi John,
I think the course covers a lot of topics in AI so hope you get the broad introduction that you are looking for. Also the app was really nice, with simple, clean UI. Hope we get to see more cool apps in the future! ']}, {u'text': u'What is your name?
Stanton Lee
Where do you live?
Kathleen, GA (about 2 hours south of Atlanta)

Why are you taking AI?
It is one of the required courses for the Interactive Intelligence specialization and it sounds more interesting than Machine Learning.
What other OMS/GT CS courses have you taken?
CS 6300 Software Development ProcessCS 6440 Intro to Health InformaticsCS 6310 Software Architecture and DesignCS 6250 Computer NetworksCS 6475 Computational PhotographyCS 8803 Special Topics: Graduate Introduction to Operating SystemsCS 8803 AI in RoboticsCS 6035 Introduction to Information SecurityCS 6340 Software Analysis and TestingCS 6505 Computability, Algorithms, and Complexity (I can't seem to get a B in this class so I am trying something new)
I am also taking CS 7637 Knowledge-Based AI this semester.
What do you do when you're not working on classes?I am a software engineer.I like to hunt and fish (though I rarely have time for it now).
What is something interesting about you?
I worked in textiles for 14 years before deciding to pursue a career as a Software Engineer.', u'responses': [u'Hey Stanton,
You've made the right decision: Shun the Dictatorship that is Machine Learning. Glory be to Starneria.
(We have this little friendly rivalry thing going)
How did the change in careers happen?
We look forward to working with you!']}, {u'text': u'What is your name?Dominic Follett-SmithWhere do you live? (or) Where are you from?Cape Town South Africa for the time being.Why are you taking AI?Was recommended by an OMSCS friend.What other OMS/GT CS courses have you taken?Intro to OS, KBAI and AI4RWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)I work full time and read voraciously.What is something interesting about you?I'm kinda obsessed with high-quality Chinese tea.', u'responses': [u'Hey Dominic,
What would you say is the most interesting book you've read recently? We hope you find Russell & Norvig interesting :D
We look forward to working with you!', u'Just finished:  Lincoln In The Bardo, the Man Booker for 2017 which I strongly recommend. Concurrently reading: 'Algorithms To Live By', 'Philosophy of Mind: A Contemporary Introduction', 'Buddhist Romanticism', and 'AI A Modern Approach' (20%) ;)If I don't continue this semester, I look forward to seeing you all in Fall or Winter :) - thank you for your help earlier!']}, {u'text': u'
What is your name?
Thuan Vo
Where do you live? (or) Where are you from?
Fremont, California (East Bay / San Francisco Bay Area)
Why are you taking AI?
It sounds interesting to me, and I want to know what actual AI is.
What other OMS/GT CS courses have you taken?
I took KBAI and DVA
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Watching movies either at home or movie theater (prefer AMC), playing soccer, Crypto Currencies, PluralSight.
What is something interesting about you?
Hmmm, I’m a boring person, but like to make friend with people. Also, I usually fly back and forth between North and South California for work and family.
', u'responses': [u'Hi Thuan, welcome to AI! Can you give me some dirt on crypto currencies? I've been casually using coinbase recently but don't feel like I'm really getting into it. What are your long term thoughts?']}, {u'text': u'What's your name?
Kuan Chao

Where do you live? (or) Where are you from?
Fremont, California (East Bay / San Francisco Bay Area)
 
Why are you taking AI?
I'm very interested in AI and machine learning. I would like to learn more about it and use the skills I gain here at work

What other OMS/GT CS courses have you taken?
Machine learning; machine learning for trading; data and visual analytics; complexity & algorithms
 
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Tutoring, Trading

What is something interesting about you?
I like math and math-related computer science classes.', u'responses': [u'Hello Kuan, and welcome to AI! What do you tutor for?']}, {u'text': u'What's your name?
Eftychios Eftychiou
Where do you live? (or) Where are you from?
Currently living in Brussels, originally from Cyprus and born in South Africa
Why are you taking AI?
Needed for my specialization and out of genuine interest in the field
What other OMS/GT CS courses have you taken?
AI4R, ML4T, CV, CP, DVA, SDP, CN,SEC
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Air Transport Attache in the Permanent Representation of Cyprus to the EU
What is something interesting about you?
One would think that my present career has no relevance to CS but from my experience our lives are more and more intertwined with technology and having a solid understanding of the basics allows me to make sound policy recommendations. ', u'responses': [u'Hello Eftychios, and welcome to AI!

""from my experience our lives are more and more intertwined with technology and having a solid understanding of the basics allows me to make sound policy recommendations."" That is so encouraging to hear. I'm so glad people outside of CS understand the importance!']}, {u'text': u'What is your name?
Saalis Umer

Where do you live? (or) Where are you from?
New Delhi, India

Why are you taking AI?
To gain more insights into ML and AI. Want to pursue this field as my career.

What other OMS/GT CS courses have you taken?
ML4T

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Make iOS Apps

What is something interesting about you?
Programming enthusiast, travel lover, married, going to be a father in 2 months', u'responses': [u'Welcome to AI, Saalis!

Any personal iOS apps you want to share with us?', u'I have worked on a bunch of different apps. Last few apps I worked upon:
Inshorts and HomeShop18.

Also last night, I completed the undefeatable 3X3 TicTacToe app with Minimax algo. https://github.com/saalisumer/TicTacToeWill work on extending it to more than 3 size, and using alpha beta pruning to better the performance', u'Did you try Apple's Swift yet. I think you might like it.
I am also a part time iOS developer for my bicycle club. However I've switched now from Objective-C for that app to Swift', u'Yes, I have been working in Swift as well. Swift is cool. But actually I started working on TicTacToe on Objective-c 2 years back. Only now when I studied min-max algo, computer moves become unbeatable.']}, {u'text': u'What is your name?Sachin Garg

Where do you live? (or) Where are you from?New Delhi, India

Why are you taking AI?To learn the concepts of Artificial Intelligence and incorporate the same in my future ventures.

What other OMS/GT CS courses have you taken?ML4T (in Spring 18)KBAI, HPC (in Fall 17)

What do you do when you're not working on classes? (Career, research, hobbies, etc.)I currently work as a Software Development Manager at Times Internet Limited. In my free time, I like to play badminton and cricket.

What is something interesting about you?I've co-founded an NGO (Helpiez) and also developed an app (wisslr) for my undergraduate college.

Everyone is welcome to connect me on LinkedIn: https://www.linkedin.com/in/sachinjnd', u'responses': [u'Hi Sachin, and welcome to AI! How cool of you to start an NGO. How was that experience?']}, {u'text': u'What is your name?  Michael TehranianWhere do you live? (or) Where are you from?  Saratoga, CAWhy are you taking AI?  I like the topics of game playing and planning in an uncertain environment  What other OMS/GT CS courses have you taken?  Computational Photography, AI for Robotics, Computer Vision, and Machine Learning.What do you do when you're not working on classes? (Career, research, hobbies, etc.)  In my free time I like to play the guitar, bike riding, learning Japanese, and playing video games.What is something interesting about you?  I recently spent three weeks in Japan for the holidays/new years and I loved it there. I can't wait to go back this summer!', u'responses': [u'Hi Michale, and welcome to AI!

I've been considering taking the AI for robotics course myself. What was your opinion on it?']}, {u'text': u'What is your name? Sudharshan Nagumallu NatarajanWhere do you live? (or) Where are you from? Secaucus, New JerseyWhy are you taking AI? AI is applied almost in all new Softwares, I like to learn to keep myself ready for new challengesWhat other OMS/GT CS courses have you taken? 'Computability, Complexity, and Algorithms' and 'Software Architecture and Design'What do you do when you're not working on classes? (Career, research, hobbies, etc.) Lead Engineer at Grubhub.comWhat is something interesting about you? Interested in politics, treaking', u'responses': [u'Hey Sudharshan,
Looks like it's still early in the program for you - hope we can make this course interesting! Welcome!
And yes, we like to think this course gets you prepared to tackle some real-world problems - hope we can live up to it :)']}, {u'text': u'What is your name? Jason SeeleyWhere do you live? (or) Where are you from? Live in Brooklyn, born in Missouri (US).Why are you taking AI? Who wouldn't want to take AI right now?What other OMS/GT CS courses have you taken? KBAI, IOSWhat do you do when you're not working on classes? Software Dev.What is something interesting about you? I'm playing with 3D printing right now, very fun--not sure its quite ready for prime time.', u'responses': [u'""Who wouldn't want to take AI right now?""
Indeed! We hope we're able to give you the insights you seek in this course :)
Welcome, Jason! Looking forward to working with you.']}, {u'text': u'What is your name?
Josh Wycuff
Where do you live? (or) Where are you from?
I live in Atlanta, Georgia (US). I am from Chattanooga, Tennessee (US).
Why are you taking AI?
AI is an interesting topic that is relevant to my career interests.
What other OMS/GT CS courses have you taken?
KBAI, Software Architecture & Design
What do you do when you're not working on classes?
I'm an Analytics Engineer working for GE.
What is something interesting about you?
My wife and I enjoy rock climbing.
', u'responses': [u'Hey Josh!

Looks like we hail from the same town. I live by Hamilton Place. It's a small world.

Good luck!', u'Hey Josh,
My roommates enjoy rock climbing too - I mentioned earlier in this thread that I've always wanted to give it a shot, but my fear of heights doesn't really let me get too far :)
Hope we can make this course interesting for you - looking forward to it! Welcome!']}, {u'text': u'
Frank HinekAtlanta, Georgia, USAI've been interested in cognitive science, computer science, and behavioral science for many years, and studying Artificial Intelligence is a fascinating intersection of these domains of knowledge.KBAISpending time with my family, contributing to open source projects, and when I can find the time, woodworking and practicing guitar.Although I call the USA home today, I was born and lived for the first two decades of my life near Panama City in the Republic of Panama.
', u'responses': [u'Hi Frank. It is nice to see you in this course as well! This past semester, I was in KBAI with you.', u'Hey Frank,
Welcome to the course :)
We hope this course lives up to your expectations - I know @Noah Bilgrien is very interested in cognitive science, and might share some interests with you!']}, {u'text': u'What is your name? Esther ParkWhere do you live? (or) Where are you from? Northern Virginia Why are you taking AI? I would like to learn concepts of AI What other OMS/GT CS courses have you taken? 6300, 6400, 6440What do you do when you're not working on classes? (Career, research, hobbies, etc.) BowlingWhat is something interesting about you? Love traveling around the world', u'responses': [u'Hi Esther! I live in Fairfax VA!', u'Hi Esther, welcome to AI! Hope you enjoy the class.']}, {u'text': u'What is your name?Wafa NakbiWhere do you live? (or) Where are you from?Alameda, CAWhy are you taking AI?I'm interested in ML and learning algorithms.What other OMS/GT CS courses have you taken?DVA, Database Systems Concepts and DesignWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)I play with my 2 year old sonWhat is something interesting about you?I love coding challenges', u'responses': [u'Hi Wafa,It's nice that you enjoy coding challenges and learning algorithms, I think you would really like working on the assignments then :) Hope we can make the course enjoyable for you and we look forward to working with you!']}, {u'text': u'
What is your name? Travis WardlowWhere do you live? (or) Where are you from? I currently live in Baltimore, Maryland but I am originally from New Jersey. Why are you taking AI? To learn a little about AI and for the Interactive Intelligence Specialization.What other OMS/GT CS courses have you taken? Computer Networks, Network Security, Intro to Information Security, Software Dev Process, Software Architecture and Design, and Intro to Health InformaticsWhat do you do when you're not working on classes? (Career, research, hobbies, etc.) I like skiing and watching soccer.What is something interesting about you?I am a certified scuba diver.', u'responses': [u'Hi Travis, and welcome to AI!

I'm also in interactive intelligence- in fact, I've put together an interactive intelligence seminar on campus for a few people. I can send you the reading list (once we figure out what it is, exactly) if you're interested. The first reading is quite a great overview of interactive intelligence, and I'm sure you'll like it: https://distill.pub/2017/aia/
']}, {u'text': u'
What is your name?  Sarah Peyda MooreWhere do you live? (or) Where are you from?  I live in Stockholm, Sweden.  I am originally from Atlanta, GeorgiaWhy are you taking AI?  I really like the topics of the course, and I regret not being able to finish in the SummerWhat other OMS/GT CS courses have you taken?  CN, SDP, CV, CP, KBAI, EduTech, HCI, AI for RoboticsWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)  I work as a patent attorney for a large international company, managing their patent portfolio.  I like to travel, and now I am exploring Europe.What is something interesting about you?  I used to live in Munich, Germany, and before that, I lived extensively in Tokyo, Japan.
', u'responses': [u'Hi Sarah, and welcome to AI! I've seen some interesting use cases of AI in law recently- any that really stand out to you?']}, {u'text': u'What is your name?  Pepper MillerWhere do you live? (or) Where are you from?  Brownsburg, IndianaWhy are you taking AI?  Because AI is awesome!What other OMS/GT CS courses have you taken?  KBAIWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)  I work at a small software company making data products. I have four young kids that take up most of my free time. Between semesters I try to cram in as much video game time as possible.What is something interesting about you?  I'm a huge Indianapolis Colts fan!
', u'responses': [u'Hi Pepper, welcome to AI.

What video games have you been playing lately? ', u'I just finished Steamworld Dig 2 for the Switch.  A solid metroidvania game!', u'Ah I've heard good things about that game. I have a Switch too but haven't had a chance to play many games on it after finishing Breath of the Wild.']}, {u'text': u'What is your name? JulieWhere do you live? (or) Where are you from? currently in Downtown Los Angeles. Originally from Manila, Philippines. Lived in Tokyo (6 years) and the Bay Area (1 year) in between. Why are you taking AI? It's a good complement to my ML specialization. I'm also very excited about the topics and the upcoming projects. What other OMS/GT CS courses have you taken? DBS, CN, ML, DVA, RL, ML4T, IOS, GA, CP (getting out soon!)What do you do when you're not working on classes? (Career, research, hobbies, etc.) I work as an Integrations Engineer at a Martech startup in Silicon Beach.  Whatever free time I have left goes into singing and stumbling through recitals. What is something interesting about you? Copping (and occasionally reselling) sneakers has been my other, other side hustle for about a year now.', u'responses': [u'Hi Julie,Glad you're excited about the upcoming projects! I had a lot of fun doing them and hope you do too. We look forward to working with you!']}, {u'text': u'What is your name? Edwin NavarroWhere do you live? (or) Where are you from? Live in San Francisco Bay AreaWhy are you taking AI? Have always been interested in thinking processes and have experimented with chess playing programs.What other OMS/GT CS courses have you taken? GIOS, CN, IIS, and NS. Currently taking HPCA.What do you do when you're not working on classes? (Career, research, hobbies, etc.) Multi-varied past career with long period as C developer. Play blues & rock guitar in a local group.What is something interesting about you? I took my one and only undergrad computer course in 1969. (think punchcards)', u'responses': [u'Hi Edwin,I guess I took AI for the same reason and ended up really liking the subject, hope you enjoy it as well. It is fascinating to think how a CS course would have been in 1969! Very interesting.']}, {u'text': u'What is your name? Janet ChoWhere do you live? (or) Where are you from? New York, NYWhy are you taking AI? This sounds like a great introduction class to learn about how to get started on AIWhat other OMS/GT CS courses have you taken? IIS and SAWhat do you do when you're not working on classes? (Career, research, hobbies, etc.) Software developer, like to run and skiWhat is something interesting about you? I like to plan travels to distant location for running and skiing', u'responses': [u'Welcome to AI Janet! Hope you get to ski a lot this winter - I'm a snowboarder myself so I look forward to winter every year.']}, {u'text': u'What is your name? Anthoney BrownWhere do you live? (or) Where are you from? Currently live in Savannah, GA. Originally from Thomson, GA.Why are you taking AI? I'm taking A.I. to develop a fundamental knowledge base of A.I. algorithms and best practices to implement them to solve various solutions. What other OMS/GT CS courses have you taken? SAAD, SDP, KBAIWhat do you do when you're not working on classes? (Career, research, hobbies, etc.) My hobbies are powerlifting, hanging out with my dog, and playing video games.What is something interesting about you? I will be getting married the first week of this class and taking my honeymoon the second week of class.', u'responses': [u'Hi Anthoney! Congratulations on your marriage and hope you have a great honeymoon. What an awesome way to start the semester.']}, {u'text': u'What is your name? William FleshmanWhere do you live? (or) Where are you from? Live in Columbia, Maryland from Lawton, OklahomaWhy are you taking AI? I love applying AI algorithms to problems.What other OMS/GT CS courses have you taken? 
Computer Vision, Machine Learning, Mach Learning for Trading, Reinforcement Learning, AI for Robotics, Data and Visual Analytics
What do you do when you're not working on classes? (Career, research, hobbies, etc.) I'm a Captain in the Army and father of two daughters. What is something interesting about you? I enjoy long range shooting. I developed a portable ballistics computer (on raspberry pi) with speech to command processing that adjusts a rifles scope via motors. So as environmental variables change (wind, temperature, distance to target, etc.) I could update the firing solution hands free.', u'responses': [u'Hi William, Welcome to AI Captain!
That is an interesting project. Can I know what further additions are you planning?
Hope we can add to your knowledge.
Goodluck!', u'I don't have any future plans for that particular project. I have thought about moving the ballistics engine to other platforms, but there are plenty already available for mobile. I would love to get my hands on a pair of Google Glass and put the project on there. For most practical applications (like hunting in bad weather or shooting at competitions) you can't have motors attached to your scope. But having a hands free way to see/update the firing solution so you don't have to take your face off the rifle would be super helpful. I can actually think of several military applications for the Glass platform. ', u'Prof @Thad Starner would be the perfect person to discuss this with if you are interested in moving this to Google Glass! Agreed, having a hands-free device would be the end goal of your project as it will be the most beneficial. 
Hope you can continue working on this to get to another cool working prototype! :)']}, {u'text': u'What is your name? Ivan RasnikWhere do you live? (or) Where are you from? Atlanta, originally from UruguayWhy are you taking AI? Everybody is doing it, right?What other OMS/GT CS courses have you taken? This is my last course, I have taken all core ones, plus IOS and IISWhat do you do when you're not working on classes? (Career, research, hobbies, etc.) I have a full time job and three kids under 9....What is something interesting about you? I've seen things you people wouldn't believe. Attack ships on fire off the shoulder of Orion. I watched C-beams glitter in the dark near the Tannhäuser Gate. All those moments will be lost in time, like tears in rain. ', u'responses': [u'Hi Ivan, welcome to AI! Wow it must be difficult to balance the workload with three kids. And I can see you're a Blade runner fan! Hope you enjoy your last OMSCS course :)']}, {u'text': u'1. What is your name? Michael Gilreath
2. Where do you live? (or) Where are you from? Atlanta GA
3. Why are you taking AI? To get an introduction to the topic and a general understanding of AI concepts
4. What other OMS/GT CS courses have you taken? Machine Learning for Trading, Software Development Process, Software Architecture and Design, Intro to Health Informatics, Introduction to Information Security, Network Security
5. What do you do when you're not working on classes? (Career, research, hobbies, etc.) I work full time as a software engineer
6. What is something interesting about you? I started my undergrad as a music major', u'responses': [u'Hi Michael,That's quite a transition from music to computer science! Hope the course helps you in getting a good introduction to AI, we look forward to working with you!']}, {u'text': u'What is your name? Agustin Mora
Where do you live? (or) Where are you from? Arlington, VA
Why are you taking AI? I'm fascinated by AI and ML. I want to take ML next and this course will help prepare me for that.
What other OMS/GT CS courses have you taken? Educational Technology
What do you do when you're not working on classes? (Career, research, hobbies, etc.) I'm a software engineer. I enjoy playing basketball and volleyball, going out with friends, and playing some video games.
What is something interesting about you? I've finished more than 50 Project Euler problems', u'responses': [u'Hi Agustin, I'm taking ML this semester too so I think that this course has prepped me for it quite a bit. And I love Euler problems too :) Hope you enjoy the course and have fun! How did you find the Edu Tech course?']}, {u'text': u'What is your name? Zhiwei QianWhere do you live? (or) Where are you from?  Houston TexasWhy are you taking AI? very interested in this subjectWhat other OMS/GT CS courses have you taken? SDP, ML4TWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)  I work as a geologist.What is something interesting about you? I enjoy cooking but hate to wash dishes. so whoever eat my food do the dishes (usually it would be my husband).', u'responses': [u'Hey Zhiwei,
I like that arrangement - it's sort of what I have at home too! I cook, roommates clean :)
@Thad Starner We have a geologist in the class!
Looking forward to working with you!']}, {u'text': u'What is your name? Hsin An HsuWhere do you live? San Jose, CAWhy are you taking AI? I want to understanding AI.What other OMS/GT CS courses have you taken? Database Systems Concepts & Design, Software Dev Process, Computer NetworkingWhat do you do when you're not working on classes? (Career, research, hobbies, etc.) Take care my baby and dog.What is something interesting about you? I just had a baby!', u'responses': [u'Hi Hsin, welcome to AI. Congratulations on your baby and hope you have a good semester.']}, {u'text': u'What is your name? Nick ZeleiWhere do you live? (or) Where are you from? Kansas City, MOWhy are you taking AI? Interested in AI and want to understand general AI concepts. What other OMS/GT CS courses have you taken? KBAI, Computer Networks, Graduate Operating Systems, and Machine Learning For TradingWhat do you do when you're not working on classes? (Career, research, hobbies, etc.) Software Engineer (work). Bicycle, video game, travel, guitarWhat is something interesting about you? I love to travel and see new places.', u'responses': [u'Hey Nick,
That's a pretty wide breadth of courses you've taken! 
You've definitely come to the right place for AI though. We try to make this course as good an introduction as possible. Hope we can live up to the expectations!
Looking forward to working with you :)']}, {u'text': u'What is your name?
Greg Tracy

Where do you live? (or) Where are you from?
I live in San Francisco, CA.

Why are you taking AI?
I’m interested in the topic and looking to get involved in the field.

What other OMS/GT CS courses have you taken?
Computer Networks

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I’m a software engineer at Apple.  Outside of work, I like to travel and exercise.

What is something interesting about you?
I lived in seven different places before starting college.', u'responses': [u'Hey Greg,
Moving can get pretty crazy. I lived in 10+ houses myself prior to starting college :)
Hope we can give you what you seek from this course - we like to think it's a great entry point to the field!
Welcome to the course!']}, {u'text': u'What is your name?
Avery Bub


Where do you live? (or) Where are you from?
Madison, WI


Why are you taking AI?
I am interested in the material, and I hope to learn some useful techniques that I can apply at work.


What other OMS/GT CS courses have you taken?
KBAI


What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work at an education tech company based in Irvine


What is something interesting about you?
I was an Econ major as an undergrad
', u'responses': [u'Hey a fellow Wisconsinite!  Good to see you!', u'Hi Avery, welcome to AI. Many people have been able to use in their work what we learn in this class. Hope you can do the same and enjoy the class.']}, {u'text': u'What is your name?
Jake Gilbert

Where do you live? (or) Where are you from?
Seattle Washington

Why are you taking AI?
I took KBAI and really like the subject

What other OMS/GT CS courses have you taken?
KBAI and DVA

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Mountain Biking, Snow Boarding, Traveling, Mining Crypto

What is something interesting about you?
I have only lived in Washington state.', u'responses': [u'Hi Jake, Welcome to AI!
We hope that this course can add to your knowledge in this field.
Good luck!']}, {u'text': u'What is your name?
Jianhua Huang 

Where do you live? (or) Where are you from?
Phoenix, AZ

Why are you taking AI?
I have learned the theory of ML in a lot of courses. It is time to write the algorithm by myself now. 
What other OMS/GT CS courses have you taken?
DVA (CS6242), ML (CS7641), ML4T (CS7642), DB (CS6400)

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
work, hiking, and camping

What is something interesting about you?
hmmm, I just found out that you can go snorkeling, even if you don't know how to swim', u'responses': [u'Hi Jianhua, Welcome to AI!
This course will introduce concepts and ask you to program them in the assignments.
If you are more interested in theory, ML for Theory is an interesting course that you could look at. 
Good luck!']}, {u'text': u'What is your name?Phuc PhamWhere do you live? (or) Where are you from?I'm from Viet Nam and has been living in California.Why are you taking AI?I want to get a master degree with a specialization in ML / AIWhat other OMS/GT CS courses have you taken?ML and KBAIWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)Full time job which is  QA Engineer and a 60 gallons discus tank to take care. Helping my wife to manage a family restaurant. What is something interesting about you?I also in Taekwondo class but haven't taken a test for a long time. The belt color is not important for me. :D ', u'responses': [u'Hi Phuc, welcome to AI!
It's nice that you enjoy Taekwondo, it must be a pretty good outlet after work :)
We hope you enjoy this class as well! ']}, {u'text': u'What is your name? Collin CampbellWhere do you live? Hendersonville, TennesseeWhy are you taking AI? It's an interesting topic which I can apply to my hobbies and work.What other OMS/GT CS courses have you taken? 6300, 6310, 6400, 6440, 6460, 7646, 7637What do you do when you're not working on classes? (Career, research, hobbies, etc.) Family time, fishing, and my job is in HR in a healthcare company helping to adopt technology.What is something interesting about you? I worked in the Olympic village at GT in 1996.', u'responses': [u'Hi Collin, I see that you've taken the Health Informatics course (6440) which I think might have been very useful for you. Hope you find this class interesting as well. And it's nice that you worked here in 1996, must have been a great atmosphere during the Olympics! ']}, {u'text': u'What is your name?
Melanie

Where do you live? (or) Where are you from?
Mountain View, CA

Why are you taking AI?
I'm interested!  I like algorithms and theory.

What other OMS/GT CS courses have you taken?
Software Architecture and Design, Databases, Information Security, Computer Networks

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I'm a scientific software engineer, working on research software for NASA.  I like knitting and travel and live music. I have two kids.

What is something interesting about you?
My academic background is mostly in Physics and Astronomy.', u'responses': [u'Hi Melanie, Welcome to AI!
This course may have more of a programming side than algorithms and theory and we hope to make it interesting for you. 
You seem to be building a strong background in CS.
Good luck!']}, {u'text': u'What is your name?David SchmidlinWhere do you live? (or) Where are you from?Hillsboro, OR ( about 30 minutes west of Portland )Why are you taking AI?I've always been interested in AI, especially Neural Networks, and want to explore that area of research more.What other OMS/GT CS courses have you taken?I took CS 6476 Computer Vision last term and my final project was to create a Conventional Neural Network (CNN) in TensorFlow for house sign detection in an image.  I would like to deepen that knowledge.What do you do when you're not working on classes? (Career, research, hobbies, etc.)Full time job as a .Net developer at a local large tech firm.What is something interesting about you?I have been studying Aikido for over 6 years now, I find its a great way to help reduce stress and silence my mind.  I enjoy learning, working on side project, PC games, board games and Roleplaying games such as DnD or Star Wars.  I like games :)', u'responses': [u'Hi David!Welcome to AI and we hope you enjoy the course! Since you like games, I think you should try the Game AI course next :) I took CS 6476 last semester and I really enjoyed it as well.']}, {u'text': u'Greetings Everyone,

What is your name?
My name is Chad William Long as you'll see here on piazza.

Where do you live? (or) Where are you from?
I live in Chattanooga, Tennessee, in the United States. 

Why are you taking AI?
I am taking AI as I have an interest in exploring this field as a potential area for a job in the future. 

What other OMS/GT CS courses have you taken?
I took CS 6250 - Computer Networks and CS 6340 - Software Analysis and Test in my first semester last fall.

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I am currently reading, exercising, spending time with friends and my girlfriend, and learning to be a disciple of Christ when I am not doing school work. My computer science background is not as strong as most people here so success for me takes many more more hours than normal for now.

What is something interesting about you?
I am planning to find a job in Japan after finishing this degree program.', u'responses': [u'Hello Chad! Welcome to CS6601!

I hope you enjoy this class and good luck on finding a job in Japan. ']}, {u'text': u'Hey, 
What is your name?Jarrod St. LouisWhere do you live? (or) Where are you from?Byron, GeorgiaWhy are you taking AI?I've always been mildly interested in this topic and hoping this class will enlighten me on what this field has to offer.What other OMS/GT CS courses have you taken?CS-6750 : Human-Computer InteractionCS-6035 : Intro To Info Security - O01CS-6340 : Software Analysis & TestingCS- 6300 : Software Development ProcessWhat do you do when you're not working on classes? (Career, research, hobbies, etc.)work...What is something interesting about you?I'm a soccer fan', u'responses': [u'What team do you support? I'm a United fan!', u'Hi Jarrod, welcome to AI!']}, {u'text': u'What is your name?
Josh Woo
Where do you live? (or) Where are you from?
Waterloo, Ontario, Canada
Why are you taking AI?
I find it fascinating and it's also the last required core course for my specialization.
What other OMS/GT CS courses have you taken?
SDP, KBAI, HI, CP, HCI, MLT, CN
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Working out, traveling (mostly for work). I work for PlayStation.
What is something interesting about you?
A lot of people think I'm Japanese or Korean when they meet me, but I'm neither and also can't speak either language.', u'responses': [u'Hi Josh, welcome to AI! Mind telling us a little bit of what you do for PlayStation?']}, {u'text': u'What is your name?
Enrique Gonzalez
Where do you live? (or) Where are you from?
I live in Charlotte, NC but I'm originally from El Salvador
Why are you taking AI?
I've always had a fascination with AI. I remember wanting to build virtual assistants when I first learned to program.
What other OMS/GT CS courses have you taken?
Knowledge-Based Artificial Intelligence, Artificial Intelligence for Robotics, Educational Technology, Software Development Process, Introduction to Operating Systems, Software Analysis and Test, Introduction to Health Informatics
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I'm a full-time dad of two and enjoy spending time with them. I'm also a software engineer by day, Pokemon trainer by night.
What is something interesting about you?
I enjoy playing squash and used to be on a dance crew a long time ago.', u'responses': [u'Hi Enrique, Welcome to AI!
I too had a similar fascination with AI when I was young. 
I hope this course helps your curiosity in AI to turn into more projects.
Good luck!']}, {u'text': u'What is your name?
Benjamin Bernhardt 

Where do you live? (or) Where are you from?
I currently live in Canton, GA, about 20-30 minutes south of Blue Ridge

Why are you taking AI?
I've always had an interest in AI, and I'd like to learn more. Plus, it's part of the spec I'm in

What other OMS/GT CS courses have you taken?
I've taken HPCA, SAAD, and SPD

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
My current job is developing web services for a lot of the smaller US ISPs (our largest customer is ~150k modems). At home, I read, play video games, and occasionally engage in StrongMan workouts with my family

What is something interesting about you?
I volunteer at the two largest Atlanta geek conventions (Momo and Dragon) and am rather noticeable as a kilted viking', u'responses': [u'Welcome to AI, Benjamin! I got to see the Dragon con parade last year, maybe I saw you in it.']}, {u'text': u'What is your name?
Erich Renken

Where do you live? (or) Where are you from?
Atlanta, GA

Why are you taking AI?
Interesting subject matter and it's a required course.

What other OMS/GT CS courses have you taken?
SDP, KBAI, EdTech, CN, HCI, and DB

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I like to play guitar, go hiking, and hang out with my wife and 2-year-old son.

What is something interesting about you?
I hiked the Appalachian Trail (2,185 miles) in the Summer of 2013.
', u'responses': [u'Hi Erich,The Appalachian Trail sounds amazing to hike! I guess that will be on my bucket list. I've only been able to hike at Stone Mountain in GA so far, which is minuscule in comparison :)Welcome to the course, we hope you have fun!', u'Hi, Athira! I really like hiking out at Stone Mountain, too, and I try to hike the Cherokee Trail (the loop around the mountain) as often as possible. Looking forward to learning a lot this semester.']}, {u'text': u'What is your name?
Ganapathi Alwarappan
 
Where do you live? (or) Where are you from?
Sunnyvale, CA
 
Why are you taking AI?
For Career advancement.

What other OMS/GT CS courses have you taken?
CS6250,CS8803,CS7637,CS6300,CS8803,CS6475

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Working as a Archictect with Siemens PLM and busy with my family.

What is something interesting about you?
I always interested in learning new things.
', u'responses': [u'Hi Ganapathi,It's great that you're interested in learning new things as AI is a changing field and there is so much to learn! Hope you enjoy the course and we look forward to working with you!']}, {u'text': u'What is your name?
Brian Greenwald
Where do you live? (or) Where are you from?
Chicago, IL
Why are you taking AI?
I'm going the Interactive Intelligence route and felt that the class was a natural follow-up after getting a taste of AI in AI4R last semester, which really piqued my interest in the field!
What other OMS/GT CS courses have you taken?
InfoSec, ML4T, AI4R, Computer Networks, SDP
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Software Engineering Consultant at an open-source platform company. When not at work or doing stuff for courses, I'm probably playing video games or hanging out with my husband and 2 yorkies.
What is something interesting about you?
My undergrad was in Psychology.
', u'responses': [u'Hi Brian, and welcome to AI!

Mind telling us what open source platform you work for?', u'Sure - I work for Liferay. Here's our public github: https://github.com/liferay/liferay-portal
Anyone can pull down our source and build it into a working portal digital experience platform (we're moving away from the ""portal"" description). It's really easy to set up - the wiki on git shows you how. Liferay out-of-the-box comes with an implementation for users, permissions, authentication,and more while of course allowing you to extend or build additional functionality in Java. So basically it cuts out a lot of development time for new projects and allows our users to focus on business logic.', u'It's a great configurable and extensible platform. We used it as an backbone infrastructure for a Healthcare portal back in 2006!', u'Gurpreet, glad to hear it! I probably wouldn't recognize Liferay from 2006 though. It's come a long way!']}, {u'text': u'What is your name?
David Bloss

Where do you live?
San Francisco Bay Area, California

Why are you taking AI?
AI is a fascinating subject and I am taking this class to help build a strong foundation for my future career.

What other OMS/GT CS courses have you taken?Computer Networking
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Working at Workday, finishing an Android app I've been postponing, watching Vice documentaries, spending time with my wife, taking my dog for runs.

What is something interesting about you?
A few summers ago I learned how to solo skydive. ', u'responses': [u'I'm sure you hear this from many people.... but ""I've always wanted to skydive but have never gotten around to it."" How many dives did you have to take before you could dive solo?

Welcome to AI!']}, {u'text': u'What is your name? Helin Shiah

Where do you live?
Portland OR

Why are you taking AI?
Intrigued by the subject and was looking for a highly-reviewed course to take this semester.

What other OMS/GT CS courses have you taken?
Computer networks and intro to operating systems

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I'm a software engineer at a startup; I spend many mornings and evenings figure skating.

What is something interesting about you?
I abhor figure skating costumes. If it were up to me, everyone would compete in all black.', u'responses': [u'Hello!  Nice to see a fellow Oregonian in the program. :)  ', u'Hello! I was hoping there would others nearby taking this course. If we have time in the future it'd be cool to meet up and study together.', u'Hi Helin, welcome to AI! Figure skating would definitely be different if there were no costumes. 
I highly recommend studying with other students - it really helps to talk in detail with a peer about the material, especially in preparation for the exams.']}, {u'text': u'What is your name?
Lily Pytel
Where do you live? (or) Where are you from?
Boston, MA
Why are you taking AI?
It is a fascinating topic, but also a required course in my concentration :-P

What other OMS/GT CS courses have you taken?
SDP, SAD, Compilers

What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work as a software engineer at a healthcare analytics company by day, student by night, avid board gamer by semester breaks and enjoy ballroom dancing.

What is something interesting about you?
Certified cat lady. Volunteer at a shelter and have probably met hundreds of cats in the past three years. ', u'responses': [u'Hey Lily, welcome to AI.
I'm from Boston, too. I have a grumpy 3 year old cat and he's the first pet I ever had.
Do you have any good board games to recommend?', u'Hi Lily,
What style is your favorite - Modern (Standard) or Latin? BTW, Q Ballroom in Cambridge is awesome, especially Charlotte classes. :)', u'Hi @Mansoo, do you have a preferred style (e.g. world building, competitive, quick, long, intricate)? My favorites are Dominion (great for 2 players, asset gathering, online version available), Pandemic (not competitive, app available), Spyfall (quick fun party game), Secret Hitler (less quick but still fun party game), Plague Inc. (competitive, quick and adapted from the excellent computer game), and about a million more!

Hi @Kazimir - I don't know what modern\standard is exactly, but probably that's my favorite. Favorite dances are Waltz and Foxtrot, although I enjoy them all overall. I will check out Q ballroom - thanks for the tip!']}, {u'text': u'What is your name?
Benny Joseph
Where do you live? (or) Where are you from?
Greenbrae, CA
Why are you taking AI?
It's always been a topic that I have been interested in but never had the opportunity/time to go deep. 
What other OMS/GT CS courses have you taken?
Computer Vision, Computer Networks
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
Pretty much all my time is focused on work (I work for Allbirds) and spending time with my two young kids (3yr & 4 month old)
What is something interesting about you?
I enjoy triathlons', u'responses': [u'Hi Benny!

Nice to have you in the class. Yes, you will find this class really going deep in AI. Hope you will enjoy it.']}, {u'text': u'Adam SullivanI live in La Grande, Oregon.I enjoy thinking about difficult problems and AI has some of the toughest.I have taken AI for robots and I am currently taking Data & Visual AnalyticsI am a software developer for a cattle company. When I have free time I enjoy playing games with my wife, son, and friends.While working on my undergrad I was able to work with swarm robots.', u'responses': [u'Hi Joseph, and welcome to AI! I'm curious, what kind of software does a cattle company require? Anything to do with your swarm robot work (I'm only half joking here.)', u'Hi Noah, We have over 70,000 head of cattle and around 200 people total to take care of them in 5 locations so we use software to help track cattle, keep inventory, determine what to feed the cattle and when to feed the cattle. We also use a variety of custom applications to analyze performance figures. As of yet we do not have any robots around any of the yards but I keep harassing the CEO of the company to dish out the money for a few drones and to let me work on them for a year or so. I think they would work well for herding cattle, and maybe cowboys as well :)']}, {u'text': u'What is your name?
Chris Giron
Where do you live? (or) Where are you from?
Austin, Texas
Why are you taking AI?
It is a subject I have always been interested in and I feel it will compliment my ML specialization
What other OMS/GT CS courses have you taken?
CCA, SDP, ML, HIT, DVA, RL, IOS, and ML4T
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work as software developer for GM. During free time, I like playing sports or hanging on the lake.
What is something interesting about you?
I played on Texas football team during my undergrad years at UT while studying Aerospace Engineering', u'responses': [u'Hi Chris!

Welcome to CS6601. We get few students from Aerospace every semester. Hope you will enjoy the class.']}, {u'text': u'Ginger GilsdorfI live in Chandler, AZ (born and raised in Blacksburg, VA)I've dabbled in AI/ML topics on a few courses in my undergrad, and enjoyed the topic. Also looking forward to the ML courses in OMSCS.HP Computer Architecture, Computer Networks, Network SecurityI enjoy cooking and traveling, and learned to scuba dive recently. Had my first official dive in Bora Bora, which was incredible!I have 4 brothers, 4 sisters, and 22 nieces/nephews (for the moment). :)', u'responses': [u'Hi Ginger, Welcome to AI!
Well, we hope to augment your interest in the field through this course. 
That's awesome, I have heard it has some very great views under with clear waters.
That's one big sized family!
Good luck! :)']}, ...]",,0.0,489.0,6,,Student Introductions,[announcements]
5ad7d4250d63974e20c3904c,"
Note: All official announcements will be posted on T-Square. They may be double-posted here, but don’t rely on that. Make sure to check your T-Square email notification settings!

Due: January 14th at 11:59PM UTC-12 (Anywhere on Earth time)
Introduce yourself and complete the start-of-course survey.

Assignment: Getting Started with CS6601
Welcome to AI! You have a few tasks to complete for the first week:

Once you are certain that you plan to stay in the class, complete the start-of-course survey**. You can find the survey under the Tests & Quizzes tab on T-Square. We’ll use the results of the start-of-course survey to inform when we schedule office hours, connect you to others in your discipline or geographic location, and inform other elements of how we structure the class.

Enroll yourself on Piazza, then introduce yourself here!

Read over the course materials, including the syllabus and the schedule. The first lecture is Game Playing, and you can begin watching the first half of the lesson (through Depth-limited Search). 

Assignment 1 will be posted shortly.

If you are not familiar with Python, start learning! Although you can use any tutorial you like, here are a couple to get you started:
A beginner’s guide
An interactive track in CodeAcademy

We also recommend that you set T-Square to your local time zone if you haven’t already so that you’ll see due dates in your own local time.

** - Please do not complete the start-of-class survey until you're certain you plan to stay in the class, at least through the end of the first week. If there's a chance you may drop the class during Phase II registration (the first week of class), please wait until after the end of Phase II registration (Friday, Jan 12, at 4:00PM EDT) to complete the start-of-class survey.

",jc6w44hrp9v2ki,"[{u'text': u'And order the textbook. ', u'responses': [u'That is covered in the syllabus document linked above :)']}, {u'text': u'Is my understanding correct regarding the class schedule for assignments?

AI Isolation Player released on Jan 15 and due on Jan 28 (2 weeks)
Tri-directional search released on Jan 29 and due on Feb 11 (2 weeks)
Bayes Nets Sampling released on Feb 12 and due on Feb 25 (2 weeks)
Decision Trees and Forests released on Feb 26 and due on Mar 18 (3 weeks)
Expectation Maximization released on Mar 19 and due on Apr 1 (2 weeks)
HMMs released on Apr 2 and due on Apr 22 (3 weeks)', u'responses': [u'The due dates are correct. The release dates are ""Week of"". For example, AI Isolation Player will be released the week of Jan 15, and not necessarily on Jan 15 itself.

We usually aim to get the assignments out by the Wednesday of the week or earlier.', u'Thanks Ravikiran for confirming. Working on the study time table.

Hmm! So getting less than two weeks for four assignments :-)', u'whoops, wrong thread.', u'then you may be taking on too many classes!']}, {u'text': u'The slides linked on the syllabus for week #1 (Game Playing) are all rotated 180 degrees. Any plans to fix this? As viewing from a mobile device or tablet while commuting can be challenging :)', u'responses': [u'If you download the PDF and open it in Adobe Acrobat Reader DC, you can rotate the view.', u'But printing is really bad if you rotate. I've printed 3 copies so far, but I haven't found the printer settings to get it to go 4 slides/page and left to right, top to bottom page ordering. ', u'pdftk chapter06.pdf cat 1-endwest output chapter06_rotated.pdf', u'A heads up although it's not urgent, the link for chapter12.pdf https://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/19-planning/chapter12.pdf in fact links to chapter 13, while the linked pdf for chapter 17 https://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/chapter17.pdf is apparently missing the right-hand side of the slides', u'We'll look into this and fix it ASAP.']}, {u'text': u'Any material on the Assignment 1?', u'responses': [u'AI Isolation Player released on week of Jan 15']}, {u'text': u'For the final exam, will it be available to take that entire week? I had a trip scheduled already for April 27-29 so I'm hoping it's flexible.
Thanks!', u'responses': [u'Yes, you can complete and submit any time during the exam week i.e. from April 23-29. ']}, {u'text': u'I was taking ""Start-of-course Survey"" for CS6601 AI, After putting all my answers I clicked save button,  when I returned to the page for submission, I am unable to see some answers, Text Areas are blank. Is this a known bug? Do I need to retake the survey? I would really appreciate the quick help.

Thank you!', u'responses': [u'There is a Save button and a Submit button. Did you submit or only save?', u'I did click on save button first, and text for 3 textboxes disappeared. I clicked on word count and it was showing number of words present there, So I assumed it's there but not visible. I couldn't go back and edit it so I submitted the survey.
Now I want to know if I can retake this survey?', u'Does it even matter? Is there a contribution to our course grade from the survey? T-Square being the semi-randomly error-prone interface that it is, it's a game of chance whether your or indeed our answers have really been saved, submitted, or just discarded into the ether :-D', u'urg!  there is a reason we are switching.  sorry for the irritation.  can you tell us the browser you were using?']}]",,0.0,469.0,7,,Week 1 Announcement,[announcements]
5ad7d4260d63974e20c3904d,"Hello everyone,

It appears that someone is marking followups as resolved on @6. I can't actually figure out who, as Piazza doesn't give us a record of that. I assume it's in an attempt to be helpful, and we thank you for the effort, but as I've mentioned on the post: we'd like to say hi to each of you here, so please leave your intros Unresolved.

As a rule of thumb, please don't mark others' posts or followups as unresolved in this class. If you ask a question and it gets answered, please mark it resolved yourself. If we believe a post has been resolved adequately, we will mark it resolved. If neither of these has happened, it serves as a reminder that we need to get back to the post. We may not get back to 100% of your posts, but we'll do our very best, and this goes a long way in enabling that.

",jc6w44hrp9v2ki,"[{u'text': u'I marked my own Intro resolved when I wrote it!', u'responses': [u'That's fine, I'll go through and make them all unresolved now.

There was someone doing each one manually though, and I had no control over it - watching the number of unresolved followups tick down steadily was particularly harrowing.']}, {u'text': u'we'd like to say hi to each of you here

Or maybe not, after all :-D', u'responses': [u'We are doing our best.', u' 

I noticed :-)']}]",,0.0,423.0,9,,Please don&#39;t mark others&#39; followups as unresolved!,[announcements]
5ad7d4260d63974e20c3904e,Has anyone found a good resource for a digital version of the course book?,jc6w44hrp9v2ki,"[{u'text': u'Missed the student's answer with same link.

As per class syllabus - Note there is a much cheaper CourseSmart edition for “rent.” 180 days rental is $39.99', u'responses': []}, {u'text': u'Just get the international edition for less than $25; for instance https://www.ebay.com/itm/Artificial-Intelligence-A-Modern-Approach-by-Stuart-Russell-Peter-Norvig-a/232027200395
Supreme Court Approved®', u'responses': [u'I've used Abebooks, www.abebooks.com, for books in other classes and always had good results', u'True; even cheaper, $20.48 including free shipping currently https://www.abebooks.com/servlet/BookDetailsPL?bi=16353214169', u'Does the international edition have the same content than the US one?', u'I've bought 3 so far and though I don't have other editions to do a direct comparison, they seem to have the same content. They say 'Global' or 'International' edition and the paper is thin, but that's all the difference I've noticed.', u'There are  28 chapters in us version 26 in international. We aren't going over the extra two chapters in this course']}, {u'text': u'Looks like the whole pdf. http://web.cecs.pdx.edu/~mperkows/CLASS_479/2017_ZZ_00/02__GOOD_Russel=Norvig=Artificial%20Intelligence%20A%20Modern%20Approach%20(3rd%20Edition).pdf', u'responses': [u'Thanks. :)', u'Thanks.', u'Thanks William!', u'This copyrighted material at the published link doesn't seem to have the legal rights to be shared, so using it can be considered a violation of the academic honesty policy. Make sure you know where it's coming from before you use it.']}]",,0.0,391.0,10,Looks like this is a possible option: https://www.vitalsource.com/products/artificial-intelligence-peter-norvig-v9780133001983  But it's the same price as a physical copy on Amazon.,Digital Course Book,[other]
5ad7d4260d63974e20c3904f,"I've seen in other courses people create a post for LinkedIn profiles so if you're interested, add your profile here!
#pin",jc6w44hrp9v2ki,"[{u'text': u'https://www.linkedin.com/in/andrey-akhmedov-b76010b6', u'responses': []}, {u'text': u'Everyone is welcome to connect me on LinkedIn:  https://www.linkedin.com/in/sachinjnd', u'responses': []}, {u'text': u'https://www.linkedin.com/in/kaflesudip', u'responses': []}, {u'text': u'https://www.linkedin.com/in/joelgenter/', u'responses': []}, {u'text': u'www.linkedin.com/in/digitaltwin', u'responses': []}, {u'text': u'https://www.linkedin.com/in/aronlau/', u'responses': []}, {u'text': u'



https://www.linkedin.com/in/shettyrajeshn 




', u'responses': []}, {u'text': u'Mine is :https://www.linkedin.com/in/phamphuc/', u'responses': []}, {u'text': u'', u'responses': []}, {u'text': u'linkedin.com/in/graeme-mccrodan-cfa-08692014', u'responses': []}, {u'text': u'https://www.linkedin.com/in/esther-y-park', u'responses': []}, {u'text': u'https://www.linkedin.com/in/bosuk-hong/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/edcampos/', u'responses': []}, {u'text': u'http://linkedin.com/in/chris-hedenberg-9294b742', u'responses': []}, {u'text': u'https://www.linkedin.com/in/juliechua/ ', u'responses': []}, {u'text': u'https://www.linkedin.com/in/andres-osorio-3059682b/
', u'responses': []}, {u'text': u'https://www.linkedin.com/in/rupal-gupta-241506/', u'responses': []}, {u'text': u'', u'responses': []}, {u'text': u'https://www.linkedin.com/in/ltganesan/', u'responses': []}, {u'text': u'www.linkedin.com/in/wade-berglund-144b5ab4', u'responses': []}, {u'text': u'https://www.linkedin.com/in/evanda/
', u'responses': []}, {u'text': u'Would love to network with you guys! 

LinkedIn Profile', u'responses': []}, {u'text': u'www.linkedin.com/in/daniel-martinez-2592895', u'responses': []}, {u'text': u'https://www.linkedin.com/in/jwsheng/', u'responses': []}, {u'text': u'http://linkedin.com/in/ajalix/', u'responses': []}, {u'text': u'
https://www.linkedin.com/in/nk4312/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/jennyeckstein/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/charles-he-1794a92b/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/edgarbautista/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/diego-vacanti/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/ming-choi/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/mohan-gangadhar/', u'responses': []}, {u'text': u'www.linkedin.com/in/chad-long-3b1543100', u'responses': [u'My bad, I sent a lot of you invitations with 6035 instead of 6601 in my message. I am in both this semester.']}, {u'text': u'https://www.linkedin.com/in/william-zhuang-cfa-000143b3/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/zhiwei-qian-46785356/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/kazimirkolossovski/
', u'responses': []}, {u'text': u'https://www.linkedin.com/in/montoyajessica/
', u'responses': []}, {u'text': u' https://www.linkedin.com/in/kevindbrandt/
', u'responses': []}, {u'text': u'www.linkedin.com/in/bkerner', u'responses': []}, {u'text': u'https://www.linkedin.com/in/adam-sullivan-154b9677/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/briangwald/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/mike-williamson-9924055/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/will-giddens-0451145/', u'responses': []}, {u'text': u'www.linkedin.com/in/william-wu-aa081359 ', u'responses': []}, {u'text': u'https://www.linkedin.com/in/hopat/

', u'responses': []}, {u'text': u'https://www.linkedin.com/in/chanik-caleb-jang-a293146b/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/rajanjethva/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/keith-adkins/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/nathan-susanj-35856824/ ', u'responses': []}, {u'text': u'https://www.linkedin.com/in/oyvindr/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/tylerroland92/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/patrick-hu-75993057/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/eliseeiden/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/matthew-levy-5ba690b3', u'responses': []}, {u'text': u'Joseph
https://www.linkedin.com/in/vjoseph/
', u'responses': []}, {u'text': u'Zhi Zhang
linkedin.com/in/zhi-z-9801801a', u'responses': []}, {u'text': u'https://www.linkedin.com/in/joseph-osei-boateng', u'responses': []}, {u'text': u'I don't update this, but https://www.linkedin.com/in/bob-viswanathan-46053b2/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/jeremypratt1/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/sai-prakash-nanduru/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/meenusinha/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/gcalmasini/ :)', u'responses': []}, {u'text': u'Ying Xie
https://www.linkedin.com/in/gavinxie1129', u'responses': []}, {u'text': u'https://www.linkedin.com/in/badalsingh/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/alexander-pitzer-66262244/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/carlosaguayo', u'responses': []}, {u'text': u'https://www.linkedin.com/in/morrispj/', u'responses': []}, {u'text': u'
https://www.linkedin.com/in/simhareddy/', u'responses': []}, {u'text': u'Hi All, Connect me on 
https://www.linkedin.com/in/bheeman/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/thiakx/', u'responses': []}, {u'text': u'https://eg.linkedin.com/in/yassermakram', u'responses': []}, {u'text': u'https://www.linkedin.com/in/dawnking/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/jasonmoix/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/tim-cordova-cissp-15924114b', u'responses': []}, {u'text': u'https://www.linkedin.com/in/brandon-sheffield/
', u'responses': []}, {u'text': u'https://www.linkedin.com/in/attiqk/', u'responses': []}, {u'text': u'www.linkedin.com/in/cognitivegate', u'responses': []}, {u'text': u'Feel free to connect with me (https://www.linkedin.com/in/ahmadnazeri/)
Adding something about yourself, computer science joke, or book/article/video recommendation as a note would be greatly appreciated.', u'responses': []}, {u'text': u'https://www.linkedin.com/in/ktmud/

Hit me up, Boston folks! Or if you are into urban design, finance, social justice, politics, or foreign languages...', u'responses': []}, {u'text': u'Good idea!! You have the privilege of having good connections when you study in a good place. So, I am here, on linkedIn: https://www.linkedin.com/in/guptasuhail/


Happy to connect with my course-mates.
', u'responses': []}, {u'text': u'https://www.linkedin.com/in/joshikruti/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/stanarefyev/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/frankginac', u'responses': []}, {u'text': u'https://www.linkedin.com/in/navnitbelur/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/aniltiwari8/', u'responses': []}, {u'text': u'www.linkedin.com/in/', u'responses': []}, {u'text': u'Happy to connect with fellow learners and colleagues in the field!
https://linkedin.com/in/frankhinek', u'responses': []}, {u'text': u'Thank you for starting this thread!
https://www.linkedin.com/in/xin-ren-b3743b17/', u'responses': []}, {u'text': u'linkedin.com/in/yu-niu-81a49779
', u'responses': []}, {u'text': u'Happy to connect with you all. 

https://www.linkedin.com/in/hbindra/', u'responses': []}, {u'text': u'Excited to (virtually) meet you all! 
https://www.linkedin.com/in/aqilhirji/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/dmattox/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/danielubernal', u'responses': []}, {u'text': u'https://www.linkedin.com/in/santuche/en', u'responses': []}, {u'text': u'https://www.linkedin.com/in/pepper-miller-404529a', u'responses': []}, {u'text': u'https://www.linkedin.com/in/ankit-arora-44a4932/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/karthik-kasaghatta', u'responses': []}, {u'text': u'https://www.linkedin.com/in/thanh-tam-nguyen/', u'responses': []}, {u'text': u'https://www.linkedin.com/in/lance-stalker-b58b96146', u'responses': []}, {u'text': u'https://www.linkedin.com/in/abinsalm/
', u'responses': []}, ...]",,0.0,441.0,11,,LinkedIn,[other]
5ad7d4260d63974e20c39050,"Maybe I missed it, is there a slack for this class?",jc6w44hrp9v2ki,[],,0.0,363.0,12,#cs6601,Slack?,[other]
5ad7d4260d63974e20c39051,"The 2018 Google Calendar for cs 6601 is not displaying anything. Can you guys (TAs) please update the course calendar, so that we can import that into the Outlook/ Google calendars?",jc6w44hrp9v2ki,"[{u'text': u'Are you referring to the office hours calendar?', u'responses': [u'No, I am referring to an importable course calendar which used to contain the Assignment due dates as well as the dates of midterm and the final exam. ', u'I guess you guys posted one. Thanks.', u'I don't think being anonymous makes you anonymous from the TA's. On top of that, why would you want to be anonymous for asking for a calendar?', u'I agree with Brett!

And if you're ever scared someone's going to label your question as silly-dumb-stupid, then just reference me; I ask dumb questions all the time, haha. Never been a fan of anonymous posts throughout my OMSCS experience.

-Q.
(in case anyone's wondering, this has my preferred name since grade school. Full name = ""Quyen"")', u'This is my 7th class and still have never posted an anonymous post. And I have asked some stupid questions over my 7 classes too. The only time I think people tend to post anonymously is when they are being critical of the TA or professor. I understand this as people are afraid of backlash. However, I like to think that the TAs and professors are professionals and this is not an issue. Everyone should be able to take criticism. It is what makes us better people in the end.']}]",calendar posted here: @15,0.0,371.0,13,,2018 CS 6601 Course Calendar,[other]
5ad7d4260d63974e20c39052,"It seems like some of the other classes are moving to 'Canvas'.

Will this particular instance of the class remain on T-Square all semester or will it transition to Canvas?",jc6w44hrp9v2ki,[],It will remain on T-Square for this semester.,0.0,362.0,14,,Canvas vs T-Square,[other]
5ad7d4260d63974e20c39053,"Hi everyone,

Here is the ICS file containing all the important due dates, which you can import into your calendars.

CS 6601 Spring 2018 Calendar

#pin",jc6w44hrp9v2ki,"[{u'text': u'Thank you for this!', u'responses': []}, {u'text': u'Thank you! This is useful.', u'responses': []}, {u'text': u'Perfect, thank you!', u'responses': []}, {u'text': u'Thanks!', u'responses': []}, {u'text': u'Thank you', u'responses': []}, {u'text': u'Wonderful thank you.', u'responses': []}, {u'text': u'Very useful. Thanks!', u'responses': [u'Much needed. Thanks!']}]",,0.0,462.0,15,,Assignment and Exam Calendar,[other]
5ad7d4270d63974e20c39054,"What is your name?
Mohammed Abdulla
Where do you live? (or) Where are you from?
Bangalore, India.
Why are you taking AI?
Artificial Intelligence is a fascinating and field and it is relevant more than ever. I want to have a broad introduction to subject and different problems in the domain. And also I work in AI research and this would be a course requirement for my specialisation.
What other OMS/GT CS courses have you taken?
This is my first Course.
What do you do when you're not working on classes? (Career, research, hobbies, etc.)
I work for a Fashion E-commerce based out of India. We apply AI to improve customer experience in out platform. I am a avid reader and spend lot of time reading about anything and everything I find. Also I binge watch shows. 

What is something interesting about you?
I know 7 languages.",jc6w44hrp9v2ki,"[{u'text': u'Welcome to the class, but you should really be posting this in the Student Introductions thread. @6', u'responses': []}]",,0.0,340.0,18,,"Hi Everyone,",[a6]
5ad7d4270d63974e20c39055,,jc6w44hrp9v2ki,[],,0.0,335.0,19,"One of the most straightforward methods may be with $$\LaTeX$$, more particularly tikz, http://www.sfu.ca/~haiyunc/notes/Game_Trees_with_TikZ.pdf in view of the fact that you could just copy-paste the graphic element that refers to the individual game config, then modify as necessary for siblings/children",Would anyone know how to create the isolation game tree visualization in the video lesson 1.8?,[lesson1]
5ad7d4270d63974e20c39056,"On the Complete Isolation Tree in lesson 1 No. 13, I found there are 2 very similar child branches but propagating different values up to the next level. Could anybody tell me why?

Thank you.

P1:

P2:
",jc6w44hrp9v2ki,"[{u'text': u'That's a relief, thank you!', u'responses': []}]","Looks like a mistake. For the one labelled P1, the top-most +1 should be a -1 similar to P2. The minimizing node will select the -1 branch to the right.",0.0,325.0,20,"The only difference I see is the blue O's starting position in both child nodes. But that wouldn't explain the difference in the parent node value necessarily, I'm just thinking out loud as well as showing an observation.

EDIT: Thank you Prof, I clearly over analyzed that one...",Would any one tell me the reason for the different results?,[lesson1]
5ad7d4270d63974e20c39057,"I noticed in Lesson 1 No.18, it says the center position has 16 spaces in which it can move, but other positions have 12 or fewer spaces to move. That's the reason using ""12"" in the worst case: 25 x 24 x 12^23, am I correct?

But, at the position as below, doesn't it have 14 spaces to move? 

",jc6w44hrp9v2ki,"[{u'text': u'Makes sense. 12 should be the average branching factor. Thank you.', u'responses': []}, {u'text': u'I tried to find the actual branching factor at move#3 and could draw an image where some cells in game can give multiple 14 and 11 legal moves. However looks like 12 is the best estimate.
', u'responses': []}]",,0.0,299.0,21,"I noticed in the errata/notes, at the bottom of the video's page, he refers to 12 as the average branching factor. I think your answer, 14, would be correct if he decided to use the worst case scenario. I'm guessing he didn't since these were very rough/liberal guesstimates.

Note: In addition to the scenario you provided, there are scenarios where there are only 11, 8, 9, etc legal moves (for move #3)",Max Moves,[lesson1]
5ad7d4270d63974e20c39058,"I am reading the ""chapter6.pdf"" study material from week 1 and compared it with the book. Two pseudocode are different as shown below (the top one is from the book P170):


As both are to maximise the utility on the root node, why the one on the book starts with Max-Value() and the study material starts with Min-Value()? What did I miss? Thanks. ",jc6w44hrp9v2ki,"[{u'text': u'ah, that's it. Thanks. 
$$argmax_{a\in ACTIONS(s))} MIN\_VALUE(RESULT(state,a)) = \upsilon \leftarrow MAX\_VALUE(state, -\infty, +\infty)$$ + return the action in ACTIONS(state) with value $${\upsilon}$$', u'responses': []}]","In the top algorithm, Max-Value is immediately called.
In the bottom algorithm, it says ""maximizing the Min-Value(...)"", which is same as just using the Max-Value, just worded differently.",0.0,303.0,22,,alpha-beta prune,[lesson1]
5ad7d4270d63974e20c39059,"In Lesson 1, section 16 (max number of nodes visited) it would seem to me the total number of possible games is not 25!, but rather no more than 25!/16, considering that one could ""normalize"" the various possibilities. There are 4 rotations of the board and 4 board flips (horizontal and vertical).  This would imply for every game there should be 16 possible layouts, depending on one's perspective in viewing the game (and whether or not the viewer is creatively using a couple mirrors).  Why should the perspective of the viewer contribute to the number of possibilities computationally?

Edit 2: After thinking about this, maybe there are only 6 transformations possible?  2 rotations of the board is equivalent to a horizontal + vertical flip, so you have 4 rotations and 2 possible flips.

Edit 3: We'd have to adjust the upper bound a smidge higher because a reflection of a move in the middle isn't really a reflection and a rotation of a center square move isn't a rotation.  We can decrease the upper bound confidently by understanding that there are only 6 possible first moves (a wedge representing 3 from the top row, 2 from the middle and the center).  So, confident upper bound is 6 * 24!",jc6w44hrp9v2ki,"[{u'text': u'I was thinking about this too. Board state after the first move seems to have 16 equivalent representations, as you pointed out. So, total number estimate goes down to AT LEAST 25!/16. If the second half-move is not on the line connecting the first one against the center, there will be one board flip to around this line to get an equivalent state. So, estimate goes down by a factor of 2. 

On a bigger scheme of things, these factors hardly matter comparing to the factorial (or exponential) laws.', u'responses': [u'Perhaps at the beginning of the game it wouldn't offer much advantage, but I think it might make a difference later..?  Maybe not, as there wouldn't be as many symmetries available.', u'Yes, I think this is spot on.', u'The professor discusses this exact topic in a later lecture, actually. ', u'Oh, cool.  Thanks.', u'If anyone's still looking, I believe the symmetrical board's rotation is discussed in lec1 vid44.
-Q']}]",,0.0,297.0,25,,Why not total number of moves: 25! / 16?,[lesson1]
5ad7d42d0d63974e20c3905a,"Hi - I see the mid term exam dates in the calendar are from March 5th to March 11th

I am traveling overseas for part of those dates.

So am I able to take the midterm anywhere within this date range? Or is each student allocated a specific date they have do the exam on?

Thanks",jc6w44hrp9v2ki,"[{u'text': u'Many thanks and good to know. Which reminds me - is this a proctored mid term exam or a take home (open book?) exam?
', u'responses': [u'Syllabus says ""We are still determining the format and best way to administer them, but they will most likely be take-home.""', u'It'll be a take home.', u'Good to know. Can we expect any sample questions to prepare and what to expect in mid/finals?', u'You will get plenty of opportunities to practice from the challenge questions posted by the instructors. Other instructions on the mid/finals will be posted as we approach them.', u'@Richa: What is a take home test? Is it time bound or we get questions, work on solution and submit after we complete it (Obviously before due)', u'The midterm will be available on the 5th in the form of a pdf. You download the pdf and work on the problems and submit it on or before the 11th.', u'Thanks Xuewen. ']}]","Hi David,

The midterm will be available on the 5th and is due on 11th so you can submit anytime before the deadline.",0.0,342.0,26,,Mid Term Exam Dates,[other]
5ad7d42d0d63974e20c3905b,"I just made an optimal tic-tac-toe AI as a warmup to using minimax and was wondering the preferred way to represent the game tree in code. I was focusing mainly on the algorithm so I literally copied the board (2d list) for each node of the game tree. Luckily tic-tac-toe is simple enough that I was table to search to end game quickly despite the deep copied nodes.

However, I imagine the preferred way is to have one game board in memory and 'push' a move onto the board at the beginning of the recursion call and then 'pop' the same move at the end of the recursion call. Therefore, you just have one game board that is being modified with recursive calls.

Is this the correct way to expand and search a game tree such as tic-tac-toe?",jc6w44hrp9v2ki,"[{u'text': u'I would also love to know more about the code implementation of minimax algo....', u'responses': []}, {u'text': u'yes, coding with recursion in mind is a good idea. I first did game trees in Lisp, and coded it as a recursive list of lists, with the children of each ply being a sublist.  Ordering within that list will matter for optimization later, so keep that in mind.  Once I figured out what I was doing with alpha beta I went back and profiled what was taking the most time and then started optimizing, starting with the algorithm itself, the order of expanding the children, and then looking at my data structures.', u'responses': []}, {u'text': u'You can encode the board state with an integer. A 64 bit unsigned int can encode current board for 8x8. One more bit can be used to identify whose turn it is (actually unnecessary as you can tell this by the tree search depth) and maybe a little bit more to encode each players current position. It costs a bit to unwrap the ints into a board class, but that's a trade off you have to test. ', u'responses': []}, {u'text': u'Just finished intelligent undefeatable tic tac toe iOS App using Minimax algo..... 3X3 board works well.... for board size > 3, it takes too much time.... Will work on alpha beta pruning to make higher levels work well.... I am also using deep copy to copy states during recursion...... I wonder what would be the optimum way.....https://github.com/saalisumer/TicTacToe', u'responses': []}]",,0.0,319.0,27,"I think that would be a sound way to do it. You would also need to be sure you do ""clean up"" of other aspects of the state like who's turn it is once you pop the moves.

Alternatively, if the memory of the board and depth of search aren't going to be excessive then sending a copy of the board down the recursive calls probably wouldn't be too bad either. There would only every be d copies of the board in memory (where d is the depth of the search). This would make multi-threading/multi-processing a bit easier to implement in the future.",Representing a Game Tree in Code,[lesson1]
5ad7d42d0d63974e20c3905c,"

Why expected value of the most branch is <=1.5? Is that because the greatest value we can get for that branch only equals 0.5 x (-3) + 10 x 0.1 + 5 x 0.4? If so, when we pick ""-7"" for most left of that branch, why can't we just use ""-7"" + the greatest value of the rest (10 x 0.1 + 5 x 0.4) ? Sorry for asking too much. :( ",jc6w44hrp9v2ki,"[{u'text': u'@Ting, how is it possible to get 10 for the right most node?', u'responses': [u'Before you search it, you just assume for the sake of the $$\alpha \beta$$ calculation that it is the largest value possible']}]","-7*0.5 + 10*0.1 + 10*0.4 =1.5After we get the node for <= -7, we assume the other two branches have the maximum possible values to calculate the maximum possible value for their parent node. Still, 1.5 is less than 5.2, so we can prune the other two branches.",0.0,280.0,29,,Why the most right expected value is &lt;=1.5 ?,[lesson1]
5ad7d42d0d63974e20c3905d,"1. Game Playing through Depth-limited Search; review/learn Python; play each other in Isolation; Chapter 1-2; Chapter 5.0-5.2
R&N slides on Game Playing

Can you explain what does ""play each other in Isolation"" means. Am I missing some chapters?",jc6w44hrp9v2ki,"[{u'text': u'
Well, I plan to teach Isolation tomorrow to my 11 year old (who will likely beat the crap out of me!), should help to clarify the rules, and learn strategies that work best.', u'responses': [u'Your prediction applied here as well. But I can safely say that after one day, I can now soundly defeat my 13yr old niece, haha! Show no mercy, Gerardo!!

PS. watch lec1 vid55 for strategy and cheat sheet!! (but don't show your 11yr old!) Haha.']}, {u'text': u'hopefully we will add a permanent hangout link shortly that people can visit. or you can look for a. partner now here or on the slack channel.', u'responses': [u'
I made an account (abwh) to play in https://bodogemu.com/en/games/isolation , if anyone is interested

Updated: rules are way different from the original Isola or the version in our course, look at the article below by David Mattox for an alternative.', u'That game is different than ours.']}, {u'text': u'Awesome interface to play game of isolation - http://aws.mattox.pro/samples/Isolation/Index.html

Details @ https://www.linkedin.com/pulse/shall-we-play-game-turn-based-artificial-intelligence-david-mattox/
(Inspired by this course!)', u'responses': [u'This is awesome!']}]","In addition to what Jacob said, you can find a friend to play with and if that's not possible then you can try out various opponent moves yourself and get a general idea of strategies you can develop/use for Assignment 1.",0.0,317.0,30,I believe it means to find a friend and actually play the game isolation with them.,play each other in Isolation,[lesson1]
5ad7d42d0d63974e20c3905e,Is it a must that assignments need to be completed in Python?,jc6w44hrp9v2ki,"[{u'text': u'Is 2.7 still the desired version?
', u'responses': [u'Yes. Please check @38']}, {u'text': u'
  Yes.  Our testing software assumes python. 
', u'responses': [u'Thank you.']}, {u'text': u'Are there restrictions as to what kind of Python we are allowed to use? For instance, only core Python, or core Python plus numpy, core Python plus pip modules, add our own custom modules for instance coded in C then compiled as Python modules, leverage of pip such as pip install Cython,  use of dynamic or static compiling more generally?', u'responses': [u'Core Python plus modules specified on a per-assignment basis. Custom modules are not supported as they won't be found on our autograder environment', u'Thank for the clarification Ravikiran :-)']}]",Yes. Our testing and feedback systems assume Python.,0.0,325.0,32,"Yes, all the starter code and assignments appear to be in Python.",Programming Language,"[other, group_study]"
5ad7d42d0d63974e20c3905f,"Hi,

The slides on Game Playing appears to be upside down. Can the professor or TAs update the pdf document?

Thanks!



",jc6w44hrp9v2ki,"[{u'text': u'R_Nchapter06.pdf', u'responses': [u'Thanks! I was also able to rotate the slides 180 degrees after downloading it.', u'thanks Gregory!', u'see the followup to @7 for the pdftk method']}, {u'text': u'', u'responses': []}, {u'text': u'I rotated it and saved as a new file. Most pdf readers cannot save rotated views. So go ahead download it through my google drive.
https://drive.google.com/file/d/10cv6H0_7tJHOGLLHwzqiXV8wj6PjXQwn/view?usp=sharing', u'responses': []}]",,0.0,266.0,33,You should also br able to open them in a reader and rotate twice,Game Playing Slidea not displaying correctly,[feedback]
5ad7d42e0d63974e20c39060,It looks like someone is converting people's questions into notes.... When you do that you lose the student answer. Is there a reason behind doing this?,jc6w44hrp9v2ki,[],Just went through most of them and converted them back. Whoever is doing this please stop converting questions to notes; it hides students' answer and instructors' answer.,0.0,271.0,34,The chances are it's someone who doesn't know what they're doing. You get a lot of spurious edits to questions etcetera similarly.,Reason Someone is Converting Q&#39;s to Notes,[other]
5ad7d42e0d63974e20c39061,"I looked on line for some additional resources to solidify the minimax & alpha-beta pruning algorithms in my mind and found the following resources.  Figured I'd share since it helped me.

Videos:
A/B pruning w/ John Levine
A/B pruning w/ Pieter Abbeel

Web app that you can use to step through both minimax and a/b pruning of a tree.",jc6w44hrp9v2ki,"[{u'text': u'Thanks so much. These are excellent resources.', u'responses': []}, {u'text': u'Yes - the web app simulation is really helpful for understanding this. Thank you for posting. ', u'responses': []}, {u'text': u'Very interesting app. Thanks for sharing.', u'responses': []}, {u'text': u'Thank you so much. this helps!!', u'responses': []}, {u'text': u'Thank you SO much. A/B pruning w/ John Levine made alpha-beta pruning so clear! I just wasn't able to grasp it from the lectures and I watched them about 4-5 times.', u'responses': []}]",,0.0,275.0,35,,Minimax w/ AB pruning resources,[lesson1]
5ad7d42e0d63974e20c39062,"Hello Everyone!
Please find below a google calendar link, that I created for my personal use. The calendar contains all the deadlines based on Course Schedule. Disclaimer: I do not take responsibility for any incorrect information or for any missed deadlines. Please double and triple check the dates! 

I hope you all find it useful.

CS-6601 Calendar Link",jc6w44hrp9v2ki,"[{u'text': u'Very useful, thanks!', u'responses': []}, {u'text': u'Thank you! This is great', u'responses': []}, {u'text': u'There's one that the instructor provided in @15 as well', u'responses': []}, {u'text': u'I imported both this cal and the one @15. Thank you, Jenny! Sincerely!
-Q', u'responses': []}]",,0.0,274.0,36,,Google Calendar,[announcements]
5ad7d42e0d63974e20c39063,"In week 3 of the course schedule, it mentions the Korf paper but there is no hyperlink. What is the title of the  Korf paper we should read for week 3 or do you have a hyperlink to the paper?",jc6w44hrp9v2ki,[],"It is the same paper as mentioned in week 1.

update: I believe all of the papers you need to read are included in the reading nodes in the video lectures.",0.0,286.0,37,My guess is that is the same Korf paper as week 1 if you didn’t already finish it. If not someone can correct me:,Week 3 paper read,[lesson2]
5ad7d42e0d63974e20c39064,"Hi - the notes say that we have to use Python 2.7. Is this a minimum? i.e. can we use Python 3?
Python 3 is so much better than 2.7 so really hoping the answer is yes. If not, is there a reason we have to be limited to 2.7?
Thanks",jc6w44hrp9v2ki,"[{u'text': u'It could possibly be that their assignment templates and grading scripts are coded in 2.7, and it would take some considerable time and effort to upgrade them to 3.x.', u'responses': [u'Right - well possibly. Although its the sort of update you would want to do at some point. So why would people wait..
Python 3.0 is so much better. Everything I've done before is Python 3 so I have to unlearn some of the excellent features in 3 :-(', u'I agree. Python 3 is way better. And canvas is also much easier to use than T-square.', u'Could you post the Canvas URL for this course 6601? Somewhere along the line I missed seeing that.
thanks', u'So is python 3 fine?', u'It seems not :-(
Could we have a TA confirm?', u'I guess I can always create a new conda environment.  Just a pain in the butt ', u'It's hard to transition to a new version of a language which is not backward compatible given limited number of TAs supporting class of this size. Version info will anyways be out with the release of assignment 1 :-)', u'Every OMSCS course I've taken so far has used python 2.7.  I would get used to it.  Also this course is using T-Square only - no canvas.', u'If you dont mind me asking what are some features in Python3 that make it so much better?', u'If you're a web developer, it's got unicode strings by default.
If you're a numerics person, there's now a matrix multiply operator
If you're server side, there's async 
Generally, py3 has better string interpolation too. ']}, {u'text': u'Just to collate the info - we are using T-Square this semester for the class. We are planning our migration to Canvas, but due to reasons beyond our control it couldn't happen this semester.
And we are still using Python 2.7 for this class. You are welcome to write Python 3 code, but we do not make any guarantees that it will work on the automated testing framework.', u'responses': [u'I think there's still an open question about external libs like numpy. I'm assuming this will be included in the assignment, so no biggie. Just a lot of folks are already coding and thus curious about what they can leverage.', u'They will be included on a per-assignment basis.']}]","We would highly encourage using Python 2.7 to avoid any compatibility issues. While you may be able to write python 3.X code that works fine, there is no guarantee. To echo Nick Lynberg from the below conversation, most of the classes at GaTech use 2.7.",0.0,308.0,38,,Python 3 vs Python 2.7,[other]
5ad7d42e0d63974e20c39065,"What a first week! We had a mad rush hiring TAs so we could open the
course to more students, which caused more students to sign up, which
led to a feedback loop.

I am hoping everything is settled now, and we have our full complement
of TAs and students.

My goal is to infect you with my enthusiasm for AI and provide some
insights along the way that you will not get anywhere else.

For some of you, this class is the first course in your graduate
career. We are a world-leading university in technology and artificial
intelligence, and we have high expectations of our students and
ourselves. It may take some adjustment in switching from an
undergraduate to a graduate mindset.

In helping with this process, I thought I'd take a second and share my
guidelines on how to succeed in OMSCS 6601.

Briefly,

Assignments are designed to provide deeper experiences than we can do
in lecture. The assignments are 60% of your grade. Only your highest 5
of 6 assignments scores will count. Every semester there are students
for whom doing all 6 assignments would have improved their grade. My
suggestion is to always turn something in for each assignment. Only
drop an assignment in dire need.

We expect our students to proceed with the assignments in good
faith. We try to make clear what each assignment is teaching, and we
have the expectation that our students attempt the assignments using
the techniques from class. In assignment submissions, we want to see
evidence of learning and try to make a grading system that rewards the
student for showing that learning. For the extra credit assignments we
have more expectation of creativity, especially in ways that show
mastery of AI techniques.

The midterm and final are designed to emphasize a broad survey of
knowledge. They are each worth 20% of the grade. The videos offer a
*minimal* knowledge of the techniques in this class. The book is much
more complete. Read it, and participate in the Piazza discussions on
challenge questions - these help prepare for the quizzes. In fact,
**most of the challenge questions come from previous exams.**


CHEATING:

Please follow the honor code, posted on the syllabus. We try to make
it simple: IF YOU ARE LOOKING AT SOMEONE ELSE'S CODE, whether it be
that of a fellow student or a public GitHub repository, YOU ARE
CHEATING.

Detecting cheating involves using AI algorithms. This course teaches
AI algorithms. Your professor, who creates new AI algorithms, was just
given significant resources by the Dean to design AI systems to detect
cheating. You see where I am going with this line of reasoning.  Don't
cheat. Just don't do it. Our rate of cheating is relatively low
compared to most on-line and on-campus classes. My goal is to render
it nil by making it easier to learn the material than trying to fool
our cheating detection agents, whether that be copying from another
student or paying for someone to do your homework on one of the
freelancer sites (yes, we do detect that).

Instructor's philosophy:

My goal is to follow the Richard Feynman style of teaching. Teach the
intuition in the lectures to build understanding and confidence, test
the basics in the exams to insure students get a survey of knowledge
that (hopefully) will stick with them, and enable deep
learning/discovery/exploration in the assignments while building
skills and ""practical"" experience. Every semester we have students
reporting that they used the code they wrote for their assignments for
their job or research, so we think we are on the right track!

CS6601 is special. It is the foundational course and textbook for the
Intelligent Systems PhD qualifier exam, for which I supervise the
grading. Students take this course with me and 2.5 years later have to
answer researchy questions based on their exposure to material from
this book (and all their other reading/experience for the
qualifier). Six years ago I vowed to myself to do a better job
preparing them. Agreeing to do OMSCS is part of that process, as these
PhD students can refer back to the videos and assignments while they
prepare for their qualifying exam. Hopefully, my goal of providing a
good knowledge base of the PhD qualifier also means that students in
OMSCS6601 get a good grounding in AI. We teach the same material
on-campus and on-line, with on-campus doing peer learning sessions in
class on the same challenge questions we are posting on-line. I
believe that peer learning in-class really helps students understand
the material, and I encourage on-line students to pair up and discuss
the challenge questions as well.
yet, I'm afraid, but we definitely *are* paying attention to
suggestions on how to improve things. For example, based on feedback
last year, the challenge question discussion at the end of the Search
lesson is now improved and foreshadows some of the discoveries that
should happen in coding tri-directional search.

Time balance: Finding the right time balance is difficult, and we've
been tuning the workload. Here is the amount of time on-campus
students said they spent on the identical course last semester:

0-3  3-6  6-9  9-12 12-15 15-18 18+
0    3    7    22   18    16    17

On-line students often report higher numbers.

In undergrad, each credit hour should equal 3 hours of work a week. A
3 hour class should average to 9 hours of work, including lecture. But
grad school is different. For a normal 2 year Masters degree, I advise
my students to take a max of 2 ""real"" classes a semester and focus the
rest of their course credits on research in order to get the maximum
out of their experience. These are full-time students, generally
without jobs. For those of you doing 2+ OMSCS classes while living in
the real world, I don't know how you do it! (BTW, OMSCS students *can*
do independent study with a professor - called an ""8903"" - in fact,
much of the anti-plagiarism software is being written by OMSCS
students doing independent study with me).  Use the class schedule to
help pace yourself and know where you should be for each week of the
course.

OK, now that we have the administrivia out of the way, let's get
started with the fun stuff! I fell in love with AI making a automatic
player for a game called Isolation. Hopefully, in the next couple
weeks, you will make your first AI that is ""smarter"" than you - an
Isolation player that is better at playing the game than you are.

Game playing search is a special case of search, which is covered in
the early chapters of the book. I would suggest reading all the
search chapters to get a solid understanding of the topic before
embarking on coding your agent.

#pin
",jc6w44hrp9v2ki,"[{u'text': u'Super useful note - thank you. Makes me very excited for the class.

For anyone who had a bit of trouble w/ the above formatting see below :)
---------------------------------------------------------------------------


What a first week! We had a mad rush hiring TAs so we could open the course to more students, which caused more students to sign up, which led to a feedback loop.

I am hoping everything is settled now, and we have our full complement of TAs and students.

My goal is to infect you with my enthusiasm for AI and provide some insights along the way that you will not get anywhere else. For some of you, this class is the first course in your graduate career. We are a world-leading university in technology and artificial intelligence, and we have high expectations of our students and ourselves. It may take some adjustment in switching from an undergraduate to a graduate mindset.

In helping with this process, I thought I'd take a second and share my guidelines on how to succeed in OMSCS 6601.

Briefly,

Assignments are designed to provide deeper experiences than we can do in lecture. The assignments are 60% of your grade. Only your highest 5 of 6 assignments scores will count. Every semester there are students for whom doing all 6 assignments would have improved their grade. My suggestion is to always turn something in for each assignment. Only drop an assignment in dire need.

We expect our students to proceed with the assignments in good faith. We try to make clear what each assignment is teaching, and we have the expectation that our students attempt the assignments using the techniques from class. In assignment submissions, we want to see evidence of learning and try to make a grading system that rewards the student for showing that learning. For the extra credit assignments we have more expectation of creativity, especially in ways that show mastery of AI techniques.

The midterm and final are designed to emphasize a broad survey of knowledge. They are each worth 20% of the grade. The videos offer a *minimal* knowledge of the techniques in this class. The book is much more complete. Read it, and participate in the Piazza discussions on challenge questions - these help prepare for the quizzes. In fact, **most of the challenge questions come from previous exams.**

CHEATING:

Please follow the honor code, posted on the syllabus. We try to make it simple: IF YOU ARE LOOKING AT SOMEONE ELSE'S CODE, whether it be that of a fellow student or a public GitHub repository, YOU ARE CHEATING.

Detecting cheating involves using AI algorithms. This course teaches AI algorithms. Your professor, who creates new AI algorithms, was just given significant resources by the Dean to design AI systems to detect cheating. You see where I am going with this line of reasoning. Don't cheat. Just don't do it. Our rate of cheating is relatively low compared to most on-line and on-campus classes. My goal is to render it nil by making it easier to learn the material than trying to fool our cheating detection agents, whether that be copying from another student or paying for someone to do your homework on one of the freelancer sites (yes, we do detect that).

Instructor's philosophy:

My goal is to follow the Richard Feynman style of teaching. Teach the intuition in the lectures to build understanding and confidence, test the basics in the exams to insure students get a survey of knowledge that (hopefully) will stick with them, and enable deep learning/discovery/exploration in the assignments while building skills and ""practical"" experience. Every semester we have students reporting that they used the code they wrote for their assignments for their job or research, so we think we are on the right track! CS6601 is special. It is the foundational course and textbook for the Intelligent Systems PhD qualifier exam, for which I supervise the grading. Students take this course with me and 2.5 years later have to answer researchy questions based on their exposure to material from this book (and all their other reading/experience for the qualifier). Six years ago I vowed to myself to do a better job preparing them. Agreeing to do OMSCS is part of that process, as these PhD students can refer back to the videos and assignments while they prepare for their qualifying exam. Hopefully, my goal of providing a good knowledge base of the PhD qualifier also means that students in OMSCS6601 get a good grounding in AI. We teach the same material on-campus and on-line, with on-campus doing peer learning sessions in class on the same challenge questions we are posting on-line. I believe that peer learning in-class really helps students understand the material, and I encourage on-line students to pair up and discuss the challenge questions as well.

[possible missing text?] yet, I'm afraid, but we definitely *are* paying attention to suggestions on how to improve things. For example, based on feedback last year, the challenge question discussion at the end of the Search lesson is now improved and foreshadows some of the discoveries that should happen in coding tri-directional search.

Time balance: Finding the right time balance is difficult, and we've been tuning the workload. Here is the amount of time on-campus students said they spent on the identical course last semester:

0-3 3-6 6-9 9-12 12-15 15-18 18+0   3   7   22   18    16    17
On-line students often report higher numbers.

In undergrad, each credit hour should equal 3 hours of work a week. A 3 hour class should average to 9 hours of work, including lecture. But grad school is different. For a normal 2 year Masters degree, I advise my students to take a max of 2 ""real"" classes a semester and focus the rest of their course credits on research in order to get the maximum out of their experience. These are full-time students, generally without jobs. For those of you doing 2+ OMSCS classes while living in the real world, I don't know how you do it! (BTW, OMSCS students *can* do independent study with a professor - called an ""8903"" - in fact, much of the anti-plagiarism software is being written by OMSCS students doing independent study with me). Use the class schedule to help pace yourself and know where you should be for each week of the course.

OK, now that we have the administrivia out of the way, let's get started with the fun stuff! I fell in love with AI making a automatic player for a game called Isolation. Hopefully, in the next couple weeks, you will make your first AI that is ""smarter"" than you - an Isolation player that is better at playing the game than you are.

Game playing search is a special case of search, which is covered in the early chapters of the book. I would suggest reading all the search chapters to get a solid understanding of the topic before embarking on coding your agent.

', u'responses': [u'Thanks!']}, {u'text': u'Thank you Professor Starner.

For those interested here is a link to past qualifying exams.
https://www.cc.gatech.edu/current/doctoral/phdcs-qualifier/past', u'responses': [u'thanks!  good idea!', u'Wow, this is really interesting. For Ph.D candidates, is this THE exam? Or merely one part of a bigger examinatoin process?

Thanks,
Q.', u'There is a written exam and an oral exam. The student also has to provide a research portfolio that must include at least one publishable paper.']}]",,0.0,415.0,39,,How to succeed in OMSCS 6601,[announcements]
5ad7d42e0d63974e20c39066,"Assignment 1 Section 1 discussions go in this folder.

Important notes from our discussion below (please keep checking this):

 When our AI is tested, will it randomly be determined if they play as player 1 or player 2 for each game?
50% times- player 1 and 50% times- player 2. Strictly that way. The sequence is random though

",jc6w44hrp9v2ki,"[{u'text': u'Thanks. Assignment 1 isn't up yet though, right?', u'responses': [u'Minh, 
          This is the link to the class schedule, hope it helps.
https://docs.google.com/document/d/e/2PACX-1vQUknZ8qmSvxc5URif1APfBGA_OT1ngFycRQRAtFXr6yaghuJrdjzMnObuVw4sux0J4lNiXqtS5IiGx/pub', u'Not up yet.', u'Assignment 1 is released. please check the @57', u'Thanks. What are the different sections for?', u'Please check on README']}, {u'text': u'Wanted to confirm few rules ::
1.In each move 2 queens will be moved at a time by player.
2.In the 2 queen isolation as each player has 2 queens . One queen of a player can be blocked by active position held by another queen of same player.', u'responses': [u'For question 1, I agree the readme is a bit ambiguous as it says

There are two players, four game pieces and a 7-by-7 grid of squares. At the beginning of the game, the first player places both the pieces on any two different squares. From that point on, the players alternate turns moving both the pieces when [aside from needing to specify player 2's opening move] it should have either said both of the player's own pieces, or all 4 of the pieces. It's relatively clear that it must have meant to say both of the player's own pieces, as when you look at isolation.py, particularly Board.get_legal_moves() & Board.get_opponent_moves() you see that either player moves its own 2 pieces

For question 2, it would be the normal effect, that a current or preceding location blocks the board at that location. Clearly there would be no mileage in a newly moving piece from the current turn blocking its fellow during the current turn, as you could simply transpose the 2 moves; similarly 'swapping' [similar to castling] or 'block & jump' could simply be reordered to 'no collision, go opposite ways' or 'move then block behind' respectively, etcetera', u'Atharva- Yes to both. 
Mark- You can check working by actually playing with Random player.']}, {u'text': u'1. I understand we can't write code outside of the classes. Can we import functions from the python standard modules for use inside our classes?
2. When our AI is tested, will it randomly be determined if they play as player 1 or player 2 for each game?', u'responses': [u'1. You can use python modules.Use of numpy skipy isnot allowed. Quickcheck- check all your libraries should not be installed on server. We are not installing other libraries. So you can use all the functions in already given imports. If any confusion about any particular library- please ask!
2. 50% times- player 1 and 50% times- player 2. Strictly that way. The sequence is random though', u'Thanks! Also, will a new CustomPlayer() be instantiated for every game or will it be the same object playing multiple games? (There is a value internal to my class that will be updated during play. If the same object will be used for multiple games I will have to come up with a way to reset the value at the end of the game).', u'Good question- New CustomPLayer for every game.
']}, {u'text': u'Submission script failure:
I was just testing if I could submit random output and got the following error: ""Username and password failed (do you use two-factor?)""

I do use Duo 2FA to access GT resources. What should I do, as 2FA cannot be disabled.
', u'responses': [u'Linking your solution post here for easy reference @67']}, {u'text': u'w.r.t. OpenMoveEvalFn:

Note 2: indicates to take into account overlaps. 

Assuming an empty board and the Queens are called '11' and '12', is the following a correct analysis.

I place Q11 in center. She has 24 open moves before Q12 is placedQ12 is place at (0,0). This reduces Q11's moves by oneQ12 has 14 open movesThere are 6 overlaps (indicated in red circles) where both Q11 and Q12 share the same open move

Thus my total open moves for this board is 31. Is this analysis correct?

', u'responses': [u'That is what I am thinking too.  It makes sense to me.  Hopefully, someone who is sure will chime in. 

I am also curious what is meant by this hint:
""Be very careful while doing opponent's moves. You might end up reducing your own moves.""
This algorithm seems pretty straight forward whether calculating the opponent moves or your own.  How could I reduce my own moves?', u'Not sure about that either. 

I think we're supposed to return #myMoves - #opponentMoves

I haven't thought it all the way out yet, but I would think that #opponentMoves would use something similar to what I have above, but there may be some additional 'overlaps' between the two sets of moves that additionally needs to be pruned prior to returning a score.
', u'Yes as phillip said its #mymoves-#oppMovesHowever, your myMoves seems correct. Hit Bonnie to check the answer!', u'I'm passing the Bonnie test. Is it safe to assume that the Bonnie test is fairly comprehensive? (e.g. that Bonnie tests several different cases including potential edge cases before issuing a 'pass')

The JSON file doesn't give any indication of the number of tests performed.

The reason I ask is I'd like to be somewhat sure that my function is correct rather than find out much deeper into the assignment that it had some basic flaw that wasn't caught by Bonnie. (I don't expect a guarantee from Bonnie, but it would be nice to know that it at least passed several test cases.)', u'Bonnie is there to play with our players. It might not cover all the edge cases. 
However, your marks against bonnie for last submission are final. 

For OpenMoveEval- if you are getting full points for that - you are good', u'Hi Kshitish,

Are we sure that Bonnie is calculating correctly? For instance, for the test that is included in the local code, that I think Bonnie anticipates -3 as the answer to, it looks as though it should be -1?

own_moves
{11: [(1, 1), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (0, 1), (0, 2), (0, 3)], 12: [(5, 6), (5, 5), (6, 5), (5, 4), (6, 3), (4, 6), (4, 4), (4, 3), (4, 2), (4, 1), (4, 0), (3, 6), (3, 5), (2, 5), (1, 5), (0, 5), (3, 4), (2, 3), (1, 2), (0, 1)]}
[['Q1', '11', '10', '10', '00', '01', '00'],
 ['10', '10', '01', '00', '00', '01', '00'],
 ['10', '00', '00', '01', '00', '01', '00'],
 ['10', '00', '00', '00', '01', '01', '01'],
 ['11', '01', '01', '01', '01', 'Q2', '01'],
 ['10', '00', '00', '00', '01', '01', '01'],
 ['10', '00', '00', '01', '00', '01', '00']]
n_own_moves 28 + 2 duplicates = 10 for Q1 + 20 for Q2 = 30
opponent_moves
{21: [(1, 5), (2, 6), (1, 4), (2, 4), (3, 4), (4, 4), (5, 4), (6, 4), (1, 3), (0, 5), (0, 6), (0, 3), (0, 2), (0, 1)], 22: [(3, 3), (4, 4), (5, 5), (6, 6), (3, 2), (4, 2), (5, 2), (6, 2), (3, 1), (4, 0), (2, 3), (2, 4), (2, 5), (2, 6), (2, 1), (2, 0), (1, 3), (1, 2), (0, 2), (1, 1)]}
[['00', '10', '11', '10', 'Q1', '10', '10'],
 ['00', '01', '01', '11', '10', '10', '00'],
 ['01', '01', 'Q2', '01', '11', '01', '11'],
 ['00', '01', '01', '01', '10', '00', '00'],
 ['01', '00', '01', '00', '11', '00', '00'],
 ['00', '00', '01', '00', '10', '01', '00'],
 ['00', '00', '01', '00', '10', '00', '01']]
n_opponent_moves 29 + 5 duplicates = 14 for Q1 + 20 for Q2 = 34
n_net_moves = 28 - 29 = -1', u'Wait. you mean is there a same board in Bonnie? No. We have different boards there. Otherwise people will hardcode the answer. ', u'The first result from Bonnie's test of the OpenMoveEvalFn() returns the result from our own code; it seems to correspond precisely to the result from the local test', u'Wait, it seems to work now, as though it had been fixed :-)', u'Hmmm i didnt change anything. Anyways nice!', u'I'm not complaining :-)

However, I hear the people from PEP8 may need to have words with you at some stage :-D', u'Hi, I have question about the above way of calculating my moves,

Consider
Q1 has 7 Unique moves
Q2 has 1 Unique move move
So total = 7 + 1 = 8

But for opponent 
Q1 has 3 moves
Q2 has 3 moves
Total = 3 + 3 =6

Based on the above way eval function would return 2. But does player 2 have high probability to stay in the game as player one's Q2 cannot stay for more than one game?

']}, {u'text': u'w.r.t to README regarding Section 2 and 3a, it says ""Your AI defeats an agent with OpenMoveEval""

Does this mean that for these three parts we need to use the (#myMoves - #opponentMoves) that we're trying to solve in section 1a for our agent as well?

Or only that the AI we'll be tested again will be using the correct (instructor) implementation of OpenMoveEval and that we're free for Sections 1b, Section 2 and 3a to use either our CustomEvalFn or what we come up with for our Student version of OpenMoveEval??My assumption is that for Section 1b & higher we're free to use our CustomEvalFn if we prefer it to OpenMoveEval.', u'responses': [u'Yes. You can use Custom Eval starting from Random Player itself. For starting point we have given MyMoves-OpponentMoves. ']}, {u'text': u'How to identify whether our AI is the player 1  or player 2 .

From the keys of board.get_legal_moves()?', u'responses': [u'Our algorithm should be aware of the the player type so as to apply the logic (min or max) accordingly (mentioned during office hours).

One way to know it is to get the active player from the game board and check for its instance to be of type CustomPlayer.', u'But if we're playing against Random Player, the custom player code will only be called for the AI, right? In that case we can always apply max logic i think.', u'The CustomPlayer() will need to apply max and min logic while traversing the game tree. The players move function will only be called when it's the players turn. So you know to always start out maximizing and alternate max/min while going down the tree. ', u'I would think that using the boolean ""maximizing_player"" that is provided in the function signature would tell you if you are the max or min.', u'Right. But since the minimax function is called recursively (which is the easy way) you'll have to flip the value of that variable on subsequent calls.']}, {u'text': u'For beginning to implement minimax/alphabeta, I'm confused on exactly what to do with the time_left() function.  Do I need to be constantly checking this function to make sure I return before it returns 0?  Like, if I'm implementing iterative deepening, and I'm halfway through a particular depth level when the timer is going to run out, do I need to return right then and then or I will lose immediately?  How frequently do I need to check to make sure I return on time?', u'responses': [u'It completely depends on you. When and how many times you have to check the time. For alphabeta and minimax- ideally - the algorithm doesnt use timeout factor in it. In iterative deepening we check the time. However, to beat our players, especially the last two you need to use timeout wisely', u'Am I doing something wrong if my program consistently times out for minimax and alpha beta for the first move with a depth of only 1?  I've tripled checked my algorithm and it seems correct.  I was under the assumption that just to beat RandomPlayer consistently I wouldn't need to implement any of the extra features (my own eval function, iterative deepening, checking for symmetrical boards, etc. but it doesn't seem like I can even successfully search a depth of one without at least some kind of additional features outside of the basic alpha beta algorithm.  Is this true or do I need to take a look at my code to see if I'm potentially doing the algorithms wrong?', u'Yes. Its expected behavior right? The branching factor for first level is very very high (i have discussed this in youtube live). You need to handle this issue. ', u'I think I underestimated just how large it really was, thinking that as long as I didn't go too deep (like to level 3 say) the exponential growth wouldn't be too much for the computer to handle.  Obviously I was wrong, as adding some hardcoded cases for moves 1 & 2 made my solution not only pass section 1, but also section 2.  Thanks!']}, {u'text': u'I am having hard time understanding relationship between score() method of OpenMoveEvaFn class and move() function of CustomPlayer(). During game play, move() method of CusomPlayer will be called, but not getting how it will use the score() method to determine the next move (in order to defeats a random player >= 90% of the time.)

It is easy for section 2 (using minimax algorithm) and section 3 (using alphabeta algorithm) to determine the next best move but what to use for section 1?', u'responses': [u'OH. wait. So you need to design minimax and alphabeta to beat RandomPlayer. RandomPlayer test is given to check whether your player is functioning okay. Normal minimax and alphabeta should definitely beat Random Player. ', u'So you are suggesting to implement ""normal"" minimax / alphabeta for section 1? Still not getting what needs to be implemented in move() function for section 1 of the assignment.', u'Yes. Section 1 Random Player is given for testing if your algo is working fine. ', u'Inside move- you are calling either minimax or alphabeta or any other function (like iterative deepening)']}, {u'text': u'Kshitish, can you confirm that we can not use numpy? What about itertools?
Is there a reason as to why we can not using these libraries?', u'responses': [u'No numpy. Itertools yes. 
Numpy is used in some assignments. There we will explicitly mention it.', u'Just for my understanding, why can we use itertools, but not numpy? I dont understand the reasoning behind placing such constraint?', u'Most of the run time in these codes is manipulating the board state. If you use numpy, you can be much faster (and have a better player) without really implementing a better search algo. I think the assignment goal is to teach us about the search strategies, not low level code optimisation. Hence, we are writing code in a simple, but slow language (Python), without low level acceleration.
itertools is probably accepted because one cannot have a python install without itertools since it is part of the standard library. ', u'That would make sense. Thanks. (Though would have preferred both elements, algorithm and optimization, allowed to influence the outcome!)', u'What Jonathan says is correct. Just to clarify: we do allow you to make simple optimizations to eval functions if you wish (some students like to do that for the botfight), but not the use of numpy, as that would skew results greatly.']}, {u'text': u'for the next move state, do we need to consider (q1,q2) and (q2,q1) results in the same board state? and only consider one of these scenarios?', u'responses': [u'I am not getting you.. please elaborate', u'Lets say Q1 has 2 legal moves as (0,1), (0,2), Q2 has 3 legal moves (1,0),(0,1),(0,2).
So if Q1 chooses (0,1) and Q2 chooses (0,2) for next move, there is a new board state
what if Q1 chooses (0,2) and Q2 chooses (0,1) for the next move, there would be the same board state or not?

', u'There would be new board state right? What we are checking here is - what is the eval function at that board state. As in which state is betterI cant go in further details. ']}, {u'text': u'after submission, I got following error
TypeError: __init__() takes at least 2 arguments (1 given)
I did not change any function signature.

However, in the class CustomPlayer it has
def __init__(self, search_depth, eval_fn=OpenMoveEvalFn()):
and it was used in player_submission_test.py as
h = CustomPlayer()

should I remove search_depth?', u'responses': [u'or add a search depth like:
h = CustomPlayer(3)
', u'I got the error when I did python submission.py.
There is no place for me to do CustomPlayer(3) ?', u'Just set a default value for search_depth in the CustomPlayer.__init__() args', u'You actually have to set search_depth=<something> in __init__, since the server tests call an empty CustomPlayer().']}, {u'text': u'Assignment 1 - Section 1
Are we suppose to implement minimax in order to beat RandomPlayer test in section 1 or rather just OpenMoveEvalFn? Thank you.', u'responses': [u'', u'OpenMoveEvalFn is relatively useless on its own.  You can asses the value of any given board state, but you need a minimax of at least depth 1 to pick the max state.']}, {u'text': u'Okay so this code is a bug I think in given code:
def utility(self, game, maximizing_player):    """"""Can be updated if desired. Not compulsory. """"""    return self.eval_fn.score(game)
Should be:
def utility(self, game, maximizing_player):    """"""Can be updated if desired. Not compulsory. """"""    return self.eval_fn.score(game,maximizing_player)

In given code of CustomPlayer
', u'responses': [u'Nope. With Python, you can pass a subset of arguments and set the others to default.

maximizing_player_turn is being defaulted to True:

def score(self, game, maximizing_player_turn=True):
', u'This is not resolved. If you don't pass the argument then the variable has no value being passed. So, by not passing the variable it will never get called as we are supposed to use utility to get the score. ', u'I think what Brett is getting at here is that the maximizing_player param is not being passed through to the eval function. So when minimize calls eval() it is going to use the default value for max. So the eval will always use maximizing_player=true', u'Yes. There should be max player parameter if you are using utility function. ', u'Aha! I thought it was about initializing the function argument. Yeah, this parameter should be passed across the execution flow.', u'But, only the AI will be calling the utility function, so in this case, where does maximizing_player_turn argument come into play in the utility function?
My understanding is that the openMoveEvalFn always returns mymoves - oppmoves, and we only use maximizing_player to decide whether to take minimum value or maximum value amongst the nodes.

Please correct me if I am wrong, because i'm not getting correct results.', u'@Parth
I have the same question as you. Did you figure this out?

Thanks!', u'When you walk down the depth of the simulation (e.g. if your starting depth is > 1) and you are using a move simulation that updates the board to reflect the simulated moves (e.g. using forecast_move()), the active player will change with each move down in the tree and the evaluation of the board differs depending on who the active player is.

For example,

isolation.py calls your CustomPlayer.move(). move() calls minimax (or alphabeta or whatever other function you're going to use)
at this point it's your move.   the active player is your player. So you typically make a move. If your at the bottom of your depth, you will typically evaluate the board as it exists after the move.  If you make the move using game.forecast_move, the active player will be your opponent. If you evaluate this board, you probably want to take that into account.if you are not at the bottom of your depth, you will probably call yourself (minimax again) and this time when minimax is called, it is evaluating the board as your opponent (what we would call a minimizing node).


So you need to evaluate the boards differently based on whether it's your move or its your opponents move (it will always be your move when your move() function is called, but when you walk down further in the tree, the party that is moving will go back and forth depending on who moved last in your simulation).']}, {u'text': u'I have the OpenMoveEvalFn working and passing in Bonnie, but I'm unsure if I took the naive approach here.
My code is always assuming that get_legal_moves() always equates to the AI, and get_opponent_moves() equates to the other player. Looking at the code, it looks like that relates to the ""active player"" and ""inactive player"" respectfully. 

Are we assuming the active player is always the AI? I saw a comment somewhere about checking the instance of the active player. So if the active player is not an instance of our class, then we are the opponent. 

Is this correct logic?', u'responses': [u'Upon further inspection I see that they are being swapped after a move is made. So we are always effectively going to be the active player. I think the instance checking comes up later when determining something else that I haven't quite figured out yet.', u'I used the same assumption, I think it is the correct way to go (I passed in Bonnie as well). Still trying to wrap my brain around everything to see how this all fits together. I actually wrote my own version of get_legal_moves last night before realizing it was provided :( ', u'Hey guys! Here is my take -
1. Yes. Yours will always be max player. 
2. BUT- if you are doing minimax- you will do a max level- then you will start with min level.. But how are you going to go for min level? One way as I said in youtube live is- use forecast move. What does forecast move does- it creates a new board and changes active player to inactive. So now you are min player right? This explanation is only valid if you are doing algorithm in this way. ', u'Thanks for the response. I was looking into using that forecast.
Is there a recording of that youtube live? I was at work and not able to watch it.', u'Same link @68']}, {u'text': u'What constitutes a move? From the second example test in player_submission_tests.py, we are setting move count to 4 for placing four queens.

b.move_count = 4

However, during the play, we increment move count based on player's turn (counting the active player's two queens as one move)

self.move_count = self.move_count + 1

Is this correct?', u'responses': [u'Yes', u'Maybe I was not clear in my question. Both of them are conflicting or am I missing something?', u'Okay. So in that example- We have already done that many moves. So we initialized count to 4. Even if we dont do that and say its first move - it is fine for that example. ', u'Got it. Thanks Kshitish!']}, {u'text': u'Do we even need to use the maximizing_player_turn option present in the OpenMoveEvalFn? My understanding is that it will always give us #mymoves - #opponentmoves, so we need to change anything.

The only change will come where we are using minimax, because there we need to either take the minimum value of the child nodes or the max value of the child nodes.

Please let me know if my understanding is correct.', u'responses': [u'Please check my reply above. Putting it here again-
""1. Yes. Yours will always be max player. 
2. BUT- if you are doing minimax- you will do a max level- then you will start with min level.. But how are you going to go for min level? One way as I said in youtube live is- use forecast move. What does forecast move does- it creates a new board and changes active player to inactive. So now you are min player right? This explanation is only valid if you are doing algorithm in this way. 
""
So you might need that parameter if you design the algorithm in that way', u'Yes, i understand that we need to play each level as AI and the opponent alternatively, and we can use the maximize_player argument of minimax to decide whether to take the max or min of the child node utilities. However, I am not able to understand what is the purpose of maximizing_player_turn in the utility function, because the score calculation of a particular board stays the same irrespective of who is playing.

', u'Yes. But what if you are winning or losing. What will you return. And how will you decide that who is loosing. 
This is the thought of giving maximizing_player_turn parameter. But if you have designed the algorithm such that you can do it without the parameter- ignore it. ']}, {u'text': u'I implemented a version of minimax function for Section 1 part 2. I am able to get the computer player to win in most cases for the first 2 test cases in player_submission_tests.py, where move_count is 4. However, on the 3rd test, where the board is not filled with first 2 moves by each player, i.e. move_count of 0, the program ends up timing out. I am able to make first move by computer player, i.e. move_count of 2, and board size of 5x5 and complete in time, but for 7x7 with move_count of 2, the program takes long and times out.

What am I missing? Any hints?', u'responses': [u'Yes. This is somewhat expected behavior. Check my discussion on youtube live about timeout. The branching factor is huge. It might get timeout at first move itself. So use some strategy to reduce time per move or simply randomize first few moves. 
It depends on you how you want to design the agent. ', u'I was having the same problem. I solved it (at least for the vanilla minimax) by increasing my time_left threshold.']}, {u'text': u'It's not yet clear to me what this note means in ""OpenMoveEvalFn"":
""Be very careful while doing opponent's moves. You might end up reducing your own moves.""
If all I have to do is just MyMoves-OppMoves, then the above warning doesn't make much sense to me.
But I practically just got started, I'll just leave this question here and if I figure it out I'll comment back.', u'responses': [u'I believe that it has to do with if you are using OpenMoveEvalFn to evaluate the movement score for the next level and you are using game.forcast_move() to generate the board for that analysis, the current player and the opponent will change after the move (e.g. if you move your queens, then the current player will be your opponent).  You have to keep this in mind when you evaluate the score (you typically want *your* score, not your opponents score).', u'Conor is correct. I have discussed this in Youtube live.']}, {u'text': u'I just noticed the following line in the project description:

You may not create additional external functions and classes that are referenced from within this class

Does this actually mean that we cannot add any new functions or classes anywhere in player_submission.py? For example, we could not create a Tree class in the player_submission.py file to help with our minimax structure? Or is it saying not to create any new files outside of player_submission.py?', u'responses': [u'I don't believe you need a tree structure for your min-max as the values should flow up through the recursions and return values.  But I can't tell you exactly what the restrictions are.', u'While Conor is correct that you don't need a tree structure, I don't believe it restricts you from making helper functions within player_submission.py to make your code cleaner especially if you're reusing the same logic in multiple places. Instructors, please correct me if I'm wrong.', u'Yeah I guess it's probably best to just stick with the pure recursive implementation since that's what the minimax function signature seems to be asking for anyway']}, {u'text': u'Clarification regarding the ""score"" function:

The number of moves is the number of unique combination of moves that the two queens can currently perform?  For example, if it is the opening turn, would {11:(0,0),12:(0,1)} be considered a different move option from {11:(0,1),12:(0,0)} or would they be considered the same for the purpose of counting the number of available moves?', u'responses': [u'These are different moves. Your queen 1 and queen 2 are individually different. However- you might use some strategy of your own. But for OpenMoveEval consider it different', u'So for a 2x2 board, the following possible opening positions would actually constitute 12 potential moves, not 6?

', u'But only 2 unique moves. That's the more important distinction.  (0,0) and (0,1) and (0,0) and (1,1). All other moves are reflections or rotations. Since it doesn't matter if Q11 or Q12 occupies either piece, you really only need to evaluate the two moves.']}, {u'text': u'Is any one else seeing this (on windows)

Winner: <player_submission.CustomPlayer instance at 0x05717A80>

', u'responses': [u'Yes, I see the same when computer player wins. I believe that is as expected.', u'Yes, this is expected. This means custom player (AI Player) won the game.']}, {u'text': u'I am able to get the computer player to win > 90% of times for section 1 using the minimax function I have currently. I make the fist 2 moves of the computer player based on legal moves available in move function as suggested as strategy in earlier thread. The rest of moves use minimax. All three test cases pass locally and as mentioned > 90% of time computer player ends up winning. However, when run against bonnie I get a success rate of 35 percent or win ratio of 0.35. What is different between the local random player moves and bonnie random player moves. Are they not the same? Why am I getting a success ration of 0.35 against Bonnie?

Please note that in my local tests the Computer player is always player 1 and Random Player is player 2 when creating the board. Is this a good assumption to make when running testings remotely?', u'responses': [u'I believe one of the differences is that on Bonnie, you sometimes make the first move rather than the second move -- at least I have seen it reported that half the time you are player 1 and half the time you are player 2 (though not officially written anywhere).  ', u'Yes. 50% player1 is your player and 50% your opponent. There is no difference in random player from local test and Bonnie (Copy-pasted). ', u'Thanks. I made some changes to eval function which enables custom player being player1 or player 2. I still see my agent fare way better locally than on Bonnie. Need to figure why..', u'Hi Aravind.  Did you resolve this issue?  I am seeing the same thing.  Locally, I have been getting 20/20 wins as player 1 vs the random player and 20/20 as player 2 .  However on Bonnie I can't get better than 20%.  I'm in the process of moving my work to a linux virtual machine to see if that makes a difference.  My local setup is in Windows right now.', u'Hi Aravind.  After a lot of pain, I was able to match the Bonnie failures with my local results by looping the game runs in a FOR loop in the test file.  I had to set up a loop in the test file so multiple games run back-to-back.   Memory was remaining in my CustomPlayer class from the previous game.  Making sure the game started from a clean slate fixed my problems.  
']}, {u'text': u'I noticed with correct utility value my AI wins when it moves first.  However, when it moves second, it frequently loses to random player.  If I multiply the utility value by -1 then AI wins when it goes second and loses when it goes first.  Any one seen this behavior or have any hints as to why?', u'responses': [u'carefully check and use maximizing_player_turn / maximizing_player parameter.', u'Hi Rajan I had that thought too.  When I submit with Bonnie my custom eval fn gets 5/5 points which suggests my eval fn is fine.  So I'm not sure using maximizing_player_turn there will help.  However maybe in the minimax class..', u'yes, you are going in right direction. Think about minimizing player.', u'Be careful here... maximizing player is not about player1/player2.   It is about whether it's your turn or not *in your simulation*.  They will never call you for a minimizing player move, but you may call the evaluation function after you've simulated you making a move (in which case get_legal_moves will return the moves for your opponent since you went last) and you may call yourself after you have simulated *them* making a move (in which case get_legal_moves will return the moves for yourself).

The basic evaluation tests just verify that you score the board correctly.  They don't test whether or not you are doing anything different for when you've made a move or they have made a move -- that is only needed for your minimax/alphabeta simulations evaluation.

When you are evaluating the board in your simulations you always want to know what the score of the board is from *your* point of view.   If you're on a maximizing node, you will pick the maximum value from your child nodes.  If you're on a minimizing mode, you will pick the minimum value from your child nodes (since they would obviously want to make the move that gets you the worst score).', u'Great. I cant describe the situation better than Conor's reply and Rajan's reply. Please follow that', u'Thanks for the hints. Looked back again at my evaluation function even though I got 5/5 on this in the beginning. Made sure I was using active player and inactive player variables from the game. Now, it doesn't matter if CustomPlayer is player 1 or player 2. In either case using minimax I am getting custom player win >90% locally. But, remotely I still see timeouts reported. Need to see what else I can optimize. May be more initial moves without minimax..? ', u'Finally made it past bonnie for section 1 :-)']}, {u'text': u'With a bare minimax implementation (no opening book), I'm getting timeouts quite early, even for a search depth of 2. 

How are other people faring with timeouts using minimax?', u'responses': [u'I'm getting same for bare MiniMax, particularly on early moves of the game. 

I can't see how one can examine 7x7 state space for moves 1 to 4 using just MiniMax and making it much past depth 2.

It seem like game.forecast_moves() which I use to generate successor states used almost all the run time when I profile it in PyCharm. I can't figure out a way to avoid using forecast_moves to explore each new move on a level.', u'It is expected that in the early moves you will get a timeout if you try to exhaustively evaluate all of the paths (there are too many possible combinations to evaluate, especially if your minimax function isn't super efficient.     You will need to adjust things -- perhaps by having some opening book moves, perhaps by using randomness if the options are too many, perhaps by using iterative deepening, or, of course, perhaps all of the above.', u'Yes. Timeout is an issue which you need to handle. ', u'Regarding opening book. Are you just developing them intuitively? It's not practical to simply let the minimax or alpha beta explore a single move to end game. (even with all the time.)

I have a intuitive sense of what would be a good opening move if Player 1 and an ~okayish~ sense of what might be good moves to explore if Playing as Player 2 at game open, but they're more intuitive than deep-search based. 

Using reflections/rotations, I can reduce my Player 1 First move down to 132 possible moves to explore (down from 2352 in a naive implementation), but still, trying to search 132 possible opening moves to end game doesn't seem feasible.

If going as Player 2 (meaning my first move opportunity is on Move 2 of the game), then my open search space balloons back up to over 2000 as it there are fewer 'reflection'/'rotation' moves that can be culled. (At least so far as I see it right now. More though may need to go into this.)

So at end of day is an opening book mostly just gut instinct?? Or is there a clever way to find a really good, reduced set of option?', u'Developing a good eval function or opening moves is your instinct. However, to understand it more you can see how your player is losing. By playing which moves your player losses at start. Or which moves are taking a long time. I not saying to do this checking at runtime. Just playing locally']}, {u'text': u'For each step in MiniMax should we be looking at each possible combination of moves available to (q1,q2) or should we be doing something more efficient?

For example is q1 has 3 legal moves 1,2,3 available and q2 has 2 legal moves 3,4 available:

Our miniMax should iterate through (3*2)-1 legal moves (q1,q2):(1,3),(1,4),(2,3),(2,4),(3,4)?

I ask because this seems like the MiniMax tree would blow way worse than when both players just had 1 queen each.', u'responses': [u'If you were playing, would you only consider some moves or would you want to consider all possible moves?  That should drive your answer.

Of course when the combination gets too many you need to use something else to make the choice because an exhaustive search, especially with depth > 1, will take too much time.  Think opening moves.  Think falling back on randomness.']}, {u'text': u'Hi, Please confirm the requirement for assignment section 1?

1.Implementing just  OpenMoveEvalFn?
2. When OpenMoveEvalFn is called have both player made at least one move? or should we consider empty board too? 
', u'responses': [u'Section 1 of assignment consists of two parts which are submitted through submit.py file.

1) OpenMoveEvalFn - In this you need to finish score function. This should consider both players. It has to work with all the possible positions of board.
2) Minimax - Basic minimax algorithm. In which your player has to win >= 90% against RandomPlayer']}, {u'text': u'Is it a typo?

RandomPlayer move() function in test_players.py is

if not len(legal_moves[game.__active_players_queen1__]) and not len(legal_moves[game.__active_players_queen1__]): return None,None
Should second check be for queen 2

if not len(legal_moves[game.__active_players_queen1__]) and not len(legal_moves[game.__active_players_queen2__]): return None,None
', u'responses': [u'Yes, I think so too. But, it doesn’t seem to affect the outcome of the game.']}, {u'text': u'Is the following a legal move:
player1 0.Queen1: (1,4)Queen2: (4,3)  |     |     |      |      |   |     |     | 22 | 11 |   |     |     |  -- |      |   |     |     | 21 |  -- |   |     |     | 12 |      |
player2 0.Queen1: (2,2)Queen2: (3,1)  |     |     |      |      |   |     |     |  -- | 11 |   |     | 21|  -- |      |   | 22|     |  -- |  -- |   |     |     | 12 |      |

In words, is it ok for Q2 to hop over Q1 in the same move--or do they move in sequence, and if Q1 blocks Q2's path Q2 can not go past Q1?
', u'responses': [u'That should be a legal move, but I don't know if __apply_move__ is smart enough to handle that.', u'Looking at the code for play_Isolation and __apply_moves__, it checks that both moves are legal moves before making the move then moves the two queens without checking again to see if the move is legal in between the move, so that move would be legal and the game would allow it (assuming I'm reading the code correctly, of course).', u'thanks, that checks out with my reading of the code too--wasn't sure if that was intentional though', u'I am getting a positive value for ""num_invalid_moves"" from Bonnie which I can not reproduce or induce locally; is there any insight into what these invalid moves might be?
', u'invalid moves on bonnie are when you have no moves and thus have lost the game.', u'ok, I'll file that in the poorly named variables category and move on. :)']}, {u'text': u'From reading the 2 Queen's isolation game, my understanding is that during one turn both queens are moved by player1 then player2 moves both his queens in one turn. Is that correct?', u'responses': [u'Yes.']}, {u'text': u'Definitely better than RandomPlayer: 0.00/30Test output of OpenMoveEvalFn: 5.00/5

Does this means, my OpenMoveEvalFn is good? I need to just concentrate on my Random Player?', u'responses': [u'Yeah you should work on your minimax/alpha-beta pruning. Check the contents of the JSON for any hints on what might be wrong. I.e. if you timed out.', u'Just FYI... you may still need adjustment on your OpenMoveEvalFn  to get it to work correctly in your minimax.  Bonnie is telling you it is scoring a board correctly but bonnie isn't testing that your function knows how to deal with the fact that you may simulate moves by bot you and your opponent.     This was discussed in more detail in some of my responses in @40', u'[edit] wrong post']}, {u'text': u'Seeing how much time I have left:
If I print time_left I get something like this:
<function <lambda> at 0x10fc86668>

How do I translate that into something readable or comparable to exit out gracefully.', u'responses': [u'it's a function, use parenthesis', u'Thanks, showing all my python weaknesses here.']}, {u'text': u'When I run submit.py, I get the following output after waiting for ~30 minutes:
Uploading submission...[=========================== 100% ===========================] 12430/12430
Waiting for results...Done!
Results:--------""Clyde failed to process the job.""Could this be an issue with my player_submission.py, or might it be a server-side issue?', u'responses': [u'What does it have on bonnie.udacity.com for this run?', u'bonnie.udacity.com seems to be timing out for me when I try to access it via browser. I, however, did manage to get past the issue after resubmitting. I reduced my time cutoff per turn from 9.5 seconds to 7 seconds. Thanks for replying!']}, {u'text': u'Hi, I am trying to build the basic minmax algorithm. The one thing i noticed , For 2 queen isolation, there 49C2 ways we can position two queens in initial board. From level 1, we may have slightly less options and but branching factor is still high. I am not sure whether it will will complete the search even for two levels. Am i missing something, Can someone clarify?

To get possible branches i am generating permutations of queen 1 and queen 2 moves removing duplicates from queen 2. 
Queen 1 legal moves = [(1,2), (1,3)]
Queen 2 legal moves = [(2,3), (2,4)]
Possible moves to branch = [( (1,2), (2,3) ) , ( (1,2), (2,4) ) , ( (1,3), (2,3) ), ( (1,3), (2,4) )] ', u'responses': [u'The guidance from the Kshitish in office hours and on piazza has been that you need to adapt things for the earlier moves (using open moves, using randomness, limiting depth at that stage) because the branching factor is too deep at that stage to do deep analysis.', u'Correct']}, {u'text': u'Hi, When i run test locally, most of time i get the below message. What does this mean? Should i reduce my brach factor?

sample larger than population', u'responses': [u'You might try searching for that on google... lots of results that point towards something in the use of a random number generator (but I have never seen this from my running of the code provided -- so I would *guess* that this is from your use of the code).

You could also use a debugger to step through the program to find out where this is coming from.']}, {u'text': u'""Traceback (most recent call last):\n  File \""/home/vmuser_uaqbmlnj/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 102, in test_beats_random\n    self.evaluate_against(RandomPlayer(), 0.9)\n  File \""run.py\"", line 55, in evaluate_against\n    win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n  File \""run.py\"", line 32, in simulate_games\n    student_agent = CustomPlayer() # Force the reinitialization of the player after every game\nTypeError: __init__() takes at least 2 arguments (1 given)\n"", When i submit my code to bonie server i am getting
TypeError: __init__() takes at least 2 arguments . I think, this is not something we control?', u'responses': [u'It is... you need to set the default depth for your CustomPlayer.', u'So, should i set default depth like below?
def __init__(self, search_depth=2, eval_fn=OpenMoveEvalFn()):', u'Yes... If 2 is the depth you want to search in your minimax/alphabeta']}, {u'text': u'Considering my_moves calculation in the above posts

Q1 has 7 Unique moves
Q2 has 1 Unique move move
So total = 7 + 1 = 8
 
But for opponent 
Q1 has 3 moves
Q2 has 3 moves
Total = 3 + 3 =6
 
Based on the above way eval function would return 2. But does player 2 have high probability to stay in the game as player one's Q2 cannot stay for more than one game?
 
 ', u'responses': [u'The measure is a heuristic.  You can choose to make up your own heuristic to score the board.  Note that the cost to calculate the heuristic typically goes up as you add more smarts to it while with this heuristic, you would likely figure out in the next stage of depth that the first player would likely not have a successful move on their next turn (hence why depth is pretty important).']}, {u'text': u'Has any one got the below error when submit to Bonie server. Code running fine locally

""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_jqftlryu/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 102, in test_beats_random\n    self.evaluate_against(RandomPlayer(), 0.9)\n  File \""run.py\"", line 55, in evaluate_against\n    win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n  File \""run.py\"", line 36, in simulate_games\n    winner, move_history, termination = game.play_isolation()\n  File \""/home/vmuser_jqftlryu/workspace/isolation.py\"", line 260, in play_isolation\n    if curr_move_queen1 is None or curr_move_queen2 is None:\nUnboundLocalError: local variable 'curr_move_queen1' referenced before assignment\n"",

', u'responses': [u'just to confirm i set the default depth 3', u'Looking at the code in isolation.py, it seems that if you have an exception in your application other than an AttributeError, it will print the exception and then continue at which point it will run into line 260 before curr_move_queen1 is assigned.  See:

        try:
                legal_player_moves=self.get_legal_moves()
		curr_move_queen1, curr_move_queen2 = self.__active_player__.move(game_copy,legal_player_moves , time_left) #queen added in return 
                 
            except AttributeError as e:
                raise e
            except Exception as e:
                print e
                pass
            
            if curr_move_queen1 is None or curr_move_queen2 is None:

Is there something on the line above the traceback error you have?', u'Thanks Corner. You made my day., Your message helped me to identify the issue. Also I was able to summit the code with default depth one and go past 90% win rate.', u'How did you solve it... ?', u'Getting the same error. How did you solve it?', u'There should be something in the output above that statement that indicates the cause of the problem (the print e statement outputs the exception).', u'I've seen the same error. In my case it's because some error in CustumPlayer.move( ) that returns ""None"" to cure_move_queen1 in:
curr_move_queen1, curr_move_queen2 = self.__active_player__.move(game_copy,legal_player_moves , time_left)
', u'You should not get that curr_move_queen1 is not assigned before referenced if you return None (it is assigned the value None and that if statement on line 260 is actually checking to see if the value is None).   You could be getting other errors, but it should not be this same error.

None is a valid return and essentially means that you've lost.  Hence why the next line after the If which checks to see if either of the two move positions are None says that the inactive player has won.']}, {u'text': u'Hi, just for clarification: shall we use only minimax (w/o alpha beta) for Section 1? Or if our AI with alpha beta beats the random player, it will also count as an acceptable submission?', u'responses': [u'My understanding is that you can use either. 

Play is done by calling the 'move()' function. So within the move function you can choose to either just run minimax, alpha beta, or whatever else you desire.

In mine, I set a flag that I could change easily for testing purposes. 

If you use a custom eval function, also be sure to change the '
eval_fn=OpenMoveEvalFn() to eval_fn=CustomEvalFn()
in your players __init__ function. Also set depth to a default to avoid errors this is discussed else where.

Your init should look something like:

def __init__(self, search_depth=4, eval_fn=CustomEvalFn()):

']}, {u'text': u'Performance Evaluation

Given a 7x7 board and playing as Player 2 on Move 1, there are usually around 1081 unique moves for placing your two queens on the board after the opponent had started the game and play  a first move (47*46/2) = 1081

I'm curious to how many levels of depth you can make it.

I'm using alphbeta and iterative deepening and I can usually clear level 0 and about 500 moves of level1 if I choose to try and evaluate all 1081 moves.

I've done some heuristics to pair my opening move search down to about 250 moves as Player 2 Move 1.

On this reduced set (250 starting moves to evaluate), I can make it through level 0, level 1, about 10 to 30 moves into level 2.

Level 0 = my move
Level 1 = opponents respone
Level 2 = my next move,
Level 3 = opponents response, etc.

I'm curious as to how many levels of depth you can make it give an certain number of moves to evaluate.

i'm using a MacBook Pro i7 2.7ghz and no multiprocessing:

I'm getting roughly (early in game moves where there's more space):

1081 moves. -> about half way through level 1
250 moves -> just a smidgen into level 2
75 moves -> about 25% through level 3
40 moves -> almost all the way to level 5 (usually almost to the end of level 4)

I've been staring at my code for a long time and I can't figure out how to make it much faster. I'm using iterative deepening, so perhaps I'm spending too much of the time 'redoing' each search level. Has anybody found a clever way to cache an iterative search?? (I don't know that it is possible)

Profiling indicates that the vast majority of the time is actually spent in the 'get_legal_moves()' routine which is ridiculously expensive

Curious to know if I'm in the ballpark or way under performing in my code.', u'responses': []}, {u'text': u'While calculating myMoves, if queen 1 has 0 legal moves and queen 2 has 3 legal moves, what value should I use for myMoves while returning value for score of OpenMoveEvalFunc?
Should I use myMoves = 0 + 3 or myMoves = 0?', u'responses': [u'mymoves=3']}, {u'text': u'I submitted my section 1 and met 90 % mark. But After that i changed my file lot to meet Section 2. So my last section 1 score is final? , should i submit separate player_submission.py for each section?', u'responses': [u'If you've gotten full credit for one of the submits, you're good.   You're last run on bonnie is the recorded score for your submission. 

I just updated my player_submission.py between submissions and then pulled down the copy from bonnie that achieved score X so I can turn it in on T-Square (bonnie has a link for you to download the program that was tested).', u'Wait, where does it say we have to submit anything on T-Square? The directions just say to submit to bonnie and it uses your last run.', u'Look at the announcement for this week (@135).   They have also mentioned it in several posts here/there.

It's not mandatory, but as a backup.', u'Okay so I guess I can safely ignore if on Bonnie. Hopefully']}, {u'text': u'Question on homework 1.  Do we need to read the entire chapter 5 to be able to do the homework or is it only up to 5.3?  Thanks', u'responses': [u'What homework? Do you mean the assignment/project? Then no, you don't have to read to do the assignment but it would probably help as chapter 5 covers all the material you will need to solve the project. It is pretty time consuming so I would get started soon.']}, {u'text': u'So, I am going through my solutions to section 1. I am scoring a 5/5 on first part but I am not following the result to the letter. Is it okay the way it is or should I resubmit following the OpenEval rules to the letter? Mine has some special handling for terminal state and reverses score based on maximizing player. Just want to know if this is okay considering it scored a 5/5 on Bonnie.', u'responses': [u'As long as you have your 5/5, you are good.   Note that it is only the last score that counts (so if you run it again because you're working on the other points available in that part of the assignment and you change OpenEvalFn, it is possible that the score goes down -- so keep an eye on it).  Your grade is the score on the last run you made in bonnie in each of the parts (submit, submit_a and submit_b)']}, {u'text': u'Im getting a syntax error when running 'play submission_test.py'  

print 'OpenMoveEvalFn Test: This board has a score of %s.' % (h.score(sample_board))

can i change the syntax for this file?', u'responses': [u'never mind.  i was using python 3 env']}, {u'text': u'...', u'responses': []}, {u'text': u'Hey im pretty confused about how to calculate the overlap between opponent moves and your moves.  should that be done as well?  or is it enough to find intersection of opponent moves and subtract that from your moves?', u'responses': [u'never mind']}, {u'text': u'I keep getting the answer -1. is this what everyone got?  How do I hit bonnie?  sorry im new to gatech.  ', u'responses': [u'you hit bonnie by running the submit.py scripts. 
submit.py for section 1
submit_a.py for section 2
submit_b.py for section 3', u'This is covered in ""How to submit your code"" in the README.md included in the assignment.

Be sure to read that file as well as the setup.md.']}, {u'text': u'How do you know if you are player1 or player2.
Would it be possible to figure this out by tracking the movecount if movecount is 0 you are player 1 or if you see movecount as 1 you are player2', u'responses': [u'I figured this out by chaning the order in player_submission_tests.py', u'I use movecount.  If the first time I am called, movecount is zero, I am player 1.  Otherwise I am player 2.']}, {u'text': u'maximizing_player=True

What is maximizing_player arg in all the functions?  Are we supposed to do anything with this?
', u'responses': [u'You might want to search on maximizing_player in the search box to the left.  You'll find a number of references to it.']}, {u'text': u'When I run the local code for minimax, it keeps giving back the error 'AttributeError: CustomPlayer instance has no attribute 'time_left''. Anybody has the same issue?', u'responses': [u'make sure that you are passing the time_left lambda function all the way down to the place where you are trying to calculate the time remaining. then you can do time_left() to get the time remaining.', u'Do I need to add an argument in the initialization for the CustomPlayer?', u'This is probably because you are referring to time_left as a variable rather than a function.  Make sure you're using time_left() (with the parenthesis).']}, {u'text': u'For OpenMoveEvalFn, what am I missing here?

return (total number of q1 and q2 legal moves available for active player) - (total number of q1 and q2 legal moves available for inactive player)

In the player_submission_tests.py OpenMoveEvalFn test, I get
  ""OpenMoveEvalFn Test: This board has a score of -4.""

as a result from 30 - 34.  

', u'responses': [u'Are you possibly counting the same move for both q1 and q2', u'i merged q1 and q2 into the same list and converted to a set.  That eliminated any duplicate legal moves between them both.  That bettered the scoring slightly but still fails Bonnie.', u'Was able to resolve the issue.  Bad assignment of variables.']}, {u'text': u'I'm trying to get a vanilla minimax written as a recursive function. I'm finding that it's making a game tree successfully, but frequently returning illegal moves (trying to move through another piece, or not on the diagonal). I suspect what's happening is it's returning a 'best move' for depth 3, but the actual board is still at depth 0. So it's skipping ahead to the leaf move rather than making the next move that would go down the branch toward that leaf.

I'm trying to decide whether to:

1) Keep looking for some way to adjust my recursive function to return the correct score AND moves (hints appreciated!)

2) change the minimax() function to just return a score, rather than a score AND moves, and keep the first-round options in a dictionary in the calling function. When I get the score, I can look in the dictionary and choose the moves. I am not super comfortable with this option since it changes the requirements of the assignment.

3) go straight to iterative deepening, since that will only let me look one layer at a time.

Thoughts?', u'responses': [u'You should ignore moves from the lower levels and just use the move at the top level that achieved the best score looking down through the levels.

ID will still have this issue when you look at depth = 2 or depth = 3.  You want the best move at the top even though you're looking deeply down the tree.']}]",,0.0,430.0,40,,Assignment 1 Section 1 discussions,[a1]
5ad7d42f0d63974e20c39067,"I am new to Python and trying to learn the basics. So thought to share the links. Pls feel free to add to the list.

From ""Week 1 Announcement"":

A beginner’s guide
An interactive track in CodeAcademy

Others:

Udacity - 
https://classroom.udacity.com/courses/ud036
https://classroom.udacity.com/courses/ud1110

Coursera
Search link - https://www.coursera.org/courses?languages=en&query=python

EdX - from Dr. Joyner - Intro to computing using Python - CS1301 at GaTech
Search link - https://www.edx.org/course?search_query=python

My fav. - Lynda (free membership with GATech login)
Search link - https://www.lynda.com/search?q=python

Some great Numpy books (Every eBook & every video just $5 till Jan 17th)
https://www.packtpub.com/all?search=numpy



",jc6w44hrp9v2ki,"[{u'text': u'Good one. Thanks', u'responses': []}, {u'text': u'If you're a MATLAB user, this also helps a fair bit: http://mathesaurus.sourceforge.net/matlab-numpy.html
', u'responses': []}, {u'text': u'Thanks for the links. These should be useful.', u'responses': []}]",,0.0,280.0,46,,Python Resources,[python]
5ad7d42f0d63974e20c39068,"Could someone share printed syllabus and calendar?  Google service is restricted by Chinese government, I can't open the links which posted by instructor. Thanks!",jc6w44hrp9v2ki,"[{u'text': u'Curious, would a VPN service be a solution to that restriction? Might find myself in a similar situation soon. Thanks!
-Q.', u'responses': [u'There are ways of shutting down VPN access too, of course', u'So how would one maneuver through a restrictive location such as China? Not looking to do anything nefarious (haha), just OMSCS matters.']}]","You can also try to use the VPN provided by Georgia Tech.
https://faq.oit.gatech.edu/content/how-do-i-get-started-campus-vpn",0.0,260.0,47,"CS6601_Course_Schedule_Spring_2018.pdf
CS6601_Syllabus_Spring_2018.pdf",Could someone share syllabus and calender,[other]
5ad7d42f0d63974e20c39069,Is assignment 1 released yet? I didn’t see anything under t-square.,jc6w44hrp9v2ki,"[{u'text': u'It released now, just in case you haven't seen it yet.
-Q.', u'responses': []}]",,0.0,289.0,49,"As per @7, ""We usually aim to get the assignments out by the Wednesday of the week or earlier.""",assignment 1 not released yet?,[a1]
5ad7d42f0d63974e20c3906a,"Why is the answer to the second level 2-1-2-2-1?
For the second node I get the following... Can someone explain what I'm doing wrong? Thanks
",jc6w44hrp9v2ki,[],,0.0,271.0,50,"The second node is a minimizing node, hence the utility value of 1 will be propagated to that node.",1 - 25 Quiz Results,[lesson1]
5ad7d42f0d63974e20c3906b,"Hello everyone,

We have now switched to individual links for each Office Hours session. Please refer to @316 for details.
From this week onwards, we will be holding office hours through Google Hangouts. All office hours will be held at this link:
https://hangouts.google.com/call/9gyYYBoMAdlaOaUy7cp5AAEE
Please join the call at the appropriate time. Outside of Office Hours, the call will still be available for anyone who wishes to engage in discussion!

The Office Hours calendar is available here. Please note that we are still in the process of adding and finalizing times, and it may take us a couple of days to do so.

Please also refer to the Office Hours section of the syllabus document for details.
",jc6w44hrp9v2ki,"[{u'text': u'Is there a way to add the calendar to my own Google calendar? I tried importing from url, but since it's an embed link, it didn't work.', u'responses': [u'
Click on the ""+Google Calendar"" button on the lower right.


', u'
Can be accessed in iCal format at the following URI   https://calendar.google.com/calendar/ical/7f5agh74re4ldpkddoqa91ce4s%40group.calendar.google.com/public/basic.ics

Note: Process described here
', u'The +Google Calendar worked, thanks!']}, {u'text': u'Hi, 

Could I request that the office hours be recorded (or a transcript released) for the benefit of those of us in non-US timezones? The office hours are currently scheduled during my commute to work, I am unable to watch them.', u'responses': [u'Hey Jonathan,
We are still in the process of scheduling Office Hours, but we expect to cover timeslots from 9am EST to 11pm EST - does this range not work for you on any day of the week? If so, we can see what to do about it.
However, we will not be recording Office Hours - the reasons for this are given in the Office Hours section of the syllabus document linked in the original post.', u'Thanks Ravikiran. I am looking at this week's OH on my Google calendar, and I see them as 1am, 1:30am, 4:30am, 7:30am and 3am. 7:30am may work out, except I need to commute to work in the mornings.

TBH, I think EST mornings give the best chances of working out. 9am EST should be 8pm over here, unless I'm mistaken.', u'We have OH at 9AM EST on Tuesdays starting next week.', u'Alright. Looking forward to that. ']}, {u'text': u'Hi, just wanted to ask are these OH sessions recorded?

I read through all admin and logistical paperwork and thought it said that these sessions were NOT recorded. But then I saw that Assignment 1's YouTube Live's even IS recorded (@68).

Thank you,
Q.', u'responses': [u'Assignment specific OH sessions and Thad's OH sessions will be recorded. All others would be not recorded.', u'Thank you, Ting!']}, {u'text': u'I am seeing the message, ""You are not allowed to join this video call""

How do I get around this issue?', u'responses': [u'I believe Hangouts has a limit of 10 people on a call at once - try to join again in a few minutes?']}, {u'text': u'Is the link posted in the main part of this announcement the one that we should be using for all office hours? I have seen that sometimes I am able to see others + TA join and at other times it is just barren.', u'responses': [u'@169', u'It's the first time we're trying to use the same link for all Office Hours, and we are seeing some issues with Hangouts. We'll try to fix this ASAP. In the meantime you can use the link for the current session in @169 (for the next five minutes). Apologies for the issues.', u'Oh I saw this much too late :( The note also isn't showing for me on Piazza for whatever reason.']}]",,0.0,327.0,51,,Office Hours for this semester,"[announcements, office_hours]"
5ad7d4300d63974e20c3906c,"Hey everyone!

Registration is now over, and our class gets underway with an official strength of well over 400 students!
The first lecture is Game Playing, and you should watch the entire lesson by the end of this week. You can check out the details of Office Hours on @51.

Assignment 1 will soon be available, and we will make an announcement when it is!

Please make sure you complete these items from last week if you haven’t already:

Complete the start-of-course survey. You can find the survey under the Tests & Quizzes tab on T-Square. We’ll use the results of the start-of-course survey to inform when we schedule office hours, connect you to others in your discipline or geographic location, and inform other elements of how we structure the class.

Introduce yourself on Piazza! @6

Read over the course materials, including the syllabus and the schedule. 


",jc6w44hrp9v2ki,[],,0.0,333.0,52,,Week 2 Announcement,[announcements]
5ad7d4300d63974e20c3906d,"Hi everyone, i'm confused in lecture 1 video #18.Can any one please explain how could he come up with the numbers: 12^12 = 10^13And the 2 lines after that. Thank you, ",jc6w44hrp9v2ki,"[{u'text': u'There are 25 possible squares. After the first and second move, the next move is done as a queen moves. The previous quiz calculated 16 as the max move in the middle as a queen moves, but the rest have 12 or less. In probability, the typical solution in this case is the factorial since every move has fewer possibilities than the one before. However, I note that this is not a true assumption in this case, but it offers a reasonable estimate. It is a guess and a bit wrong as is seen in lesson 20. So 12! is a guess for the number of moves and the branching factor after the first two.

I think the 12^13 is wrong in the last line. It should be 12^12 or 10^13 and honestly, I think it should be left out entirely. 12! replaces it in the math. Using the above information, it should be 25 x 24 x 12! which is approximately 10^11. Maybe I misunderstood something here.  I would also mention that using the same technique discussed in lesson 20 that I came up with an average branching factor of 8.4 and average depth of 17.6 on 1000 randomly generated games which is very consistent across runs. That puts the actual figure for randomly guessing moves at less than 8.4^18 which is approximately 10^16. Smart opponents doing optimal play should be significantly less than that.', u'responses': []}, {u'text': u'Brian's explanation above is great! Thanks, Brian.

I also struggled with this video. There are many estimates used. The great thing is that both of the presenters notes when an estimated figure is used. I had to rewatched the specific video at regular speed (x1) a few times but if you note down when the presenter mentions when an estimate is used, it makes it easier to follow the math.
-Q', u'responses': []}]","There will be a maximum of 25 moves in a game (25 squares). This is our tree depth.
Now we are trying to figure out the branching factor, so that we can calculate the number of nodes that we will have to search (at least a broad estimate).

First move (player 1) = 25 possible moves.
Second move (player 2) = 24 possible moves (1 is blocked by 1st player)
In all other turns there will be around 12 legal moves. 

So we can do a calculation like 25 x 24 x 12 x .. [23 times] ... x 12 = 10^27. The reason we have the number twelve 23 times, is because we have 25 moves max - 2 first ones which are 25 and 24 respectively. 

But then we realize that the final move can not possibly have 12 legal moves, because, well it's the final move, no other positions are open- since the players have already filled 24 squares. We then realize that none of the last 12 moves can physically have more legal moves than the open squares. So the last move has a maximum of 1 legal move, the 2nd to last has a max of 2 legal moves and so on. So the new calculation is as follows:

25 x 24 x 12 x ... [12 times] ... x 12 x 11 x 10 x ... x 3 x 2 x 1. 
Again we have a total of 25 factors, which is the maximum number of turns. 

Hope this clears things up.

 ",0.0,250.0,53,,Question related to branching factor,[lesson1]
5ad7d4300d63974e20c3906e,"I wrote some code to do a plain vanilla MinMax tree (no pruning, no depth limited etc) that builds a tree for an arbitrary game. I also started playing with blocking out (with an '*') some cells so that players cannot move there or through there. For almost all games the computer wins as expected.

However for the game below the computer finds that all opening moves have a score of -1 so there is no opening move that leads to a definite win. According to my understanding of the lecture the algorithm should then just pick the first child of the root node (for the first move). However this move is immediately fatal for the computer player since the human can just to move cell (0,1) and the game is over. (as an aside this game generated >61,000 tree nodes in 1.3 secs on my 3 year old Mac).

So I'm thinking in this case where all scores are -1  there has to be a better way for the computer to pick its move. e.g. If all legal moves have scores -1 then look ahead for each legal move and pick one that at least has a path to a win. For example in the game below an opening move to (0,0) has no path to a win whereas a move to (0,2) could have a possible path to a win depending on how the other player moves. Or maybe look at all paths and scores below each legal move and pick the move that has the highest ratio of wins to losses. This does not guarantee a win but avoids the immediately fatal state and improves the probability of a win.

Any further thoughts on what this type of tweak to the algorithm could do better? The state after the computer's first move -

O _ _ _ 
* * _ _ 
_ _ _ _ 


To clarify after Jonathan's question below - the '*' are barriers where no player can move, the 'O' is the computer's opening move and 'X'  is the human's 1st move which wins immediately

O X _ _ 
* * _ _ 
_ _ _ _ 

Also if the human screws up and first moves to someplace other than (0,1) the computer can go on to win depending on the human's move. Almost all bad first moves by the human allow the computer to find definite paths to a win no matter what the human does next.",jc6w44hrp9v2ki,"[{u'text': u'Sorry, I don't understand what you are doing. What does the symbol ""0"" represent? ', u'responses': [u'The '0' is where the computer first moves.
So when the human 'X' moves the end state where the human wins is
O X _ _ 
* * _ _ 
_ _ _ _ 
and the '*' are barriers where no player can move to or through', u'Also if the game is just 3x3 the computer does find an opening move (1,2) that guarantees success no matter what the human does after that :)

_ _ _ 
* * O 
_ _ _ 
', u'Why not try opening at (3,3)? Or are you saying 1st player will always lose this game? If so, then the computer, while acting unintuitively, is doing exactly what it's meant to do - it can't win, and makes an arbitrary (1st) move.You could randomise from valid moves if you have no chance of victory.I think you can experiment with discounting: instead of propagating the min or max directly up the tree, try propagating 0.99*min or 0.99*max at each level. This will favor ""longer"" game, as you desire, ', u'With the 3x3 game, the outcome is obvious - that move partitions the board into 2 equal halves. Opponent has to play in one of the partitions, and the computer then moves into the opposite partition. Since the computer moves into it's ""half"" of the board later, it can outlast the opponent (by exactly 1 turn).', u'1. Not sure if this move is always fatal. Probably not but the existing algorithm as described in the lecture would never pick it unless it has a >0 score. BTW I am using 0 (not 1) based indexing. Right - the arbitrariness of the move is what bothers me.. its like the computer says I give up at the opening if I can't guarantee a win.
2. Yes - that would be a line or two of code and be much better (and maybe make the algorithm more human). But a tree search looking for win paths as described in the post seems like it could do better than random.
3. Interesting idea - I think you are saying this would cause the algorithm to favor opening moves with deeper child trees and so longer game potential and more chance the human will make a wrong move.', u'With discount factors high enough (but still <1), the computer's decision will not change. 
On second thoughts, the discount will favor paths through the game tree that end in a quicker victory - it will ""delay"" the game because that's the best way to slow down a loss.']}, {u'text': u'I think what you're saying is if the game is small enough to search to end game and is revealed to be 'futile' from the very first move, what should you do??

I was playing with this myself on some 3x3 and 4x2 boards and there are definitely board configurations where player 1 is doomed from the beginning. Any move ends up losing, ASSUMING the other player plays perfectly as well.

The perfect opponent is a pretty big assumption. So yes, what to do?

At first I thought, simply pick the opening move that has the largest number of #mymoves after the move. However, having played with it a little bit, I think returning the best move found at the deepest depth right before the 'losing' move might be the best option. On some of the boards like the 3x3, I seem to recall that after going 7 or 8 levels deep, there were about 3 moves left at that level before on the next level all 3 became 'losers'. Thus 6 opening moves lead to quicker loss and 3 moves made it almost to the end.I think selecting one of those three might be the best option as it would require your opponent to play perfectly up to that point in order to kill you on the last move. Some false move along the way might allow your AI to exploit their non-perfect play and recapture the advantage.

That said, I'm not sure this is the best way either, perhaps some strategy to set up for hopeful partitions, or better ways to exploit a non-perfect opponent would be better????
', u'responses': []}]","If the computer can search to the end of the game, then it either finds a definite win, or a definite loss. If it finds a definite loss (all positions give a -1), then it will lose no matter what to a perfect opponent, so it might as well lose in the first round. However a smarter strategy, against a non-perfect opponent would be to delay the game, and maybe even try to confuse the other AI. So you could program your player to change its strategy when it reaches a definite loss.",0.0,270.0,54,,MinMax Algorithm Tweak?,[lesson1]
5ad7d4300d63974e20c3906f,"When we say our algorithm is going to a certain depth, lets say, Depth = 4, do we mean 4 plys (One Max Move & One Min Move) or do we simply mean 4 levels deep, such that a Min or Max move is considered its own level. 

For example, is (A) or (B) the correct way to view this? (A) takes depth to mean a 'complete' ply per depth (B) takes depth to mean each individual level irrespective of ply.  While I've labeled them Iterations, I think Depth might have been a better label. (A) would be seen as 2 levels deep and (B) would be seen as 4 levels deep. Which is it???


 [o] Example A is correct
[o] Example B is correct",jc6w44hrp9v2ki,"[{u'text': u'I'd like to chime in here to shed a tad bit of perspective. The most correct answer is that it is up to you to decide. There is no ""correct"" or ""wrong"" way of defining what one depth step is here, as long as it is consistent across your subtrees. However, in this case, B will likely yield the best result

Iterative deepening, at the end of the day, is just an acknowledgement of the fact that each successive layer of a tree has exponentially (see the formula) more nodes than the previous. Therefor, the amount of time it takes to search through successive iterations at different depths increases very quickly. Therefor, you should make your ""depths"" as small as possible (as in B compare to A), because going through all the layers up until the one that your algorithm will cut off at will take roughly the same amount of time regardless of which way you divide them. Therefor, if your algorithm would hit its time constraint while searching for depth 8 (using your B model to define depth here), then model B would be able to search down to depth 7 completely, while model A would only be able to search down to depth 6 (depth 3 using it's way of counting) because it counted in twos.', u'responses': [u'We follow the conventions from the book.  The starting node is level 0.  the max move is level 1.  the min is level 2. and so on.  Take a look at the figures in the book, which should make it clear.', u'Thanks for the explanations. I had a suspicion (B) was correct. Wanted to clarify so when I hear or read something about minimax going to 'depth n' I understood it correctly. ']}]",,0.0,274.0,55,,Understanding Iterative Deepening (and MiniMax depth),"[a1, lesson1, polls]"
5ad7d4300d63974e20c39070,"I don't seem to find slides used in the videos, can you please share or point out where they are located?",jc6w44hrp9v2ki,[],They can be found on the schedule,0.0,241.0,56,"chapter6.pdf

Here are the slides for first chapter.",Lecture Slides,[announcements]
5ad7d4300d63974e20c39071,"

Hi All! 


 


Welcome to CS6601. First assignment- 2 Queens isolation is out!  


 


Git repo for the assignment is here.  


 


You can find detailed instructions in README part of git repo.  


 


Bonnie server is activated for first and second section. Section three will be activated in few days. Do not hit Bonnie for third section till instructed.  


 
Attach your final submission (with AI.txt if entering for botfight) in T-Sqaure. 

Lets discuss here:

Assignment 1 discussion - Installation and setup and other difficulties @58 


Assignment 1 Section 1 discussion @40 


Assignment 1 Section 2 discussion @59 


Assignment 1 Section 3 discussion @60 




Hope you enjoy the assignment!

",jc6w44hrp9v2ki,"[{u'text': u'I have a question about the following regarding CustomPlayer:
""You may not create additional external functions and classes that are referenced from within this class.""

Can we use our own classes such as custom Exceptions are those not allowed as well?', u'responses': [u'Exceptions is allowed. Yes you can create own classes. Make sure you create in player_submission.py 
Simple thing-- Bonnie only takes player_submission. ', u'Just to make sure I am staying within the bounds of the rules.... Within player_submissions, we can create any classes or functions we want as long as they do not use functions outside the standard libraries and pass using Bonnie? There is no such thing as illegal code as long as it is our own and within player_submissions, correct?', u'As far as I have seen, anything you write that is your own is fine.  Just be sure to put that all in player_submission.py']}, {u'text': u'I tried to sign in using my github account, but it says invalid ""LDAP login credentials."" What is LDAP and how to get it? Is it different from a regular github account?', u'responses': [u'Your LDAP credentials are your GATech credentials. The assignment is hosted on github.gatech.edu. So you'll need to log in with your T-Square ID and password.']}, {u'text': u'It's okay to pass each consecutive test with different programs if we're incrementally building our AI, right? E.g. to submit an AI that uses minimax and AB pruning for test 1; an AI that uses minimax, AB pruning, and iterative deepening for test 2; etc. I'm guessing what's important are the bonnie test results rather than the code being identical, but better to ask a dumb question than get a 0 or something.

Thanks!', u'responses': [u'Yes it's ok. Your last submission on Bonnie is what matters. Check 2nd comment on @60 ']}, {u'text': u'Hi, Is the board size will be constant 7 X 7 ? As i have tuned my code for it, and getting bad result at Bonnie compare to local i am started suspecting the size.', u'responses': [u'It's 7 X 7']}, {u'text': u'For Assignment 1 section b

Can i hardcode the depth = 2 for minimax and 3 for Alphabeta?', u'responses': [u'You may set the depth to whatever you want in your own functions.  They will create your AI by calling CustomPlayer without specifying a depth (so it will take your default depth).']}, {u'text': u'Now that the deadline passed can we get a breakdown of grades? Or at least a median so we can get an idea of how we are progressing. The assignment was difficult and I know alot of people would love to know where they stand.', u'responses': [u'Give us some time to collect the scores from Bonnie. We'll release the stats soon after. The scores will also be uploaded on T-Square. ', u'Thanks Richa, looking forward to seeing that :-)']}, {u'text': u'Hi. It was a great assignment. It took lot of effort tune the code. But I have few suggestions for future assignments. 
1. Please provide some limited log from server. It is so difficult to find what goes wrong in server when everything seems working with local test file
2. If code doesn't take whole 120 min to run, please give frequent bonnie runs instead of waiting for two hours.', u'responses': [u'Glad you liked the assignment!

And thank you for your suggestions. We have duly made note of these! I do want to highlight however, that Assignment is the heaviest in terms of Bonnie load (given the class size and the assignment requirement itself) and the limit it calculated based on the class load overall. It tends to get better as we progress in the course.
As for point 1, it is very valid and we'll try to include it in our upcoming assignments - to provide more relevant information from Bonnie!']}]",,0.0,416.0,57,,Assignment 1,[a1]
5ad7d4300d63974e20c39072,"
Important notes from our discussion below (please keep checking this):

About git repos being private
Please check Gerardo's and Ravi's answer below.
",jc6w44hrp9v2ki,"[{u'text': u'Looks like I don't have access to push my branch to remote repository.

git push --set-upstream origin <my_branch_name>

remote: Permission to omscs6601/assignment_1.git denied to <my_user_name>.
fatal: unable to access 'https://github.gatech.edu/omscs6601/assignment_1.git/': The requested URL returned error: 403', u'responses': [u'The original class repo for the assignment is restricted to the instructors. 

You need to create your own *fork* in GitHub, and clone your repository ""copy"". Github has good tutorials you can check for guidance. 

IMPORTANT: Make sure is not accesible publicly or with us!', u'I don't think you can make a forked repository private. For now, I created my own repository and made it a mirror of the course repository. See instructions here:

https://help.github.com/enterprise/2.10/user/articles/duplicating-a-repository/

I don't know if this will be able to easily handle incoming changes from the TAs however.', u'Were the rules that our repos can't be public ever, even in the future? As that would make a difference whether I set my remote to github.gatech.edu or a private repo at github.com', u'Yes. You are not allowed to make your code public at all, even in future. And please ensure that your code is not accessible publicly.

Here's a tutorial for how you can create a private fork and sync to it: https://stackoverflow.com/questions/10065526/github-how-to-make-a-fork-of-public-repository-private
', u'Hi Mark,

yes, cannot be shared /made public now or any time in  the future. If any current or future student reads your code, you could  indirectly facilitate academic fraud, and be subject to academic sanctions.

I know it makes it difficult to showcase your projects, say, as a portfolio during interviews, but that's how the GT honor code works.

In my case, I have all my private repos in Bitbucket, and add the class repo as an upstream to fetch updates. The only problem is that makes it a bit more difficult for the TAs to have a look at my code to help if I'm stuck, but they can access all your Bonnie submissions  :-)', u'Does it mean, I need to buy subscription at Github to create a private Repo?  What is is the recommended or the method being used by previous students (This is my first sem)?

', u'Actually I got it, I can create a private repo on https://github.gatech.edu. with my user account.', u'Ravikiran, thanks for the clarification.

Gerardo, as a matter of fact as I recall there is a way of letting prospective employers see your private github.com repos, although it may be 'all or nothing'; either they see all of your private repos, or none at all. Incidentally there are differing interpretations of how far 'ever in the future' is applicable for individual courses, so that is the reason for the question. Clearly it matters more for some courses, while for some courses such as this that seem to change the assignments with some regularity; such as from semester to semester, from year to year, etcetera for the specific purpose of undermining students who would be looking up code, a more reasonable approach to future secrecy that accords more precisely with the schedule of assignment changes, may be feasible. Although obviously Ravikiran's answer is good enough for the time being, it would be kind of nice to hear from Prof. Starner how he thinks the balance works for this course, as the welcome post & syllabus don't specifically address the length of time code should be kept private, nor the factors impinging upon that.

Badal, you should be eligible for github.com student, unless they have changed the system recently, too. The advantage being that your remote repos should stay accessible beyond graduation etcetera; although it would be relatively straightforward to mirror your github.gatech.edu repos some place before graduation, it's the kind of task that could potentially get skipped :-D', u'Incidentally Ravikiran, that SO post https://stackoverflow.com/questions/10065526/github-how-to-make-a-fork-of-public-repository-private somewhat overcomplicates the task of making a private repo copy of a public repo,

All you need to do, is$ git clone https://github.gatech.edu/omscs6601/assignment_1.git
$ cd assignment_1
then create a new private repo some place, such as https://github.gatech.edu/MBenjamin35/cs6601_assignment1.git
then$ git remote set-url origin https://github.gatech.edu/MBenjamin35/cs6601_assignment1.git
$ git push -u origin master
$ git remote add upstream https://github.gatech.edu/omscs6601/assignment_1.git
Then changing to a differently-named branch for work may assist with pulling changes from upstream; remember to pull from upstream, push to origin; Robert's a relative :-)', u'nice.  your method worked like a charm.  thank you']}, {u'text': u'Hi,
I tried logging in to https://gatech.github.edu  using the same credentials as buzzport/canvas , but it says Invalid credentials.
Do I need to be able to login to this repo or not required.
thanks,
KK', u'responses': [u'Yes, you must be logged in.

Unlike other sites, there's no redirection to GT SSO. Make sure you are using your student id (i.e. abwh123) and not your email alias.', u'Gerardo is correct (again)', u'It won't last for long...']}, {u'text': u'I have a higher version of requests installed - requests==2.18.4The version in requirements.txt is 2.13.0Can I skip installing requests 2.13.0?', u'responses': [u'Hi Richard, 
I would recommend you to use the version as stated as they would be the exact specification on the bonnie server on which your submission would be graded to avoid any issues. 
You may look at pyenv or virtenv to not disturb existing environments of your system if you do not want to.', u'no big deal...installed over it....', u'Seems too late, but you might want to checkout virtualenv - it lets you have different versions of Python packages for different projects on the same machine...

https://virtualenv.pypa.io/en/stable/']}, {u'text': u'Did I miss a vagrant, or other, virtual machine config setup for this class?

That has been incredibly helpful for isolating language and library version dependencies and submission scripts for other OMSCS courses.', u'responses': [u'I don't think there is a course supplied VM for this class....', u'Use a conda or virtualenv environment.', u'I set up a conda environment. Pretty easy solution.

conda create --name py27AI anaconda python=2.7

(You could do a basic install by omitting 'anaconda' from the above, but I like having all the base anaconda packages at my disposal)

On Mac, I created a 2.7 environment and then installed:

conda install future
pip install nelson
conda install requests=2.13.0

There didn't appear to be a conda package for nelson so I used pip instead. It installed nelson 0.4.2
', u'+1 for miniconda, I've used different envs (2.7 and 3.5) simultaneously in the same machine.

If you insist on full isolation. Here's an idea: make a clone of a previous VM, AND install miniconda on top. Even better, do it in a Docker container with your own crafted image as base.

There are many ways to make this work.']}, {u'text': u'when i install the required packages... it seems to also install ""requests-toolbelt"".. no idea what is that.. any idea?

C:\Madhukannan\GATECH-OMSCS\Spring2018\CS6601-AI\Assignments\assignment1\assignment_1>pip install -r requirements.txtCollecting future==0.16.0 (from -r requirements.txt (line 1)) Downloading future-0.16.0.tar.gz (824kB) 100% |################################| 829kB 235kB/sCollecting nelson==0.4.0 (from -r requirements.txt (line 2)) Downloading nelson-0.4.0-py2.py3-none-any.whlCollecting requests==2.13.0 (from -r requirements.txt (line 3)) Downloading requests-2.13.0-py2.py3-none-any.whl (584kB) 100% |################################| 593kB 279kB/sCollecting requests-toolbelt>=0.7.0 (from nelson==0.4.0->-r requirements.txt (line 2)) Downloading requests_toolbelt-0.8.0-py2.py3-none-any.whl (54kB) 100% |################################| 61kB 690kB/sBuilding wheels for collected packages: future Running setup.py bdist_wheel for future ... done Stored in directory: C:\Users\Madhukannan\AppData\Local\pip\Cache\wheels\c2\50\7c\0d83b4baac4f63ff7a765bd16390d2ab43c93587fac9d6017aSuccessfully built futureInstalling collected packages: future, requests, requests-toolbelt, nelson
Successfully installed future-0.16.0 nelson-0.4.0 requests-2.13.0 requests-toolbelt-0.8.0
', u'responses': [u'It's a secret lib that steals your identity with a chisel, see http://bfy.tw/G5YP']}, {u'text': u'Just to clarify, ""Section"" 1, 2, 3 are submit, submit_a, and submit_b accordingly? I read over README multiple times but I can't figure out what constitutes each sections in the assignment.', u'responses': [u'Yes.
Section1- OpenMoveEval and Random - submit.py
Section2- Minimax and Alphabeta - submit_a.py
Section3- Iterative and Kshitish's secret eval - submit_b.py (not activated yet. Dont hit till instructed)', u'We are to submit a single player_submission.py file three times, rather than develop three versions of it?
', u'It will take whatever is there in player_submission.pySo update that file and hit again. ']}, {u'text': u'
Keep your GitHub account!!!Create Private Repo!!Not Pay a Dime while student!!!

https://education.github.com/pack', u'responses': []}, {u'text': u'I'm able to clone the repo over HTTPS but not SSH. SSH is timing out. Is this some problem on my end or is it disabled at the gatech level?', u'responses': [u'Looks like it's restricted to GT network only. https://faq.oit.gatech.edu/tags/category/github', u'Gah, I just spent forever trying to figure out why I couldn't do it via SSH! :facepalm:']}, {u'text': u'I am trying out the first part submission by running the following command:

python submit.py

and getting the following error:

Late Policy:

  ""I have read the late policy for CS6601. I understand that only my last
  commit before the late submission deadline will be accepted.""

Traceback (most recent call last):
  File ""submit.py"", line 92, in <module>
    main()
  File ""submit.py"", line 85, in main
    require_pledges()
  File ""submit.py"", line 28, in require_pledges
    ans = raw_input(""Please type 'yes' to agree and continue>"")
NameError: name 'raw_input' is not defined

What am I missing?', u'responses': [u'raw_input is a built-in function in Python 2, and it's used to collect keystrokes from the user (you, in this case). Are you sure you're using Python 2 and not Python 3?', u'Thank you Sasha! That was the problem! I am working on the assignment from pyCharm with v2.7 but tried submitting from shell prompt which has 3.x version on the path.']}, {u'text': u'Where is 'bonnie' explained? It seems to be maybe a test server, but also a module, and also perhaps a way of submitting code? I searched all the text resources for this course and couldn't find it—maybe it's in a video I haven't watched yet.', u'responses': [u'Bonnie is where the code is submitted to be automatically graded. The included submit.py files will taken care of the process. After you submit, as long as there are no errors, you should get the results back in a json file. You can also check your submissions online at https://bonnie.udacity.com.

Bonnie isn't addressed in any of the lecture videos, since the lectures address the material only. There is a short description about Bonnie in each assignment Readme.', u'But many students are in first/second semester of their course. Their should be a formal post in Piazza atleast explaining how Bonnie works. I really had to go through unofficial slack and whatsapp group of old students to understand this. It is my suggestion to include Bonnie introduction in every course as a piazza/reddit or even through a shared doc.']}, {u'text': u'There seems to be serious white space issues in many of the provided files. Is it possible to get this officially 'cleaned up' and corrected. It appears that a mix of spaces and tabs were used to create the Assignment.

While I'm sure I could work my way through all the code and apply fixes, I would be concerned that I might mess something up, particularly when there are lines following (try/excepts) and (if/else) blocks. For example, is the line following it 'correctly indented' when it is outside of the except or correctly indented 'inside' the except?

It's hard to read Issolation.py and figure out what is or isn't inside of a conditional in certain areas.', u'responses': [u'I'm surprised you are having this problem.  what editor are you using?  we generally try to be consistent in how we code.', u'In PyCharm the fix seems to be to use:

From Menu-> Code -> Reformat Code

To auto-magically fix the files.', u'+1
PyCharm and VS Code, is quite difficult to read and understand what is going on.

PyCharm can ""reformat"", but I'm worried about changing the logic inadvertently.', u'In VSCode on Windows I was able to reformat the entire document for all the py files. This converted all the tab characters to 4 spaces and seems to have cleaned things up.', u'PyCharm complains about it until you fix it but agreed we could inadvertently screw something up by doing this.', u'It's worthwhile observing that a careful inspection discloses that some of the tabs are worth 8 spaces, some are worth 4. Some indentations contain mixtures of tabs & spaces, so basically calling it a mess is an understatement.

The point is that there is a very comprehensive, relatively straightforward, set of guidance that is designed specifically for the purpose of making Python code universally legible. The fact that mixed tabs & spaces works in some subset of editors, is not very persuasive. Python code that is even minimally respectably maintained, should respect PEP8. It's not asking very much to lint/inspect code before claiming it is alright. The tab errors aren't the only errors either.

""looks alright in Ubuntu 17.10 with gedit"" ""checked in Mac"" ""approve, release"" is, frankly, simply not robust checking at all.', u'Incidentally, for assignments 2-6, here's a suggestion to appear more supremely competent as well as possibly pick up some hints for best practice, there are many many checkers – websites, cli python pip installable, vim, etcetera, quite aside from integration in pycharm / eclipse pydev etcetera – before releasing messy code on an unsuspecting large group of consumers :-) pep8 check', u'I submitted a PR to the class repo that cleans up all the spacing issues.  If someone could take a look at it, I think we would all appreciate it.', u'Can one of the TA's please pull in that change request.', u'Would appreciate that as well. Mixed indenting in Sublime Text is very hard to look at (pep8 would be a nice convention to follow). Current situation reading isolation.py:', u'i agree this is a problem, it looks that way on github too']}, {u'text': u'I am observing error ""unresolved reference""  for the object ""board_copy"" in isolation.py.Any idea?
print game_as_text(winner, move_history, termination, board_copy)', u'responses': [u'Are you running isolation.py? As in making changes there?
', u'Please use player_submission_tests.py for playing. Dont change isolation.py (if you are changing)', u'I am not changing that .I was just browsing through the files and noticed this object being passed which appeared to have an unresolved reference.I was just wondering if it is something that has been noticed.
', u'I think it was just a misnamed variable... From isolation.py

if __name__ == '__main__':

    print(""Starting game:"")

    from test_players import RandomPlayer
    from test_players import HumanPlayer

    board = Board(RandomPlayer(), HumanPlayer())
    winner, move_history, termination = board.play_isolation(time_limit=30000, print_moves=True)
    print game_as_text(winner, move_history, termination, board_copy)
I think that the last argument to `game_as_text` is supposed the `board` variable, not `board_copy` ...', u'He mentioned that in the hangout video. Basically, you should never run isolation.py by itself anyway. I just commented out everything after the first print statement.', u'Thanks for the clarification. Everything works fine now!']}, {u'text': u'Putting this here since it’s just a general question about the assignment. The end of the search videos mention that the book has actual code associated with it as supplemental materials. Are we allowed to look at that code for our assignments? ', u'responses': [u'Pseudocode is fine and you should have reference in your code (at the beginning and where you use the code)
Please don't look at the actual code. ']}, {u'text': u'I use command ""pip install -r requirements.txt"" to install python package, but I got following error ""
pip: command not found"". Could some one tell me what had happend?  ', u'responses': [u'@76 in case using windows']}, {u'text': u'You need to install pip first on your system.If you are on MAC use command. Sudo easy_install pip and then try installing packages from requirements.txt', u'responses': []}, {u'text': u'So, I am working on a Mac at work and a Windows at home. I am running the application in Pycharm on both and sharing the code via my gatech repository. I got it running on Mac but when I try running on my Windows machine it keeps given an error on both command line and pycharm. I did some google searching and it seems to be cause we are using an import only available on Linux macines:

Line in question: 
import resource
Error I get:
C:\Python27\python.exe C:/ai/AIassignment_1/player_submission_tests.pyTraceback (most recent call last): File ""C:/ai/AIassignment_1/player_submission_tests.py"", line 6, in <module> import resourceImportError: No module named resource
Process finished with exit code 1

How can I run this on Windows?', u'responses': [u'Hmm! I am also using a similar setup (Windows at work and Mac at home) and was able to sync and run code on both machines. Only hack I had to make was in the nelson.gtomscs package on windows to ignore SSL verification while submitting the code (else it was failing). 

""resource"" is an internal package of Python and available on Windows as well. For now, to get going, just remove line 6 as ""resource"" package is not used in that file.', u'I tried upgrading to 2.7.14 but it made no difference.', u'Hmm. As per python docs, ""resource"" seems to be a ""unix"" specific service. So unfortunately, we will have to use Mac for using resource service.

I never tested player_submission_tests.py on Windows but after reading your post, tried testing and got the same error!', u'It's an unused import in that particular file, you may safely comment it', u'Okay, it isn't used, and maybe it is my lack of python knowledge, but is it going to cause issues elsewhere in the program? Meaning is it needed to optimize other things maybe? Anyway, if everything will work with it commented out then why is it there? Oversite?', u'No, it won't cause trouble & as for oversight, of course; a PEP8 inspection would have flagged it up, of course :-D', u'Okay, good with that', u'Noticed that isolation.py has a check to import this package. player_submission_tests.py should also have a similar check.

# import resource
if platform.system() != 'Windows':
    import resource
']}, {u'text': u'Hi,
I have a first cut of the eval function and would like to test this with bonnie. I have never used this tool before . Is there a read me or some info on how to go about it', u'responses': [u'Never mind found it.', u'pl share', u'from the prompt (directory of the assignment1) type ""python submit.py"" and follow the program prompts', u'Yep, when in doubt just do it and deal with the consequences of the blue screen of death.']}, {u'text': u'I'm getting the following error when I submit part 1,

File \""run.py\"", line 32, in simulate_games\n    student_agent = CustomPlayer() # Force the reinitialization of the player after every game\nTypeError: __init__() takes at least 2 arguments (1 given)\n""
The code runs fine on my system (famous last words...) and I haven't changed the args to __init__, but just added a few variables after the self.search_depth = search_depth line. ', u'responses': [u'Sorry. lets continue on the other private thread you posted. ', u'I think you just need to set a default value for depth in the _init_ method. Their testing code doesn't set it.', u'I'm running into the same issue, what was the solution?', u'Same issue. Is it possible to share the solution that was arrived at in the private thread? Are we allowed to change the function signature to __init__ to make depth a named value with a default?', u'You have to add a default for the depth.   Set the default for dept to a value that is appropriate for your solution. 

Note that they also tell us to change the default for the evaluation function if you define your own.', u'Geesh...

Just found this... Doh. ', u'And now I need to wait 30 more minutes. Harumph...']}, {u'text': u'I am getting auth errors while trying to submit. Is this known issue?
I am using Python2.7 and eclipse as editor on windows 10.

  File ""C:\gatech\cs6601-01\submit.py"", line 92, in <module>    main()  File ""C:\gatech\cs6601-01\submit.py"", line 89, in main    submit('cs6601', 'assignment_1', filenames)  File ""C:\Python27\lib\site-packages\nelson\gtomscs.py"", line 36, in submit    session = build_session(environment, id_provider, jwt_path)  File ""C:\Python27\lib\site-packages\nelson\gtomscs.py"", line 25, in build_session    jwt_path).new()  File ""C:\Python27\lib\site-packages\nelson\sessionbuilder.py"", line 47, in new    jwt = self.login_for_jwt()  File ""C:\Python27\lib\site-packages\nelson\sessionbuilder.py"", line 122, in login_for_jwt    gt_login(session, self.root_url, username, password)  File ""C:\Python27\lib\site-packages\nelson\sessionbuilder.py"", line 172, in gt_login    raise ValueError(""Username and password failed (Do you use two-factor?)"")ValueError: Username and password failed (Do you use two-factor?)', u'responses': [u'I'm running a conda 2.7 environment, Windows 10. When running `python submit.py` from my conda env command prompt, it submits successfully.', u'Thanks! I just tried from an elevatd command shell. It works now.
Eclipse (pydev) have some issues.']}, {u'text': u'It's unclear which function should be used. Are any requirements which exactly function I should use for which submission
can I use 'alphabeta' for all or I should use 'minimax' for the first section and 'alphabeta' for the second and the third??', u'responses': [u'You can do anything you want. They only call the move() method.', u'hmm, but why do we need to implement 2 functions in that case and how the second is going to be tested/verified if I use only 'alphabeta' for example.', u'I also have same question. Thanks Alex for asking it.

Is this question resolved? I see it as resolved in piazza. If it's resolved, which function we need to use while submission.', u'I submitted parts 1 and 1_a with minimax as the function.  Working on part 1b with alphabeta as the function.  Depending on your efficiency you may need alphabeta for part 1a (to win against alphabeta without timing out on your move).

minimax is a core part of alphabeta and you should verify that you get the same results when looking at a particular board with minimax and alphabeta (to make sure your implementation of alphabeta is correct).

To get full credit on part 1b, you may need to go beyond alphabeta and implement other optimizations (iterative deepening, better eval function, etc.)', u'Yes thats correct - David. You can use any function. Thanks Conor. Great explanation.']}, {u'text': u'I seem to be getting this error when submitting part 1.

""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_wxqszpum/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 102, in test_beats_random\n    self.evaluate_against(RandomPlayer(), 0.9)\n  File \""run.py\"", line 55, in evaluate_against\n    win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n  File \""run.py\"", line 32, in simulate_games\n    student_agent = CustomPlayer() # Force the reinitialization of the player after every game\nTypeError: __init__() takes at least 2 arguments (1 given)\n"",

I have set default values in the __init__ method of my CustomPlayer.

I did set a few extra variables in that method but it runs fine locally.', u'responses': [u'You need to assign default value to search_depth parameter in __init__ function of CustomPlayer class.

You can refer youtube video for this suggestion.', u'Yes. Initialize to some depth as Rajan said']}, {u'text': u'I've been getting this error for part 1 when submitting to the server:
{    ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_xmfbhiop bash -c \\\""cd /home/vmuser_xmfbhiop; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_1 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""\"", \""stderr\"": \""bash: line 1:    28 Killed                  python run.py assignment_1 > run_stdout.txt 2> run_stderr.txt\\n\""}""}

I had previously submitted and successfully got points for the first part of part 1, but now, when trying to submit the .move function as well, it doesn't seem to be taking.  It's successfully running locally with minimal timeouts.  Does anyone have any idea on how to fix this?', u'responses': [u'The fact that it was killed makes me think you ran into the hard timeout but there's usually some other indicator.', u'Chances are it's a memory limit, so th'intrawebs suggests for python returning code 137 https://stackoverflow.com/questions/35116689/tensorflow-exited-abnormally-with-code-137#35117550', u'I have the same problem and my script takes less than 1GB of memory running against RandomPlayer in 7x7. Is using 1GB memory too much already?', u'137 means your script was killed.    Given the ulimit command used to setup the shell to run the script, I would suspect that your program is being killed because there's a limit of 160K of output and you probably have a lot of prints in your program. ', u'Thanks Conor, I managed to find the problem. It should be memory or timeout problem.
I'm using a ""tree"" like dict to store the games forecast. I accidentally update the wrong nodes of the ""tree"" and made it unreasonably huge (though still can run in my computer). I'd suggest others who face this problem try to print out the size/len of the objects in the script to see which part went wrong.', u'When I received the timeout it explicitly indicated it was a timeout rather than killed:

...2> run_stderr.txt\\\"") exceeded the timeout of 7200 seconds.\""}""

The default memory limit is unlimited (though you can be running into OS memory limitations that aren't specified on ulimit, so it is possible.  I was just pointing to the size limit specified for outout -- if you output more than 160K of data, it looks like your program will be killed.', u'I got this error too.  This does seem to be related to a memory limitation on Bonnie.  I reduced the size of my game tree and the error went away.']}, {u'text': u'I'm trying to submit section 3 and am getting:


Uploading submission...
[=========================== 100% ===========================] 56264/56264

Waiting for results... \Traceback (most recent call last):
  File ""submit_b.py"", line 92, in <module>
    main()
  File ""submit_b.py"", line 89, in main
    submit('cs6601', 'assignment_1b', filenames)
  File ""/Users/philglau/anaconda/envs/pytorch27/lib/python2.7/site-packages/nelson/gtomscs.py"", line 49, in submit
    return abstractsubmit(submission, refresh_time = refresh_time)
  File ""/Users/philglau/anaconda/envs/pytorch27/lib/python2.7/site-packages/nelson/abstract.py"", line 37, in submit
    while not submission.poll():
  File ""/Users/philglau/anaconda/envs/pytorch27/lib/python2.7/site-packages/nelson/abstract.py"", line 125, in poll
    r = self.s.get(self._get_poll_url())
  File ""/Users/philglau/anaconda/envs/pytorch27/lib/python2.7/site-packages/requests/sessions.py"", line 501, in get
    return self.request('GET', url, **kwargs)
  File ""/Users/philglau/anaconda/envs/pytorch27/lib/python2.7/site-packages/requests/sessions.py"", line 488, in request
    resp = self.send(prep, **send_kwargs)
  File ""/Users/philglau/anaconda/envs/pytorch27/lib/python2.7/site-packages/requests/sessions.py"", line 609, in send
    r = adapter.send(request, **kwargs)
  File ""/Users/philglau/anaconda/envs/pytorch27/lib/python2.7/site-packages/requests/adapters.py"", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='bonnie.udacity.com', port=443): Read timed out. (read timeout=None)

Not sure what to make of this. Error on my end?? or did bonnie fail to respond? It uploaded the submission and started processing the the spinning ""/"" but then ended with the timeout. (I had walked away so didn't see it happen, just the results.)', u'responses': [u'What is the expected run time of Section 3 on Bonnie? In other words, how long should it take to run in the best case scenario?

My rough guess is at least 6 games, probably 10. 

10 games * 12 moves * 30 seconds per player * 2 player = 120 minute!!

Time for two games == 4 hours?? Is that right? That seems crazy if it's the case.

Hopefully bonnie is running several iterations of the game as separate processes, but nonetheless. Particularly given class size.', u'I think there's a hard timeout at 7200 seconds (aka 2 hours), so if you don't complete within that amount of time, it will kill your submission.

The HTTPS connection issue you reported above seems more like a networking issue than an execution issue.']}, {u'text': u'Hi guys.  I’m just starting this assignment now as I’ve been swamped with work.  Just curious.  Is korfs paper a required reading to do this homework?  Thanks ', u'responses': [u'Depends on how well you understand alphabeta.  It is a good source for understanding that pruning algorithm, but you can get some of it from the class and other sources such that you don't need to read the paper.', u'thank you conor.  ']}, {u'text': u'ImportError: No module named resource
Running player_submission_tests.py results in this error. From what I gathered, it appears to only be an issue in Windows environment according to this https://stackoverflow.com/questions/37710848/importerror-no-module-named-resource. Did anyone find a workaround for this?', u'responses': [u'', u'Hey Sandy it is a windows error. I already asked about this, you can comment out the line or copy the way the same resource is handled in isolation.py. ']}]",,0.0,412.0,58,,Assignment 1 discussion - Installation and setup and other difficulties,[a1]
5ad7d4300d63974e20c39073,"
",jc6w44hrp9v2ki,"[{u'text': u'In the comments of the minimax function, it states that the function should return:

Returns:
    (tuple, tuple, int): best_move_queen1, best_move_queen2, val

What does val represent?
', u'responses': [u'Nevermind, I figured it out. It represents the utility value.', u'Could you explain what utility value is?

I'm kind of confused about what this value is. Is this value just related with utility() function for anyone need it?', u'its is the output of the minimax algo for the specified depth.

It may be of use in part_3 ( part_b?) in the iterative deepening to determine if going deeper is worth it or not.', u'the ""utility"" or ""score"" is of use in any recursive algorithm that is examining the scores of the layer below.   My minimax and alphabeta functions call themselves as they dive into deeper analysis.']}, {u'text': u'Has anyone else encountered the following error when trying to submit the second part of the assignment:

Results:
--------
{
    ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_dynlfsjz bash -c \\\""cd /home/vmuser_dynlfsjz; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_1a 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""F\"", \""stderr\"": \""bash: line 1:    28 Killed                  python run.py assignment_1a > run_stdout.txt 2> run_stderr.txt\\n\""}""
}

Last night, I got it a couple of times, but I was eventually able to re-submit and have it work. However, today I have tried to submit ~10 times and I get this error every time. In other classes, I know Bonnie sometimes reacted poorly to a lot of print() statements, but I shouldn't have anything printing when my agent runs. It also runs fine locally every time. I'm not sure if this is an issue with Bonnie or my agent.', u'responses': [u'No. It should not behave weirdly because of print statements. 
Is it getting timeout? Check locally. ', u'When I run locally, I do not time out. Do timeouts cause the whole program to crash on Bonnie? There seems to be a num_timeouts in the result string when it runs successfully, so I would not think this would break it', u'Chances are it's a memory limit, so th'intrawebs suggests for python returning code 137 https://stackoverflow.com/questions/35116689/tensorflow-exited-abnormally-with-code-137#35117550']}, {u'text': u'I see this weird message for the Assignment part II -

""Traceback (most recent call last):\n File \""/home/vmuser_njpqrxsy/AIResult.py\"", line 26, in func_wrapper\n ans = func(self)\n File \""run.py\"", line 115, in test_beats_alphabeta\n self.evaluate_against(TestAI(method='alphabeta'), 0.65)\n File \""run.py\"", line 55, in evaluate_against\n win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n File \""run.py\"", line 36, in simulate_games\n winner, move_history, termination = game.play_isolation()\n File \""/home/vmuser_njpqrxsy/workspace/isolation.py\"", line 260, in play_isolation\n if curr_move_queen1 is None or curr_move_queen2 is None:\nUnboundLocalError: local variable 'curr_move_queen1' referenced before assignment\n""

isolation.py has not been changed and this has worked well for Assignment part I. Since the resubmit cant be done before 2 hours, this will take long time to figure out. 

Seems, It would be a better practice to disable the 2 hour constraints in case of errors reported in the first 1-2 mins or so.', u'responses': [u'You are returning invalid move. While playing with RandomPlayer- you might have not faced this issue. But in section 2- with smarter players, you might lose at some points which you have not detected. I will recommend testing it on local board with different board states. 

I completely understand the frustration. Bonnie does not allow to check that. This semester we tried our best to avoid time constraints. Divided one big section with 3-4 or sometimes more hours to 3 sections with 2 hours. ', u'Post a private thread if you think there is some specific issue. We will discuss further there', u'I'm facing this issue as well, even in section 1, with depth 1 minimax against RandomPlayer, however, it seems to run fine locally.', u'I'm running into problems with num_invalid_moves on Bonnie too. My CustomPlayer is performing well locally versus a custom made minimax (no illegal moves are made), but on Bonnie it loses every game, receiving 20 for num_invalid_moves on both tests. I also tested this against part 1 and having the same problem. Does that mean that my player is making illegal moves on every game? That surprises me, since I'm using get_legal_moves_of_queen1 and get_legal_moves_of_queen2, and works fine locally. Any ideas on what to check?
', u'I found in @114 that num_invalid_moves can just means you lost that game (for example, you got cornered and there are no more valid moves).  That got me pointed in the right direction and I found my problem.  In my case, I had a bug that only showed up when I instantiated my player using all default parameters (calling CustomPlayer()).', u'If the instructors/TAs would merely change the code in isolation.py to correct the error handling the actual exceptions being thrown will show up in the Bonnie output... grr...']}, {u'text': u'What should we return for the moves in case a game board does not have legal moves for one of the player's queens?', u'responses': [u'None', u'@kshitish

I am using forecast_move which then uses __apply_move__ and if one of the moves is none in __apply_move__ I get the error:

TypeError: ""'NoneType' object is not iterable""

As it is trying to get the row and col from the None object of the move.

How do you suggest we pass in the move set when only 1 queen has moves left?', u'That would be an illegal move (just moving one queen) and the other side has won if both queens can't move.  You should not try simulating an illegal move.', u'Hey Conor,

That clarification is great! It simplifies things. I reread the instructions and its there:

""The first player who is unable to move any one of the queens loses.""

I missed it the first read.

Thanks']}, {u'text': u'My program is taking longer than expected to run and at the end it shows the winner is Random player for 5*5 board. How much time it ahouldbtake when I consider the depth to be 4?', u'responses': [u'Try running with depth 3 and compare that to the running time with depth 4. Because everyone's implementation will be so different, it is hard to give a concrete answer on expected execution time. 

However, you should general see an exponential increase in running time from one depth the next.', u'Right. For first 2 moves- i will even expect to get a timeout if depth is 4. (7x7 game)', u'You would expect timeout on MiniMax at level 4 7x7 or AlphaBeta at Level 4 on 7x7??', u'Level 4(4th move of your player)- I am not sure. For first move- depth 4 yes for both minimax and alphabeta']}, {u'text': u'So I've been running submit_a for approx 2 hrs now... what's the expected response time?', u'responses': [u'Strange... I hit space bar and then it throws an error. Nice :(

Traceback (most recent call last):  File ""submit_a.py"", line 100, in <module>    main()  File ""submit_a.py"", line 96, in main    submit('cs6601', 'assignment_1a', filenames)  File ""C:\Users\rake\Anaconda3\envs\py27\lib\site-packages\nelson\gtomscs.py"", line 46, in submit    return abstractsubmit(submission, refresh_time = refresh_time)  File ""C:\Users\rake\Anaconda3\envs\py27\lib\site-packages\nelson\abstract.py"", line 39, in submit    sys.stdout.write(""\rWaiting for results... {}"".format(next(wheel)))IOError: [Errno 0] Error

', u'It will typically time out around 2 hours or so (at least that's what happened to me on part 1b when I had the depth too high).', u'Interesting. I had depth set to 1 just to see what would happen...', u'If you're not doing something special in the first few moves (when the possible moves for each queen are very large) you may get timeouts if your coding is not very efficient. ', u'Finally completed after a third attempt that I kicked off in the middle of the night. This with Max_Depth=10 + iterative deepening.

The attempt prior simply timed out after 7200 seconds.']}, {u'text': u'We have a comment under  Evaluation function ""score()""""Note:Be very careful while doing opponent's moves. You might end up reducing your own moves.""
I was trying to figure out how it can possibly happen.Can an example be provided?', u'responses': [u'You are probably calling your evaluation function when doing minimax.

Whose utility are you actually calculating?', u'Yeah, look at some of the responses in @40 pertaining to this.']}, {u'text': u'Is the size of the board on bonnie always 7x7? Or can it vary?', u'responses': [u'I believe all their tests are 7x7, but I would not write my code with that assumption (so that you can test it offline with 5x5 boards and such).', u'thanks Conor. yeah that makes sense. I was trying to think of a way to have a table of open moves and it seemed easier if it was a fixed board size...', u'7x7 for Bonnie.', u'thanks Kshitish :)']}, {u'text': u'Question about feedback from bonnie. I get the following response when testing minimax in section 2.

{    ""output"": {        ""points_available"": 20,        ""win_ratio"": 0.0,        ""points_awarded"": null,        ""num_invalid_moves"": 0,        ""num_timeouts"": 20    },    ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_rvpxdjmi/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 109, in test_beats_minimax\n    self.evaluate_against(TestAI(method='minimax'), 0.65)\n  File \""run.py\"", line 63, in evaluate_against\n    \""Your player didn't win more than a %f fraction of the games.\"" % win_thresh)\nAssertionError: Your player didn't win more than a 0.650000 fraction of the games.\n"",    ""description"": ""Beats MinimaxPlayer""}

If my ""win_ratio"" = 0.0, does this mean I lost every attempted game? :(', u'responses': [u'Script is timing out on each execution without making a move.', u'Yes. Either timing out or losing.', u'Losing would show as an invalid move generally, wouldn't it?', u'hmm, ok. so i am taking more than 10 seconds to make move I guess. thanks!']}, {u'text': u'What should we submit for Section 2?

For one we implemented evaluation function and minimax, should we implement alphabeta for Section 1 or Section 2?', u'responses': [u'To succeed in section 1a you have to beat both minimax and alphabeta both using openMoveEvalFn.   You may be able to do that with a good eval function and minimax.  You may need a decent alphabeta.    Your chances are higher with a good alphabeta.']}, {u'text': u'for section 2 how do we change the move function? is it supposed to call minimax or alphabeta? ', u'responses': [u'Just update the move function to call an alphabeta function.']}, {u'text': u'For Section 2, Are we allowed use ""CustomEvalFun""? To do that is it enough to change the default eval at CustomerPlayer eval like 

def __init__(self, search_depth=1, eval_fn=CustomEvalFn()):Also for minimax and alphabeta test, i hope isolation will pass 'minimax"" or ""Alphabeta"" when call the move function', u'responses': [u'Yes. ']}, {u'text': u'""output"": {    ""points_available"": 20,    ""win_ratio"": 0.5,    ""points_awarded"": null,    ""num_invalid_moves"": 10,    ""num_timeouts"": 0},I got the above results. What does ""num_invalid_moves"" means as we are using the legal moves we get from the board. ', u'responses': [u'That you lost with some invalid move or no moves left. It means there was no timeout.']}, {u'text': u'Any tips to improve win rate?', u'responses': [u'Play better :-)...

On a more serious note, you should not need tricks on the first two parts of the assignment -- a good implementation of minimax and alphabeta should be able to win sufficiently.    I was able to do so with minimax alone with a depth of 2 (though by the skin of my teeth).

The 3rd part, on the other hand, I haven't figured out how to beat yet.', u'May be i am doing some basic wrong. i reach win ration 50%. I will check again. Thanks', u'I had a bug for the longest time where I was projecting incorrectly. You probably just have a bug. I ended up going through game history and looking for my AI making an obvious bad move. I recreated the game state and then ran a debugger on that part so that I could see why it was calculating wrong. That found the bug.', u'Try playing locally against random (you can change player_submission_tests.py to run multiple tests with your custom player and the random player).   Note that you should test locally when you are player 1 and other times when you are player 2 (sometimes your AI may work well as one but not as the other if there's a problem in your assumptions/coding).  You can adjust this where the Board is created (player 1 is the first argument, player 2 the 2nd).', u'I think I have implemented the alpha-beta correctly. But I still could not reach depth 2 or 3, which times out.
Did you use any special optimization?', u'How does it compare to your minimax?    It should be faster than minimax while still getting the same results.

I wrote a separate test script to test my alphabeta against my minimax (to ensure that at the same depth with the same source board they had the exact same results). 

I also added some metrics to measure how many end nodes I was evaluating to see if my alphabeta was actually reducing their number.']}, {u'text': u'One more question, will the below case be always when minimax or alphabeta of custom player is called?
maximizing_player=True', u'responses': [u'They will call your move function.  Your move function should call your move determination algorithm (minimax, alphabeta or otherwise) without setting this (making it true).

Now, when your minimax calls itself as it walks deeper in the tree to look at simulating subsequent moves, you will need to adjust this setting.   For example, you simulate that you move your queens to location A and B, then you call minimax on that board to see how well it looks for your opponent and in that instance, you pick a move for them and then call your minimax again, but this 3rd time you will be scoring how well the board moves are for you again.  

So the player that you are looking at the board for in different levels of simulation will be different (and how you treat the scoring and whether or not you want to maximize the score/minimize the score will be different).', u'minimax doesn't call itself right?, minimax calls min and min calls max, max call min', u'my minimax recursively called itself and did the min-ing and max-ing within itself.', u'Yep, you can do it without recursion I am sure but recursion was the logical choice for me for both minimax and alphabeta']}, {u'text': u'Is there a way to access Bonnie server and check our runs and extra the file we used to run. ?', u'responses': [u'https://bonnie.udacity.com']}, {u'text': u'Hi , After much tuning, I consistently get 75% (for 20 runs) win ratio locally with minimax depth = 2 and alphabeta depth =3 .  But i get terrible result in Bonnie. Is there a way i can check Bonnie logs to see where i am loosing.', u'responses': [u'If you're looking at the JSON file, timeouts indicates that your program did not return a move in time. Invalid move indicates that you lost with no move valid left. If you don't see an illegal move in testing, then you're likely fine with bonnie. This is all the information we receive.

Unless you are playing against a CustomPlayer, you are playing the RandomPlayer on your local machine. The RandomPlayer does not represent the minimax and alphabeta used by the Part 2 bots. Hence the RandomPlayer tests may return a higher percentage than bonnie.', u'You are right, i was testing my custom player against the random player. Finally i was able to cross the 65% mark. Thanks lot for all you help']}, {u'text': u'Is board always will be 7 X 7 when run on Bonnie Server?', u'responses': [u'Yes on a 7x7 board for every game for Bonnie']}, {u'text': u'Is Bonnie's agent also limited by timeout or does Bonnie get to fully explore through the search depth?', u'responses': [u'a) for a 7x7 board, to fully explore through the search depth would take a very, very long time (years).  So they clearly are not doing so.
b) we're fairly confident that they are living under at least the same constraints that we are living under (10 seconds) -- though that is an assumption.  I haven't seen a TA say one way or another.  I would even hazard that they may be living under less time in order to give us a reasonable chance to win.']}, {u'text': u'How does the server code invoke the CustomPlayer::alphabeta(...) function

for Section 1 of the assignment I coded some of the intial moves (which i call bookmoves) in the move() function itself and did not code them in minmax()

if the server code by chance calls the alphabeta directly then i guess my intial moves would never be called right?

Basically my question boils down to: Is it okay to write some code within CustomPlayer::move() ?', u'responses': [u'It doesn't.  Bonnie just invokes your CustomPlayer and it's CustomPlayer.move() function.   You have to adjust your CustomPlayer if you want to use a different sub-function (e.g. if you want to call a function you added called alphabeta(), you need to adjust that in your move() function to call it).', u'Thanks that helps']}, {u'text': u'game.forecast_move(q1_nxt_mv,q1_nxt_mv)My understanding of this function is that it applys your moves and leaves the gameboard at that, and also returns this new gameboard. Next the opponent is supposed to make its moves, but how do you make the opponent make its, without the opponent making its moves I dont see how you can get down to the next level in the tree and do some processing of moves at the next levelOr have i got this totally wrong', u'responses': [u'That gives you back a game.  You then take that game and make a move on it (you'll be making your opponent's move).  So if you pass that game down to the next level in your recursive function, the next level will be dealing with your opponents move.', u'ah so now we have to think of what best the opponent would do. my mind was reluctant to help the opponent I should have thought of that. Thanks', u'It's not that you help the opponent, it's that when you are choosing moves, you assume that you are playing against an opponent as good as you are so that you play the best that you can.']}, {u'text': u'I have my alpha-beta with iterative deepening algorithm winning over minmax on bonnie with constant over 65% - 70%. However, the winning ratio over alpha-beta on bonnie is always around 50%. I'm using open eval function. So this means my alpha-beta algorithm is not implemented correctly?', u'responses': [u'The best way to tell if your alpha beta is implemented correctly is to test it against your own minimax.  The analysis for the exact same move to the same depth should be the same for both.  I actually added a testing option in my move() function that tries both minimax and alphabeta to verify a) that they get the exact same results for each move and b) that the alphabeta gets that result with much less evaluations (i added a counter to the eval to see how often it is called underneath the two functions).

Assuming that is the case, you should be able to do alphabeta to a deeper depth than minimax (which should help you if your algorithm is correct).']}, {u'text': u'I thought our goals are progressive that each one is built on the one above...meaning it's easier to beat the minimax than the alphabeta agent in section 2. However I'm getting points for alphabeta but not for minimax due to lower winning ratio. Is this just a matter of luck? I was assuming there's  no randomness in the testing agents. Anyone has ideas/tips on this?', u'responses': [u'There is some randomness in the opening moves  , otherwise there is no point in running 20 games ,without the randomness the game is deterministic and you will get the same move sequence and result on every test run. ', u'thanks. It turns out that in order to improve performance, I added some bad heuristics for early steps which led to lost of game.

Having a local minimax/alphabeta opponent player and test against it with printed game moves chart really helped debugging and finding out the issue in code.']}]",,0.0,382.0,59,,Assignment 1 Section 2 discussion,[a1]
5ad7d4310d63974e20c39074,"

",jc6w44hrp9v2ki,"[{u'text': u'I submitted and got full points, however the description in the resulting JSON was ""Beats Thad's secret Eval Function"" and it appeared my win ratio was only 60%. Does that test still need to be updated?', u'responses': [u'From @57:
Section three will be activated in few days. Do not hit Bonnie for third section till instructed.

It was only open for testing. Please do not attempt to hit Bonnie. Your score will not count.', u'Oh I missed that! Thank you!', u'Sorry for the delay. It will be released by Thursday. ', u'Is it safe to submit to section three at this point?', u'Just saw email go out that Section 3 is ready.  Thanks.']}, {u'text': u'Are we expected to have the same code in all three of our submissions? Or, are we finished with the assignment as soon as we are rewarded the full marks for the three sections? (i.e. outside of the requirements laid out in the readme and the scoring rubric for this assignment, are there any other sources of points/deductions?).

Scenario A: If a student receives full marks on submission #2 (submit_a.py) without completing alphabeta, is that still a 100% for that section, or will they need to complete both alphabeta and minimax, then resubmit?

Scenario B: What about a student who receives full marks on submission #1 (submit.py) using just alphabeta without doing minimax?', u'responses': [u'No. You can have all three submissions different. Yes. You are finished as soon as you get required points on Bonnie. As far as code is concerned- please also zip and submit on T square for backup. Its compulsory. 
We might check the codes if needed for MOSS and other plagarism checking. Apart from that- your last Bonnie submission is final', u'Screnario A: Thats fine.Any one is fine. Or you can direct use iterative deepening and new strategies and submit from section 1. Thats also fine.
Screnario B: Thats fine. 
', u'Kshitish, do we need to upload all three versions of code to T-square? If yes, any naming conventions to follow?', u'Yes. Use any naming convention. Its for backup', u'Thanks for the clarification Kshitish (Wasn't even aware that it was mandatory to upload our code to t-square!).', u'Kshitish, can you make this ""compulsory"" policy a lot more visible?  Not many people are going to spot it in a thread that is only related to section 3 and with a question that is only partially related.

It also seems odd to require a t-square upload when Bonnie saves the code for every run.', u'Yes. I will make an announcement before deadline about Tsqaure. Sometimes there is some problem in submission to Bonnie. Or students say that they had some issue. Or last submission had not given any results. For that - we ask for tsqaure backup. (there is always some issue for one or two students!). Even if you not upload it there is no penalty, but we can't do anything if there is any issue. So I recommend putting it on Tsquare after you are sure that that is your last submission. ', u'Thank you for the clarification.

Since there is no penalty, I would not describe it as ""compulsory.""  Perhaps ""Optional, but recommended.""', u'Ah makes sense, definitely seems worth it to upload the backup. It would suck to fail the assignment due to a technical glitche (but it sounds like it's happened in the past). better say than sorry. Thanks!', u'""As far as code is concerned- please also zip and submit on T square for backup. Its [compulsory].""

In case we only need to upload one player_submission.py that works for all 3 phases of the assignment, then should it or must it be zipped?']}, {u'text': u'If my agent acts each turn within 10 seconds and nothing is added during initialization, is it sufficient to guarantee the game can end within 120 minutes?', u'responses': [u'I have the same issue, got exceeded the timeout of 7200 seconds, but I had each turn within 10 seconds and nothing during initialization', u'No. This is additional restriction added. We considered 120 minutes taking into consideration average moves played games. Actually max moves played in games removing some exceptions. So it came to less than 120 minutes. And then added some more time for small calculations etc. Everything came to be 120 minutes. This does not mean your game will compulsorily end in 120 minutes. This is add on factor which you must consider while designing your strategy. For example- initial 2-3 moves taken full 10 sec. ', u'Sorry, I am having difficulty to understand your reply :)
Are you saying we can't use up all 10 seconds in order to fulfill the 120 minutes requirement?

So I get all my moves under 10 seconds, but somehow Bonnie stay complaining it takes more than 120 minutes in overall.
There can be only 25 turns in each game (including both mine and the opponent), and there are 20 games in total AFAIK.

25 * 10 * 20 = 5000 seconds

And 5000 < 7200, so I am wondering why it will end up timeout.
What factors contribute to the extra time I spent to?

Thanks!', u'You do two rounds of twenty games against two different opponents, so 5000*2> 7200', u'Thanks Chris, so to conclude, we can not use up the 10 seconds in every step? :)', u'Is it safe to assume our opponent will get to use the full ten seconds for every move? So the burden of staying under the 120 minutes falls on us? ', u'Is it really intended though...
We only have time_leff to check for the 10 seconds limit, but we don't have equivalent for the 120 minutes thing.
And thus, it sounds doesn't make sense that the burden is in our end? 

Should we update the 120 minutes restriction as per the above maths?
That is, 25 * 10 * 20 * 2  = 10000 seconds

Thanks :)', u'Thanks for everyone's responses!Now I understand why timeout still happens even if my agent acts within 10 sec.

However, IMO this is not a right requirement. The spec states that agent has to act within 10 sec. As long as this rule is obeyed and the initialization time is reasonable, the agent should not be penalized. After all, I have no control on the amount of time my opponent spends and the time needed for booting up the game, etc.

Agree with Tony on updating the time restriction from 120 minutes to 25 * 10 * 20 * 2  = 10000 seconds.

Alternatively, if we really have to enforce the rule of 120 minutes for 40 games, could we at least get the average number of seconds that each turn should take? ', u'There are 25 turns of moves in maximum in each game. So both my agent and the opponent have 25 / 2 = 12.5 turns of moves on average.Assume the opponent uses the entire 10 sec for each act. Then the maximum time it can spend is 12.5 * 10 * 40 = 5000 sec while the timeout limit is 7200 sec.That means in worst case scenario, my agent has (7200 - 5000) / 40 / 12.5 = 4.4 sec for each act while my opponent has 10 sec.Is this high-bar requirement deliberately set?', u'+1, from readme, I think 120 minutes is enforced to avoid students cheating in constructor only (like loading a giant play book into memory), so the restriction should be at least >= 10000 seconds. ', u'Others have said (on slack) that they have limited their code to using 7 or 6 seconds rather than 10 in order to get them to pass presumable for this reason.', u'If limiting our agent's time limit to 7 or 6 seconds helps pass the 120 total minute time limit, would the instructors' kindly consider decreasing the official 10 second per-turn limit?

I don't believe the argument that it's possible to figure out the maximum number of turns per game, multiply by 10 seconds, and get an upper-limit on total run time that is less than 120 minutes. That calculation is conflating two different measurements: CPU time and wall clock time. Our AI might always respect the 10 second CPU time turn limit, but the total run time depends on Bonnie's server load.

It's easy enough for us to change our code to meet any given per-turn time limit, but the total time includes both our bot and the opponent. It's unfair for our bot to play with a 6 second time limit against an AI that's using a 10 second limit.

Reducing the per-turn time limit would also help us see results faster, which would make this a more pleasant assignment to work on.

Reducing the time will also reduce Bonnie's server load. We're almost a week from the due date and the system is already overloaded. It's only going to get worse as we get closer to the deadline.', u'The point of the overall runtime limit is that sometimes agents have to make the decision when to keep searching and when to quit. For example, if you can make your turns take 1 second for the first few moves, then you can take the full 10 seconds later and still come in under the 120 minute time limit. If they changed the time_left function to only allow 6 seconds per turn, that wouldn't be possible.

However, I still have doubts about how this will come into affect for the peer-to-peer bot tournament. Can we always take 10 seconds for those turns? Or will both agents be disqualified if some game-level time limit is exceeded?']}, {u'text': u'Apologizes if this is inappropriate to ask, if it is then please ignore/delete (not trying to break any honor rules or anything)...

Is it possible to get any subtle hints as to what might be a good evaluation function?  I'm just trying to beat the iterative alpha beta (which I have also already implemented myself) and I'm having no luck with OpenMoveEvalFn anymore.  I've considered a couple of different things, but as far as I can tell they only make my AI worse, not better, so I think I'm headed in the wrong direction.  Would love to be able to spitball ideas off a TA in a private question if that is allowed!', u'responses': [u'It helped me to play a couple games on paper. Toward the middle/end of the game I would try to evaluate the board states through visual inspection. Trying to answer these questions helped me:

1. What aspects of this board state lead me to believe player x has the upper hand?
2. What would OpenMoveEvalFn miss given this board state?', u'On paper only? Did you not write a visualization of the game like with turtle or something?', u'There's already a print function built into the board class if you need an automated visualization. I played 2 games with my wife on grid paper. It took much less time drawing a box around 49 cells than it would take to write visualization code (YMMV). 

I think you can get a lot of intuition from just looking at a few random states in the middle of a game. However you accomplish that is up to you! :)', u'I will also suggest same things as William told. 
Apart from that-check the README hints. ']}, {u'text': u'If I add print statements in player_submission.py for the third section, can I get an output of those from Bonnie (something like debug logs)?

I know it will add timings because of IO operations but I want to see which move is taking longer time on server. I couldn't reproduce time out on my local machine even through worst depth at level 1.

Getting an idea about the program is running on server, it will give me clue to resolve time out issue.

Once I resolve issue, I may resubmit section 3 without print statements.', u'responses': [u'i think bonnie automatically turns print off so they won't be visible to you', u'Thanks!']}, {u'text': u'At least a couple people have received this both locally on the command line and when viewed through the Bonnie website:
', u'responses': [u'i got it when i closed my laptop after submitting', u'Same.  It's very annoying if your internet connection goes out and you're timed out for another submission.', u'I got this error code from Bonnie as well, without a known cause, after about an hour of running.  Any ideas why this error occurs?

This error code appears on bonnie.udacity.com in the results summary of my submission, but it would seem strange if the runs on bonnie require a constant connection to student machine the submission was made from.', u'I ran a test where I submitted a run and then killed the terminal, terminating the tasks that were running.  close to 2 hours later, the run completed and bonnie was updated with the results.   So at least for this test, it seemed to run even though the shell was gone.', u'Ideally this should not happen. Once you submit it, the server is still running. You will not see the results on your local machines if  you switch off but it should be visible on Bonnie', u'If you'll notice, Kshitish, that screenshot is a capture of Bonnie's web interface.

The other student it happened to had the same thing occur.
']}, {u'text': u'""If you wish to compete in the tournament, simply include a plaintext file with a description of your agent, titled ‘AI.txt’, while submitting for the third section of tests (submit_b)""

What should the AI.txt description contain ? My name or just a random name ?  

Also, to submit for botfight, do we simply need to execute ""python submit_b.py"" ?  Or do we need to submit AI.txt also in the command ?', u'responses': [u'The file AI.txt would be submitted by the script submit_b.py if you give the required arguments. Please refer to the submit_b.py file for it. The file AI.txt can contain a BRIEF description of your implementation of the evaluation function if you have a Custom one and other aspects of the implementation. You DO NOT need to explain the code, we just want to know what was your rationale behind your AI player in a few sentences.']}, {u'text': u'I'm trying to submit for section 3 on bonnie and keep getting a ConnectionError:



I did a quick search and no one else seemed to have this problem. Any ideas what's going wrong? ', u'responses': [u'Seems like a network connection issue.   Since you are already ""waiting for results"", I presume your code has been copied up.  You should seem something like:

Uploading submission...
[=========================== 100% ===========================] 34815/34815

which indicates that you are -- at least -- able to connect to bonnie.   I would see if the submission completes (you can go to https://bonnie.udacity.com to see the results of your runs).   If not I would resubmit (presumably from a stable network connection).', u'Still occasionally getting this error. When I get it, sometimes bonnie shows the full submission as completed with a score, while other times it's empty. I can get the submission through to bonnie about 2/3rds of the time now so I'm able to at least work with it for the time being.  ']}, {u'text': u'I am trying to implement Iterative Deepening(ID) with Alphabeta pruning. As per my understanding, ID increments depth at each step and calls alphabeta and once the timeout occurs (if it has been handled properly), it returns the best move for the queens.

However, I have noticed that if I give ID the liberty to go to as deep as possible, it is mostly performing worst than simple alphabeta implementation. What is the reason behind this behavior? Do I need to use some special technique with ID to improve its performance?', u'responses': [u'I would *guess* that there's something wrong in how your scoring the possible moves (though it is possible in some cases that the score preference to a subsequent level can lead you astray, it should not consistently do so unless you have some other issue at play).

One potential here is that you're looking at the wrong player's moves.  Another is that you're not updating the game table accordingly at each simulation. 

You also could have a problem with how your handling running out of time.  If you have a partially processed level and that results in you only looking at that portion of the level you processed, it's likely you could be eliminating branches unnecessarily -- you should fall back to the prior completely processed level.

Not saying any of these things are going on as I really don't know.  But you should not be getting consistently worse gaming if you're going to a deeper level.', u'Thank you!! Your ideas really helped me, especially the one regarding partially processed levels. I modified the bug and its now picking up the results from prior levels. However, I also noticed that my ID keeps on running to great depths. Unless I change

while True 
to
while current_depth < MAX_DEPTH (say =10)
Is this something expected or my ID should work fine without having to put a check with MAX_DEPTH?', u'I can't give you any absolutes because I don't know your algorithm/implementation.

However, ""while True"" is an endless loop.  It will go forever until you have some terminating condition inside your loop that breaks out. 

Theoretically the maximum possible depth is around 12-13 (4 pieces to place on 49 squares).  If you're going deeper than that you probably have something wrong in your simulated play.

You may still have timeout issues long before you get to 10 or 12 given the branching factor that's possible with this assignment.', u'Could in theory get a stack overflow error though or whatever Python gives in that condition.', u'Thank you everyone!

@Conor Cahill
Can you please elaborate ""(though it is possible in some cases that the score preference to a subsequent level can lead you astray, it should not consistently do so unless you have some other issue at play).""

I am sometimes getting lower utility score for subsequent levels (with different moves)- in this case I am choosing subsequent levels even though the score is lower. Is that a good idea - should there be a terminal state that I am missing?', u'If you're only looking at a depth of 3, the score can indicate that path 1 is the right path since it gives you the highest score at that point.  However, you may find out later that that path actually ends up where all options lose to your opponent (but you can't tell that because you can't exhaustively search).', u'So now I have implemented IDAB with Move ordering and I am hovering around 50% against 1b agent. However, I am wondering if the move ordering should be done in decreasing/increasing order depending upon whose turn it is - maximizing or minimizing player's (respectively)? Or should it be always decreasing because my agent will always be the maximizing player?', u'I got over your hurdle Rupal by playing with the Eval function and starting spots. You are close you can get there.']}, {u'text': u'In the future I think it would be nice if the last 5 points was separated from the other 20 points. After accomplishing the 20 points I've noticed that when I do better against the secret eval I do worse against the 20 pointer. I think this will discourage many to even pursue the last 5 points as they will fear losing the 20 points they've achieved. Just a thought!', u'responses': [u'Can't agree more.Combining those two parts just discourages people to work on that 5 marks.', u'Adding my vote to this as well. I'm not likely to try to iterate anymore as I don't want to risk losing the 20 points.', u'Okay. I will put this suggestion in my document for next semester TA suggestions. 
However, as compared to last semester- just one submission 4 hrs for complete assignment- this time we made significant progress. Otherwise, to play against random you need to play against secret eval. ']}, {u'text': u'Thanks', u'responses': []}, {u'text': u'Are we allowed to add additional parameters to custom function? something like:
def score(self, game, maximizing_player_turn=True, extra_param=None):', u'responses': [u'The ReadMe file says we can't change the function signatures of the provided methods. We can only change the default values of the attributes already given. ', u'/What if we changed the function signature and passed Bonnie?
']}, {u'text': u'I'm struggling a bit with the last section. Implementing iterative deepening on its own is not difficult but I'm not grasping how I need to use the results of the previous iteration to fuel the next.

I was wondering how much guidance I can ask for while still honoring the student code. The most I've been able to get is a 55% win ratio agains the ID agent in the Bonnie server. I'll keep trying out but any help will be greatly appreciated! :-)', u'responses': [u'I think you are at the same point that most of the class is currently. We can discuss approaches and techniques, but not code. That being said, the best opportunities to gain an advantage on Part 3 is your strategy for your first two moves and creating a better CustomEvalFn since the bot is on the OpenMoveEvalFn. Otherwise we can only match the depth of alpha beta and ID.

With you being so close as it is, I think a slight change in your first move strategy for the first 2 where the branching factor is too high might earn those last 20 points.', u'Thank you Chad. That makes sense to me. I've only been using an opening move on the very first turn. I'll give that a shot. ']}, {u'text': u'Hint for some people implementing iterative deepening:  make sure that your evaluation function works correctly on all depths of the tree!  And by all, I mean both even and odd depths.  Turns out I was assuming that I was always the active player, so on odd depths of the tree I was evaluating the board state in such a way that would best benefit the opponent!  I didn't catch it in parts 1 or 2 because I had hard coded evaluating to a search depth of 2 for those submissions, and my code worked for even depths.  Just a tip for maybe anyone who has been ripping their hair out the past few days trying to figure out how to better optimize when they thought their algorithm was working otherwise.', u'responses': [u'thanks for the hint! I was having the same problem.', u'I did not get it. When you evaluate ""active player moves -  inactive player moves"" , doesn't it always gives benefit to active player irrespective whether it is opponent or us?', u'The problem lies in how the forecast_move method works.  So if you are implementing iterative deepening, and initially only searching the first level, then you want to apply all of your possible moves, and then take the maximum of the output of those moves and take that as the best move before you search the next level (in case you don't finish it).  Now the problem is that when you use forecast move, the active player switches to be your opponent after you apply your move.  Meaning that if you do active play moves - inactive player moves you're no longer doing mymoves - oppmoves, you're doing oppmoves - mymoves.', u'Thanks Carey,

Indeed the way the way the player is coded can lead you astray. I had the same issue.
', u'Thank you :)

I almost gave up after trying so many different things. It turns out I had the same problem. :)', u'Unfortunately this didn't totally get me there for some reason, so looks like I will be sticking with the 75 points.  Glad I was able to help others though!', u'It is a shame! I managed to pass the first two parts with the wrong implementation, but tweaked the hell out of everything else, opening books, eval function and so forth. Once fixed the bug it all worked up to 95 pts. The last 5 wasn't worth the effort.
', u'Efty

Same here, i managed to pass first two parts with wrong code. But improved lot with almost all techniques hit 99% win locally/100 runs, but some reason i always got 0/20 in Bonnie. I am still breaking heads whyyyyyyyyyyy']}, {u'text': u'What is the test case should i use for locally to rest third section?

Custom Player vs Random Player or Custom Player vs Custom Player?
r = RandomPlayer()h = CustomPlayer(4)game = Board(h, r, 7, 7)', u'responses': [u'Both...  They will run it 50% with you first and 50% with them first.

You should also consider playing your custom player ID vs custom player AB (or custom player Minimax).  they should give you a better run for your money.', u'Conor, Thanks for the advice. I see what i was missing for section 2, which i seems i passed luckily', u'Conor, How can i test custom player ID vs custom player AB? should i create new class custom player AB?', u'You can do it that way.  You could, for testing, add a parameter that allows you to specify the underlying method to use (though this changes the signature of the function.  You could also add a setting for the class as to which function to use and add getter/setter APIs to change this.  I did the latter (I have a setting that indicates whether my move() should call Minimax, AB or IB and have a getter/setter that can see/change that setting.  Then I create two different instances of CustomPlayer, one for each function I want to test.']}, {u'text': u'For section three , is it mandatory to use customEvaFnl Function or can we still use OpenMoveEvalFn?', u'responses': [u'You can use whatever eval function you want.']}, {u'text': u'What if I changed the function signature but still passed on Bonnie? Do I need to resubmit?', u'responses': [u'Thats fine. Which signature are you changing? if score - then there is a problem']}, {u'text': u'Hi, I see one of the improvement techniques suggested is ""Store the evaluation scores for past moves."". But wouldn't score be affected in ID for each level considering opponent might have chosen different move?', u'responses': [u'You're not saving the score based on the level.  You would be saving the score based on the board so that if you arrived at the exact same board (perhaps via a different order of moves) you would already have the score calculated.

The ""state"" of the board includes which positions have been occupied by a queen at any point in the past as well as the current position of your queens and their queens (though it doesn't matter which of your queens or which of their queens as long as the pair of queens occupy the same two locations).']}, {u'text': u'Tested my code with against section 2 minimax and alpha beta. It beats them both. I am doing Custom Eval, move ordering, killer moves and remembering old eval scores. Still i get 0/20 . Am i missing some thing?', u'responses': [u'What is your approach for searching the tree? alpha beta, minimax, iterative deepening?', u'for section 3, i am using iterative deepening (alphabeta). I am tested my ID against both minimax and alphabeta.', u'A custom eval will help you gain an advantage. Also some randomness with your first move or two will help change each game sequence, which will allow your custom eval to have a greater variety of games to win. If you use the same first move for every game against the same depth of analysis, you're essentially playing 10 games with nearly the same moves as you both are using alpha beta to as far a depth as you can go within the time frame.

Some assumptions I had that were proven incorrect by bugs were:
My alphabeta was not actually finding the best move at every depthMy Custom Eval function assigned advantages to my opponent instead of me since I incorrectly used active and inactive playerI was not correctly finding the best move with my iterative deepening

I can say that with a good CustomEval, a good opening move strategy and correct ID with aphabeta, you can achieve 13 wins without partitioning optimization, killer moves, move ordering, or saving old eval scores of boards. These and optimization of ID to search even further are needed to get the full 100 and be competitive at the bot fight.']}, {u'text': u'I have just realized that adding AI.txt is not sufficient to join the tournament, a command line option is needed, is that too late to join it? :)', u'responses': [u'On the same boat. I didn't realize that we needed to pass an extra argument while submitting. The instructions in the README gave the impression that the file just needed to be present when submitting. I assumed the script just looked for the file. Would it be possible to still be considered for the tournament?', u'Made the same error.', u'Could the TAs chime in to see if there's any chance we could still be considered for the face-off? I'm very interested to see how my agent does :-)', u'Create a private post. I will send some instructions individually. ']}, {u'text': u'As Assignment one has ended, can we share our code to find out what wrong in the code and why could not pass section 3?', u'responses': [u'Only share code on a private post with the instructors so they can help you out. Publicly sharing your code even after the class is over would put you at risk of an honor code violation, which is not your intention.', u'Unfortunately, you can't share your code even when the assignment deadline is over. For multiple reasons, which includes the fact that some students have extensions from the Dean's Office and are still working on the assignment. Even otherwise, public sharing of code is not encouraged. We do, however, encourage discussion of ideas, which we will initiate soon after the results of the bot-fight are declared. The winners can share their strategies and we encourage an open discussion of ideas then. ', u'Richa, Can we share with Instructor's in private post. Like to know what is wrong.', u'Frankly- this is a huge class and instructors might not be able to go through the code. After the botfight results are declared, we have discussions on the strategies. ']}]",,0.0,392.0,60,,Assignment 1 Section 3 discussion,[a1]
5ad7d4310d63974e20c39075,"I was looking at keeping my code saved and track the progress while not violating any code of conducts. 

I found this answer helpful.

Anyone who is not an expert at git, can follow the above steps. 

$ git clone --bare https://github.gatech.edu/omscs6601/assignment_1.git
$ cd assignment_1.git/
-- create a private repo on github.gatech.edu/username. I have created 6601assignment_1. Then follow
$ git push --mirror https://github.gatech.edu/username/6601assignment_1.git
$ cd ..
$ rm -rf assignment_1.git/
$ git clone https://github.gatech.edu/username/6601assignment_1.git
$ cd 6601assignment_1/
$ git remote add public https://github.gatech.edu/omscs6601/assignment_1.git
$ git pull public master
$ git push origin master
",jc6w44hrp9v2ki,"[{u'text': u'I've also removed the public url for push just to be safe.

git remote set-url --push public DISABLE', u'responses': []}, {u'text': u'Thank you Anil :)', u'responses': [u':)']}, {u'text': u'Incidentally, as that is – marginally, not that it really matters – an overcomplication, in case there are more people who are not acquainted with git, a simplified sequence is
$ git clone https://github.gatech.edu/omscs6601/assignment_1.git
$ cd assignment_1
Then create a private repo at github.gatech.edu/username, for instance cs6601_assignment1. Then$ git remote set-url origin https://github.gatech.edu/<your username>/cs6601_assignment1.git
$ git push -u origin master
$ git remote add upstream https://github.gatech.edu/omscs6601/assignment_1.gitThen as necessary for instance to pull from upstream $ git pull upstream master, to push to the private repo $ git push -u origin master or some working branch etcetera', u'responses': [u'Very helpful tip!', u'']}, {u'text': u'Thank You. Your tip was helpful. As per my understanding, Once we are done cloning, the newly created repository is NOT our working directory. We need to create a new branch and then do work on that branch. Correct?', u'responses': []}]",,0.0,236.0,62,,Private repository on https://github.gatech.edu/,[other]
5ad7d4310d63974e20c39076,"
Is there a particular IDE that people like to use for this class such as Pycharm or do many just use the basic IDLE? Is there any specific one that would be particularly useful for this class?",jc6w44hrp9v2ki,"[{u'text': u'I have used vi for most of my python coding in prior classes...   I'm going to try to use pycharm this semester to see how it goes...', u'responses': []}, {u'text': u'I'm partial to VS code myself. It's not as robust as PyCharm, but I prefer how it's laid out. The one downside is that the python debugger is quite slow. However, the debug faculties other than that are quite good.

I work a lot in javascript, which VS code is phenomenal for.', u'responses': [u'I second this. I use VS Code for Rails, JavaScript, Python...you name it. If there wasn't VS Code, I'd probably use Atom or Brackets.', u'I third this. VS Code is a very good editor to get used to for this program, especially since various courses will have you use different languages. ']}, {u'text': u'PyCharm is great. I also like VS code - but a major drawback is you can’t undock editor windows so you’re pretty much limited to a single monitor, which is lame.', u'responses': [u'Haven't tried, but probably you can open another window pointing to the same project/folder?  Nope, switches focus to previous window...']}, {u'text': u'+1 for pyCharm. Fully functional student license is free (with GATech mail id).', u'responses': []}, {u'text': u'
Yes, PyCharm with Anaconda works well for me too.', u'responses': [u'I had the latest version of Anaconda (with Python 3.x). So instead of downgrading to 2.x version, I ended up using my base install 2.x version.']}, {u'text': u'I use Python a lot for my day job so I've got a good setup with tmux and vim. It does code linting with pyflake/flake8, which helps catch a lot of simple errors straightaway. I have it configured so I can move code between an editor pane and an ipython pane. It's not the easiest to get started in, though, so I only recommend it if you really need a power tool.

This reminds me, I need to figure out how to get it to lint Python 2 code so I stop getting notified about syntax errors every time I use a print statement...', u'responses': [u'
Maybe we can request permission to use the future package :-)     

UPD: already included in requirements.txt, may not help much.

']}, {u'text': u'Personally I like using Sublime with a REPL.', u'responses': []}]",You can use anything you like but Pycharm is a popular choice.,0.0,258.0,63,,Python IDE,[python]
5ad7d4310d63974e20c39077,Came across this extensive blog post simulating Chutes and Ladders and some folks here might think it was interesting,jc6w44hrp9v2ki,"[{u'text': u'Neat! Thanks for sharing :)', u'responses': []}]",,0.0,191.0,64,,[off-topic] Chutes and Ladders,[lesson1]
5ad7d4310d63974e20c39078,"Professor Starner reminds me of an article I read many, many, many years ago, which profiled an individual dedicated to mobile computing and showed pictures with this person harnessed with computer and display, just out in the world.  I think it was maybe in Wired magazine or an MIT publication.",jc6w44hrp9v2ki,"[{u'text': u'He'd probably be the best person to comment, but it sure sounds like he's the one you're talking about.

Regardless, he is the guy.', u'responses': []}, {u'text': u'Wow, now I'm taking a class taught by ""that guy""!  This is great...thanks for the link.', u'responses': []}, {u'text': u'Thank you and great post, Richard!

That site is insanely cool.... I can still recall how ""amazing"" I thought the Nokia 6600 was and now I'm just laughing at the thought reading that piece on the site. Crazy to think that was ~15 years ago!

Prof. Starner, you're not that guy..

You Da Man!', u'responses': []}, {u'text': u'Very brave in hindsight, considering the amount of radiation even a mobile phone used to put out back then. Your duck fireball may not have been the only memorable cooking event, there could have been the memorable Thad microwave too :-)', u'responses': []}]","I am ""that guy.""

Actually, there was a whole cluster of us, called the MIT Wearable Computing Project, which I founded while in grad school.

Our web page was at

https://www.media.mit.edu/wearables/history.html

It was one of the earlier web pages ever made!",0.0,253.0,65,,"Professor Starner, are you the guy?",[other]
5ad7d4310d63974e20c39079,"Hi all

I am wondering why the boxes in red circles are considered as ""prune-able"". 
To my knowledge, they are larger than its sibling (10 > 0 and -3 > -7), so the min node is not necessary to care about them at all? And I don't think we should consider them as pruning?

Thanks

",jc6w44hrp9v2ki,[],"Once the algorithm gets to the middle green probability node, it knows that it's looking for something greater than 5.2 (since the left green probability node is calculated to be 5.2).

In the first min node triangle (with 0 and 10), as soon as 0 is seen, it calculates the highest possible value for the above green circle. Since 0 is encountered, the left min node knows it is <=0. For the right min node, it assumes the highest possible value of 10. Then using the probability of each min node, the highest possible value of the green probability node can be calculated:

0.5*0 + 0.5*10 = 5.0

So the algorithm computes that the middle probability node is at most 5.0. The pruning includes the 10 in the left min node and the whole right min node because the decision to prune is reached before looking at these nodes.

Similar calculation for the right probability node after encountering the -7 in the first min node:

0.5*-7 + 0.1*10 + 0.4*10 = 1.5

The -3 can be pruned since the calculation that 1.5 is less than 5.2 allows the algorithm to prune right away.",0.0,197.0,66,,Question regarding &#34;54. Quiz: Probabilistic Alpha-Beta Pruning&#34;,[lesson1]
5ad7d4310d63974e20c3907a,"The submission script won't work as-is if you have 2FA enabled for GT login. 
Here's my workaround for windows.
Go to https://bonnie.udacity.com/auth_tokens/two_factor
download the JSON web-token. Rename it ""gtomscs_jwt""
Put it in the same folder as your submit.py

That worked for me, somehow.",jc6w44hrp9v2ki,"[{u'text': u'Hello, im having trouble submitting the assignment.  I own a mac.  When clicking on the link above, I right clicked on ""this link"" and clicked save link as 
and as soon as i type ~, i get a go to folder.  When i finish typing ~/.nelson/gtomscs_jwt
and click go, i just get a beep.  but nothing happens.  Can anyone suggest a work around?', u'responses': [u'You need to save it as .json']}]",,0.0,223.0,67,,Tips for 2FA users,[other]
5ad7d4320d63974e20c3907b,"Hi All!

Assignment 1 was released yesterday. Some of you might have started it. 

We normally have youtube live session for each assignment in the first week when it is released. In youtube live, we generally go through the code and understand what each function does. We are not going to discuss strategies or understand concepts about minimax or alphabeta. This event is mostly 'how to start' guide. I will discuss some questions. Last time there was some problem of seeing the chat while I was on hangout air. So I recommend you to use this piazza post follow up to send questions. I will keep checking this thread during the course of the session. 

The event is recorded. For those who are not able to attend the session,you can see the event on the link later as well. I highly encourage you to attend the session just to resolve any doubts you have about the given code. If you are not able to attend, feel free to use piazza or TA office hours for more interaction. 

Thanks! Link for the session: https://youtu.be/KkLcMvegoLo
Time - 12 noon EST
",jc6w44hrp9v2ki,"[{u'text': u'Is anyone able to view the recording with the link provided? I missed the live session.', u'responses': [u'I think it's happening tomorrow.', u'Ack.Thanks Jim.

From the calendar link Office Hours i thought there was one earlier today and the above link was for that one.
']}, {u'text': u'To allow you to prepare in advance, could you give us an illustration of what you mean in the comments to OpenMoveEvalFn():
            1. Be very careful while doing opponent's moves. You might end up 
               reducing your own moves.
            2. Here if you add overlapping moves of both queens, you are considering one available square twice.
               Consider overlapping square only once. In both cases- myMoves and in OppMoves. 
            3. If you think of better evaluation function, do it in CustomEvalFn below.  In particular, although it seems clear we are not supposed to double count own moves for q1 that coincide with own moves for q2, are we supposed to not double count own moves that coincide with opponent moves?', u'responses': [u'Adding to that, is the parameter maximizing_player_turn relevant to the calculation? As in, are we calculating an evaluation from the perspective of the player whose turn it is [is it called in tests only from the perspective of AI player's turn], or should we assume that the AI player is the maximizing player, then assign own & opponent accordingly?', u'I will come to the Note section in youtube live session. Thanks for asking that. 

Your second question- maximizing_player_turn is given for you in case you need it. You might not need it. In previous semesters few students requested for giving access which player turn you are in. That's why it is there. ', u'Similar to what Kshitish said, I am using maximizing player to know whether the AI is the active player in the game state or the inactive player in the game state so that I can use prewritten methods to grab the list of legal moves for AI and opponent.', u'Hi Kshitish,

I think your description could be clearer; even though it looks as though we've understood it collectively, maybe you could clarify.

For instance, say [integer values for simplicity] player 1 had moves for q1 3,5,7,9, for q2 3,4,5,6 then player 1's moves are 3,4,5,6,7,9
then say player 2 had moves for q1 2,4,6,8, for q2 3,4,6,8,9,10 then player 2's moves are 2,3,4,6,8,9,10
however player 2's moves include 3,4,6,9 that are player 1's moves too; there is an interpretation such that player 2's moves should not include those, they should be 2,8,10', u'Thanks, as you say is as I've understood it more recently, it's worthwhile hearing it from you for the sake of subsequent questions of course though :-)', u'So has it been clarified which interpretation is correct?', u'Anthony, MarkBenjamin1, Lily

DId you confirm this? I understood it as MarkBenjamin1 described, but do not seem to pass Bonnie OpenMoveEvalFn. Can you please confirm/clarify.', u'I only merge moves by a single player (not counting the same move twice within a single player.  I do not merge across users.  (so P1.Q1 may be able to go to (1,3) and P2.Q2 may be able to go to the same position and this has not impact on their scoring.   However, if P1.Q1 and P1.Q2 can go to the same space, i only count it once for that player.

This is different than Mark describes.   But it does pass the OpenMoveEvalFn test on Bonnie.', u'Conor, are yew trolling? :-D']}, {u'text': u'The closing of campus today due to weather doesn't affect this live stream, right? I would imagine not, but I'd like to confirm. ', u'responses': [u'No change. I will host it from home :)']}, {u'text': u'Are we allowed to use what I'm assuming is private methods/members found in isolation.py (i.e. anything with __,  __inactive_players_queen1__, etc.)?', u'responses': [u'Yes. I think they are needed to make a nice algorithm.']}, {u'text': u'Can we assume that we are always the maximizing player.', u'responses': []}, {u'text': u'How to test score function code against bonnie?', u'responses': [u'but you have to wait for 30 mins', u'How do we use Bonnie?https://bonnie.udacity.com/ there is no upload link...', u'You call ""python submit.py"" and it uploads the program to bonnie and runs the tests for that stage of the assignment.

You can go to https://bonnie.udacity.com to see the results that are recorded for prior runs as well as the number of runs left in your quota and/or time before you can run again if you've used up your quota.']}, {u'text': u'For the section 1 test (submit.py), it seems that Bonnie is calling CustomPlayer() without specifying a search_depth argument even though the function signature requires search_depth.

The instructions in the README say we can't change the function signature.

Can you advise?', u'responses': [u'Set a default value', u'Ok, thanks for clarifying.  I want to be careful as providing default values is a modification of the function's arguments, even though it isn't necessarily changing the order, naming, or number of arguments.', u'You are not permitted to change the function signatures of any of the provided methods.
You are permitted to change the default values within the function signatures provided. In fact, when you have your custom evaluation function, you are encouraged to change the default values for __init__ to use the new eval function.']}, {u'text': u'​For OpenMoveEvalFn, if q1 has 5 legal options and q2 has 5 legal options (none of them overlapping), then you would have 5*5 combination of moves instead of 10 correct? 

Is this what the function is looking to return? ', u'responses': [u'Okay thanks for answering!

I believe you clarified that the OpenMoveEvalFn should just return (options_AIq1 + options_AIq2 - AI_options_overlapping) - (options_Opq1 + options_Opq2 - Op_options_overlapping)']}, {u'text': u'Can I just run player_submission_tests.py now to get understanding of how the game would work on server?', u'responses': []}, {u'text': u'You may also show how one has to initialize board = game in the functions so that the functions will be selectable in IDEs', u'responses': []}, {u'text': u'Sorry if this has been asked somewhere else. For the last line: print game_as_text(winner, move_history, termination, board_copy) in isolation.py. Is the variable board_copy a typo? Shouldn't it be board.copy()? Thanks. ', u'responses': [u'I have the same question.', u'It should be board.copy(), it is a typo, it was answered in office hours that it is a typo', u'Yes, it should have been board.copy().  Kshitish confirmed this in the Google Hangouts session yesterday.

However, it shouldn't pose an issue as you don't want to run isolation.py directly.

In order to do tests, you should run player_submission_tests.py or create your own.']}, {u'text': u'How does the timer timeout work? In a cursory read of the code it seemed that a timeout event caused a loss for that player after 10 seconds. If so, do we need to use our own timer or is there a way to access the engine's timer in our code?', u'responses': []}, {u'text': u'your screen is not visible', u'responses': []}, {u'text': u'could you show the indentation that you think isolation.py should have?
Especially play_isolation()', u'responses': [u'Just show us how it is indented when you look at it', u'I am using pyCharm and used the command as per https://www.jetbrains.com/help/pycharm/reformatting-source-code.html for indentation.', u'The trouble is that it is all screwed up to start with, you can't automatically mend what is horribly broken', u'I've got pycharm too, obviously', u'It worked for me. Just imported the project and run the commands.', u'How do you know that the indentation it has produced, is the original indentation that Kshitish intends?', u'I have tried that before, incidentally & the results aren't unequivocal', u'I think so as the project still works as expected. I went through the code after reformatting and it did made sense and provided much clarity to understand the execution flow.', u'Hmm, interesting. Let me test again....', u'If you open the code within the github web interface, that also showed the correct indentation for me.', u'The issue with indentation is a mix of tabs and spaces.  However, as it is currently indented, it runs.  Just don't mess with the file and you'll be fine.', u'Ugh', u'It has weird mixtures sometimes a tab is worth 4 spaces, sometimes 8', u'You can't be sure that play_isolation()'s try-catch logic is working as intended without pen testing', u'If you look at the file in github in your browser it shows it formatted I believe. I had to change tabs to spaces to show consistent formatting in vim', u'Nicely noticed Anthony; I've noticed he views the code at the start of the video too; an unusual move scheduling for 12pm-1pm then going from 11:45am-12:30pm :-D']}, {u'text': u'because in Isolation the class is Board and not game
', u'responses': [u'Tried didn't work in pycharm']}, {u'text': u'Hi there are a few questions on youtube chat would you prefer us to ask it here instead?', u'responses': [u'They expect us to do it here only. Going by my previous semester experience']}, {u'text': u'If there is no code outside of the functions you have given for us, how would we add an opening book or such? Would it need to be an array inserted into the function code?', u'responses': []}, {u'text': u'Are the terms ""Board"" and ""game"" interchangebly used .. its a bit confusing', u'responses': [u'Ok fair enough.. thanks for clarifying']}, {u'text': u'This could be dumb question but are we suppose to edit and submit player_submission.py only? ', u'responses': []}, {u'text': u'Tried in Pycharm didnt work. Forced to include the ""board = game""', u'responses': [u'Player_submission.py', u'thanks']}, {u'text': u'How do we handle CPU requirements? since my cpu is different from the servers, how do we account for an average timeout per move?', u'responses': [u'The timers use RTC ( real time clock) and should be independent of CPU clock speeds.. but I may be incorrect.']}, {u'text': u'Loser is determined by the first player who can not move 1 of their queens correct? Meaning even if my 2nd queen can still move if my first queen is dead I lose?', u'responses': []}, {u'text': u'a move is counted when q1 and q2 both are moved ?', u'responses': []}, {u'text': u'Can you demo or explain the evaluation function of a toy example in a 3x3 board? That helped a lot on previous courses like CV', u'responses': []}, {u'text': u'Is there a way to turn on auto subtitles for the video?  I'm terrible with accents and subtitles would help me a lot.', u'responses': [u'Youtube has subtitles generated automatically. (CC on the bottom right)', u'Thanks, must have missed it.']}, {u'text': u'Any chance we can not do office hours or stuff like this in the middle of the day? Most of us are taking online classes because we work during the day.
Thanks', u'responses': [u'TAs are scheduling their OHs. Mostly we have taken slots which covers all times from morning to night. There would atleast be one OH slot every working day. 
Youtube live- Yes. We can arrange this in middle of the day from next time. I will inform the TAs who are doing next assignments. ']}]",,0.0,406.0,68,,Assignment 1 - Youtube live event,[a1]
5ad7d4320d63974e20c3907c,"What is the runtime environment for the tournament going to be like? Specifically, what are going to be the OS, CPU, and RAM resources?

Will both opponents run on the same physical machine, or will there be some sort of resource isolation to prevent one AI from interfering with the other?",jc6w44hrp9v2ki,"[{u'text': u'Can you please post the system specs?

I don't see how Bonnie can provide any sort of isolation between threads or processes. Are we allowed to use multiprocessing?

What about network calls? Are we allowed to run the game on a server and call out to it? That would seem unfair to me, but I'd like to see a written list of rules.', u'responses': [u'Sorry- We are taking time. Frankly, even I dont know which system we are going to use. I will discuss with the team and will let you know. ', u'No network calls for sure. No multiprocessing. 
We are not testing that skills. We are trying to design a game with AI strategies which can beat other AI strategies', u'Keeping it unresolved for now', u'Forbidding network calls isn't surprising. I'm glad to see that written out as a rule.

I'm surprised that multiprocessing is excluded. Modifying minimax to run in parallel across multiple cores seems extremely relevant to the scope of this course. We already have pseudo-code from the textbook for how to implement minimax and alpha-beta pruning using a single thread. Honestly, someone could implement that pseudo-code without fully understanding the concepts. But modifying that code to run in parallel would require mastery of the techniques.

This is a masters level class. I don't expect you to teach multiprocessing. But you should expect that many of the students already have multiprocessing experience.', u'We're trying to figure out what the processor specs are for Bonnie. We don't directly have access to the system, and are only given access to it as part of the Udacity infrastructure, so it might be tough for us to get a definitive answer.

We do know that you are definitely not allowed to use more than 500MB of memory (if that matters - it will in future assignments) and your program might get killed at lower thresholds (~400MB) as well.

Also, we do accept that many students have considerable experience with multi-processing. In fact, a huge number of OMSCS students are far more accomplished programmers than we are. However, the aim here is to provide a level playing field for everyone when it comes to AI techniques. For example, a student may go to great lengths to implement minimax, alphabeta, node ordering, quiescent search and possibly even a movebook, but can still get destroyed by a person who has a multi-threaded implementation of just minimax and alphabeta. It is important to note that the algorithms with pseudocode provided in the book are only enough to secure a fraction of the points for this assignment.

In practical and industry use, multi-processing techniques are used heavily in such applications (and should be!) but our aim here is to have students be at an advantage through their knowledge of the advanced adversarial search techniques rather than purely their programming experience - there will be plenty of opportunities in future to make use of programming knowledge :)']}]",Similar to Bonnie environment. Also with same set of timeouts and rules.,0.0,240.0,69,,Botfight environment,[a1]
5ad7d4320d63974e20c3907d,,jc6w44hrp9v2ki,[],"In addition to what Giacomo said,

If you are using multiple git accounts (for work and school). Run this script in the assignment root folder to set correct credentials for a particular repo
git config user.name “<your gt username>”git config user.email “<your gt email>”

Hope this helps!",0.0,205.0,70,You don't have to. Go to github.gatech.edu and sign in with your gatech id ,How do I create a GitHub account with Georgia Tech?,[other]
5ad7d4320d63974e20c3907e,"I am a novice in Python and have a basic question about the provided code for assignment 1 and indentation.

I view the project code in PyCharm IDE and look at, for example, the test_players.py file. Here are 2 questions related to indentation:

1) For the move() method in RandomPlayer():
def move(self, game, legal_moves, time_left):   
flag=True
while flag:
    ....
The method code starting with flag=True is not indented. The IDE does not like this. If I indent everything in that method block, the IDE is happy. Is there a reason why the code is not indented?

2) For the move() method in HumanPlayer():
def move(self, game, legal_moves, time_left):
    print ""here in ""
    choice = {}
    print len(legal_moves[game.__active_players_queen1__])

    if not len(legal_moves[game.__active_players_queen1__]) and not len(legal_moves[game.__active_players_queen2__]):
    print ""error""
        return None, None
    i=0
queen=game.__active_players_queen1__
    for move in legal_moves[game.__active_players_queen1__]: 

The line ""queen= game.__active_players_queen1__"" is de-indented from the rest of the code. I'm getting an error in the IDE there ""unresolved reference 'game'"", unless I indent that line.

In general, I'm having to change indentations to successfully ""Run"" the python code for assignment 1, otherwise I get ""Process finished with exit code 1"". It doesn't seem that I should have to make these changes, so I'm guessing I am not understanding something here. If anyone could share some python wisdom, I would greatly appreciate it!

Thanks!
Brian

",jc6w44hrp9v2ki,"[{u'text': u'I'm using VS Code on a Linux VM and I can also confirm that there are some serious indentation problems with the source files that I'm having to fix manually. The play_isolation method in isolation.py is especially confusing to correct. Did someone edit these files with tabs instead of spaces or vice versa?', u'responses': [u'Glad to hear that I am not crazy, haha. I thought I was misunderstanding some basic principle about python/indentation.

I was confused, seeing as the instructions indicate ""you'll only have to edit and submit player_submission.py"".', u'The good news is that you don't have to modify any of the source files except player_submission.py. In fact, I would suggest you shouldn't, as you don't want to risk breaking it or making it behave improperly. The bad news is that those other files are sure hard to read.', u'Right - PyCharm tolerates the mixture of spaces and tabs used for indentation in the initial code to run the project.

However it does not display the indentations correctly when some lines use spaces and others use tabs for indentation which makes reading the code pretty bad :( ']}, {u'text': u'Will save a lot of trouble and frustration if this was fixed in the repository.

', u'responses': [u'+1

It is particularly worrying in the try/catch code for isolation.py's play_isolation() method, whose logic is rather difficult to parse without knowing what the indentation should be', u'Either way possibly we should try to crowdsource a PEP8 indentation (as well as whitespace) that is a bit less of a mess than what we've been giventest_players.py updateplayer_submission.pyplayer_submission_tests.py [with some logic unaddressed, such as the lack of search_depth as discussed]isolation.py update includes what we hope is the intended indentation for play_isolation() now tooplease check them', u'The setup for assignment 1 says to write the implementation in a git branch. So the various .py files that violate PEP8 could be fixed and then those changes merged back in to student projects. The upside then becomes that the isolation.py and the others then become readable/decipherable. The downside probably is that people already possibly unfamiliar with Python now also have to get to grips with git. 

Also maybe the TA who mentioned online tools to fix the problem could list some of those with recommendations on which to use.', u'I think the main one they were referring to is at copout.com :-D', u'Thanks for the fixes, Mark!']}]",Oh. Okay. So there is an indentation issue here. You can use some online tools which gives proper indentation if lost. Sorry for that. Yes you are correct. Feel free to make indentations. ,0.0,274.0,71,,Python code indentation question,"[a1, python]"
5ad7d4320d63974e20c3907f,"This question may have to wait till the live session tomorrow .. but I was hoping not.

So I downloaded the a1 github code. I run file isolation.py. It prints about 200 lines of output'. Then it prints 'Select move index for queen1:'
However anything I type here ends up saying 'Illegal move .."" or various exceptions such as 'NameError: name .. is not defined"". Perhaps the 'Select move..' prompt could have been written to give a hint of what it expects?

So question is simply is there any basic instructions on how we can just start playing around with this project to get started. e.g. get the player's first move to show on a board.
",jc6w44hrp9v2ki,"[{u'text': u'@68 they will have a you tube live event that will probably go over this.The human player move is confusing but it seems like there is an integer that maps to the move tuple, so you need to enter that integer from the list it prints. ', u'responses': [u'Yes. Your understanding is correct for human player.']}, {u'text': u'For testing - please use player_submission_tests.py not isolation.pyThe main part code in isolation.py is for server side testing. I will go over this in youtube live. ', u'responses': []}, {u'text': u'I made two print statement changes to make playing as a human easier (disclaimer: I was doing this by running isolation.py, not player_submission_tests.py like the TA suggests).

First I added `print self.print_board()` to isolation.py at line 245 (right under `while True:`). Second, I commented out `print choice` in test_players.py at line 46.', u'responses': [u'Thanks I'll try that. Getting started first as a human is important just to get an intuitive sense of how the game works. So I want to do that first before running long exhaustive testing scripts. ', u'Thanks, Donovan. As David said this is a nice way to start working an intuition about the game up.']}]","Take a look at the source.  I haven't  looked to see what the human player segment does in a while, but last time I looked at Kshitish's source it was pretty readable.",0.0,276.0,72,,Trying it out,[a1]
5ad7d4320d63974e20c39080,"So, I cloned the public repo and created a private repo on the branch.  However, there seems to be multiple branches of the public repo. This is disconcerting as I am unclear which branch is the correct one to work off and what is different and each branch and why are there all these branches?",jc6w44hrp9v2ki,[],You should be working off of the master branch for each assignment unless told otherwise.,0.0,221.0,75,,Branches,[a1]
5ad7d4320d63974e20c39081,"Okay so have python have pycharm but don't know what pip is and don't have it. 

Instructions:
The submission scripts depend on the presence of 3 python packages - requests, future, and nelson. Install them using the command below:
pip install -r requirements.txt
 
When I try this I get:
'pip' is not recognized as an internal or external command,operable program or batch file.

Please provide equivalent instructions for a Windows machine.

Thanks

Extra details:
C:\ai\assignment_1>python -VPython 2.7.10
C:\ai\assignment_1>pip'pip' is not recognized as an internal or external command,operable program or batch file.
",jc6w44hrp9v2ki,"[{u'text': u'Got it thanks everyone', u'responses': []}]",You can also install the packages via Pycharm by going to Preferences -> Project Interpreter and create a Virtual Environment from there. You can then add the necessary packages. Hope that works!,0.0,212.0,76,"Error is because Windows cannot find the ""pip"" utility. It should be on the class path. Goto the location of python installation, copy the path up to ""Scripts"" folder and add that path to the ""Path"" environment variable. Another quick alternative will be to navigate to that location from command prompt and run the pip install command.",pip command on windows,[a1]
5ad7d4330d63974e20c39082,"There's a lot of cool stuff happening in AI these days, so I thought it would be nice to have a thread to share the most interesting stories without adding too many questions to the sidebar.

EDIT: please add a little bit about the site and why you like it if it's not obvious from the URL

#pin",jc6w44hrp9v2ki,"[{u'text': u'I'll kick us off with  The Google Brain Team — Looking Back on 2017 (Part 1 of 2) ', u'responses': []}, {u'text': u'My fav. site - https://openai.com/', u'responses': []}, {u'text': u'Resources to keep up to speed on general AI related subjects in main stream.
Email Newsletters:
https://www.getrevue.co/profile/wildml
https://jack-clark.net/
http://newsletter.ruder.io/

Resources to keep up to speed on topics at the research edge.
Blogs:
http://bair.berkeley.edu/blog/?refresh=1
http://blog.shakirm.com/

Filtered Resources:
http://www.arxiv-sanity.com/
https://openreview.net/



', u'responses': []}, {u'text': u'This is a great idea! While it is not news; it is a Q&A question for best intro resources.
https://news.ycombinator.com/item?id=16138353&utm_source=hackernewsletter&utm_medium=email&utm_term=data', u'responses': []}, {u'text': u'Just a few places I visit regularly to keep up on things AI and CS related:

3Blue1Brown: incredibly well made video about advanced mathematics and machine learning.
Two Minute Papers: short videos about recently published papers, focused on AI.
Mark Brown aka Game Makers Toolkit: very well researched, high production value videos on game design, that have greatly influenced my approach to software as a whole.
r/MachineLearning: one of the best moderated subreddits out there that manages to do a great job sticking to research and really helps keep you up to date with everything that's brand new.
Nicky Case: a genuinely awesome person who focuses on interactive systems and explorable explanations. Some really interesting work that is probably best classified as HCI meets computer eduction.
http://lineardigressions.com/: a very approachable podcast on various topics in machine learning, AI, and statistics.
http://michaelnielsen.org/: a cool guy who writes about cool stuff. Big picture and outside-the-box AI work mostly.', u'responses': []}, {u'text': u'I thought this article was interesting, especially due to Prof. Starner's research around wearables.
https://www.theverge.com/2018/2/5/16966530/intel-vaunt-smart-glasses-announced-ar-video 

Looks like the intent is to create glasses that are less intrusive to wear, but still use AI to determine what kind of information (text messages, directions, Yelp reviews,...) to display. They are in development, and may never actually be produced, but there will be an ""early access program"" for developers this year.

Full disclosure: I work for Intel, but I hadn't actually heard of these smart glasses until the public announcement, and don't have any ""insider"" info on them. :)', u'responses': []}, {u'text': u'Just found out about this AMA happening on reddit featuring
Yann LeCun, Facebook AI Research
Eric Horvitz, Microsoft Research
Peter Norvig, Google https://www.reddit.com/r/science/comments/7yegux/aaas_ama_hi_were_researchers_from_google/', u'responses': []}, {u'text': u'http://news.mit.edu/2018/computer-system-transcribes-words-users-speak-silently-0404 wow this is  impressive', u'responses': []}]",,0.0,346.0,77,,AI news &amp; links,[other]
5ad7d4330d63974e20c39083,"Hi,

Is there a video that covers instruction on how to submit the programming assignments?


James",jc6w44hrp9v2ki,"[{u'text': u'Thanks Brett.

So there's no way of checking if parts of the assignment are correct?

For example, once I finish OpenMoveEvalFn , there's no way of submitting this individual function and validating it, separate from the rest of the assignment?

James', u'responses': [u'You can submit the file and check the score for ""Test output of OpenMoveEvalFn""', u'Thanks Gurpreet,

Looks like I missed something on the orientation of how the assignment submission and grading works?

I suspect there are instructions somewhere on, for example, how create github account using the student account, how check score after submitting  assignment, etc.

Could you point me to the document that has these details? Looks like I'm completely lost

', u'I am not aware of any specific video covering all these details. I am just following pointers in the link posts of @57 and post @68. Also, there are several posts that cover git specific info. As you are already doing, just continue posting your specific questions on piazza...', u'Hello James,
You should have a github account here https://github.gatech.edu/. (login with your Georgia Tech credentials)
Regarding the submission process, you can refer to the README.md file of each assignment.
In general, good practice is to test your code locally, and when you've done some considerable progress- submit to the server (through the submit.py file).
You will then be able to see your formal results on the console window and on a separate file that will appear on your assignment_1 folder. There, you will see what went wrong, and the individual score on each part.', u'That github link leads to a 404.', u'The fat finger brigade strikes again :-D']}]",,0.0,227.0,78,"As an example, run the following command at the console to grade your code for Section 1 of Assignment 1:
python submit.py
",Which video covers instruction on submitting assignments,[a1]
5ad7d4330d63974e20c39084,"Can someone tell how #my_moves is calculated in the leaf nodes?

Thanks!


",jc6w44hrp9v2ki,"[{u'text': u'Thanks for the answer!
In the left-most leaf, the blue circle already chose its move as the left bottom square, isn't the next move for x ? not circle anymore?', u'responses': [u'It's the count of moves the player has left if they moved there. It's a ""what-if"" analysis and the utility value tells the algorithm how ""good"" the move would be. The evaluation function wants the player to make a move that maximizes the number of moves they will have left.', u'""What-if analysis"" is a great way of clarifying it. Thanks, Brett!']}]",,0.0,217.0,80,"By the rules of Isolation, a player can move like a queen in chess. ""The queen can be moved any number of unoccupied squares in a straight line vertically, horizontally, or diagonally"" - Wikipedia (emphasis mine).

So, for example, in the left-most leaf node, the player (the blue circle) can only move one space to the right, because all of its other legal moves have been occupied.",quiz about testing Evaluation funciton,[lesson1]
5ad7d4330d63974e20c39085,I'm trying to install pycharm and not sure which release has python 2.7,jc6w44hrp9v2ki,"[{u'text': u'To expand onto Nick's answer, if needed, you can choose your Python version when creating a new project or change it from the ribbon tab Pycharm>Preferences, then search for ""Project Interpreter"".

Had to adapt to this version in KBAI and depending on your code, this may actually have a relatively large effect when running through Bonnie.

Hope that helped,
Q.', u'responses': [u'Thanks, that worked!']}]",,0.0,207.0,81,"You can run any version in PyCharm, you just need to set your interpreter in project settings.",Which Pycharm Release has python 2.7,[a1]
5ad7d4330d63974e20c39086,"Hi,
I was trying to do a dry run on the CustomPlayer.py without any changes .
In the player_submission_test.py, when I debug the 5 X 5 test, the get_legal_moves at line 63 seems to report incorrect legal moves for Queen 11.

Initial board state: 
b.__board_state__ = [
    [0, 0 , 0, 0, 0],
    [0, 0,  0, 22, 0],
    [0, 0,  0, 11, 0],
    [0, 0,  0, 21, 12],
    [0, 0 , 0, 0, 0]
]
b.__last_queen_move__[""queen11""] = (2, 3)
b.__last_queen_move__[""queen12""] = (3, 4)
b.__last_queen_move__[""queen21""] = (3, 3)
b.__last_queen_move__[""queen22""] = (1, 3)

legal_moves=b.get_legal_moves() reported values 
{
  11: [
         (3, 2), (4, 1), (2, 4), (2, 2), (2, 1), (2, 0), (1, 4), (1, 2),          (0, 1)
      ], 
   12: [
          (4, 4), (4, 3), (2, 4), (1, 4), (0, 4)
       ]
}



",jc6w44hrp9v2ki,"[{u'text': u'Thanks for the clarification.. I was looking at more conventionally in the sense that the ( x, y ) meant X => horizontal and Y => vertical.
Based on your answer , this works.

Thanks again,

KK
', u'responses': [u'Conventions are relative. I would argue that (x,y) ""convention"" is specific to the Cartesian coordinate frames and is not general convention. For example, in classical computer vision, working with neural nets, or tables in data frames(pandas), the ""convention"" can be (row,col) or (y,x), with (0,0) in the upper left hand corner.

In reality this should be specified so we don’t have to assume and there is no confusion.', u'You need to look at the __board_state__ to see that it is a list of lists, so that the first of the indices is to a row, for instance __board_state__[2] is [0, 0, 0, 11, 0] the second of the indices is to an entry [column] in that row, for instance __board_state__[2][3] is 11']}]","They all seem fine to me, which move seems illegal? Remember that the first index here, in this representation, is going to be your y-coordinate, so the (4,1) corresponds to:

b.__board_state__ = [
    [0, 0 , 0, 0, 0],
    [0, 0,  0, 22, 0],
    [0, 0,  0, 11, 0],
    [0, 0,  0, 21, 12],
    [0, X , 0, 0, 0]
]",0.0,253.0,82,,get_legal_moves bug?,[a1]
5ad7d4330d63974e20c39087,"Some questions on time limits.. the instructions say 'Your agent will have a limited amount of time to act each turn (10 seconds)'

1. In the project code we are given is this timeout enforced in any way by the project? e.g if I run isolation.py or player_submission_tests.py and my move() takes longer than the time allocated is there some type of check? Reading through isolation.py etc I don't see any such code. So is the time limit somehow checked when we submit our code? If so, is that some type of interrupt or notification into our code to say time is finished? And if so, is there anyway we can simulate such an event in the project code we are given?

2. Is time_left() broken? In the following statement what units is time_limit? I assume millisecs..
board.play_isolation(time_limit=30000, print_moves=True
The reason I ask is that code like

        while True:
            time.sleep(2) ## 2 seconds
            print('TL->', time_left())
generates this output
('  TL->', 29999.417)
('  TL->', 29999.304)
('  TL->', 29999.248)
('  TL->', 29999.163)
('  TL->', 29999.071)
('  TL->', 29999.01)
which seems like it gives the move many days to complete.

The relevant code in isolation.py (for MAC os) is 

    def curr_time_millis():
        return 1000 * resource.getrusage(resource.RUSAGE_SELF).ru_utime
..       
    move_start = curr_time_millis()
    time_left = lambda : time_limit - (curr_time_millis() - move_start)
So it looks like somewhere along the line the time units are messed up. e.g. time_limit is 30,000 whereas curr_time_millis() returns a value like 160 and so time_left() will take many days to return <=0",jc6w44hrp9v2ki,"[{u'text': u'Thanks for the info. My best guess at this point is that the isolation.py was tested on Windows but not on Mac. The Mac version uses a different mechanism to get time. I suspect that there is a difference in semantics between time() on Windows and RUSAGE_SELF on Mac. 

        if platform.system() == 'Windows':
            def curr_time_millis():
                return int(round(time() * 1000))
        else:
            def curr_time_millis():
                return 1000 * resource.getrusage(resource.RUSAGE_SELF).ru_utime

But any any event I think the isolation.py code is broken. On a Mac curr_time_millis() is returning values like 150. So the following expression is going to take a very long time to return a value close to zero on a Mac. Like days or weeks ..
time_limit - (curr_time_millis() - move_start)
I'll wait and see what the TA says..', u'responses': [u'are you using python 2.7 or 3?', u'So its Python 2.7 but as far as I can tell its not version specific. (and this is MAC OS)

import resource
import time
import platform

print (platform.python_version())

start = int(round(time.time() * 1000))
time.sleep(1)
stop = int(round(time.time() * 1000))
print ('using time()', stop-start, start, stop)

start = 1000 * resource.getrusage(resource.RUSAGE_SELF).ru_utime
time.sleep(1)
stop = 1000 * resource.getrusage(resource.RUSAGE_SELF).ru_utime
print ('using RUSAGE:', stop-start, start, stop)
Results

3.5.2
using time() 1001 1516318755469 1516318756470
using RUSAGE: 0.03399999999999892 54.656 54.69

2.7.10
('using time()', 1002, 1516318943310, 1516318944312)
('using RUSAGE:', 0.02699999999999747, 18.142, 18.168999999999997)
', u'Measuring time with getrusage(resource.RUSAGE_SELF) seems like an odd choice. That would exclude resources used by child processes. So what if someone's AI used a subprocess to search the game tree, and just slept in the main process until the child found a result. The curr_time_millis() function would never increase in that case. At the very least, it'd be more accurate to measure time with getrusage(resource.RUSAGE_BOTH). 

From the python docs: https://docs.python.org/2/library/resource.html
resource.RUSAGE_SELF¶
RUSAGE_SELF should be used to request information pertaining only to the process itself.
resource.RUSAGE_CHILDREN
Pass to getrusage() to request resource information for child processes of the calling process.
resource.RUSAGE_BOTH
Pass to getrusage() to request resources consumed by both the current process and child processes. May not be available on all systems.', u'Agree - but what I can't figure out is why isolation.py needs to anything other than just use time() like in the code I put above. It appears to do what is intended, well at least as far as I understand what is intended.', u'Agreed, I would probably just use wall clock too.

That's assuming the game is going to run on a machine with a relatively light system load. time() works well on our personal machines, since there probably aren't many other computationally expensive processes vying for the CPU. But that might not be true for Bonnie. Using getrusage might be more consistent if there's resource contention.', u'Good points. I think that isolation.py probably never gets executed during the grading of what we submit.  So I think I'll just throw out the original time management code in isolation.py and write something in there myself that makes more sense for the MAC.', u'David,

You need to test it properly without using time.sleep(), as I say time.sleep() gives up the CPU so that what is being counted, is active CPU time.
For instance
        import time
        counter = 0
        loop_timer = time_left()
        repeats = 5
        print time_left(), time.time(), counter
        while repeats > 0:
            counter += 1
            if loop_timer - time_left() > 2000:
                repeats -= 1
                loop_timer = time_left()
                print time_left(), time.time(), counter
        for rep in range(5):
            print time_left(), time.time()
            time.sleep(2)would produce for instance9999.913 1516356473.34 0
7999.909 1516356475.99 1087981
5999.904 1516356478.64 2179572
3999.899 1516356481.3 3267530
1999.894 1516356483.94 4355895
-0.109 1516356486.59 5447102
-0.150000000001 1516356486.59
-0.184000000001 1516356488.59
-0.296 1516356490.59
-0.391 1516356492.6
-0.476000000001 1516356494.6

As you see from that, even the incrementing loop only uses 2s of resource time for around 2.65s of wall clock time, while the time.sleep() loop uses from around 0.03s to around 0.1s of resource time variable, for 2s of wall clock time', u'David, I am running into this same issue on a mac. What did you end up doing to solve this? Also, did your solution work when you sent this to Bonnie.', u'I think it boiled down to a conceptual misunderstanding when I started the project of what the time check function was supposed to be doing. So its designed to measure CPU time and not wall clock time. i.e. how many CPU cycles did your move take rather than how many wall clock seconds. If you think about it has to be this way - right? If I submit on an already heavily loaded Bonnie grading many submits then my moves are going to take longer measured in wall clock time (and that is not a problem with my code). However, CPU time measurement is independent of the current load on Bonnie and is a measure of how much CPU processing you are doing.

So the bottom line is that if your time check is failing then your code is taking too much CPU processing to run. It will also timeout when you submit it so you do need to figure out ways to reduce the CPU time. The most typical cause for this would be trying to search too many levels and but there may be other things in your code as well.

']}]",,0.0,277.0,83,"It seems the time.sleep() function gives up the CPU so it uses virtually no time in user mode – nor in kernel mode for that matter either. See https://docs.python.org/2.7/library/resource.html#resource.getrusage

From the manpage for getrusage() in conjunction with the Python documentation, I think the Python implementation of it is returning a microseconds float value, so the 1000 * converts that to milliseconds",Time limits,[a1]
5ad7d4330d63974e20c39088,"Hi Everyone, 

Quick question about input parameters of minimax function, to clarify that I understand them correctly.
minimax function has the next signature: minimax(self, game, time_left, depth, maximizing_player=True)

depth - is a level in the game tree to which we can/should go during one move. is it correct?
time_left - is a max time which can be used for 1 move(in our case one execution of minimax function) Is it correct?

Thanks
Alex",jc6w44hrp9v2ki,[],,0.0,263.0,84,Look at the comment directly following the function signature definition,"Clarification. minimax - time_left, depth params.",[a1]
5ad7d4330d63974e20c39089,"So the rules for the first move of each player say the player's queens are placed on different squares. How about for moves after the first - can the two queens move to the same square?
e.g. if in the first player move Q1 goes to (0,0) and Q2 goes to (0,2) in the 2nd player move can both Q1 and Q2 go to (0,1)?
thanks
",jc6w44hrp9v2ki,"[{u'text': u'No, players can not move to a square that has already been previously filled or is currently occupied.', u'responses': []}, {u'text': u'The get_legal_moves API from the isolation.py is supposed to get provide the set of locations that the queens can move to in the current play', u'responses': []}, {u'text': u'ok thanks. Note that the code provided in the project allows it as a move as illustrated below so I assumed it was valid.

-- |    |    |    |    |    |    | 
   | -- |    |    |    |    |    | 
   | 21 | -- |    |    |    |    | 
   | -- | 12 | -- |    |    |    | 
   |    |    | 11 |    |    |    | 
   |    | -- | -- |    |    |    | 
   |    |    | -- |    |    |    | 

---> [0] q21: (3,0)
[1] q21: (2,0)
[2] q21: (1,2)
[3] q21: (0,3)
[4] q21: (1,0)
---> [5] q22: (3,0)
[6] q22: (2,0)
[7] q22: (1,2)
[8] q22: (0,3)
[9] q22: (1,0)
Select move index for queen1:0
Select move index for queen2:5

-- |    |    |    |    |    |    | 
   | -- |    |    |    |    |    | 
   | -- | -- |    |    |    |    | 
21 | -- | 12 | -- |    |    |    | 
   |    |    | 11 |    |    |    | 
   |    | -- | -- |    |    |    | 
   |    |    | -- |    |    |    | 


-- |    |    |    |    |    |    | 
   | -- |    |    |    |    |    | 
   | -- | -- |    |    |    |    | 
21 | -- | -- | -- |    |    |    | 
   |    |    | -- |    |    |    | 
12 |    | -- | -- |    |    |    | 
   |    |    | -- |    | 11 |    | 
', u'responses': [u'No it doesn't. You have omitted the message you should see beneath, that says Queen1 move same as Queen2 move. Not allowed!']}]",No,0.0,267.0,85,No,Rule clarification,[a1]
5ad7d4340d63974e20c3908a,"Hello Everyone!

I hope you are enjoying the assignment! Section 3 is now activated. You can hit Bonnie for third section as well. 

For those of you who haven't started- please start early! Normally we face a lot of difficulties near deadline due to load on server ( specially assignment 1!). 


",jc6w44hrp9v2ki,"[{u'text': u'Will there be any partial credit given for part 3?  I noticed that it seems like an all or nothing affair.', u'responses': [u'No. There is no partial credit. But your grades are curved. Even if you feel that the marks are low- remember that your grade is curved.', u'How have the grade thresholds been in past semesters – what kind of figures?', u'More particularly, what have the median percentages been for assignment 1 & for the semester?', u'I would also like to get an idea on this. ', u'Assignment 1's thresholds are not really meaningful since we change the game each semester and see different results each time around (fewer or more people scoring 100s, etc.) Also, please keep in mind that curving is only done after the final grade for the course has been calculated, which means that Assignment stats are only present to give you an idea of where you might stand in the class, and will change as students drop the course.

That being said, the overall median was in the high 80s in previous semesters, with some degree of variation between semesters.', u'Thanks for the information Ravi :-)', u'High 80s, ugh', u'That's disheartening, part 3 is proving pretty tough.', u'I still predict a median of 75% which is up from my original of 55%']}, {u'text': u'I got the following error from Bonnie after waiting for two hours:

Clyde failed to process the job.
Any ideas?', u'responses': [u'I hit the same error in 1a and resolved it by reducing my timeout from 9.5s to 7s. I'd suggest giving that a go.', u'I think this has more to do with bonnie load rather than your code.']}]",,0.0,369.0,89,,Assignment 1 -Section 3 Activated.,[a1]
5ad7d4340d63974e20c3908b,Are we suppose to implement minimax in order to beat RandomPlayer test in section 1 or rather just OpenMoveEvalFn? Thank you.,jc6w44hrp9v2ki,[],,0.0,20.0,91,"OpenMoveEvalFn is relatively useless on its own.  You can asses the value of any given board state, but you need a minimax of at least depth 1 to pick the max state.",Assignment 1 - Section 1,[a1]
5ad7d4340d63974e20c3908c,"Is there a penalty or problem if I submit a solution one time and later on improve it and submit again?
",jc6w44hrp9v2ki,[],"You can submit assignment 1 once every 30 minutes as of now. It is possible that we may change it to once every hour or even longer due to the burden of the server as it comes closer to the end.

However, some later assignment may have a total quota and you should be careful.
You can and should always log in to bonnie.udacity.com to check the quota for the assignment you are working on.",0.0,245.0,94,,How many times we can submit same assignment?,[a1]
5ad7d4350d63974e20c3908d,"I might be asking a silly question. 

I am using pycharm. My test classes run. I was able to understand the flow.
I have copied the random player's move function into custom player's move function just to check my submission.

When I am running submit.py from PyCharm, it waits forever after ""username"". 
I checked at https://bonnie.udacity.com/student/ but don't see any of my submissions.

C:\Python27\python.exe F:/work/OMSCS/Courses/AI6601/assignment_1/submit.pyLate Policy:  ""I have read the late policy for CS6601. I understand that only my last commit before the late submission deadline will be accepted."" Please type 'yes' to agree and continue>yes
Honor Pledge: ""I have read the Collaboration and Academic Honesty policy for CS6601. I certify that I have used outside references only in accordance with this policy, that I have cited any such references via code comments, and that I have not copied any portion of my submission from another past or current student."""" Please type 'yes' to agree and continue>yesGT Login required.Username :userid
After this, it does nothing.

What am I missing? Had anyone gone through this?",jc6w44hrp9v2ki,"[{u'text': u'Weird. Please make this post public(remove important details like your userid). To see if any others are facing this issue. I will keep it unresolved so other TAs can see if they have answer.', u'responses': []}, {u'text': u'Same. PyCharm on Windows. Glad to see it's not just me and thanks for the workaround, Gurpreet.', u'responses': []}, {u'text': u'I have install python 2.7 and the addition modules in requirements.txt and verify the packages
and see the nelson folder under site packages, when try to run \submit.py I get the following error,


', u'responses': [u'Can you check and confirm if you are using the correct python install? You might have multiple installs and the default version on classpath might  not have those packages.

Also try giving absolute path to the python install, eg:

C:\assignment_1-master>C:\Python27\python submit.py
', u'The absolute path works, that helps.
Thanks']}, {u'text': u'I had the same issue as well, running in cmd prompt like solution suggests works.', u'responses': []}]",,0.0,220.0,96,I am facing the same issue running from PyCharm on Windows. Works fine on Mac. Workaround is to run the submit.py from the windows command prompt and not from within PyCharm.,Submit not happening,[a1]
5ad7d4350d63974e20c3908e,"I modified player_submission_tests.py to see the results of two RandomPlayer()'s playing against one another as suggested in the YouTube live meeting.

I got the following back for move_history of the game.

[[[(1, 4), (4, 0)], [(2, 2), (0, 3)]], [[(4, 4), (4, 5)], [(2, 1), (6, 3)]], [[(4, 3), (2, 5)], [(4, 1), (5, 4)]], [[(5, 3), (3, 4)], [(3, 2), (6, 4)]], [[(5, 2), (3, 6)], [(3, 0), (5, 5)]], [[(5, 0), (5, 6)], [(0, 0), (4, 6)]], [[(6, 1), (6, 6)], [(2, 0), (2, 4)]], [[(6, 0), (6, 5)], [(1, 0), (3, 5)]]]

I'm trying to make sense of this. I believe that the first four tuples correspond to opening placement, but then the next set of tuples confuses me. After [(1, 4), (4, 0)], [(2, 2), (0, 3)] I would assume we are in this position.


         22      112112    


But then I can't figure out how the following moves make sense: [(4, 4), (4, 5)]. If Queen_11 moves to (4,4), then Queen_12 cannot move to (4,5) without going through Queen_11, which I do not think is allowed. I must be misunderstanding how to reconstruct the game from move_history. Can anyone help explain how to better interpret this output?

Thanks!
",jc6w44hrp9v2ki,"[{u'text': u'Thanks. That would make sense but then how do you know which queen moved to a particular position if both can legally move to the same square? Is it not possible to recreate the game without looking ahead to try to work through those issues?', u'responses': [u'In RandomPlayer- there is a case which handles this issue of same moves. Check its code again. Also- its stupid. it will get whatever value it has.. say same queens. And check its validity. If not it will pick another pair']}, {u'text': u'Hi, I'm trying to modified player_submission_tests.py to see how two Random Player too.
But after changing Line 81 ""CustomPlayer"" to ""RandomPlayer"" I got below error:
        print 'OpenMoveEvalFn Test: This board has a score of %s.' % (h.score(sample_board)) ^ SyntaxError: invalid syntax

Is any other part you also modified?
', u'responses': [u'There is mixed spacing in that ""try"" block that PyCharm picks up.  It will not run correctly in PyCharm until that block is correctly indented.  This is an issue stemming from the upstream repo.', u'You may safely remove all try/catches & all the indentation that connects specifically to the try/catches, when testing locally. In fact, it's quite sensible to do so, so that you see all errors more clearly.']}]",,0.0,246.0,97,"It is not a required condition that Queen_11 should move first then Queen_12. In this case if Queen_12 moved to (4,5) , then Queen_11 can be moved to (4,4).",Understanding move_history,[a1]
5ad7d4350d63974e20c3908f,"How to define if my player is maximizer or minimizer?

From the lessons and videos, we always assume that AI player is maximizer and it always tries to maximize the score but in player_submission_tests.py CustomPlayer() is second player. Does that mean that AI player is minimizer? Can I switch p1 and p2 value for testing?

p1 = RandomPlayer() p2 = CustomPlayer()Thanks,Rajan",jc6w44hrp9v2ki,[],"In general for minimax, the maximizer and minimizer depends on whose turn/move it is.

For player 1's turn, player 1 is maximizer and player 2 is minimizer. For player 2's turn, player 2 is maximizer and player 1 is minimizer.

This makes sure that each player is choosing the best moves for itself, not the best move for their opponent.

I recommend testing your algorithms with your CustomPlayer as both p1 and p2.",0.0,237.0,98,"Whenever your agent is called, the move method will be used. Considering that it is always asking you to make your move and you want to win, you will know that when move is first called you are wanting to maximize your chances.",How do we know if AI player is maximizer or minimizer?,[a1]
5ad7d4350d63974e20c39090,"So if the mini-max tree for our player is as follows -

root (one node)
nodes (parents = root) - a node for each legal candidate move for the player
..
Is the root considered level 0 or is the next level down considered level 0? I'm assuming the latter..

So for example if the requirement says 'Your AI defeats an agent with OpenMoveEval function that uses minimax to level 2' that would mean the agents mini-max tree would have 3 rows (levels 0, 1 and 2) and a single topmost root node parenting level 0. Is that correct?
",jc6w44hrp9v2ki,[],We have depth 2. I.e 2 levels down. Not only one level.,0.0,212.0,101,,Minimax level numbering?,[a1]
5ad7d4350d63974e20c39091,"Hi everyone,

I'm confused with the utility and the score function in player_submission.py. What are the difference and the purpose of them?

Please help!

Thank you,",jc6w44hrp9v2ki,"[{u'text': u'I thought we were supposed to get the score calculated by OpenMoveEvalFn using utility function. Is that not correct?', u'responses': [u'Score is calculated by OpenMoveEval. Thats correct. By utility?- depends on you']}]","Utility function is just given as an add on function. You might not use it.
Normally people want to use this function to write some code checking win or loose and returning some values for that cases and then calling eval function.",0.0,216.0,102,,Difference between utility and score function,[a1]
5ad7d4360d63974e20c39092,"Simple question, in YouTube discussion, it was noted as a starting out step is to sent both players to RandomPlayer in player_submission_test.py to start to get a good sense of the game.

I have done that but the game does stops and props for input as it was playing ""HumanPlayer"".

What am I missing?",jc6w44hrp9v2ki,[],"This should not happen. Are you doing this? cross check-
In player_submission_test.py change the CustomPlayer to RandomPlayer for 7x7 matrix test and run player_submission_test.py

If you follow this.. it should run RandomPlayer vs RandomPLayer",0.0,197.0,103,,RandomPlayer set to play RandomPlayer,[a1]
5ad7d4360d63974e20c39093,"It seems that every time CustomPlayer .move() is called, the active queens are always queens 21 and 22.

My Questions:
Am I always player 2 with queens 21 & 22? If so how come I sometimes lost when queen 11/12 got stuck? (see images below)

If I'm randomly player 1 or 2, how do I know which player am I, inside minimax() or alphabeta()?

Edit: I replaced HumanPlayer to CustomPlayer(3) in player_submission_tests.py :

Random Game 1Random Game 2

Many Thanks~",jc6w44hrp9v2ki,"[{u'text': u'Again, I used HumanPlayer as Player 2 and I'm controlling queens 21&22, but it shows I won when I clearly have lost.
Looks like something wrong with the 'Winnder:' line... Anyone experience the same problem, or it is me accentually messed up the code?

', u'responses': [u'Solved.']}]",,0.0,235.0,105,"It's my CustomPlayer went wrong. It returns best_moves = (None, None) when opponent has no moves, which result in losing. I should instead simply return a random move and win.",Which player am I?,[a1]
5ad7d4360d63974e20c39094,"Hi everyone,
Following the lecture, beginning of the game, if we place the queen in the middle of the board, we will get the maximum # of move.But for the project, we get two queens. Can any one please tell me what the best positions to get max # of moves for two queens?

Thank you,
",jc6w44hrp9v2ki,[],,0.0,191.0,106,I believe this is something you have to figure out from thought and experimentation.,maximum number of moves,[a1]
5ad7d4360d63974e20c39095,"This is my 2nd semester. No experience of Bonnie. Can someone please explain how Bonnie works for submitting and evaluating assignments? I think there could be many like me. I tried https://bonnie.udacity.com/ and login through Gatech. but there is no upload link as of now.Or if there is already some post on Bonnie that I am not yet able to find, please share the link.

Thanks
Saalis",jc6w44hrp9v2ki,"[{u'text': u'if I run bonnie successively, i get different scores each time. Will the last score be assigned to me? or later my code will be run again for evaluation?', u'responses': [u'The last score recorded in Bonnie for that particular part of the assignment is your official score.  So once you achieve the max score, probably good to not submit again (unless you're feeling very lucky :-)).', u'continue to Conor's answer....

or you are very sure that you will get a better score for next submission. ']}, {u'text': u'Also a beginner with Bonnie. Is there a time limit to how long it'll run? The command line failed with a timeout error and the website shows me the attached image and has not changed since it began (it's been 20 minutes). Does that mean Bonnie is still in progress?', u'responses': [u'That usually means it's still running and eventually will be filled in.  The commands do have a timeout on the server (on the order of 7200 seconds at least for part 1b.   I'm not sure what timeout you had, but from that screen pic, it looks like your run is still in progress.', u'Yep, it eventually times out :-( (in fact, it's currently been running for more than 30 minutes so will surely die soon again) Thanks for the info! I wish there had been a bit more info on this Bonnie thing for people who have never experienced it...', u'Just think of it as another learning experience.   I have used bonnie in one of my other courses, but the work was much simpler and did not have the long timeouts.']}, {u'text': u'Another follow up on this topic. Is there a step-by-step idiot's guide to submitting the assignment on Bonnie and T-square? I'm ready to test, but not sure what to do exactly.

I read the readme and setup file, but still don't know what I'm doing. Sorry this is such a dumb question. Hoping there are some others like me that could use really simple step-by-step instructions if anyone has the time to fill us in. ', u'responses': [u'Nevermind. I thought this was more complicated than it is. I had setup issues that were separate from the submitting process. Resolved by reading through this @162.']}]",,0.0,240.0,108,"You call ""python submit.py"" (for the first part, the other submits for the later parts) and it uploads the program to bonnie and runs the tests for that stage of the assignment giving you back your scoring.
 
You can go to https://bonnie.udacity.com to see the results that are recorded for prior runs as well as the number of runs left in your quota and/or time before you can run again if you've used up your quota.
",Bonnie,[other]
5ad7d4360d63974e20c39096,"Did anyone run into an issue of submit.py and submit_a.py timing out. This is the error message I got, thank you.

{ ""error"": ""{\""msg\"": \""The command $(sudo -H -u vmuser_fojruman bash -c \\\""cd /home/vmuser_fojruman; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_1 1> run_stdout.txt 2> run_stderr.txt\\\"") exceeded the timeout of 1800 seconds.\""}"" }",jc6w44hrp9v2ki,"[{u'text': u'I’m also having this issue after having switched to iterative deepening and using time left. When I run it locally it always returns the value within the ten second window because I’ve set it to end a second before the ten second window ends. I’m still getting a timeout issue when I run it on the server. Edit - it seems like with a two hour limit over 40 games, assuming ten seconds per move you’d have to average under 18 moves per game to stay under the 2 hour limit. ', u'responses': [u'This is on section three, exceeding the time limit of two hours ', u'I also have same issue.

On my local machine, with iterative deepening, I am never getting timeout and program finishes in few seconds. While running the same code on Bonnie, it gives timeout. Any reason for that?

Can we create player similar to Bonnie on local machine? It's very frustrating to wait for 2 hours (for 3rd section of assignment).', u'If you're getting a move timeout, one possible reason is that you're CPU is more powerful than there's and/or have a noisy neighbor.   I did have two runs of my part 3 (none of which pass, btw) which had the exact same code and one took almost 50% longer to run (4400+ secs vs 3000+ secs).', u'But if we are using the full ten seconds for every move, shouldn’t it not matter what cpu is more powerful? I’ll get to a further depth if my cpu is more powerful but the time should be the same, right? ', u'Yeah unless you're taking long enough between time checks to go past the limit before you get to the next check.', u'It’s checking at each new call to the min or max value so I don’t think that’s the issue', u'I got the same error when submitting section 3, exceeding 7200 seconds. 
  ""error"": ""{\""msg\"": \""The command $(sudo -H -u vmuser_zecvbdki bash -c \\\""cd /home/vmuser_zecvbdki; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_1b 1> run_stdout.txt 2> run_stderr.txt\\\"") exceeded the timeout of 7200 seconds.\""}""
I don't understand why it has to do with the way of calling time_left(). If it is CustomPlayer's turn and it runs out of time, i.e. time_left()<0 at some point, then CustomPlayer loses that game. If it keeps losing games, Bonnie should say your AI got defeated 100% (or similar) instead of getting a time out error. I assume on Bonnie, our agent (CustomPlayer) is playing with the instructor's agents for N games. Time_left() is used to ensure each game is done within limited time, so that N games can be completed within 2 hours. ', u'Yeah, agreed that it doesn’t seem to be an issue with time left, just adding that point to eliminate that as a cause as that was the explanation in the first answer to the original question. ', u'Interestingly, re-submitting doesn't have time out error but got defeated. ', u'Is there any way to avoid noisy neighbor?', u'resubmitting and hoping for the best???   I really don't know if that is an issue.   It's possible that the difference in runs can also be caused by some level of randomness in the move choices leading to longer games in one situation vs another situation.']}]",,0.0,245.0,110,"I had this issue when I was doing two level minimax for submit.py, accounting for time_left fixed the issue for me.",Section 1 and  2 timeout issues,[a1]
5ad7d4360d63974e20c39097,"Can we get some insight into where this comes from? 

My section three submission got a substantial number of these and I'm not seeing this anywhere in the provided code.  Is this just another way of reporting that we lost a game?  My agent is calling the get_legal_moves_of_queenX methods and is checking for duplicates. 

Do we have to consider the order of the moves?  Asked another way: does the 'first' queen from a given team always move first (and hence could block certain moves of the second queen)?  If so, it's then up to us to manually remove items from the get_legal_moves_of_queen2() depending on the first queen's move, right?

Thanks for any info!",jc6w44hrp9v2ki,"[{u'text': u'Would also like (double) confirmation on this.  Does this just mean we lose at a normal endgame?

I've pored over the code again and again, and it's hard to believe I am making illegal moves.  I only query for legal moves, and then filter out moves where the the queens would move to the same location.

More feedback in the json response would be appreciated.', u'responses': [u'It means you lost that game.  Take that number and do the math for 20 games.  You should see it add up correctly to your loss ratio.  So if you had 12 illegal moves your loss ratio is 0.6.  And therefore your win ratio is 0.4.', u'I think the question is

'are we making invalid moves and thus loosing due to a technicality/software error on our end that we otherwise might have won'

or

'are we simply losing  and when we're in the losing position we end up returning None,None for the last move, which is considered an invalid move.'


For example, I just got on my submit_b.py:

""output"": {
    ""points_available"": 20,
    ""win_ratio"": 0.2,
    ""points_awarded"": null,
    ""num_invalid_moves"": 16,
    ""num_timeouts"": 0
},

Personally I think the following would be much clearer:

""output"": {
    ""points_available"": 20,
    ""win_ratio"": 0.2,
    ""wins"": 4		    <-- we won
    ""losses"": 16	    <-- we lost
    ""points_awarded"": null,
    ""num_invalid_moves"": 0,  <--- no move violated the rule
    ""num_timeouts"": 0
},

or

""output"": {
    ""points_available"": 20,
    ""win_ratio"": 0.2,
    ""wins"": 4		    <-- we won
    ""losses"": 16	    <-- we lost 16 total 
    ""points_awarded"": null,
    ""num_invalid_moves"": 3,  <--- we lost 3 games because rule violation
    ""num_timeouts"": 0
},
A 'invalid_move' in my opinion is submitting a move that violates the rules of the game. Simply being in the losing position and returning None, None is not a invalid_move, or is it??

']}]",,1.0,217.0,111,"As to your last set of questions, note @97.",num_invalid_moves,[a1]
5ad7d4370d63974e20c39098,"why get_legal_moves gives key as 11 , for example 
{11: [(1, 1), (1, 0), (2, 0),

Does it give legal moves for Queen 1 for player 1 ?",jc6w44hrp9v2ki,[],,0.0,190.0,113,"get_legal_moves returns the moves as a dictionary for both queens for the active player. It would be either 11 and 12, or 21 and 22.

update : looking at code gave me clarity. I do not need answer for above.",get_legal_moves funtion clarity needed,[lesson1]
5ad7d4370d63974e20c39099,"My implementation passed both submit.py and submit_a.py.  These showed both less than 5 invalid moves.

Submit_b.py yielded 18 and 19 invalid moves on my first submit.

Any pointers to what to look for in regards to generating invalid moves would be appreciated.  I am not encountering this on my local machine.",jc6w44hrp9v2ki,"[{u'text': u'Thanks, wasn't sure if my implementation was actually returning invalid moves or if I was just losing the game those times.', u'responses': []}, {u'text': u'Am I correct to assume that when the CustomPlayer() loses it will always try an invalid move? I have only seen the ""Move of this Player is None"" termination statement whenever CustomPlayer() wins. When CustomPlayer() loses I always see something like ""illegal move of queen1.""', u'responses': [u'Nevermind. I found the answer here: @111. (Yes, this just means that you lost the game).']}]","When bonnie says invalid moves, it means that your CustomPlayer lost the game. On its turn, it has no moves left, therefore an invalid move is returned (which is a loss).

To improve winning chances, try to incorporate some of the strategies described in the readme for the assignment like partitioning, iterative deepening, better evaluation function, optimizing functions so your agent can search deeper/faster, etc.",0.0,219.0,114,,Invalid move,[a1]
5ad7d4370d63974e20c3909a,"There's a nice write up of alphabeta processing available here: 

http://web.cs.ucla.edu/~rosen/161/notes/alphabeta.html

that walks through the decisions and the data that's available and how it's processed at each level.",jc6w44hrp9v2ki,[],,0.0,208.0,115,,alpha beta example,[a1]
5ad7d4370d63974e20c3909b,"How can I make sure that I am with working with right version of Python which is 2.7 I was using Visual Studio code which is currently running V 3.6 so I know I already have 3 on my machine.
I installed  PyCharm and Python 2.7. However, I think my PyCharm is on the latest version. I am going to further explore the IDE however, wanted to know if anyone know how to easily change the version in PyCharm

",jc6w44hrp9v2ki,"[{u'text': u'Thank You. ', u'responses': []}, {u'text': u'Is this is PyCharm or Visual Studio? I'm having the same issue.', u'responses': [u'Thanks. This solved my issue.']}]",,0.0,191.0,117,"Goto Settings then Project Interpreter. There's you'll be able to see the python version that the project is running on. You can also create a virtual environment for the project.

",Different Version of Python on my machine,"[a1, python]"
5ad7d4370d63974e20c3909c,"I get a successful Minimax test when I run my test locally, but CustomPlayer is still losing locally and against Bonnie. Evaluation function passes on Bonnie.... Are we suppose to implement other techniques like iterative deepening, openbooks, reflection and so on to beat the RandomPlayer (Section 1) test on Bonnie?.. Thank you. ",jc6w44hrp9v2ki,"[{u'text': u'I'm curious about this too, because you essentially always timeout with a basic implementation of minimax without adding an opening book or some timeout heuristic hacks.   The timeout heuristics typically depend on your evaluation functions, as described in the book/lecture.

The performance of your minimax is then pretty sensitive to how you handle the timeouts.  I'm having the issue where a) time's running out, so b) I need to use the heuristic evaluation function on this current board to calculate the best move -- meaning I need to evaluate all the children to choose the best move on the current board.  You can run out of time evaluating the children, so you end up abandoning a lot of them when trying to build choose your move heuristically.', u'responses': [u'Yes. Timeout is an issue which you need to handle. Branching factor is major problem over here. This is a good learning exercise for developing real time games. You will see that there is slight improvement with alphabeta. And you will be able to handle this issue with iterative deepening. There also- you need some moves to start with. This is similar to real time scenario where there is always a time constraint. ']}]","You should be winning the Random Player with a correct Minimax. I would encourage you to run some more tests on your Minimax, it is easy to miss something.",0.0,244.0,118,,Minimax implementation issues,[a1]
5ad7d4380d63974e20c3909d,"What information do I need to add in AI.txt for player submission for tournament?

",jc6w44hrp9v2ki,[],A description of your agent. Techniques you used etc.,0.0,198.0,120,,AI.txt,[a1]
5ad7d4380d63974e20c3909e,"Once I submit (say using submit.py) I get output like 

Details available in assignment_1-result-2018-01-20-19-48-04.json
So how do I access the contents of this .json file?

Thanks",jc6w44hrp9v2ki,"[{u'text': u'ok - sorry. The answer was simple. Its returned into the current directory. I had assumed it was somewhere in my GT account remote to my local machine.
Thanks', u'responses': [u'It is.  if you go to https://bonnie.udacity.com select Student then our course.  You can click on each of the assignments you've completed and you will see each test run you've run and can view the results for each run.']}]",,0.0,192.0,121,"You can open this json file in choice of your editor. It can be Atom, Pycharm, Visual Studio code or notepad.

If you are on windows, you can right click on the file and open in text editor.",Where is submission detailed output?,[a1]
5ad7d4380d63974e20c3909f,It's really throwing me off that Minimax is supposed to return a queen1 and queen2 move. Isn't it meant to return a utility value alone? The expectation that it returns a best move is quite confusing considering that no legal moves are passed to the function.,jc6w44hrp9v2ki,"[{u'text': u'You essentially use the utility value to determine which move to make.', u'responses': [u'Right. So, why does it expect me to return moves along with the utility value. Shouldn't the only piece of information I need from that function is the utility value? I'm already iterating over the set of legal moves (passed to the move() function). I can't pass them to minimax, so that implies that I have to get the set of legal moves redundantly within minimax. I'm not sure how that makes sense.', u'I’m not sure if I completely understand your question. Ultimately, you’re trying to pick the best next move, that’s why you need minimax to return it. Edit: Conor explains it below much better than me.', u'Brett - I noticed the same thing. There appears to be no rational reason as to why the legal moves should be passed to move(). As you said, minimax needs to make the legal_moves() call itself. But even if move() needed the legal moves, game is passed to move() and they could be got directly from there.', u'I believe the reason it returns a move and a value is because it is used for both purposes (determining which move to make and understanding the score of the best move).  If you just returned the score, that would let you figure out the value of your current position, but you'd have no idea how to achieve that value.  By also returning the move that achieves that value, you then know what move to make that is targeted at the highest value. 

When your in the middle of the algorithm (beyond the root) the move doesn't matter, but because it's a recursive function with the same signatures, they all return a move.   It seems possible you could re-write the code to have an internal and an external interface where the external interface returns the move and the internal interface only returns the score, but I don't see how you'd be saving all that much to do so.']}]",Please check Conor's reply. ,0.0,241.0,122,,Minimax return values,[a1]
5ad7d4380d63974e20c390a0,"I am aware that we are not allowed to change the name of the move function defined in the class CustomPlayer : 

def move(self, game, legal_moves, time_left)

But can we ""add"" some code in this function to play around with the values returned by minimax/alphabeta?
",jc6w44hrp9v2ki,[],Yes.,0.0,238.0,123,,Are we allowed to add some code in move() in CustomPlayer?,[a1]
5ad7d4390d63974e20c390a1,Hi! Every time when I run my code I receive notice that Move of this player is None. Winner Random player. How can it be if after program execution my Custom player wins?,jc6w44hrp9v2ki,[],,0.0,223.0,126,"This looks like a coding error in the test that you're running.

in player_submission_tests.py the ""CustomPlayer Test: CustomPlayer Won"" message comes from code that searches the winner string for the term ""CustomPlayer"".  So it seems that at some point there was a winner that was the custom player. 

It's likely the two messages you have right next to each other are coming from different tests.  You can add a few output messages to your player_submission_tests.py to clearly identify each test that is being run so that you can determine where the messages are coming from.",Move of this player is None,[a1]
5ad7d4390d63974e20c390a2,"Need to maximize family time and study time ;)

",jc6w44hrp9v2ki,"[{u'text': u'I suspect you are the coffee beans?', u'responses': [u'Wife is coffee beans and I'm the corn... Thankfully my agent will have AI and not my I.', u'Actually I think playing optimally means letting your better half win!', u'Agree!']}]",,0.0,261.0,127,,Sunday morning with the family ...,[a1]
5ad7d4390d63974e20c390a3,"Throughout the semester, we will be posting a number of challenge questions. Their aim will be to encourage peer learning and help you get a deeper understanding of the material; something that videos alone cannot do. We will try to make them engaging and fun, and will also try to connect them with the assignments so that they don't feel too out of place. These Challenge Questions will not provide extra credit, but they will give you an idea of what to expect in the midterm and the final exam.

We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post in now OPEN FOR DISCUSSION.

Having said that, let us warm up with a relatively straightforward challenge question on Game Playing.

Consider this Game Tree.

A) Solve the game tree using MiniMax.

B) Solve the game tree using Minimax with alpha-beta pruning. Evaluate nodes from left to right. How many nodes are going to be pruned?


Solution - @305

",jc6w44hrp9v2ki,"[{u'text': u'How will we know that it's ""open for discussion""?', u'responses': [u'We will update the post and write with large letters OPEN FOR DISCUSSION, in a few days.', u'AlphaBeta tree values with Minimax values in green; AlphaBeta pruning in green
', u'I have not changed the visibility settings.']}, {u'text': u'Please do not post any answers until the Challenge Question is open for discussion.', u'responses': [u'What does that mean? It's open for discussion now', u'Hi Mark, 
""we request students to NOT post any comments until this post is open for discussion.""
We will open it for discussion tomorrow. We want to give people some time to solve it on their own.']}, {u'text': u'I am confused, do we submit this for bonus points or is this just to help us prep for exam?', u'responses': [u'These questions will not provide extra credit.']}, {u'text': u'This post is now open for discussion, so feel free to post your answers and discuss.', u'responses': []}, {u'text': u'A) Minimax game tree


B) Alpha-Beta pruning eliminates 10 nodes
', u'responses': [u'Ah, thanks for this solution! In mine I missed pruning the -2 leaf node. It didn't occur to me how the maximizing node above it could choose from ""<=-3"" or ""<=-1"", but after seeing your solution I realized that either of those ranges are worse than the positive 1 that the root maximizing node could pick from its left subtree, so checking that -2 is not necessary.', u'by convention, is it best to show the entire branch on the right (and all of its sub-branches) as pruned, or just the main /9\ branch itself?', u'Either is fine. Remember the inequality signs though. Good job!']}, {u'text': u'', u'responses': [u'Is this correct if we're using the notation from lectures for alpha-beta pruning?', u'This is correct! Both solutions are correct, but inequality signs are preferred :)', u'Follow up question: if we got a question like this in an exam, should we leave the nodes on the right of the tree empty like this or fill in with something like >= -inf, since we have no idea what the values are for those nodes. Just checked that either would be fine in terms of preferred notation, etc.', u'Empty nodes is fine.']}, {u'text': u'', u'responses': []}, {u'text': u'', u'responses': []}, {u'text': u'', u'responses': []}, {u'text': u'There's a great and helpful animation here for alpha-beta pruning:
http://inst.eecs.berkeley.edu/~cs61b/fa14/ta-materials/apps/ab_tree_practice/', u'responses': []}]",,1.0,379.0,128,,Challenge Question 1 - Game Playing,"[lesson1, challengeqtns]"
5ad7d4390d63974e20c390a4,"For example, if one queen can move to 2 spots but one queen is stuck, does it count as having 2 moves available if both queens can't actually move? It seems odd to me that we would count a situation where queen 1 can move to 6 spots and queen 2 and can move to 0 the same as if both queens can move to 3. Is this an example of a shortcoming of just counting open moves?",jc6w44hrp9v2ki,"[{u'text': u'Follow up to the student answer, while that seems right, doesn't that count as making a custom eval function? Are we allowed to add some weights to the OpenMoveEvalFn?', u'responses': [u'I did not add any special handling in OpenMoveEvalFn (other than dealing with who's turn it was) and only added anything else special to my own custom eval function.   Though I also have to admit that I didn't include my own eval function until I got to part 1b  (part 1 and 1a were done with just the off-the-shelf function).', u'I misunderstood the assignment and thought we are not allowed to have any special evaluation until part 1... I thought we need to do minimax, then minimax depth=2 and then a\b depth=3... it took me a while to get that that is just what the opposing agent will do and we are allowed to do whatever... anyway, I only added that special handling since I think it's technically a valid interpretation of my moves - opponent moves (at least I hope so because I don't want to submit again!), but everything else I'll do in custom for part 1b. Thanks!', u'I don't think you'll get dinged for adding special handling.  I was just saying that it's not needed to meet the requirements of bonnie for stage 1.  It may be required in some cases for 1a (though I did not do so) and it's likely required to beat in stage 1b (though I have not beaten the dragon that is 1b yet, so I can't say for sure).']}]",,0.0,261.0,129,"The score should be very low for you if your queen can't move and very high for you if their queen can't move because this means that whoever's queen can't move, they have lost.",Should OpenMoveEvalFn even bother counting moves if one of the queens can&#39;t move?,[a1]
5ad7d4390d63974e20c390a5,"
$ python submit_b.py
...
Submission includes the following files:
    player_submission.py

Uploading submission...
[=========================== 100% ===========================] 19503/19503

Waiting for results... -
Waiting for results...Done!

Results:
--------
{
    ""error"": ""{\""msg\"": \""The command $(sudo -H -u vmuser_tjlvhkqo bash -c \\\""cd /home/vmuser_tjlvhkqo; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_1b 1> run_stdout.txt 2> run_stderr.txt\\\"") exceeded the timeout of 7200 seconds.\""}""
}

I am getting the above error when submitting to Bonnie for submit_b.py. The submit_b.py script runs for almost two hours before returning this error. I am not even getting back a JSON file in the directory from which I run the submit script. I was able to run submit_b.py many times yesterday with no issues. Does this error imply that Bonnie is running low on resources?
 ",jc6w44hrp9v2ki,"[{u'text': u'Was this just today (21JAN) or did that happen other days this week?', u'responses': [u'I was able to run submit_b.py multiple times yesterday but starting this morning I have been unable to make any submits. I've only made small changes to my custom evaluation function with my submits for today. I'm thinking it may be a server resource issue as more students are submitting their code given that it's the weekend.', u'One thing that comes to mind is that a lot of students have jobs during work week, so I would assume that the servers would experience peak loads at some point over the weekend.', u'I have this same issue starting this afternoon and had been submitting code consistently all weekend. Testing again now limiting my depth to see if limiting my time searching helps ', u'I have the same issue.  After over 2 hours of waiting, my response to submit_b.py is that it timed out.']}, {u'text': u'I am also experiencing this issue with submit_b.py. Was able to complete within 1 hour yesterday but today it is getting timeout after 2 hours even with the same code', u'responses': []}, {u'text': u'I'm facing this issue as well. Tried 2 submissions back to back, both had this issue. Using iterative deepening in my code, so it does return some move, even if it falls short of time. Working fine for submit_a.py', u'responses': []}, {u'text': u'I am having different results for the same code for submit_b.py section. Surprised to see different results for the same code. Is this expected?', u'responses': [u'there's a randomess factor so it won't be totally the same for each run']}, {u'text': u'I am facing a similar issue. Code that wins the test game against a random player locally (using the provided test script) within less than 15 seconds is getting a 1800s timeout warning on Bonnie. Given the record class size, is there any way that the instructors can quickly confirm that the server isn't getting overwhelmed at some points?', u'responses': []}, {u'text': u'I hit the same timeout for 1-b submitting at 23:00 (US East) last night.   Most annoying thing is that there is absolutely no feed back at all, so the 2 hours is a complete waste of time -- no better off than if I had not submitted it.   It would be nice to know that there were n attempts, and the code won m of them; at least I could tell if I was on the right track.   ', u'responses': [u'
Turning my timeout threshold way down allowed me to at least get a run in without busting the global timeout.  To a degree I may not be checking as frequently as I should -- fearful of wasting cycles looking at the clock, but it seems I'm going to need to tweak that.  At least I know that I was beating it better than 50%, but not enough to clear the 65% hurdle. ']}, {u'text': u'Also having this issue, and wanted to add that running the same code on part a and part b gives no timeout on part a but does on part b. Does this mean we’re having to limit our time per turn to allow our opponent to use the full time or risk the global timeout? ', u'responses': [u'That's how I understood it. We get a shorter amount of time, the opponent is allowed to use up their full cycles or more -- stellar.

I can run my agent against itself 40 times in well under 2 hours, so I'm not sure how it's possible that my agent is timing out without something going sideways on the server.']}, {u'text': u'I had the same time out error about 2 hours ago (6PM eastern time). I waited a little bit, resubmitted my code and it passed both the first and second test. I highly suspect there was a server issue earlier today and someone fixed it. ', u'responses': []}]",,0.0,248.0,132,"this implies that you are running out of the hard limit for the submission execution.  It could be something in your code.  It could be something with bonnie's resources (e.g. you aren't getting as much CPU as you were yesterday).   Not sure how isolated bonnie's containers are for the submissions.  I did note that some runs I made had dramatic differences in time with zero code changes (though they both lost, of course).",Timeout on Bonnie server?,[a1]
5ad7d4390d63974e20c390a6,Can we form smaller virtual teams during this course? I completed 6400 in the fall and there was an option to form teams and we worked together on projects. It was very helpful in this virtual setting. Wondering if this course has similar arrangements and when would that trigger? ,jc6w44hrp9v2ki,[],"There are no group assignment or project for this class.

However, you can and are encouraged to form study groups to discuss challenge questions as we post them. Doing these challenge questions would be very beneficial for you mid term and final exams. You can also discuss your method about your homework, but be mindful that you should never be looking at another person's code, which would constitute plagiarism.",0.0,251.0,133,some courses have teams as part of their structure and mission.  Most do not and require all work to be done by the individual.  So far this feels to be like the latter (so that you learn the AI techniques yourself).,Team groups for 6601,[group_study]
5ad7d43a0d63974e20c390a7,"I'm trying to test my CustomPlayer against a RandomPlayer using player_submission_tests (5x5 board).

I changed the relevant portion as this:

p1 = RandomPlayer() #p2 = HumanPlayer()p2 = CustomPlayer(4)b = Board(p1, p2, 5, 5)

But this result doesn't make sense. Why does it say 'Move of this player is None' then decides that RandomPlayer wins?

OpenMoveEvalFn Test: This board has a score of -1.Minimax Test: Runs Successfully<test_players.RandomPlayer instance at 0x0000000002810A88>  player1 0.Queen1: (0,1)Queen2: (1,4)   | 11 |    |    |    |    |    |    | 22 | 12 |    |    |    | -- |    |    |    |    | 21 | -- |    |    |    |    |    |   player2 0.Queen1: (2,4)Queen2: (0,4)   | 11 |    |    | 22 |    |    |    | -- | 12 |    |    |    | -- | 21 |    |    |    | -- | -- |    |    |    |    |    |   player1 1.Queen1: (0,0)Queen2: (0,3)11 | -- |    | 12 | 22 |    |    |    | -- | -- |    |    |    | -- | 21 |    |    |    | -- | -- |    |    |    |    |    | Move of this player is NoneWinner: <test_players.RandomPlayer instance at 0x0000000002810A88>



",jc6w44hrp9v2ki,"[{u'text': u'Thanks Patrick, just seen it!

It now appears CustomPlayer will always win if it makes the first move, while RandomPlayer will win if it makes the first move.

Looking at CustomPlayer's chosen moves in this example I've posted, it appears it's acting as a minimizing player (choosing the board with the least score!) yet I expected it to be a maximizing player.

What could I be doing wrong?', u'responses': [u'Most likely your scoring is not taking into account who last moved.  See the replies I added in @40', u'Thanks Conor.

So is it right to take it that if RandomPlayer is player 1, then maximizing_player is true for Player1 and False for Player2 (CustomPlayer in this case), and vice versa?

And second clarification, how do I tell if my custom player is player 2 or player 1?

']}]",,0.0,230.0,134,"If I’m looking at it correctly, your 21 and 22 pieces have nowhere to go, resulting in RandomPlayer winning. ",Result of RandomPlayer against CustomPlayer doesn&#39;t make sense,[a1]
5ad7d43a0d63974e20c390a8,"
Assignment 1: Game Playing
Due: January 28 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 1 is due this upcoming weekend! Please check @57.  

Some extremely important pointers about assignments:

Please remember to submit on BOTH Bonnie and T-Square (with T-Square as a backup), although your official grade will come from your last submission on Bonnie. You may follow any naming convention when submitting to T-Square, as long as it is clear which code is used for which part.

You may check https://bonnie.udacity.com for details about your submissions, submission limits and wait times. 

Please please complete your assignment as soon as possible. As we approach the deadline, we always have students trying to complete the assignment at the last possible minute, resulting in Bonnie struggling to cope with the load. This may result in your submissions taking extremely long to evaluate, and occasionally not going through at all. We are not responsible for any delays to your planned schedule due to these issues - we have already provisioned as much processing power as we are allowed to. Please plan your work accordingly.

Additionally, note this line from our Syllabus page: remember that for the instructors and TAs of this class, this is a job, and we may not check Piazza on weekends. Please make sure to start the projects and assignments early enough to ask questions in advance.

Office Hours:
Office Hours are currently running, but we will still be adding slots.  Here is the OH calendar if you missed it.  

As always, here are the syllabus and the schedule.  

",jc6w44hrp9v2ki,"[{u'text': u'One suggestion that might help with Bonnie's load... if you gave us an option to do a test run against bonnie that ran a reduced number of tests (e.g. ran only 1 or 4 runs of the game instead of 20) that did not count for scoring, but let us see how our work was proceeding.  This might decrease the load on the system while we are building up to our full run (and would likely get us results faster).', u'responses': [u'This is a very good suggestion. Thanks Conor. It will not be possible to change things this semester- but I will inform other TAs handling other assignments. Also from next semester - we can definitely try this. ']}, {u'text': u'I can't say that I'm impressed with how the requirement to submit to both T-Square and Bonnie was communicated. This wasn't specified in the README or any of the previous assignment documents. In fact, this is the first I'm hearing of it at all - just a few days before the assignment deadline.

Since I've made revisions to my AI since passing the first two parts, to be able to submit the correct code for each part to T-Square now I have to either monkey around in Git to get the versions that I submitted for those parts, or resubmit parts 1 and 1A entirely.', u'responses': [u'You can find your player_submission.py file for a give submit at bonnie.udacity.com. You can download a zip containing your submission.', u'I did not know that - thank you!', u'You're welcome! Hope that saved you some time.', u'you could also use git tags so you can checkout the source code for a specific phase/tag.']}, {u'text': u'I'm unclear. On T-square, do I need to submit my code 3 different times, once for each section?

or only once for the entire assignment?', u'responses': [u'You need to submit your final submission on Bonnie that is counted as your score.', u'Can we add comments to our code (without changing any actual code) before submitting to t-square?', u'Personally, I don't see why not. Comments are just that, comments. They're only meant for human eyes. Besides, as I understand it, the t-square submissions are for backup purposes in case the TA's cannot retrieve the source code from your Bonnie submissions.', u'That makes sense to me, Brett. However, I don't want to do so without the go ahead from the TAs and then have a grading problem in case there's an equality check on the t-square submission and the Bonnie submission. And I'd rather not resubmit to Bonnie given the difficulties I'm reading about on Piazza, especially if I were to then fail the Bonnie test and have to pray to the psuedorandomization gods to put the odds back in my favor.']}, {u'text': u'Are we supposed to submit the results of the three submits (JSON files) from Bonnie and the player_submission.py script to T-square? Anything else or does cover it?', u'responses': [u'We normally just ask for the .py file. But it's no harm if you want to include the json files.']}, {u'text': u'Are are files required or just player_submission.py?
', u'responses': [u'The submit scripts will take care of the player_submission.py file and the additional AI.txt file if needed. Submit both on T-Square as well. ', u'So... I made a mistake and thought I only needed to submit the AI.txt file on T-square. I didn't create it until after I submitted my assignment for Section 3 on Bonnie. I don't want to risk submitting again just to participate in the botfight. Will players be collected for the botfight from T-square too? If not, that's OK, my mistake, just checking.']}, {u'text': u'When is assignment due in Eastern time?
January 28 at 11:59PM UTC-12 translates to January 28 at 6:59PM EST
And on my tsquare which is set to EST is showing the due dates as January 29 at 8:00AM EST ', u'responses': [u'The assignment is due on January 28 AOE, which means as long as it is still January 28 somewhere on earth (middle of the pacific east of the international date line), you can still submit.

This happens to work out to 8am EST']}]",,0.0,358.0,135,,Week 3 Announcement,"[a1, announcements]"
5ad7d43a0d63974e20c390a9,"My Custom Player almost always wins on the 5 X 5 board.

But if I test on 7 X 7 board, it doesn't even seem to make a move. Am I uncommenting the wrong lines?

   try:       """"""Example test to make sure       your minimax works, using the       OpenMoveEvalFunction evaluation function.This can be used for debugging your codewith different model Board states. Especially important to check alphabeta pruning""""""       # create dummy 5x5 board       p1 = RandomPlayer()     #p2 = HumanPlayer()       p2 = CustomPlayer(4)       b = Board(p1, p2, 5, 5)       b.__board_state__ = [           [0, 0 , 0, 0, 0],           [0, 0,  0, 22, 0],           [0, 0,  0, 11, 0],           [0, 0,  0, 21, 12],           [0, 0 , 0, 0, 0]       ]       b.__last_queen_move__[""queen11""] = (2, 3)       b.__last_queen_move__[""queen12""] = (3, 4)       b.__last_queen_move__[""queen21""] = (3, 3)       b.__last_queen_move__[""queen22""] = (1, 3)       b.move_count = 4       output_b = b.copy()legal_moves=b.get_legal_moves()       winner, move_history,  termination = b.play_isolation()       print 'Minimax Test: Runs Successfully'       # Uncomment to see example game       print game_as_text(winner, move_history, termination, output_b)   except NotImplementedError:       print 'Minimax Test: Not Implemented'   except:       print 'Minimax Test: ERROR OCCURRED'       print traceback.format_exc()   """"""Example test you can run   to make sure your AI does better   than random.""""""   try:r = RandomPlayer()h = CustomPlayer(4)game = Board(r, h, 7, 7)output_b = game.copy()winner, move_history, termination = game.play_isolation()if 'CustomPlayer' in str(winner):    print 'CustomPlayer Test: CustomPlayer Won'       else:    print 'CustomPlayer Test: CustomPlayer Lost'# Uncomment to see gameprint game_as_text(winner, move_history, termination, output_b)   except NotImplementedError:print 'CustomPlayer Test: Not Implemented'   except:print 'CustomPlayer Test: ERROR OCCURRED'



This gives the results:

OpenMoveEvalFn Test: This board has a score of -1.Minimax Test: Runs Successfully<player_submission.CustomPlayer instance at 0x0000000002723AC8> player1 0.Queen1: (1,2)Queen2: (1,4) | | | | |  | | 11 | 22 | 12 |  | | | -- | |  | | | 21 | -- |  | | | | |  player2 0.Queen1: (3,2)Queen2: (0,2) | | 22 | | |  | | 11 | -- | 12 |  | | | -- | |  | | 21 | -- | -- |  | | | | |  player1 1.Queen1: (2,1)Queen2: (0,4) | | 22 | | 12 |  | | -- | -- | -- |  | 11 | | -- | |  | | 21 | -- | -- |  | | | | |  player2 1.Queen1: (4,1)Queen2: (1,1) | | -- | | 12 |  | 22 | -- | -- | -- |  | 11 | | -- | |  | | -- | -- | -- |  | 21 | | | |  player1 2.Queen1: (1,0)Queen2: (0,3) | | -- | 12 | -- | 11 | 22 | -- | -- | -- |  | -- | | -- | |  | | -- | -- | -- |  | 21 | | | |  player2 2.Queen1: (4,2)Queen2: (2,0) | | -- | 12 | -- | 11 | -- | -- | -- | -- | 22 | -- | | -- | |  | | -- | -- | -- |  | -- | 21 | | | Move of this player is NoneWinner: <player_submission.CustomPlayer instance at 0x0000000002723AC8>
CustomPlayer Test: CustomPlayer Lost<test_players.RandomPlayer instance at 0x0000000002723E88> player1 0.Queen1: (2,6)Queen2: (1,6) | | | | | | |  | | | | | | 12 |  | | | | | | 11 |  | | | | | | |  | | | | | | |  | | | | | | |  | | | | | | | Move of this player is NoneWinner: <test_players.RandomPlayer instance at 0x0000000002723E88>
Process finished with exit code 0

",jc6w44hrp9v2ki,[],,0.0,231.0,136,"Is that 4, your depth? Is your CustomPlayer timing out? Add some debug print statements to your code to see what is going wrong",How do I switch the tests between 5 x 5 and 7 x 7 boards,[a1]
5ad7d43a0d63974e20c390aa,What is the largest size board that we will be tested on?,jc6w44hrp9v2ki,"[{u'text': u'you can access the height and width fields for the gameboard to determine the dimensions. ', u'responses': []}]",,0.0,206.0,137,I understand that the board size is a fixed 7x7.  I was surprised that there was not a get_size() function supported by the game object. ,Board size,[a1]
5ad7d43a0d63974e20c390ab,"If queen1 has 12 moves and queen2 has 10 moves, why the total moves are 22(12+10) why not 120(12*10)?
As there would be 120 different ways of making the move for the active player.",jc6w44hrp9v2ki,"[{u'text': u'I spent 3 hours trying to figure out it was 12 + 10 and not 12 * 10 ... For such questions, I feel if we are tested against a pre-determined set of answers, the algorithm / process should be clearly defined.', u'responses': []}]",,0.0,225.0,139,"You're right the total possible move combinations are 120 (assuming there is no overlap).    You can write your custom evaluation function to work that way.

In OpenMoveEvalFn we're essentially measuring the number of open spaces left that you can move to as a means of scoring the relative strength of your position.  It's an arbitrary call on how one could measure/score the current board.  You are free to experiment with your own methods (in your custom eval fn, of course).","Moves for a player, why not q1*q2?",[lesson1]
5ad7d43a0d63974e20c390ac,"Is there a method already defined in the Board class to generate the game tree ? I could not see one, but wanted to make sure

thanks
Ivan",jc6w44hrp9v2ki,[],Can you elaborate on what you're asking? Do you mean visualizing the game tree?,0.0,212.0,140,,tree generating ?,[a1]
5ad7d43a0d63974e20c390ad,"When you are deep into thinking and implementation, it is easy to unintentionally run a wrong submit.py script which may be worse than your last successful run (thanks to randomization, server overloads and timing factors). All scripts are very similar in naming convention with just an additional append)

This is what happened to me, but thankfully it was the script for next section that I executed!

Lesson learned - I am deleting the corresponding script file from the project once done with that section to eliminate chance of wrong script execution.",jc6w44hrp9v2ki,[],,0.0,216.0,141,,Always double check which script you plan to run on Bonnie,[a1]
5ad7d43a0d63974e20c390ae,"When I submit submit.py it returns an error in the JSON

student_agent = CustomPlayer() # Force the reinitialization of the player after every game\nTypeError:
__init__() takes at least 2 arguments (1 given)\n"",
This appears to be that the submission test needs to instantiate a CustomPlayer without init paramters.

However my CustomPlayer __init__ signature is 
def __init__(self, search_depth=1, eval_fn=OpenMoveEvalFn()):
so I'm not clear why the call to CustomerPlayer() fails saying it needs parameters since default values are provided in the __init__ for all parameters.",jc6w44hrp9v2ki,"[{u'text': u'I'm getting the same error right now. It works fine using the player_submission_tests.py but not on Bonnie.
', u'responses': [u'try adding a default value for search_depth in the __init__() of CustomPlayer like in my original post.
in my case it turned out I was submitting an old version of the code. The default value should correct the issue.']}, {u'text': u'What if we want a dynamic search depth? Can we make changes to the init parameters or add variables to the init? Will the depth update if we change it with self.search_depth at some point in the eval or custom eval function?', u'responses': [u'How you treat the search depth is up to you.  With ID, most have just used the initialized search depth as a maximum depth.', u'Thanks. That makes sense. So the way to set it up is to have BOTH a current depth level that you keep track of on your own and a maximum depth level set in the custom player function.', u'That is one way to set it up, of course.   Another way is to use the defined depth as a suggestion walking down until you run short of time at which point you stop, regardless of how far along you are in the depth analysis.   This works for ID, but not so much for the out-of-the-box minimax or AlphaBeta algorithms.']}]",,0.0,212.0,142,Are you sure you made that change in the right place in the right file?  submit.py will only take and use player_submission.py and your change has to be there in the one function named CustomerPlayer (it seems like either you made the change in a different file or to a different class).,__init__ error,[a1]
5ad7d43b0d63974e20c390af,"In the Readme file you suggest using the following techniques to improve over the base performance- Use partition techniques.- Store the evaluation scores for past moves.- Modify your evaluation function to account for “killer moves”.- Optimize functions that are called often.- Order nodes to maximize pruning.Could you elaborate some more on the partitioning technique for better understanding.

Thanks,
",jc6w44hrp9v2ki,"[{u'text': u'One of the udacity videos covers this.  It has several suggestions about building an agent for 1 queen isolation.', u'responses': [u'Can you be more specific about this?  I am having trouble finding that video.', u'Lesson 1, #44 ""Solving 5x5 Isolation""']}]",,0.0,223.0,143,It means finding a way to wall off a section of the board to trap the opponent.,Elaboration on Partitioning Technique,[a1]
5ad7d43b0d63974e20c390b0,"""Clyde failed to process the job""

Anyone else get this? Waited over 3 hours for a response from bonnie and that is what I got.",jc6w44hrp9v2ki,"[{u'text': u'Yes, I just got this error as well, after submitting section 3 using submit_b.py', u'responses': []}]",,0.0,190.0,145,I think it means bonnie is overloaded with submissions now so the total run-time exceed the 2 hour limit,Clyde failed to process the job,[a1]
5ad7d43b0d63974e20c390b1,I am really confused about it. Could someone explain it? Thank you.,jc6w44hrp9v2ki,"[{u'text': u'Really appreciate it.', u'responses': []}, {u'text': u'Changrui -- did you have issues with this? I find that when I specify p1 as a customPlayer and call game.get_active_players_queen() I get (21,22), i.e. player 2's queens. If I make player 2 a CustomPlayer, then I get the reverse behavior. This also extends to calls for .get_legal_moves and .get_opponent_moves. Things work well for me--provided I assume I am the inactive player, which is exactly the opposite of what I expected. Is this the behavior that prompted the question?
', u'responses': [u'I think when we evaluate the board state we are the active player. The issue you have may be that you evaluate the board when you are inactive.', u'Yes -- I wasn't paying attention to my forecast function.  Thanks.']}]",,0.0,228.0,146,"When it is the turn of a player to make a move in the isolation game that player is referred as active player. If it is not the player's turn that player is inactive player. E.g. if it is player 1's turn, then that player is active and player 2 is inactive. When it is player 2's turn, then player 2 is active and player 1 is inactive.",What is the difference between an active player and an inactive player ?,[a1]
5ad7d43b0d63974e20c390b2,"I am lack of experience of coding. Could someone explain the logics of recursive of minimax algorithm?
I got stuck all the after noon and the function still return none.
So frustrating.

any help will be appreciated.",jc6w44hrp9v2ki,[],,0.0,204.0,148,"Before you start trying to implement the minimax algorithm in code, make sure you understand the algorithm as described in the textbook and other learning resources available for students.  If you get comfortable performing minimax by hand on a few shallow tree examples, it should become more clear how to implement it in code with deeper trees.",Logics of the recursive function of minimax,[a1]
5ad7d43b0d63974e20c390b3,"Hi all,

In testplayers.py, for class randomplayer(), move function, we have:

if not len(legal_moves[game.__active_players_queen1__]) and not len(legal_moves[game.__active_players_queen1__]): return None,None

1) there are two __active_players_queen1__, one of them should be __active_players_queen2__, right?
2) why use and? From my understanding, we should use or: if one of the queens has no move, then the player loses the game. so no further move for the loser. right? 

Thanks,
",jc6w44hrp9v2ki,[],"Yes. Please correct that if needed. its a typo.
You will not see any different results because if you return any random move at end of the game- it will be checked in isolation.py and you will lose anyways",0.0,195.0,149,"Just skimmed the rest of the function; Based on that skim, seems like the following situations are possible:

There are moves available for both queens.  This will fall through the bug line and return a valid move, which is appropriate.There is only one move available for each queen, and those moves are the same.  This will fall through the bug line and return `None, None`, losing the game, which is appropriate.There are no moves available for queen 1.  This will get caught on the bug line and return `None, None`, losing the game, which is appropriate.There are no moves available for queen 2.  This will fall through the bug line, but will still return `<move>, None`, losing the game, which is appropriate.There are no moves available for either queen.  This will get caught on the bug line and return `None, None`, losing the game, which is appropriate.

Essentially this bug isn't causing any problems beyond making the code harder to understand.  Note too that the `flag` boolean variable is also a red herring and could be removed, since the code loops until a valid move is found and immediately returns that move - so the while loop should just be `while True:` and no fussing around with the flag is needed.

And specifically in answer to your question 2 - The `and` is there because the only situation not handled properly by the rest of the code in the function is that neither queen has a valid move available.  Someone was trying to fix an actual bug - that if neither queen can move the function would loop forever.  The fix they introduced intended to look for just that situation, and even though it didn't properly identify that situation, it accidentally fixed the problem.",Typo?,[a1]
5ad7d43b0d63974e20c390b4,"Was looking for some clarification on this right here, 

The README file says that is uses the evalFn while comparing it against the minimax and alpha-beta in submit.a and submit.b

Is it the expectation that our AI beats the submit script using the mandatory Evalfn or was it expected that we call and use our custom fn while doing a submission for those 2 parts?

Thanks",jc6w44hrp9v2ki,[],You can use a custom evaluation function. We encourage you to try to come up with something better than the default open moves evaluation!,0.0,210.0,150,,Custom Evaluation Function use in Submission Script,[a1]
5ad7d43b0d63974e20c390b5,I am trying to work on efficiency and was wondering if anyone would be willing to share typical run times. Thanks.,jc6w44hrp9v2ki,[],,0.0,220.0,151,"We can't really compare unless you specify a few things. I added notes after each one not to lecture but to help others who might be curious as to why.

How deep are you searching? The time complexity for the minimax algorithm is b^m, where m is how deep you are searching. So minimax with a depth of 4 will take significantly longer than with a depth of 3How far into the game do you start using minimax. The 'b' in b^m is your branching factor and reduces as the game progresses. That is why at the beginning of the game when there are a lot of open moves you will not be able to search very deep in a timely manner. The speed of your local machine. This is probably the smallest factor if we reasonable assume your computer has average processing power compared to everyone else. The algorithm itself is the most significant source of time ",How much time should minimax take to run the 7x7 game on local machine?,[a1]
5ad7d43c0d63974e20c390b6,"When I submitted my minimax to bonnie, in json result output I see following message.  Does it mean there is a problem in program or it is just call stack I can ignore.. I am particularly worried about part where it reads ""....takes at least 2 arguments (1 given)"". Please advice

""traceback"": ""Traceback (most recent call last):\n File \""/home/vmuser_txvrszdj/AIResult.py\"", line 26, in func_wrapper\n ans = func(self)\n File \""run.py\"", line 109, in test_beats_minimax\n self.evaluate_against(TestAI(method='minimax'), 0.65)\n File \""run.py\"", line 55, in evaluate_against\n win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n File \""run.py\"", line 32, in simulate_games\n student_agent = CustomPlayer() # Force the reinitialization of the player after every game\nTypeError: __init__() takes at least 2 arguments (1 given)\n"", ""description"": ""Beats MinimaxPlayer""
",jc6w44hrp9v2ki,"[{u'text': u'I have not changed any code in _init_ method. my logic works in local testing.. Is there any way I can refresh my code from repository without over writing my code ?
', u'responses': [u'right - you cannot ignore this error since your score will be zero. Can you post here the line for the 'def __init__..' for your CustomPlayer? ', u'def __init__(self, search_depth, eval_fn=OpenMoveEvalFn()):', u'just a note: I read in one thread here that I should assign some depth to search_depth parameter to overcome this error. I will try that in one hour after when bonnie allows me next submission', u'Yes. You need to define a default value for search_depth, similar to how eval_fn is given a default. When CustomPlayer() is called without any parameters, the compiler has no idea what value to use for search_depth.', u'yes it works !']}, {u'text': u'This is a bug on the instructor's side, either in the provided code or in the test suite on Bonnie.

As another student correctly pointed out adding a default value to the ""search_depth"" parameter of CustomPlayer's __init__ function (on line 75 of player_submission.py) will fix it, and indeed this signature shows up with a default parameter in README.md, however I'd like the instructors to weigh in since the project description explicitly states: You are not permitted to change the function signatures of any of the provided methods.', u'responses': [u'I believe by signature, they are talking about the parameters to the function not whether or not the parameters have a default value.  They also tell you to update the default value of eval_fn if you write a better one in the same README.md.

The need to set this default has been indicated repeatedly in different piazza posts without correction by the TAs *and* it has worked on Bonnie.', u'It should also be possible to add new __init__ params as long as they are defined with default values. i.e. that any CustomPlayer() instantiation call from the grading code succeeds. But when a TA weighs in I'd like to have confirmation of that.']}]",,0.0,223.0,152,"I'm certainly not a python expert, but it seems that you've either added an argument to the __init__() function, or deleted one of the default values for your CustomPlayer class.  I believe the error is indicating that CustomPlayer is being called with no parms (student_agent = CustomPlayer()) which implies that the prototype for the __init__() function must contain self followed by an argument list which defines a default for every one. 

If you've added an argument, or accidentally deleted a default value, I would assume this error would be generated. ",Part 2 assignment : Meaning of Error Message,[a1]
5ad7d43c0d63974e20c390b7,After Office Hours with Jainesh he mentioned that there is symmetry that we can do to help evaluate board states in a much quicker fashion. I remember seeing that in the lectures as well and as much as I can understand the concept I am lost as to how to begin with code. Is there any pseudocode or techniques that can be shared that shed a light on all this?,jc6w44hrp9v2ki,"[{u'text': u'Thanks Ravikiran for the reply.
But I really think that a recorded session would be really helpful for somebody like me who has is in a timezone about 12 hours different. Else, another way could be to have the office hours in varied time zones. I know TA's comfort need to be looked at but since this course is online conducted, office hours would go waste for somebody like me.', u'responses': [u'Hi Saalis,We have tried our best to span our office hours around the week across the whole day here (9am to 11pm EST) to cover students from different parts of the world. I think you should be able to find one suitable slot for you among these office hours. And even if you still have doubts, you can always post on piazza and we would be happy to guide you as needed. ']}]","From our syllabus document: Note that generally, these office hours will not be recorded aside from Instructor Hangouts on Air. Synchronous office hours are intended for conversations, discussions about course material, etc. rather than straightforward question-and-answer; because they are more personal to the individual attendees, they are not as useful when recorded and posted. Additionally, the pressure of knowing over 400 people may watch a private chat tends to dampen natural conversation. If anything comes up in these office hours that is relevant to the rest of the class, it will be recorded or posted on Piazza.

This was not posted on Piazza because it is a part of the lectures already.

As for the original question, I would still discourage looking for pseudocode on this topic. One, it can violate the honor code. Two, it might not really be available. I would advise you to think about how you might ""rotate"" a board - you can then try to compare rotated board states against previous ones you've generated and discard duplicates.",0.0,206.0,154,Is recorded office hour available?,Symmetry Help,[a1]
5ad7d43c0d63974e20c390b8,I am running AI agent. It does not win more than 65% time as required by assignment 2. What should I look at ? Does it mean my minimax algorithm is not implemented correctly ? or it means EvalFunction requires a change.? Any generic advice would help.,jc6w44hrp9v2ki,"[{u'text': u'Thanks for pointers. I see following in json 
""num_invalid_moves"": 18, ""num_timeouts"": 0

I guess I am hitting invalid moves because of wrong logic..', u'responses': [u'that typically means you lost 18 times and therefore your win ratio would be 0.1', u'
Invalid moves are also what is tagged when your code legitimately loses -- no valid move at the end of the game because one or both queens are trapped.  ', u'I'm in the same boat, close to passing but not quite to .65 yet for one of the tests. If you aren't already doing this I suggest running an instance of your CustomPlayer against the RandomPlayer from player_submission_tests.py. Then use print statements for each move you return as well as the print_board function to see the current state of the board. This will let you see whether you are being trapped by the opponent (and need to improve your strategy) or if you are making invalid moves (and maybe have a bug somewhere). Using this strategy I've already found one small bug that was returning an invalid move. Good luck!', u'print board was good idea. I found the error that I am calculating wrong move values for node at given depth level (2). I am always taking first move from legal moves of q1 and q2 for depth level 2 . It  may not be best move for given depth level . So some times I am winning but most of the times I am loosing.  

Now I am trying to figure out how to correct it.']}]",,0.0,236.0,155,"Make sure that you're not timing out; time outs are shown in the resulting json and if your code takes more than 10s on any one turn it will lose the game.  If you're not timing out, then make sure you don't have any bugs in your minimax algorithm.  Things like accidentally inverting the moves for Q1 and Q2 on return could cause an illegal move loss.  Set your code up to play itself via the test module provided; that might offer some clue as to what is going on. ",My AI agent not winning more 65% time,[a1]
5ad7d43c0d63974e20c390b9,"I am having a tricky problem - my agent seems to be playing OK, making valid moves based on the MiniMax algorithm. I can see when I put two CustomPlayers against one another that I get game trees which make sense and seem to correctly follow the logic.

However when playing against a random opponent I notice that my agent always makes an invalid move at the last move - namely, it attempts to repeat the last move taken by the opponent. I suspect this has something to do with the way I'm propagating the moves up my minimax tree.

Any tips on how I could handle the last move of the game? In my current implementation I am using forecast_move. When I reach a terminal state (or my depth limit) I obtain the last move made by the inactive player (which is the move which resulted in us getting to this state). This works whenever I am playing normally but at the end-game it results in me trying to take the same move my opponent did.

Any tips for bookkeeping on the game's forecasted moves? Am I missing something here?",jc6w44hrp9v2ki,[],,0.0,191.0,157,"This ""feels"" like you're looking at the wrong set of possible moves.  There should be no moves in your set of possible moves that point to an occupied space.  Is it possible you're looking at moves from the prior level?

Note that your move should not propagate up.  you only should use the move from your root of your search -- the other moves detected as you walk down your simulation tree should be discarded and only the score kept to help you evaluate which move in the higher level leads to a higher score.",Agent Repeating Last Move,[a1]
5ad7d43c0d63974e20c390ba,"TA Approved sharing this with the class!

I spent some time tonight rewriting the Human interface for the game.  Instead of searching through the list of moves, you type in the coordinates (0 based) of the two moves you want to make in the format ""y, x"" (or ""(y, x)"").  The moves can be in either order (eg, doesn't require you to enter ""Queen 1"" then ""Queen 2""), and entering ""None"" or ""q"" (case sensitive, sorry just realized I was lazy on this) will forfeit the game.

I won't claim the code has been fully tested, but it worked for a few games for me and between the interface and displaying the board between moves, it was a lot more enjoyable to test with.  If you'd rather see this as a PR I can create one (assuming I have permissions to fork and create one).

import re

class HumanPlayer():
    """"""Player that chooses a move according to user's input.""""""
    def move(self, game, legal_moves, time_left):
        print(game.print_board())

        q1moves = legal_moves[game.__active_players_queen1__]  # type: list
        q2moves = legal_moves[game.__active_players_queen2__]  # type: list
        if len(q1moves) == 0 or len(q2moves) == 0:
            print 'Out of moves!'
            return None, None
        if len(q1moves) == 1 and len(q2moves) == 1 and q1moves[0] == q2moves[0]:
            print 'Out of moves!'
            return None, None
        while True:
            move1 = get_move(""Enter move 1('y, x' or 'q'): "")
            if move1 is None:
                print 'Forfeiting game!'
                return None, None
            move2 = get_move(""Enter move 2('y, x' or 'q'): "")
            if move2 is None:
                print 'Forfeiting game!'
                return None, None
            if move1 == move2:
                print ""Can't move to the same location!""
            else:
                if move1 in q1moves and move2 in q2moves:
                    return move1, move2
                if move2 in q1moves and move1 in q2moves:
                    return move2, move1
                if not (move1 in q1moves or move1 in q2moves):
                    print 'First move ({}) is illegal!'.format(move1)
                if not (move2 in q1moves or move2 in q2moves):
                    print 'Second move ({}) is illegal!'.format(move2)


def get_move(prompt):
    strip_parens_re = ""\s*\(\s*(\S*)\s*\)\s*""
    move_re = ""\s*(\d+)\s*\,\s*(\d+)\s*""
    done = False
    while not done:
        raw_move = raw_input(prompt)
        if raw_move == ""None"" or raw_move == ""q"":
            return None
        sparens = re.search(strip_parens_re, raw_move)
        if sparens:
            raw_move = sparens.group(1)
        move_details = re.search(move_re, raw_move)
        if move_details:
            row = int(move_details.group(1))
            col = int(move_details.group(2))
            move = (row, col)
            return move
",jc6w44hrp9v2ki,[],"Hey, you can post it on Piazza, or under this: @159.",0.0,179.0,158,,Replacement HumanPlayer for Assignment 1,[a1]
5ad7d43c0d63974e20c390bb,"(Sharing with permission from the instructors.)

Hello everyone,

I hope you've made meaningful progress to the project!

While I'm struggling to get the full credit myself, I would like to share with you some changes I made to the game board that make it somewhat more readable... IMO...



Simply override your isolation.py with this file.

Hope you find this useful.",jc6w44hrp9v2ki,"[{u'text': u'One important detail that can be added to this board is a way to find the last move. like x12 and x11. It will signify that queen 1 of player 1 has moved from x11 to 11 and similarly for queen 2 of player from x12 to 12.', u'responses': []}, {u'text': u'Jianchao, you're great and my eyes appreciate this! Thank you!!
-Q.', u'responses': []}]",,0.0,214.0,159,,A more readable game board.,[a1]
5ad7d43c0d63974e20c390bc,"The deadline is fast approaching and I am still struggling to complete section 2. I'm stuck at this point as I am unable to figure what I'm missing in my code. I am using the same minimax I used during sumbit.py, with the addition to an alphabeta implementation and an iterative deepening and I'm unable to beat submit_a.py. I am hovering around 0.6 for alphabeta and 0.4 for minimax win ratios. I asked on piazza and it seemed to had work for others, I'm I missing something here in my code? Thank you in advance.",jc6w44hrp9v2ki,"[{u'text': u'And keep in mind, alot of people will struggle with this so just cause you did poorly doesn't mean that the median won't still give you a passing grade. So, don't freak out and drop the class if you can't get to far along as I had a friend who took this class and said he completely bombed the first assignment but still got an A in the class. They drop your lowest grade too. Everything is curved off a median.', u'responses': [u'Thanks for the assurance, my goal is not only to get a passing grade but also to fully understand and master the implementation. As we all know implementation is what makes any theory relevant or irrelvant']}, {u'text': u'You concentrate on the custom score function. MyMoves - OpponentMoves is only the starting. Try to make changes. Think whether weighting will help or whether the move will reduce the opponent moves or ratios. ', u'responses': []}, {u'text': u'Just curious, did you try submitting your minimax (without alphabeta or iterative deepening) for sumbit_a.py?  My minimax got me past both submit and submita.  For some reason (implementation issue I'm sure) my player does worse when using alphabeta or iterative deepening or both.  ', u'responses': [u'At the same depth, there should be no difference between minimax and alphabeta.  If you are seeing a difference, there is something wrong in your alphabeta.    I wrote a specific test to verify that for a given board and depth, the results from an alphabeta AI and a minimax AI returned the exact same values.   AlphaBeta is just an optimization of Minimax that eliminates unnecessary evaluations -- it should not change the result.']}]",,0.0,227.0,160,"It is very likely that you are missing something in your code.   your minimax output and your alphabeta output (results) should be the exact same.  You can write some test code that verifies this (e.g. given a board X with a number of moves already played, what does minimax tell you should be your move and what does your alpha beta -- they should be exactly the same given the same inputs.

You can also add debugging print statements to see how you're evaluating the situation to make sure your decision tree is behaving as you expect (that you're dropping the right nodes at the right time, etc.).

I would recommend against iterative deepening for part 1a because it shouldn't be needed and it adds additional complexity (first get the minimax and a/b working then play later).",Minimax / AB implementation issues,"[a1, code_review, office_hours]"
5ad7d43d0d63974e20c390bd,"Our aim for Assignment 1 is to pass bonnie thresholds. I want to know if we would be using the code from assignment 1 as the base code for future assignments likewise many courses.
If it is the case, it makes sense to work more on the code even if it passes the Bonnie.
Regards
Saalis Umer",jc6w44hrp9v2ki,"[{u'text': u'""future assignment will have their own base code that you will use"" <- this makes this course much interesting :)', u'responses': []}]","No- the future assignment will have their own base code that you will use, and you will likely find your own code not all that helpful.",0.0,273.0,161,I don't think we will. The topics for each assignment look to be fairly distinct.,Future Assignments,"[a2, a3, a4, a5, a6]"
5ad7d43d0d63974e20c390be,"When trying to submit, I get the error below, even though I've successfully used pip to install the mentioned packages:

Any clue?
C:\OMS-GTECH\CS6601\6601assignment_1>pip install -r requirements.txtRequirement already satisfied: future==0.16.0 in c:\users\jotigo\pycharmprojects\untitled3\venv\lib\site-packages (from -r requirements.txt (line 1))Requirement already satisfied: nelson==0.4.0 in c:\users\jotigo\pycharmprojects\untitled3\venv\lib\site-packages (from -r requirements.txt (line 2))Requirement already satisfied: requests==2.13.0 in c:\users\jotigo\pycharmprojects\untitled3\venv\lib\site-packages (from -r requirements.txt (line 3))Requirement already satisfied: requests-toolbelt>=0.7.0 in c:\users\jotigo\pycharmprojects\untitled3\venv\lib\site-packages (from nelson==0.4.0->-r requirements.txt (line 2))
C:\OMS-GTECH\CS6601\6601assignment_1>python submit.pyTraceback (most recent call last): File ""submit.py"", line 7, in <module> from nelson.gtomscs import submitImportError: No module named nelson.gtomscs




",jc6w44hrp9v2ki,"[{u'text': u'Thanks Cahill.

The python modules seem to have been imported here:

So how do I tell python to import them from this folder?

Directory of C:\Users\jotigo\PycharmProjects\untitled3\venv\Lib\site-packages\nelson
23-Jan-18 05:02 PM <DIR> .23-Jan-18 05:02 PM <DIR> ..23-Jan-18 05:02 PM 4,601 abstract.py23-Jan-18 05:02 PM 7,000 abstract.pyc23-Jan-18 05:02 PM <DIR> clyde_sample23-Jan-18 05:02 PM 12,148 developer.py23-Jan-18 05:02 PM 22,858 developer.pyc23-Jan-18 05:02 PM 2,744 gtomscs.py23-Jan-18 05:02 PM 3,474 gtomscs.pyc23-Jan-18 05:02 PM 5,391 sessionbuilder.py23-Jan-18 05:02 PM 7,924 sessionbuilder.pyc23-Jan-18 05:02 PM 2,750 udacity.py23-Jan-18 05:02 PM 3,463 udacity.pyc23-Jan-18 05:02 PM 794 uploadcallbacks.py23-Jan-18 05:02 PM 1,506 uploadcallbacks.pyc23-Jan-18 05:02 PM 1 __init__.py23-Jan-18 05:02 PM 164 __init__.pyc 14 File(s) 74,818 bytes 3 Dir(s) 333,334,851,584 bytes free
', u'responses': [u'It looks like you can use the PYTHONPATH environment variable. 

PYTHONPATH
Augments the default search path for module files.  The format is the same as the shell's $PATH: one  or  more  directory pathnames  separated  by colons.  Non-existent directories are silently ignored.  The default search path is installation dependent, but generally begins with ${prefix}/lib/python<version> (see PYTHONHOME above).  The default  search  path  is always  appended  to  $PYTHONPATH.  If a script argument is given, the directory containing the script is inserted in the path in front of $PYTHONPATH.  The search path can be manipulated from within a Python program as the variable  sys.path.

There are probably other ways.', u'Thanks! That worked,
', u'Hi James, I encounter the same issue. Can you explain more how to use $PATH to fix this? Thanks!', u'Hello Mengyun,

For my case, I'm using Windows and Pycharm.

The Nelson package had been installed when I installed Pycharm, in this folder

C:\Users\user1\PycharmProjects\untitled3\venv\Lib\site-packages\nelson
Therefore I just did
SET 
SET PYTHONPATH=
C:\Users\user1\PycharmProjects\untitled3\venv\Lib\site-packages\nelson;%PYTHONPATH%
I guess you are on Linux? Then if you already know directory where nelson packages are:

export PYTHONPATH=<absolute path to the nelson package>:%PYTHONPATH%
', u'Hi James,

I'm using Anaconda on Mac. I've added it under .bash_profile,
export PYTHONPATH=""/Users/mengyunz/anaconda/lib/python3.6/site-packages/nelson:$PYTHONPATH""
then but after source it, when i try to run submit.py, still same error
ImportError: No module named nelson.gtomscs
did i do it wrong?', u'If you:  echo %PYTHONPATH%     do you see it reflected on the path?', u'Yes i can see it, but seems too many print out.

here is my defined parameter:
# Setting PATH for Python 2.7
# The original version is saved in .bash_profile.pysave
PATH=""/Library/Frameworks/Python.framework/Versions/2.7/bin:${PATH}""
export PATH

# added by Anaconda3 4.4.0 installer
export PATH=""/Users/mengyunz/anaconda/bin:$PATH""

# added for launch sublime editor
export PATH=$PATH:/Applications/Sublime\ Text.app/Contents/SharedSupport/bin/

# added by Anaconda2 5.0.1 installer
export PATH=""/Users/mengyunz/anaconda2/bin:$PATH""
export PYTHONPATH=""/Users/mengyunz/anaconda/lib/python3.6/site-packages/nelson:$PYTHONPATH""

here is after my echo:
Mengyuns-MacBook-Pro:~ mengyunz$ echo $PYTHONPATH
/Users/mengyunz/anaconda/lib/python3.6/site-packages/nelson:/Users/mengyunz/anaconda/lib/python3.6/site-packages/nelson:/Users/mengyunz/anaconda/lib/python3.6/site-packages/nelson:/Users/mengyunz/anaconda/lib/python3.6/site-packages/
', u'Note that your PYTHONPATH includes *all* python 3.6 libraries when you're supposed to be using 2.7.x for this project.  That seems problematic to me.', u'Hi Conor, yes when i open anaconda i choose to use python 2.7, but still everything installed under python 3.6.
', u'As Conor says, that sounds as though it's asking for trouble']}]",,0.0,184.0,162,"I believe your pip and your python are in different paths and so when you install the required components they are not available to your python invocation.

I don't know how to fix this on Windows... on a UNIX system, I'd tell you to run which pip and which python to see where you are getting them from and see if there's a python available where your pip is lying about.
",No module named nelson.gtomscs,[a1]
5ad7d43d0d63974e20c390bf,"My CustomerPlayer is winning most of the time when tested locally, but on Bonny it submission gets a score of zero.

The json file doesn't show any timeouts, and no other error/information either:


{
    ""total_points_available"": 35,
    ""tests"": [
        {
            ""output"": {
                ""points_available"": 30,
                ""points_awarded"": null
            },
            ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_qiubofhm/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 102, in test_beats_random\n    self.evaluate_against(RandomPlayer(), 0.9)\n  File \""run.py\"", line 55, in evaluate_against\n    win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n  File \""run.py\"", line 36, in simulate_games\n    winner, move_history, termination = game.play_isolation()\n  File \""/home/vmuser_qiubofhm/workspace/isolation.py\"", line 260, in play_isolation\n    if curr_move_queen1 is None or curr_move_queen2 is None:\nUnboundLocalError: local variable 'curr_move_queen1' referenced before assignment\n"",
            ""description"": ""Definitely better than RandomPlayer""
        },
        {
            ""output"": {
                ""points_available"": 5,
                ""points_awarded"": 5
            },
            ""traceback"": """",
            ""description"": ""Test output of OpenMoveEvalFn""
        }
    ],
    ""total_points_awarded"": 5
}",jc6w44hrp9v2ki,"[{u'text': u'Thanks Mark,

I've actually removed all try -- catch clauses in the test file and it runs fine locally.


When submitted, json seems to give this error: 

line 260, in play_isolation\n    if curr_move_queen1 is None or curr_move_queen2 is None:\nUnboundLocalError: local variable 'curr_move_queen1' referenced before assignment\n"",

The line it's referring to in play_isolation is:

if curr_move_queen1 is None or curr_move_queen2 is None:


', u'responses': [u'Having same issue.', u'If you are using an unmodified isolation.py file, that error is most likely due to an exception that occurred in/under your move function such that your move function did not return a value.  There should be some other error message in your output prior to the ""referenced before assignment"" that will guide you towards the problem.', u'You're probably not testing starting with Player 1 and Player 2. Modify the tests to try both (or a range flipping back and forth to get some stats)']}, {u'text': u'A suggestion as one who got a similar result.
At the end of move I check to see if queen_1 and queen_2 are in local variables. If not I set them to the first legal move so that I never return None for the variable which is I'm guessing your problem. Similar checks can work elsewhere in your code.', u'responses': []}]","As Conor is saying below in the followup, try to see why the ""referenced before assignment"" output may have happened. Looking at isolation.py and the Player's move may help.",0.0,248.0,164,"One useful strategy to try to guarantee that your local testing is letting you see as many of your errors as possible, is to test your AI as player 1 as well as player 2, then remove all the try/catch with indentation in player_submission_tests.py, try/catch that is unnecessary for local testing, it simply serves to give us an indication of how the Bonnie code works",My CustomPlayer wins most of the time but gets 0 score on Bonny,[a1]
5ad7d43d0d63974e20c390c0,"I have to be honest. I have been working on assignment one since it came out and I'm still struggling with my minimax algorithm.

I was able to work through the pseudocode in the textbook and implement it, but obviously that version is no good to me because searching to the end of the game would take too long. I'm in the same boat for my alphabeta function.

I have been trying to revise both with depth limits but haven't figured out how to get them working and passing the tests. I don't want to look at code, etc. since that is not allowed. But I'm also struggling to find good resources beyond the textbook that deal explicitly with setting depth or time limits on the minimax and alphabeta algorithms. Has anyone found anything about that topic that was helpful?

I think another issue I'm having is I don't have much experience debugging recursive algorithms, which has led to a lot of frustrating debugging sessions trying to figure out what is going wrong. Any resources on that topic would be appreciated too.

Thank you.",jc6w44hrp9v2ki,"[{u'text': u'Pycharm is fairly easy to debug.
Look at your depth as you go in minimax to see how deep you are in minimax.
A thing I did to troubleshoot is played a game and analyzed the results.
Find a spot where my AI made an obviously bad move.
Recreate the game board to that exact scenario and then started debug there.
I'd play it until I got to the bad decision and see why it was scoring so high the bad move.
And found a bug with my code :)
', u'responses': []}, {u'text': u'Thanks for the replies. I took the advice here and in some other places and now have a fully functioning minimax and alphabeta functions!! 

Things that helped me:
Simplifying the game board to 3x3 or 4x4, switching depth so that the algorithm only looks ahead one move, and seeing if I could find better moves with my heuristic given the board state after printing the game as text. This helped me find an error in my code in the utility function related to using maximizing player / applying the heuristic score.Using lots of print statements instead of debugging/stepping into code. That was a great suggestion. Really helped with understanding how everything was working.And oddly enough, I thought the pseudocode on Wikipedia of all places was a little more intuitive / easy to understand than the textbook pseudocode, particular for alpha-beta pruning. https://en.wikipedia.org/wiki/Alpha–beta_pruning#Pseudocode. The Wikipedia pseudocode explicitly accounts for depth limits, which gave me some ideas on how to tackle that problem. And the recurrence back to the main function while using an if-statement to control the maximizing_player changes was a lot easier for me to get working than the book version where you have a pairwise recurrence between the max and min functions separately calling each other. Ironically, now that I have a working version, it doesn't seem so hard to do it the book way, but for some reason starting with the single function recurrence call was much easier for me.One remaining challenge with the Wikipedia psuedocode (also true of the textbook pseudocode) was modifying the function to save the best moves in addition to the best values. For that, converting some max() or min() statements to equivalent if functions helped. Also the fact that in python you can do something like:
value = self.minimax(...)[2]The above returns just the value part of the minimax function that normally returns three pieces (queen1_move, queen2_move, value). That turned out to be really useful for me. Basically it let me return the value part of the algorithm only until I found the best value, in which case I would then return the moves as well. Your mileage may vary.


Thanks for the help!', u'responses': [u'Reading this, it describes exactly what I did yesterday to pass section 3 A. I had to re-write my AB logic again but this time following the Wikipedia algorithm instead and the other steps mentioned above, like I followed them exactly :)']}, {u'text': u'This is a great and insightful thread. Thank you, everyone!

Original Poster, why anonymous? Great post/thread, but I don't know who to thank. (:

-Q.', u'responses': []}, {u'text': u'I'll come clean. That was me. I was feeling insecure after working for a week and a half and only getting 5/100 points. 

I will say that sticking with it paid off though. Eventually passed 3a on Friday night and called it quits to enjoy the weekend. Glad you found this helpful.

P.S. I don't know if this will hold for everyone but multiple times I thought my alpha beta was working correctly only to find small bugs. When I finally got it ironed out 100% I was able to pass 1b, 2a and 2b with only needing to search to depth=1 using a plain vanilla alpha-beta and no custom heuristic, reordorering of nodes or anything fancy. I added iterative deepening to pass 3a. It's worth spending time doing a lot of debugging. I found a 3x4 board best for that since it's big enough not to immediately end the game while being small enough to walk through with pen and paper to double check each output of your search is correct.', u'responses': [u'Congrats to you, sir! Admittedly, I'm at 75/100... Part 3 is killer. I don't think I belong in this course; and to think this is only the first assignment!

My algo that passed part 2 is vanilla is well. Though I must brag that it is very clean and timely. Haha.']}]",,0.0,230.0,168,"Say you want a max depth of 3.

When you are in your first run of minimax how many levels deeper do you want to go?  I would say 2.
When you are in your first sub-run of minimax (when your first minimax first called itself) how many levels deeper do you want to go?  I would say 1 (since you are already 2 levels deep). 

So the depth that you want to process at each level in your tree goes down by one.

That should give you an idea of how to do this.

As far as debugging, you may be easier served by adding lots of print statements about what you are doing in each place so that you can see what the inputs are and what the choices are being made.  You can get some of this by using a debugger and stopping and examining the data at the right points, but that's not as simple as looking at the output and seeing what you're doing.",Struggling adding Depth Limit to Minimax,[a1]
5ad7d43d0d63974e20c390c1,"Hey everyone,
I'm having a bit of trouble joining the Office Hours hangout. Trying to fix it now.

--------------------------

EDIT: Please join the call at https://hangouts.google.com/call/ZsZwAK-zYuak--rDamAXAAEE for this OH alone.
We've seen others having issues with the other Hangouts link. We'll try to fix it ASAP.

EDIT 2: I'm done with my OH for today - please stay tuned for updates on how we're trying to fix issues with Hangouts.

",jc6w44hrp9v2ki,"[{u'text': u'Hey Ravi,

As discussed on OH,

I tried again to submit my solution for both submit_a and submit_b but in both the case the 'wheel' keeps on moving and after a point it stops.
I don't see anything on Bonnie as well but my submission counts as one.
Can you please look into it on what is wrong.

If I submit same solution for 1st part of assignment, it passes.
I am not getting any feedback, neither on terminal nor on Bonnie.

Please help me with this issue. I am very much clueless right now. 

', u'responses': [u'I got it working. There was a small bug in where, it was going for infinite recursion.']}]",,0.0,233.0,169,,Ravi OH Delayed (and Hangouts issues),"[announcements, office_hours]"
5ad7d43d0d63974e20c390c2,I would like to use this information in OpenMoveEvalFn while doing the opponent's moves,jc6w44hrp9v2ki,"[{u'text': u'Thanks Conor for the insight.

 It should be set to true when it is your move and false otherwise since you're trying to maximize your score.


That's my dilemma. How do I know it's my move! 

This is the only bit of the assignment I'm struggling with. It seems my CustomPlayer wins almost all the times it makes the second move (player 2) and loses vice versa. 

I know it's related to how I return the values for OpenMoveEvalFn by I'm completely unable to crack this
', u'responses': [u'It's always your move when your move() function is called.  You control all calls to your evaluation function within your call stack and you need to figure out whether you're evaluating your own move or your opponents move and call the evaluation function accordingly.', u'Thanks, so I guess then it's something related to active and inactive player?', u'you can get the active player from the game and compare it to self. if they are equal, then the running instance of CustomPlayer has the next move. I can't highlight specific syntax for you since I'm on my phone but hopefully that's a bit of direction', u'The goal is to know what the score of the board is for you.  So you need to evaluate this from your point of view all the time.   Your point of view will come from the active player when you are the maximizing player and from the inactive player when you are not the maximizing player.  Of course, this depends on you, in your simulations, knowing who's turn it is and passing the right arguments to your evaluation function.']}]",,0.0,216.0,170,"maximizing_player is designed for this.  It does, however, have to be set to the right value when you are processing simulated moves in your minimax or alphabeta functions.   It should be set to true when it is your move and false otherwise since you're trying to maximize your score.",How would I know it&#39;s my CustomPlayers turn to make a move?,[a1]
5ad7d43e0d63974e20c390c3,"Just checking if anyone has tried using the techniques of using board symmetry to reduce the number of tree nodes we need to build? 

As far as I can tell if my player moves first symmetry can be very effective, however if the opponent moves first I don't detect any states during minimax when my player can detect and use symmetry. So one question - do we know in Bonnie if our player always moves first or second or if the order is random?

I'm also finding that increasing the search depth of minimax usually only marginally to moderately improves the win rate of my player and the extra time required to process deeper search depths seems like its just not worth it. So I'm looking for alternatives to increasing search depth to improve the win rate of my player. Symmetry is one and aggressively looking for kill moves without using minimax is another.

There appears to be interesting priority decisions in this project as to what techniques to try first (which gives the biggest bang for the buck etc) but designing and implementing each technique takes quite a bit of time. (e.g. deeper minimax, alpha-beta pruning, kill move detection, symmetry optimizations, partitioning etc)
",jc6w44hrp9v2ki,"[{u'text': u'I tried using symmetry. It’s more rare at later levels but not non existent. If the first player puts their pieces in the top left and right corners, then you put your pieces in the bottom left and right then you have a symmetric board at depth two. I think you could come up with other examples at depth two to show it’s possible. ', u'responses': []}, {u'text': u'To figure out symmetry, I rotated the board 180 degrees, then found where their pieces' mirrored positions are located. Take note that there is no function provided by the Board class that tells you where their pieces are positioned (if someone could tell me I'm wrong, I'll thank you and then go get my eyes checked). Instead, you have to do some expensive operations on the past state and the current state to find their queens.

Knowing these mirrored positions, and borrowing from the strategy presented in the Udacity video, you can move to them if they are a legal move for either of your queens (as player one), or avoid them (as player 2). I'm still unsure if these opening moves either helped or hurt my agent's win rate, but it felt better than doing random moves and it definitely helped cut down on the branching factor for the first few moves of the game.', u'responses': [u'You can use the class attribute __board_state__ which I believe has all past and current moves ', u'I tried accessing private variables (i.e. variables surrounded with ""__"") outside the Board class with no success. Am I doing it wrong?', u'I’m just calling game.__board_state__ from within custom player and that works for me ', u'I have had no problem accessing them.  For example:

game.__last_queen_move__[game.get_queen_name(game.__active_players_queen1__)]
gives you the position of queen1 of the active player (assuming I'm reading the code correctly).', u'I also used game.__board_state__ to do the symmetry rotations. It works fine both locally and in the Bonnie runs as far as I can tell.', u'Well, isn't that interesting. I rely so much on my dev tools, I assumed that since my editor wasn't providing me any intellisense information when I hovered over those variables, it meant they were private and I couldn't access them. I guess I should have remembered there are no real private variables in Python.', u'The whole leading/trailing  underscore, double underscore thing with Python variable names is kind of weird. Certainly kind of weird for a language which is so cool and elegant in so many ways. Some underscore name variations look to be cosmetic and others more meaningful. This article explains all the nuances of using underscores in variable names.', u'You can get the values without using the __ vars.  For example you can get your queens by calling: get_active_players_queens() which will return a tuple of the two queens.  But I do agree there should be more access methods.

And note, since Python is a dynamic language it doesn't really encapsulate as languages of Java does. So really everything is available.']}, {u'text': u'I didn't use symmetry but I used a hashing function to hash the board state so that i could identify boards that i had already calculated static values for. This was mainly to handle cases where the games landed up in the same board state via different move histories ( eg A->B->C and B->A->C both A & B are off-limits and queen is at C). Now that i think  about given the 4 axises of symmetry it would be trivial to write a transform which would rotate the board and then check the hash.', u'responses': []}]",,0.0,220.0,171,"For each test 20 games are played, 10 of them our player goes first, 10 of them our player goes second.",Symmetry,[a1]
5ad7d43e0d63974e20c390c4,"When I go to the course schedule and click on ""Uninformed Search"" to get the slides for this lesson, i'm directed to the slides for ""Informed Search."" Seems like the URL is incorrect for this link.

Thanks!",jc6w44hrp9v2ki,[],The link seems to work fine. Here are the slides in case you're not able to view it:Uninformed Search,0.0,176.0,172,,Missing Slides for Uninformed Search?,"[lesson2, other]"
5ad7d43e0d63974e20c390c5,"I figured some of you may be in the same boat as I was only 12 hours ago.  I couldn't get any more than the initial 5 points for the OpenMoveEvalFn.  My code was running and beating RandomPlayer a decent amount of the time but couldn't beat the Bonnie AI consistently.

A few minor changes to my methodology and I was able to get both parts of 1 and both parts of 1a passed with the same code.  Nothing fancy, just the bare minimum (not even alphabeta yet).  The code uses only MiniMax, search_depth, and a single opening move (when I play as Player 1).  Here's what I did differently:

1. In player_submission_tests.py, on the third test that plays RandomPlayer() vs CustomPlayer(), create loop that runs the game 20 times and have it alternate you as Player1 or Player2.  So, 10 games as player1 and 10 games as player 2.  Then check your win % at the end of the 20 games.  You can use this to test any changes you make over a series of games (which is what I'm assuming Bonnie is doing).  You can also stare at your code for a while your tests run.

2. Try a smaller board (3x3, 4x4, etc.) and see if you can win consistently.  On each board configuration, play around with search_depth to see its effect on win %.  Make sure to document all your attempts so you can compare them later.

3.  If you're going to debug, the time_left check will cause you to timeout while you're inspecting code.  On line 247 of isolation.py you'll find the formula time_left = lambda : time_limit - (curr_time_millis() - move_start) which you can change to ensure that you never time out.  Just make sure to change it back when you resume testing.  Python experts, please chime in on whether you can simply override time_left in __init__ rather than changing isolation.py.

4. Aside from that, the pseudo-code in the book gives you what you need.  There are some small nuances with the 2 queens, just be careful about moving queens to the same spot and timing out in various places in your code.",jc6w44hrp9v2ki,"[{u'text': u'To add to this:

Improving on a correctly functioning MiniMax is much easier than getting it working correctly in the first place. When you've navigated all the pitfalls of interacting with the game and choosing moves properly, you can see your performance rapidly improve with some tweaking. I only passed part one (after my third complete re-write) late last night, but already passed submit_a after some improvements I made tonight.

One tip I can offer which is not mentioned above: Have your AI play on small game boards and force the AI to use moves resulting from your MiniMax algorithm. At first I implemented some logic to randomly pick a legal move when MiniMax was running into problems. This hack will improve your percentage, but masks any underlying bug and makes troubleshooting difficult. It's better to allow your MiniMax algo to fail to reveal where any bug might be hiding.', u'responses': [u'I highly recommend trying the following:

1) Create boards of size 5x5, 6x6, 7x7
2) Play your CustomPlayer against another CustomPlayer, where one custom player uses the OpenEvalFunction and the other uses your CustomEvalFunction
3) Collect the average winrate over ~25 games every time you make changes to your custom evaluation function.  Consider this like a unit test.


Similarly do the above to tweak the depth your agent pursues
']}, {u'text': u'These are great suggestions.  I got nowhere until I switched to a 5x5 board and starting printing the board, along with key decision points, before and after each move. I also suggest using the forecast_move method, once I started using that it was a lot easier to make good decisions. I'm still not passing part 3, but I have parts 1 and 2 passing. ', u'responses': [u'Just curious, what were you using before forecast_move? ', u'Well, I guess my recursive call always used forecast_move.  It was when I started using forecast move in different ways that I could see when it wasn't even worth calling minimax. That helped a lot with erroring out towards the end of the game.']}, {u'text': u'Is it correct to say that the ability to search past depth 1 is more critical for a larger board? In the extreme case, the results of a first ply search for a 3x3 board will be more representative of a ""to the leaf"" search, when compared to a very large board, lets say a 100x100 board, as the first ply may have little information on the final results.

If this is the case, would testing on small boards lead to inaccurate conclusions?', u'responses': [u'I agree with that. Searching deeper means seeing closer to the end game, which definitely helps in larger boards, where end games is ""farther"".

I think testing in 5x5 is great help for debugging, and you can move to larger board afterwards.', u'Tasuku, I used a 5x5 board to get my minimax/alphabeta working. Then I tried to run on the servers and timed out on many games. This showed me that I needed a better strategy before calling minimax, so I moved to a 7x7 board and worked on opening strategies to reduce the number of open moves sent to minimax. So yes, as you say, a solution for a 3x3 or 5x5 board may not translate directly to success on the 7x7. But if your minimax/alphabeta isn't working then definitely don't try to tackle debugging with a larger board, way to complex.']}, {u'text': u'Good comments.

for 1 - I created a test framework where I could run large numbers of tests overnight to evaluate different techniques. For the opponent I used a separate 'scaled down' instance of my CustomPlayer (rather than the RandomPlayer which is not smart enough). The 2nd instance can be configured to reduce its intelligence (e.g. use fewer levels etc) as required for effective testing.

for 2- just an interesting note that if you use symmetry to reduce MM tree size the board has to be 3x3 or 5x5 or 7x7 etc. An even dimension invalidates symmetry transformations', u'responses': []}]",,0.0,304.0,176,,For Anyone Struggling,[a1]
5ad7d43e0d63974e20c390c6,I am new to Georgia and Cannot seem to find the lecture videos/ class lessons to learn from example and be able to do assignment 1? Can someone point me in right direction thank you.,jc6w44hrp9v2ki,"[{u'text': u'Udacity contains all the lectures. You should have a new student intro in there as well. Check your Ga Tech email for details.', u'responses': []}]","Hey Joseph,
Here are a few tips:
Piazza is where we have all our classroom discussions and post many announcements.It has a number of features, such as folders which will help you navigate - look at the folders underneath the Piazza logo on the top left. You can use this to go to the ""Announcements"" folder, and find the weekly announcements (Week 1, Week 2, etc.) which contain links to Udacity videos and lessons.Refer to the weekly announcements to view the class syllabus and schedule.Piazza will also get challenge questions from time to time which help you understand the material better. Also refer to the discussions.Announcements are all posted on T-Square as well, which is where your assignments and grades are released.Assignment information is also provided on Piazza and partially on T-Square. Look at the ""a1"", ""a2"", etc. folders on Piazza. Assignment 1 has a post on @57.

Hope this helps. I'm sure your classmates will be able to help as well!",0.0,207.0,178,thank u,Help,[lesson1]
5ad7d43e0d63974e20c390c7,"Hi guys,I'm having a bit of trouble opening the link so for the time being, please use the below link to join the office hours.https://hangouts.google.com/call/-xV4GyR2gxk2UQwCFgtLAAEE

We will fix the issue soon, sorry about that!

",jc6w44hrp9v2ki,[],,0.0,263.0,179,,Athira OH new link,[office_hours]
5ad7d43e0d63974e20c390c8,"Are we assuming we are moving both pieces at the same time, in other words the two pieces will not block each other when moving?
",jc6w44hrp9v2ki,[],,0.0,196.0,180,"Yes. 

The queens move like in the game Chess where the final spot is reserved, but everything in between is free unlike the game Snake. Therefore, you can't move your queens to the same spot on a given turn.",The order of two queens&#39;s moves,[a1]
5ad7d43f0d63974e20c390c9,"The minimax function takes in a depth, but according to move( ), it looks like the depth argument is used to specify the max depth, not used to keep track of the current depth in the recursion. I assume minimax( ) has to call minimax again to go another level down in the tree, and in my mind it would be wise to do something such as minimax(game, time, depth + 1). But since the depth argument is used to specify the max depth, how do you keep track of your current depth?",jc6w44hrp9v2ki,"[{u'text': u'It took me quite a while to visualize that as you go down the tree, depth decreases. depth of a child tree would be 1 less than its parent tree. thats the reason next call of minimax should have depth-1 as value of depth.', u'responses': []}]",,0.0,204.0,181,"You can try minimax(game, time, depth - 1), which would result in a count down from the specified max depth, and the termination condition will check if the depth equals 0. This should have the same intended effect.",Keeping track of depth in Recursion,[a1]
5ad7d43f0d63974e20c390ca,"Hi,

I modified player_submission_tests.py to see the results of two RandomPlayer()'s playing against one another as suggested in the YouTube live meeting.

But after changing Line 81 ""CustomPlayer"" to ""RandomPlayer"" I got below error:
        print 'OpenMoveEvalFn Test: This board has a score of %s.' % (h.score(sample_board)) ^ SyntaxError: invalid syntax
 
Is any other part you also modified?

Thanks!",jc6w44hrp9v2ki,"[{u'text': u'Fix the indention within the ""try"" block.  It goes out of whack when importing the code into a PyCharm project.', u'responses': []}, {u'text': u'turns out it is not only the indention issue. once install pycharm, the default python is 3.6, have to install again 2.7. ', u'responses': []}]",,0.0,192.0,182,It's likely you have a syntax error from a line or two above that (most likely with the line that you changed).  I don't see a syntax error in the line you are showing -- though I don't claim to be a human python compiler.,First try player_submission_tests.py as youtube stream,[a1]
5ad7d43f0d63974e20c390cb,"I'm just curious about this. After reading some notes, I think I might not be the only person who assumed, based on the grading structure, that a Minimax player w/ search depth 2 and OpenMoveEval (with some simple openers) would be expected to pass the `submit.py`. However, mine seems stuck around an 80% win rate. Curious what other people's experiences have been. (And gosh is it frustrating to spend hours on an AI and have it lose to something making random moves ;) )
 [o] Minimax D=2 w/ OpenMoveEval Passes submit.py
[o] Minimax D=2 w/ OpenMoveEval Fails submit.py",jc6w44hrp9v2ki,[],,0.0,221.0,183,,Poll: Does your Minimax Depth 2 With OpenMoveEval Win Against Random?,"[a1, polls]"
5ad7d43f0d63974e20c390cc,"In my minimax logic I am hitting situation when legal_moves_q1:  []
While I can check it like if((legal_moves_q1 is None) or len(legal_moves_q1) ==0 ):, how to handle this in minimax logic? What should I return from minimax when I am hitting it.
(as I understand, Logically it means, for this active player, no moves are left for queen1. which means he has lost the game.)
pl advice

I also want to understand if ""illegal move queen1"" kind of error message is a valid message. or I must get rid of them.",jc6w44hrp9v2ki,"[{u'text': u'The 'illegal move queen1' message can mean that you have simply run out of moves and lost, or it can mean that you tried to place your queen in an invalid space. I don't know a way to differentiate other than printing the board to see its state, or you could print your returned moves along with your current legal moves. If you have run out of moves then you need to improve your strategy, if you are returning invalid moves then you have a bug somewhere or incorrect logic when setting the next move.', u'responses': []}]",,0.0,189.0,184,"I think you can handle that in your utility and/or eval function. You can either give a loss a very negative score or, in Python, simple `-float('inf')` which is negative infinity. (or use positive infinity if you are player2). ",minimax how to handle situation when legal_moves_q1:  [],[a1]
5ad7d43f0d63974e20c390cd,Someone came across this problems? ,jc6w44hrp9v2ki,"[{u'text': u'I'm seeing this as my error output from Bonnie. Any insights to offer?

Thank you,
Q.', u'responses': [u'Typically it means you have an exception at some point above this in your code.  This is just a side effect.  Look at the other output above this and fix the problem that is reported.', u'Thank you! Yeah, I'm an idiot. Haha. Need to test code more locally.']}]",,0.0,176.0,185,"That happens when you try to read the data in a variable it doesn’t think is yet defined. Likely you have it defined in an if nest which doesn’t get called because the condition is false. 


You might also look at @190; it could be the same thing. ",local variable &#39;best_move_queen1&#39; referenced before assignment,[a1]
5ad7d43f0d63974e20c390ce,"Running player_submission_tests.py results in this error. From what I gathered, it appears to only be an issue in Windows environment according to this https://stackoverflow.com/questions/37710848/importerror-no-module-named-resource. Did anyone find a workaround for this?",jc6w44hrp9v2ki,[],,0.0,2.0,186,,ImportError: No module named resource,"[a1, other, python]"
5ad7d43f0d63974e20c390cf,"Here is another Challenge Question on Game Playing. We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.
For more on Challenge Questions see @283.

A) 1. Solve this game tree from left to right using MiniMax with alpha-beta pruning (use inequality signs wherever appropriate).
     2. Can the nodes be ordered in such a way that alpha-beta pruning can prune maximum nodes? Describe your strategy and solve the tree with the new order.


B) Solve this three-player game tree from left to right using alpha-beta pruning (use inequality signs if appropriate). The 1, 2 at the front are the player numbers, indicating which player should be maximized. The maximum combined score is 10, which means the sum of all three scores is less than or equal to 10. All values are non-negative.


--------------------------------------------------

Solution: Correct answer given by Junwei Huang in the comments below.
",jc6w44hrp9v2ki,"[{u'text': u'the reordering in green along the top tries to retain original ordering at a particular level when reordering would have no effect; p for pruned


I should possibly just add that I think we're assuming ties could be broken arbitrarily, else say for instance ties were broken in left-to-right order, all else being entirely equal from the perspective of the maximizing player, then the last $$\le 3$$ would be $$\le 2$$', u'responses': []}, {u'text': u'My solution with pruning for re-ordered tree. Interestingly, I order all max nodes in descending and all min nodes in ascending. This systematic ordering is unnecessary as my pruning is identical to the solution above. Wonder if there is algorithm to do the minimal ordering and achieve the same pruning effect. 

', u'responses': [u'In principle the leaf values are unknown until you reach them, so an algorithm to reorder minimally would be an algorithm that already knew the leaf values. As a practical matter, whenever we reorder, we reorder based on the backed-up values from the level above, in Iterative Deepening for instance', u'This is correct! Well done.']}, {u'text': u'Part A. 1.


', u'responses': [u'when the value is known for sure, out down the value.  when the value is not known for sure, i.e. when branches are pruned, then the inequality signs show that the actual values could be different', u'Thanks.']}, {u'text': u'', u'responses': [u'Is it correct ? ', u'Hey Badal, almost! Check Junwei's answer two posts above. Remember the inequality signs.']}]",,0.0,339.0,188,,Challenge Question 2 - Game Playing,"[lesson1, challengeqtns]"
5ad7d43f0d63974e20c390d0,"I've been stuck trying to code my minimax algorithm for over 10 hours. The part I'm most confused about is what value to assign a terminal node? In the lectures it seemed simple, a win was +1, a loss was -1, but if I'm using the open evaluation function, then there could be non-terminal values less than -1 which makes a terminal loss node of -1 seem like a better choice which will end the game immediately. Any hints on how to code for a terminal node? So far I have the logic inside my minimax function:

if not len(q1_moves) or not len(q2_moves):  return None, None, SOME TERMINAL VALUE
",jc6w44hrp9v2ki,"[{u'text': u'This post really helped me.  It was buried down in the thread about assignment 1 section 1 @40


Conor Cahill 5 days ago
I believe that it has to do with if you are using OpenMoveEvalFn to evaluate the movement score for the next level and you are using game.forcast_move() to generate the board for that analysis, the current player and the opponent will change after the move (e.g. if you move your queens, then the current player will be your opponent).  You have to keep this in mind when you evaluate the score (you typically want *your* score, not your opponents score).

', u'responses': []}]",,0.0,201.0,189,A terminal node equates to a win or a loss. If a win then it is good in your case so you want that route and a loss is the opposite. So any number super large returning in eval will identify that like inf or -inf.  Correctly implemented minimax is going to return the inf if it is a guaranteed win route.  Alpha beta would stop here automatically but minimax will also return this node.,What would a terminal value be?,[a1]
5ad7d4400d63974e20c390d1,"When I attempt to play a CustomPlayer(2) against a CustomPlayer(2), I consisently receive the following error from isolation.py

Traceback (most recent call last):
  File ""player_submission_tests.py"", line 60, in main
    winner, move_history,  termination = b.play_isolation()
  File ""./assignment_1/isolation.py"", line 247, in play_isolation
    if curr_move_queen1 is None or curr_move_queen2 is None:
UnboundLocalError: local variable 'curr_move_queen1' referenced before assignment
How come curr_move_queen1 not being assigned correctly in the code that was provided to us? This is on line 247 of isolation.py. It's not code that I wrote.

Has anyone else seen this error?",jc6w44hrp9v2ki,"[{u'text': u'marking as unresolved since Brett marked it resolved.', u'responses': [u'Here are some thoughts, but not a solution.

I found this error before I had attempted to implement minimax. It would only appear when I swapped randomplayer with custom or player if I recall correctly, just like you're seeing. I'm not sure of a solution since I attributed the error to my lack of a customplayer move() function. I'm running a conda interpreter with Pycharm on Windows for the sake of comparison. I did have to refactor my code with spacing issues which may have changed the indentation somewhere.', u'Comment out the 

except Exception as e: print e passin isolation.py to find out what the real error is. Most likely you'll find the problem is in your code.', u'Chad, that is what I was doing! I swapped player 1 and player 2 with custom player and random player respectively. I wonder why isolation can't handle having custom player as player 1?', u'Philip,

I just swapped Custom and Random for both the template 5x5 and 7x7 boards in player_submission_tests.py. My implementation worked with both where I move first. 

I think Andrew's advice about removing the exception will help you find the error.

Also, make sure your move function completely covers all possibilities from being the very first move to endgame where you have no moves.', u'Very sorry about that.', u'That's okay. I just couldn't figure out how to mark it back unresolved. I figured out the issue by the way!']}, {u'text': u'I'm having the same issue but only on bonnie.
I can run it fine on my computer and tried swapping players.

It runs for ~6 seconds and fails:
""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_cvanhotl/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 115, in test_beats_alphabeta\n    self.evaluate_against(TestAI(method='alphabeta'), 0.65)\n  File \""run.py\"", line 55, in evaluate_against\n    win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n  File \""run.py\"", line 36, in simulate_games\n    winner, move_history, termination = game.play_isolation()\n  File \""/home/vmuser_cvanhotl/workspace/isolation.py\"", line 260, in play_isolation\n    if curr_move_queen1 is None or curr_move_queen2 is None:\nUnboundLocalError: local variable 'curr_move_queen1' referenced before assignment\n"",
      

It's really hard to figure out what's wrong when you need to wait 2 hours to try again...', u'responses': [u'The answer is, that you are either returning simply None rather than None, None or an actual pair of moves, sometimes; or your function is not returning a value at all', u'I get that if my player_submission breaks, or doesn't return a tuple then this error can occur because the isolation class won't set these variables. I can run the player_submission_test fine on my machine, with my CustomPlayer as either player 1 or player 2 and it works fine.

I only receive this issue on bonnie, what would be different that causes this issue?

I thought maybe it was a formatting issue? i changed all tabs to 4 spaces, all line endings are unix. What am i missing? why would this break on bonnie and work fine on my local?
', u'So i compared my player_submission file from section1 to the file i was trying to submit to section_1a and 1b, I reverted back some line changes and some spaces that were added to method signatures
I was able to submit this file and it didn't fail immediately like the other submissions, still waiting on the results

I'm assuming bonnie is running under Linux? maybe i need to use a linux vm instead of windows 
']}]",,0.0,224.0,190,"Ooops read your question wrong. Deleting my answer.

Is there a second stack trace before the one you included in the question?   The only time I saw this, there was a 'leading' stack trace that actually indicated the real problem.  Looking at isolation.py, the call to move() is done in a try/except block and if an exception occurs that isn't an attribue error, it will generate a stack trace for that error and then continue.  If this is the first time through, the queen vars will be unset and cause the error you've pasted above.    

I do wonder if the isolation code should have a continue or return/raise rather than a pass when they print the stack trace; it seems that if the underlying code tosses an exception it's probably not in a state that will work if invoked again, so an abort/return seems logical.


Bottom line, every time I saw this it was something in my code that needed to be adjusted/fixed. ",Bug in isolation.py,[a1]
5ad7d4400d63974e20c390d2,"In my minimax function, when I attempt to call the open eval function, it doesn't work and I'm not sure what's happening to the context of my python program. When I run the following from minimax, nothing gets displayed in my console.

if depth == 0:
    print(""returning score: "" + str(self.eval_fn.score(game)))
    return None, None, self.eval_fn.score(game)
When I remove str(self.eval_fn.score(game))) from my print statement, it prints 'returning score' correctly. How come I can't call the eval_fn from minimax?",jc6w44hrp9v2ki,"[{u'text': u'Did you implement the OpenMoveEvalFn? Is your indentation correct so that minimax function is a method within the player class?', u'responses': [u'Yes and Yes']}, {u'text': u'If you're using PyCharm, it really helps to step through your code. Try stepping into the eval function and make sure you're returning the right value. I'd guess that as long you aren't getting any Python errors, you are entering the eval function, but maybe you're returning null.', u'responses': []}, {u'text': u'Do you mean to use OpenMoveEvalFn()? Like...

 OpenMoveEvalFn().score(game)
What are you trying to do? Just return the score after the game is over?', u'responses': [u'You can do it referencing the eval function associated with the player (e.g. using self.eval_fn)', u'Oh, I see. He just wants the ""Returning score"" to pop up and NOT just the answer.']}, {u'text': u'I am having the same problem. It submits to bonnie fine, but when I run it locally it doesn't work. I think one of the packages that we are supposed to install with this did not install properly on my local machine even though it says all the packages are fully installed. Not sure what the problem is. Did you figure it out?', u'responses': [u'Nevermind, I found it. I was calling it with the following :
CustomPlayer(2, OpenMoveEvalFn)
When it should be:
CustomPlayer(2, OpenMoveEvalFn())
']}]",,0.0,189.0,192,"You can call sef.eval_fn.score(game) in your mimax function.    I just added:

 print str(self.eval_fn.score(game))

to mine and it worked fine.  so something else is going on in your code.   Note that the way you have it written you will be calling the evaluation twice.   You might want to call it once and save the score that you then print out and later return.",Cannot call eval function from minimax,[a1]
5ad7d4400d63974e20c390d3,I am confused on how alpha beta can work if we stop at layer 3. Isn't it necessary to have the terminal nodes value in order to propagate it up the tree to conduct alpha beta pruning? Are we just using the OpenMoveEvalFn for an artificial terminal node value?,jc6w44hrp9v2ki,[],,0.0,217.0,194,"Yes, you use the heuristic evaluation function (OpenMoveEvalFn or a custom one) whenever you hit the depth limit and the node is not a terminal node. That is necessary because it's not always possible to search all the way to the end game because of the high branching factor. The heuristic evaluation function serves as a fill in for what ideally would be the end-game result. You can think of it as giving you a score related to the state of the board game at the depth-limit level. If the heuristic evaluation function thinks that the board state is a good one, then it will return an appropriate score up the alpha-beta/minimax chain.",Alpha beta depth limit of 3?,[a1]
5ad7d4400d63974e20c390d4,"In the CustomerPlayer class, the function move has a game object type as one of the arguments passed to it

How can I capture/print the value of the variable active_player that's contained in this passed object instance when the move function is called?

All my attempts are returning an instance:  <player_submission.CustomPlayer instance at 0x000000000287DB08>

",jc6w44hrp9v2ki,"[{u'text': u'You need to implement the `__repr__` method of `CustomerPlayer` class, in order to override the default behavior (which is basically the class name and instance id). See python doc and stackoverflow question .

But be careful, you may want to pay attention to how the winner is checked (in local file and probably in Bonnie grader).

# main() @ player_submission_tests.py
       winner, move_history, termination = game.play_isolation()
        if 'CustomPlayer' in str(winner):
            print 'CustomPlayer Test: CustomPlayer Won'
        else:
            print 'CustomPlayer Test: CustomPlayer Lost'
', u'responses': [u'Thanks Andrew. The clue worked', u'Thanks Andrew. The clue worked']}, {u'text': u'You can add a __repr__ method to a python calss.

    def __repr__(self):        return '<CustomPlayer: depth=%s, eval=%s, move=|%s|>' % (            self.search_depth, self.eval_fn, self._move.__name__        )
', u'responses': []}]",,0.0,191.0,195,"Could you clarify what information you're trying to retrieve? If you're looking to see if it's player 1 or player 2 and you haven't sorted out the that in earlier logic - look into 

get_active_players_queen() method in the game class and think about what the return values would be if it's player 1's queens or player 2's queens.

Another thing to consider is that the move function will always be called by your AI so if active_player is self, then you know you're looking at things from your own perspective. 

",How can Print the value string of active_player from the board,[a1]
5ad7d4400d63974e20c390d5,"
",jc6w44hrp9v2ki,"[{u'text': u'i think if player 1 moves his queen 12 to the right at that point the game is sealed since queen22 is partitioned off. it is just a matter of time before the game ends. Is you minimax returning moves for cases when all options point to a loss?', u'responses': []}, {u'text': u'I had an awful bug in my implementation that in certain cases would return a move of None instead of a valid move.  I think I resolved this by setting any variables to some sort of default move before further processing.', u'responses': []}]",,0.0,200.0,196,It seems the logic inside the move method is returning None,Why is the move of this player none?,[a1]
5ad7d4410d63974e20c390d6,"What have you completed so far?


 [o] Section 1 A: create OpenMoveEval
 [o] Section 1 B: defeat Random
 [o] Section 2 A: defeat minimax
 [o] Section 2 B: defeat alphabeta
 [o] Section 3 A: defeat alpha-beta with iterative deepining
 [o] Section 3 B: defeat Kshitish's AI",jc6w44hrp9v2ki,"[{u'text': u'Getting there....', u'responses': [u'I can't beat Kshitish's AI 85% percent of the time, but he also can't beat mine 85% of the time

I WANT MY FIVE POINTS (╯°□°）╯︵ ┻━┻', u'
Didn't think about it that way!   I pull 70% against K's AI and left it at that -- I don't have enough hair to pull out more over 5% of total grade :)
']}, {u'text': u'I need another option:

super behind because you left for a business trip the day the project was released and just got home last night! :'(', u'responses': [u'I've been in your position before, and I sympathize.  One thing I will suggest for this assignment is to just work the basic concepts that were covered in this section of the course (minimax and alpha-beta pruning with iterative deepening).  That should help you make quite a bit of progress on the assignment, even if you aren't able to knock everything out.  Remember to try and submit something before the deadline, and they grade the best N-1 out of N assignments for the course.  Good luck and stay positive!']}, {u'text': u'Im super behind as I have an interview at jp morgan next week for a potential quant job in London.  So i have been very busy preparing for that and dealing with my current work as well.  ', u'responses': [u'
Best wishes for the interview with JPM.  
', u'thank you', u'that is awesome, congrats!', u'Thanks.  I haven’t gotten it yet :).  Still need to ace the interview.  Fingers crossed']}]",,0.0,288.0,198,,Assignment 1 Poll,[a1]
5ad7d4410d63974e20c390d7,Is there any confirmation of the score in addition to the json files received?,jc6w44hrp9v2ki,[],,0.0,207.0,199,You can go to https://bonnie.udacity.com/login and browse to find your submission results there as well.,submission conformation,[a1]
5ad7d4410d63974e20c390d8,"I am confused as to why there is an argument that specifies which players turn it is. As far as I am aware, the minimax algorithm attempts to Maximize YOUR score or Minimize YOUR score. It shouldn't care what the score is of the other player. Did everyone use this flag? Is it necessary to get minimax working?",jc6w44hrp9v2ki,"[{u'text': u'I had the same question. The OH, @68, explains how the functions in Isolation.py work. Specifically, __apply_move__ on line 75 shows how the active and inactive player are swapped after a move. Some people may use this function to simulate game boards and ultimately swap active and inactive in your logic so the maximizing_player is used to indicate this to different functions.

I don't believe you have to use this flag to be successful.

Hope this helps.', u'responses': [u'Chad is correct.']}]",,0.0,235.0,200,see follow up,Why is there a maximizing_player boolean in OpenMoveEvalFn?,[a1]
5ad7d4410d63974e20c390d9,"Hi all,

I can't have OH today so I move it to Saturday 6:30 pm - 8 pm. It's a one-time change.

Sorry about the inconvenience.

Xuewen

",jc6w44hrp9v2ki,"[{u'text': u'Hi Xuewen,

I joined the OH but seems I'm the only one.
I joined the link provided below, is this one the correct one?

Link:https://hangouts.google.com/call/9gyYYBoMAdlaOaUy7cp5AAEE
', u'responses': [u'Yes

I am on OH now']}]",,0.0,294.0,202,,Xuewen OH moves to Saturday (one time),[office_hours]
5ad7d4410d63974e20c390da,"Hello there, I keep getting this error:
 {   ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_eaprknlz bash -c \\\""cd /home/vmuser_eaprknlz; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_1b 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""\"", \""stderr\"": \""bash: line 1:    27 Killed                  python run.py assignment_1b > run_stdout.txt 2> run_stderr.txt\\n\""}""}

I have tried it on two different computers (one windows, one mac) and with and without the --enable-face-off flag and it keeps happening.  I am going to try uploading at home in case it is a network issue on my end.  I just hate to wait that long to test out my new code.

Any ideas, solutions, workarounds? 

Thanks,
Jim",jc6w44hrp9v2ki,"[{u'text': u'Thank you!  Yes I was using quite a bit of memory in an effort to not call get_legal_moves so much guess it's back to the drawing board. ', u'responses': []}]",,0.0,184.0,205,"I've the same issue before, search for ""stdout"" in the below threads:
https://piazza.com/class/jc6w44hrp9v2ki?cid=59
https://piazza.com/class/jc6w44hrp9v2ki?cid=58

My problem was that I had an unreasonably large object due to some bug. Instructor also suggested that too much print to the console / extreme use of memory may result in the error you see as well.

Hope that helps",Weird Bonnie Error,[a1]
5ad7d4410d63974e20c390db,"Hi,I have been following post by post to figure out a solution to combat the time_out issue in section one which has the error saying ""exceeded the timeout of 1800 seconds"" in the error report of Bonnie. So far, I have spent 9 hrs+ ever since I tested my codes by the 5*5 test case many times provided in class. The only error I got is: Queen 1 can't move the same as Queen 2 --where I believe is not an error because that also signals an end game in all cases.

So please give any advice,I appreciate them.

Thanks ",jc6w44hrp9v2ki,"[{u'text': u'Are you timing out locally?
Are you checking the time_left() function?', u'responses': [u'Yes,I missed that () in ""time_left()"",so that was the bug.Thank you for pointing it out.']}, {u'text': u'Following @Tasuku's suggestion.

You may want to look into the `isolation.py` file.

By using this method (and the depth parameter in player searching methods), the time limits for each move and total playing can be controlled.

Here are the related codes.

# definition of a timer for each move
# at about line 247
time_left = lambda : time_limit - (curr_time_millis() - move_start) 

# the timer is passed to the player for every move
# at about line 252
curr_move_queen1, curr_move_queen2 = self.__active_player__.move(game_copy,legal_player_moves , time_left)
', u'responses': []}, {u'text': u'You can do ""print 'position X', time_left()"" in different positions in your code and run it. You should see a lot of logs like ""position X, 1234"" on your console. You can see which part took most time in your script and try to address that', u'responses': []}]",Some suggestions below. Apart from that- check your code again. ,0.0,249.0,206,,Seriously need help to account for time_left to combat the timeout issue.,[a1]
5ad7d4420d63974e20c390dc,"I ran into the following error when running submit_a.py

It submitted fine, and happened after waiting for the results for about 10 minutes.

Waiting for results... \Traceback (most recent call last):
  File ""submit_a.py"", line 92, in 
    main()
  File ""submit_a.py"", line 89, in main
    submit('cs6601', 'assignment_1a', filenames)
  File ""/Library/Python/2.7/site-packages/nelson/gtomscs.py"", line 46, in submit
    return abstractsubmit(submission, refresh_time = refresh_time)
  File ""/Library/Python/2.7/site-packages/nelson/abstract.py"", line 37, in submit
    while not submission.poll():
  File ""/Library/Python/2.7/site-packages/nelson/abstract.py"", line 124, in poll
    r.raise_for_status()
  File ""/usr/local/lib/python2.7/site-packages/requests/models.py"", line 844, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: https://bonnie.udacity.com/student/course/cs6601/quiz/assignment_1a/submission/482838


UPDATE: I logged onto the Bonnie website, and saw that my tests completed successfully. Not sure what caused the issue, but I am able to submit and see results.",jc6w44hrp9v2ki,[],"Thank you for reporting it, we will keep an eye on it.",0.0,168.0,207,,500 Server Error,[a1]
5ad7d4420d63974e20c390dd,"Hi everyone,

My submission fails with a win ratio of 0.85. Looks to me I'm almost there.

A few invalid moves are also mentioned.

Any clue where to look for / debug these invalid moves and improve the score to 0.90?


{    ""total_points_available"": 35,    ""tests"": [        {            ""output"": {                ""points_available"": 30,                ""win_ratio"": 0.85,                ""points_awarded"": null,                ""num_invalid_moves"": 3,                ""num_timeouts"": 0            },            ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_yvmnozls/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 102, in test_beats_random\n    self.evaluate_against(RandomPlayer(), 0.9)\n  File \""run.py\"", line 63, in evaluate_against\n    \""Your player didn't win more than a %f fraction of the games.\"" % win_thresh)\nAssertionError: Your player didn't win more than a 0.900000 fraction of the games.\n"",            ""description"": ""Definitely better than RandomPlayer""        },        {            ""output"": {                ""points_available"": 5,                ""points_awarded"": 5            },            ""traceback"": """",            ""description"": ""Test output of OpenMoveEvalFn""        }



",jc6w44hrp9v2ki,"[{u'text': u'An invalid move also results in the case where your player has no valid moves left. It seems you need to improve your algorithm. DId you try playing against Random Player locally? DId it have a win ratio of over 0.9? If you haven't create a loop and play locally. If the win ratio is too low, try to optimize the algorithm.', u'responses': [u'""An invalid move also results in the case where your player has no valid moves left."" +1!']}, {u'text': u'I solve this problem by setting a smaller search depth like 3 or 4. You can try it to see if it works.', u'responses': [u'Hi Changrui,

Thanks. I solved it using similar method. Playing around with depth and move_count for randomizing initial moves.']}]",Check below. ,0.0,200.0,209,,Number of Invalid Moves,[a1]
5ad7d4420d63974e20c390de,"Finally, I have built a bot that can beat my own CustomEvalFn 80% of the time! Still waiting for the results from Bonnie, but feeling very excited!

Following are the most important learnings of mine over the process, may the instructors correct me if any of my statements were wrong.

1. Don't go too deep, because that may slow things down and, based on the utility function, would subject the queens to some more extreme MIN/MAX cases that your utility function is not able to cover. The default search_depth=3 is indeed the best choice based on my experiments.2. Evaluation function is the key! Results are vastly different with different utility functions. So instead of trying to improve your loops, maybe think more about the utility function! The final version I had, takes into the fact that if one of the queens has few moves, you are likely to lose, too. So you need to find a way to guarantee that both your queens have a good number of legal moves.3. If we know the opponent's strategy, we can simply apply their algorithm in the MIN round, while in the MAX round, use a better utility function. The reason being this way we are more likely to pick a branch that our opponent may actually choose.

HTH and good luck!",jc6w44hrp9v2ki,"[{u'text': u'And a side note about using `time_left()` to get results faster. What I did is to add a `breath_time` argument for the CustomPlayer.__init__.

class CustomPlayer:	def __init__(self, search_depth=3, eval_fn=CustomEvalFn(),
                 	breath_time=BREATH_TIME):		...		self.breath_time = breath_time
Then use that argument to exit minimax earlier when testing

for m1, m2 in self.iter_moves(game):	...	if time_left() < self.breath_time:
		break

And in player_submission_test.py..

p = CustomPlayer(search_depth=3, breath_time=9000)', u'responses': []}, {u'text': u'Agreed. A good evaluation function really improves the performance a lot.', u'responses': []}, {u'text': u'I also think the starting position has a large affect. I don't have an opening book but I do have a starting position that is somewhat optimal. This tweak alone got me from 55% to 75% against the first part of section 3.', u'responses': []}, {u'text': u'----------- never mind ----------', u'responses': []}]",,0.0,241.0,210,,Some of my learnings from Assignment 1,[a1]
5ad7d4420d63974e20c390df,"Any idea what this is about?

Uploading submission...[=========================== 100% ===========================] 10884/10884
Traceback (most recent call last):  File ""submit_b.py"", line 92, in <module>    main()  File ""submit_b.py"", line 89, in main    submit('cs6601', 'assignment_1b', filenames)  File ""C:\Users\nsusa\Anaconda2\envs\omscs\lib\site-packages\nelson\gtomscs.py"", line 46, in submit    return abstractsubmit(submission, refresh_time = refresh_time)  File ""C:\Users\nsusa\Anaconda2\envs\omscs\lib\site-packages\nelson\abstract.py"", line 39, in submit    sys.stdout.write(""\rWaiting for results... {}"".format(next(wheel)))IOError: [Errno 0] Error",jc6w44hrp9v2ki,[],,0.0,171.0,212,"Following up. I checked Bonnie and the submission went through. I just didn't get the read out. I can download it from the website though. Not sure what the error is, but didn't have a negative impact anyway.",Bonnie error,[a1]
5ad7d4420d63974e20c390e0,"Not so much a question as a random thought. If you know you have a fixed move time, wouldn't tuning your depth limit to the number of moves made in the game potentially be a better option than iterative deepening? You would have to have a good idea of how deep you can search without timing out for each stage of the game, but I found that I could get quite a bit of improved performance by increasing the depth limit as I go in this sort of naïve way. (I just ran my player against random and scaled back the depth when I started timing out at various stages).

I was thinking for narrow applications (such as this game scenario, potentially), that might be better than iterative deepening because you would avoid having to re-search the top levels of the game tree and just go right to the max depth you can get away with. Theoretically, you could make this more sophisticated by having some function that evaluates the board state (number of possible moves, expected branching factor, etc.) and then makes a prediction on the depth you could search to given the time limit.

Do these ideas have merit? Is there an official search approach that does what I'm describing?",jc6w44hrp9v2ki,"[{u'text': u'Interesting discussion..

I'm not sure what you mean by '..avoid having to re-search the top levels of the game tree and just go right to the max depth ..'. For each new move it seems to me you have to start the minimax at the top again since the board state has changed due to the opponents last move. However for later moves in the game the number of possible moves to evaluate reduces and so the number of nodes in the MM tree for any given level will become much smaller.

Or maybe you are saying that you keep the MM tree from the last time it was evaluated and first navigate down the levels to find the state that matches the current game state. Then start a new MiniMax at that node and have it run deeper than it did in the previous MM tree build.

I'm playing with a way to project the number of future game states I can analyze for each new move and then figure out how many levels of the MM tree I can build without timing out. I've also played with symmetry as a good way to reduce the MM tree size. Symmetry seemed like it was one of the most effective techniques presented in the lecture.

The challenge is that all these technique ideas take a while to implement and you have to do quite a bit of testing to verify the technique is implemented correctly. And then some of them just don't pan out. e.g. I tried writing an algorithm to aggressively search directly or the 'killer move' rather than just evaluating every move possibility. But in practice for a 7x7 grid I was not able to find these cases very often. But it was often instant opponent death on smaller game boards which was fun to watch.

', u'responses': [u'I meant that with iterative deepening you start at say depth=1 and perform a depth-first alpha-beta search and then if there is time left you call alpha-beta at depth=2 and start from the top again in a depth-first search. 

I was thinking that by knowing ahead of time how deep you can search within the time limit you can cut out the iterative part and just go for it.

That said, all of these replies made good points, such as you are unlikely to save enough time to search an entirely new depth level and there are benefits to ID beyond just going deeper (move reordering, transposition tables, etc.).

Anecdotally, I was able to get to 55% win percentage on 3a with the approach described above, but when I bit the bullet and re-did my approach to do real iterative deepening I jumped to 70% win percentage and passed 3a. So after all of that, it worked better just doing vanilla ID.

One helpful hint for ID for anyone still working: time_left() is a function and you can just check to see how much is left at any point with a simple if statement. I stupidly glossed over that and thought time_left was a value and implementing the time_left function was left to students. That makes implementing ID much easier than I anticipated.']}]","The general idea behind iterative deepening is that searching from depth 1 through depth n (and all depths in between) still takes significantly less time than searching to depth n+1. So, yes, technically you would save SOME time, but the chance of that time actually allowing you to search even one layer further is incredibly low. And it doesn't outweigh the risk of the chance that you don't finish the depth that you guessed at and have to make a random, uninformed move.",0.0,215.0,213,I'd be interested to see if you used move reordering with ID if you'd still see a benefit to fixed depth. That's at least one benefit i can think of that you lose. I also tried your approach but then switched over to ID because it was too much work to tune the appropriate depth on part 3.,Alternative to Iterative Deepening?,[a1]
5ad7d4420d63974e20c390e1,"Does the file submitted for each section need to be the same? For example, if I submitted and passed section one a few days ago but since then have changed the code to pass section two and three do I need to resubmit section one?",jc6w44hrp9v2ki,[],"No, you don’t need to.",0.0,192.0,214,,submission question,[a1]
5ad7d4420d63974e20c390e2,"Anyone else getting this error submitting to Bonnie, ""
raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', error(""(54, 'ECONNRESET')"",))""? Tried 3 times today and get the same error. Each time, I have to wait the required 2 hours to try again.",jc6w44hrp9v2ki,"[{u'text': u'Udacity in general seems mostly down for me. (No videos etc)  Perhaps bonnie is not available as well?', u'responses': []}, {u'text': u'I tried 20 minutes ago and just now got a similar 'Connection aborted' error. 

raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', error(""(50, 'ENETDOWN')"",))
Maybe Bonnie is down? The submission does not show up on bonnie.udacity.com but I still cannot try again for another 2 hours..

Edit: The submission eventually went through. It seems like the connection issue was just for local feedback, but the tests continued on bonnie's servers without any problems. 
', u'responses': []}, {u'text': u'Hopefully, an instructor will look into this issue soon. I've tried all day to submit part 3 of the assignment and keep getting these errors. The last attempt threw an ENETDOWN exception and blew away my old scores (now scoring 0 on both parts!!!).', u'responses': []}]",Making it resolved,0.0,173.0,215,,Bonnie ECONNRESET error?,[a1]
5ad7d4420d63974e20c390e3,"Here is a 3rd and final Challenge Question on Game Playing.

We want students to first solve these on their own before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.

For more on Challenge Questions see @283.

> Solve the game tree below using ExpectiMax with alpha-beta pruning. The evaluation function is bounded by [-10,10]. Evaluate from left to right. Check the box over branches that should be pruned, then fill in the numerical values for remaining branches. Make sure to use inequality signs wherever appropriate!


--------------------------------------------------
 
Solution: Correct answer given by Jakob Green in the comments below.",jc6w44hrp9v2ki,"[{u'text': u'', u'responses': []}, {u'text': u'', u'responses': [u'Can you briefly explain your calculations, thank you.', u'This looks correct to me.', u'I agree
', u'Why is it 4.5 and not -0.5 for the second node? I'm also not understanding why the third node isn't 0.1 * -8 + 0.8 * -9 = -0.8 + -7.2 = -8?', u'In both cases you have to include the best possible result for the maximizer when finding the upper bound on the branch.

In the first case, the best possible score coming from the other two nodes would be 0.1*10 + 0.4*10 = 5. Since the minimizer can at least get -0.5 from the first node, the best the maximizer can do is 5-0.5 = 4.5. Since the best possible is less than what the maximizer is already guaranteed (4.7), the minimizer doesn't have to check the other two nodes because the maximizer will never pick this branch.

Same logic for the far right branch. You are neglecting to include the best possible result for the maximizing node on the second 0.1 branch, where incidentally, there is a 10 and the best possible score the maximizer could realize is -0.8-7.2+1=-7. Note that he wouldn't even do that well because of the -9 sitting there.', u'Correct!']}, {u'text': u'Do we have to iterate the node in order? If we can pick the most weight branch, then we can prune more.
Like in the last branch, if we pick the 0.8 first, it is 0.8*-9 = -7.2, then we can prune the other two branches.', u'responses': [u'You have to evaluate from left to right, so you may not choose the order!']}, {u'text': u'', u'responses': []}]",,0.0,342.0,216,,Challenge Question 3 - Game Playing,"[lesson1, challengeqtns]"
5ad7d4430d63974e20c390e4,I would like to import itertools. Is that allowed?,jc6w44hrp9v2ki,[],,0.0,177.0,218,"itertools is allowed see comment in @40

But I would be careful about others without clear guidance that they are allowed.",Can we import additional standard python modules?,[a1]
5ad7d4430d63974e20c390e5,Is it possible to decrease the wait time for submission on Bonnie as we get closer to the deadline? 2 hours wait seems a lot.,jc6w44hrp9v2ki,[],,0.0,193.0,219,"I'll take a stab at this: some people's code for the last two sections is taking the full amount of allowed time to run.  Adding on this, their servers would probably get overloaded if people were submitting non-stop come crunch time which would be bad for everyone.",Wait time for submission,[a1]
5ad7d4430d63974e20c390e6,"I've been struggling with 1b for a while now.  The max I have gotten back from bonnie is 15% against ABID and 20% against K.

Today I started from scratch,tried to implement as close to stated algorithm pseudo-code for a/b pruning and iterative deepening.  My suspicions are that somewhere either my reasoning is incorrect and/or my implementation is broken, since if it were close to what the bonnie ABID is, then I should be seeing a higher win rate. 

Any general suggestions, tips, personal anecdotes would be appreciated.",jc6w44hrp9v2ki,"[{u'text': u'I was also struggling with 1b and realized there was some problem with the algorithm. I used alphabeta with min-max algorithm. A few things I changed:1. Handling the case where there are no moves left. The values may be different for maximizing and minimizing player.2. Handing the case where max_depth is reached or it's approaching time_left. Again, the values may be different for maximizing and minimizing player.
Playing locally and checking the utility values in each moves helped me a lot. The pattern in which the utility changes after each move helped me to find my mistakes. ', u'responses': [u'Earlier, I had a rather insidious bug that would only rear its head when the AI was evaluating end game states (winning or losing boards).

1.  I have code in my utility that checks for both winning and losing game states prior to doing any other calculations with eval function.

2.  Remaining time is the first thing checked in my alphabeta function (I through an exception if I am out of time).  Max depth == 0 is the second thing I check and return an appropriate value.

I also made my own tests, running several iterations and printing board states to see if any patterns arise.  Just feel it is odd that I have such a low win rate, which leads me to believe that something must be broken in the a/b pruning w/ ID implementation.

Thanks for the reply.', u'One suggestion -when doing the ID -print out the time left at every iteration - i had bugs that were causing searches at higher depths to return prematurely. printing the time helped me realize i was not using all my time properly.', u'I do that too,but i'm going to go through it again today to see whre I am going wrong.']}, {u'text': u'I was at 50-50 odds when I had alpha-beta iterative deepening implemented. At that point you have 2 choices 1) improve the eval function using your intuitive understanding of the game or by optimizing the opening moves 2) make tweaks to the AB routines that allow you search deeper than the opponent.

I was able to tweak the AB routine , specifically i did ""Store the evaluation scores for past moves."" as stated in the README.

I was able to beat ABID but just barely (70%) given the small margin i am not going to tempt fate by resubmitting to beat the secret eval
 ', u'responses': [u'Thanks, must be something wrong in my implementation then since I'm only getting about 15% wins.']}, {u'text': u'I found a couple different bugs/issues this morning once I got to see the full visualization of the game tree.  I used this library (as well as some relaxed constraints) to render everything and isolate the issues.

', u'responses': [u'thanks! i'll check that out']}]","I will let others answer this. 
For alphabeta - Try good eval function. 
I will again ask you to check README hints.",0.0,221.0,221,,looking for part 1b suggestions,[a1]
5ad7d4430d63974e20c390e7,"Do we only have odd number in size for the square board to play?i.e.5*5,7*7 or 9*9 but not 8*8 etc.",jc6w44hrp9v2ki,"[{u'text': u'I think any size works, but the grading is on a 7 x 7. Any reason why you're asking?', u'responses': []}]",,0.0,185.0,222,The only board size you need to worry about for grading is 7x7.,Do we only have odd number size of the square board to play?,[a1]
5ad7d4430d63974e20c390e8,"If I pass submit_a.py on Bonnie using minimax only, does it count? Or do I have to use alphabeta for submit_a?
From the homework description it seems like there are no specific requirement on our side of AI regards to which method we use.",jc6w44hrp9v2ki,[],,0.0,197.0,223,I don't believe there are any requirements on the algorithm used.,"Does it matter what AI I (minimax, alphabeta) use to pass the Bonnie test?",[a1]
5ad7d4430d63974e20c390e9,"Hello, im new to gaTech and Im confused by the term ""hit bonnie to find answer""

do you mean go to the terminal and type python submit.py?  

Thanks",jc6w44hrp9v2ki,[],,0.0,178.0,224,"Yes, Bonnie is the server on Udacity that's running the grading code. This isn't explained well in the project documentation and has confused a lot of folks. 

Once you're done, run the submit.py file. You'll get your results for Section 1.","After writing the code for open eval in player submission, how do i hit bonnie ?",[a1]
5ad7d4430d63974e20c390ea,"Hi,

I observe ""ImportError: No module named nelson.gtomscs"" when try to run submit.py.
Can anyone advise how to fix?

Thanks!",jc6w44hrp9v2ki,"[{u'text': u'Hi,

Thanks for the info, I did complete setup.md, but you are right, my computer installed two python, python3.x and python2.7. The nelson.gtomscs somehow installed under python3.x.
I've looked and comment on @162, $PYTHONPATH somehow is not working for me. maybe i set it wrong... I tried absolute path of python2.7 still not working.
', u'responses': [u'Also when i tried to install the requirement again, it again installed under python3.6.
is there a way in can point it to install under python2.7?

when i open anaconda i choose use python2.7

Mengyuns-MacBook-Pro:assignment_1 mengyunz$ pip install -r requirements.txt 
Requirement already satisfied: future==0.16.0 in /Users/mengyunz/anaconda/lib/python3.6/site-packages (from -r requirements.txt (line 1))
Requirement already satisfied: nelson==0.4.0 in /Users/mengyunz/anaconda/lib/python3.6/site-packages (from -r requirements.txt (line 2))
Requirement already satisfied: requests==2.13.0 in /Users/mengyunz/anaconda/lib/python3.6/site-packages (from -r requirements.txt (line 3))
Requirement already satisfied: requests-toolbelt>=0.7.0 in /Users/mengyunz/anaconda/lib/python3.6/site-packages (from nelson==0.4.0->-r requirements.txt (line 2))', u'Your pip is installing things for your python 3.6 distribution, not your 2.7 distribution.   I don't know python well enough to tell you what you need to do to either get pip to install them in your 2.7 library path or get python 2.7 to safely use those libraries you have installed under 3.6.
', u'Since you're using anaconda, I'd strongly recommend going to the project root and setting up an environment for that project using python2. Activate the environment, then pip install the requirements file. Anaconda's website has instructions on how to set this up. This is how I have it configured on my machine, since I use python3 for everything else, and it works nicely. It's simpler and safer than adjusting your PYTHONPATH manually, and is a good practice in general so that you are always using the correct versions of packages for each project. ', u'Hi Sasha,

Thanks, i tried google anacoda's website, but when i follow steps to type ""conda <command>"", below error pops up.
somehow i'm not able to use conda
Mengyuns-MacBook-Pro:assignment_1 mengyunz$ conda info -envs
Traceback (most recent call last):
  File ""/Users/mengyunz/anaconda2/bin/conda"", line 11, in  sys.exit(main()) File ""/Users/mengyunz/anaconda/lib/python3.6/site-packages/conda/cli/main.py"", line 179, in main return conda_exception_handler(_main, *args) File ""/Users/mengyunz/anaconda/lib/python3.6/site-packages/conda/exceptions.py"", line 636, in conda_exception_handler return handle_exception(e) File ""/Users/mengyunz/anaconda/lib/python3.6/site-packages/conda/exceptions.py"", line 626, in handle_exception print_unexpected_error_message(e) File ""/Users/mengyunz/anaconda/lib/python3.6/site-packages/conda/exceptions.py"", line 571, in print_unexpected_error_message from .base.context import context File ""/Users/mengyunz/anaconda/lib/python3.6/site-packages/conda/base/context.py"", line 21, in  from ..common.configuration import (Configuration, LoadError, MapParameter, PrimitiveParameter, File ""/Users/mengyunz/anaconda/lib/python3.6/site-packages/conda/common/configuration.py"", line 53, in  from ruamel.yaml.comments import CommentedSeq, CommentedMap # pragma: no cover ImportError: No module named ruamel.yaml.comments', u'I tired delete python3.6 directory, now after install requirement.txt it is showing under, but still hit error ""ImportError: No module named nelson.gtomscs""
/Users/mengyunz/anaconda/lib/python2.7/site-packages']}]",,0.0,163.0,225,"You haven't completed the setup correctly.  See setup.md.   If you have done setup.md and are still getting this, it's likely that you have multiple python installations on the system and/or pip is installing things in a location that your python is not finding.    Possible solutions:

Find the correct python to use and use the absolute path to the python executable (see example in responses to @96)Find our where pip is installing things and add that to your PYTHONPATH (see responses to @162)",Error during Submission: ImportError: No module named nelson.gtomscs,[a1]
5ad7d4440d63974e20c390eb,"Hi - could an instructor or TA give a precise definition of what 'num_invalid_moves' in the JSON return data means? i.e. what list of move states are classified as invalid? Clearly its impossible for students to determine the precise meaning since the grading code resides only on Bonnie.

So @111 says if our player loses a game that is counted as an invalid move? So of course (10,10) or (-1,-1) is invalid. An attempt to move to an occupied cell is invalid or to move the two queens to the same location. 

Are there any other cases or states that constitute invalid move?

As someone else posted it might be helpful for the next course offering to separate the games loss number from the number of actual invalid moves. If that was the case, invalid moves would be specifically known and then require a different remedy in code other than just a game loss.  At present it appears to be impossible to tell the difference

Thanks

{
    ""output"": {
        ""points_available"": 20,
        ""win_ratio"": ...,
        ""points_awarded"" ...: ,
        ""num_invalid_moves"": ...,
        ""num_timeouts"": ...
    },",jc6w44hrp9v2ki,"[{u'text': u'ok thanks. So yes, ..'If your code is all good, it's just that you lost..' Well I hope it is all good but without being able to distinguish between a game loss and actual invalid moves in the returned JSON it's hard to tell.', u'responses': [u'You should be able to tell whether or not you are actually returning invalid moves with local testing (though, of course, that won't be 100% perfect -- it still should find most of the issues).', u'Right and agreed. And it would be a quick change for the Bonnie code to separate out the two cases and name the results more clearly. Looking through the posts it looks like some others have also been confused by the data in the JSON result. So a simple change in the return data schema would make it clearer. Our brain power (at least mine anyway) is already maxed out trying to figure out the best AI for this game so its good to be able to minimize the brain cycles taken for other tasks.']}]",,0.0,179.0,226,"It means your AI returned an invalid move.   Typically the invalid move is ""None"" for at least one of your queens in which case it means you lost because your queen had no additional moves.   It is also possible that your code returned a move that moved to an invalid location (I had this happen in one of my offline tests when an invalid return within my code resulted in old data being used)

So any invalid move results in your loss.  If your code is all good, it's just that you lost.",&#39;num_invalid_moves&#39; definition?,[a1]
5ad7d4440d63974e20c390ec,"Hi,

I'm a little confused by the statement 'The first player who is unable to move any one of the queens loses.'Just to be clear, this means that the player who is unable to move either of the queens loses, not both, right? So even if one queen has valid moves, but one is stuck, the player has lost?",jc6w44hrp9v2ki,[],,0.0,182.0,227,"Correct.  A successful move requires a move to a new location by both queens.  If either queen is blocked, game over.",Clarification regarding winning,[a1]
5ad7d4440d63974e20c390ed,"I implemented only minimax and both evaluation functions. When I submitted the section one, mine defeated RandomPlayer by 0.8. Which function does this test calls? And which evaluation function is being used to play against RandomPlayer? What is depth of this test? When I did test with given test program locally, mine always defeated the RandomPlayer. Please help me.",jc6w44hrp9v2ki,[],,0.0,183.0,228,The testing on Bonnie calls CustomPlayer to initiate your AI.  You control which algorithm is used under the hood of your player in the implementation of the move() function within CustomPlayer.    The depth to which you search is governed by the default depth you set in your __init__ function within the same CustomPlayer and the code you have in the function called by your move() function.,question for first section of assignment 1,[a1]
5ad7d4440d63974e20c390ee,"I am doing some test runs with my code. Two questions came up:
1. During a move, should we maintain the same order? queen1 always move first and queen2 always moves second.
2. During a move, legal moves of queen2( second move)  is  dependent on queen1( first move).That makes me wonder if get_legal_moves() function is returning correct set.Ideally, if order were important ,
get_legal_moves() should have returned pairwise moves possible for queen1 and queen2.In other words , a legal move should not have been defined as[ {(legal_movesof_queen1)},{(legal_moves_of_queen2)}]but as [(legalmoveof_queen1,legal_move_of_queen2)]

I think someone asked this question before but I just wanted to revalidate and ensure I am not missing anything.",jc6w44hrp9v2ki,[],,0.0,184.0,229,"The way that the code works in isolation.py is that at the start of the move it verifies that both moves are legal, then it makes the moves.  So the move of one queen cannot make the move of the other queen illegal.  there is no dependency on the legality of a move in the middle of the move.

You can imagine that the system is going to move the queens in an order such that the move is legal (though this isn't technically how it accomplishes this).",Order of the queens,[a1]
5ad7d4440d63974e20c390ef,"The lectures have a guest speaker come on and talk about his findings for winning in isolation (lesson 1 - 44), but of course this is only speaking in regards to single queen isolation. I'm confused how to implement reflection for 2 queen isolation. Do you take the first two placements of player 2, rotate it 180 degrees and place your queens there?

Also in that lecture, he states player 1 has six moves whereas player 2 has eight. I counted nine moves available for both of their queens! Can anyone clarify that?",jc6w44hrp9v2ki,"[{u'text': u'I tried this refelection approach for the 2 queens, but this adds complexity hereand doesn’t seem optimal. I tried the case where I can reflect both the queens which makes it highly unlikely to occure in game board. Not sure what would be a great reflection strategy.', u'responses': [u'It theoretically just makes it easier to choose moves (e.g. if the moves are open and you limit yourself to those moves, you will do less checking during the earlier stages).

The question is whether or not reflection actually helps in a 7x7 board with 2 queens.  They were saying that reflection helps in a 5x5 board with a single queen.  But I don't have enough data to say that also applies to the 7x7 board with 2 queens.   It may or it may not.', u'I found that doing a reflection check only really helps on the Opening Move and even then it's not perfect, but does reduce the search space a bit. ']}]",,0.0,180.0,230,"I played with this some but don't currently have it enabled.    Essentially I tried to take their positions and reflect them across the vertical, horizontal or diagonal axis to find an open move that ""reflected"" or ""mirrored"" their move.  You can do this with basic math on the indices of the move rather than trying to rotate the board.

I don't have enough info on the board you are talking about to provide any info on the 6 vs 8 vs 9.",Reflection test on 2 queen isolation,"[a1, lesson1]"
5ad7d4440d63974e20c390f0,"Hi All, I'm having trouble just beating the random AI. My understanding based on poll @183, is that I should only need min max and depth 2 plus open eval function to beat the random player. 

On a 5 by 5 board, I am beating the player consistently, but once I get on a 7 by 7 board, I start getting timeouts and lose. 

How critical is it to implement symmetry checks to reduce the number of scenarios? I feel like it's almost impossible to get a symmetrical scenario unless the queens are placed in a corner. 
i.e. if queens are placed below, then I don't see any way to get a symmetrical scenario: | . | .  | .  | .  | .  | . | . || . |21| .  | .  | .  | . | . || . | .  | .  | .  | .  | . | . || . | .  | .  |11| .  | . | . || . | .  | .  | .  | .  | . | . || . | .  |22| .  | .  | . | . || . | .  | .  | .  |12| . | . |

If I'm not even able to beat the random player using min max, does that mean my min max is not working correctly? 
",jc6w44hrp9v2ki,"[{u'text': u'Thanks Conor!!The suggestion with the evaluation counters helped me realize that my alpha beta pruning was not working. That helped resolve a lot of the issues!', u'responses': []}, {u'text': u'Hi Conor,

Thanks for the tip.

How were you able to avoid timeout issues with JUST minimax and depth = 2, and no special pruning/reducing tricks? I assume bc of your customEvalFn?

Thanks,
Q.', u'responses': [u'I had a catch that looked at the number of possible combinations between the moves and if it was above a limit, I decreased the depth to 1.  The TAs also suggested possibly picking some randomly when the choices are too high and/or having some opening book moves for the early stages when the choices are too high.']}]",,0.0,181.0,231,"I was able to pass both part 1 (submit.py) and part 2 (submit_a.py) with just minimax with a depth of 2 and no special handling of symmetry or other move reducing tricks.

If you're having trouble with time on minimax, you might consider stepping up to AlphaBeta.  AlphaBeta should reduce your time significantly (I added counters to my evaluation function so I could tell how many times it was being invoked from the different algorithms and alpha beta often saw less than 1/10 the number of evaluations vs minimax.",Timing out with search depth of 2 in first 4 move counts,[a1]
5ad7d4440d63974e20c390f1,"Feel free to update your vote as you make progress. Pick the highest level you've completed.
 [o] OpenMoveEval works 5pts
[o] Beat Random Player 90% - 30 pts
[o] Beat Minimax to Level 3 > 65% - 20 pts
[o] Beat AlphaBeta to Level 3 > 65% - 20 pts
[o] Beat Iterative Deepening > 65% - 20 pts
[o] Beat Kshitish >= 85% - 5 pts
[o] My bot will kill your bot in Tournament  n Points",jc6w44hrp9v2ki,"[{u'text': u'See @198', u'responses': []}]",,0.0,224.0,232,,Assignment 1 Progress,"[a1, polls]"
5ad7d4440d63974e20c390f2,"I tried to understand and implement it for 3rd section , however I am failing at it. It seems obvious that I am not getting this concept correct for 2 queens player. How to determine which part of the board to explore and which opposite queen to target?",jc6w44hrp9v2ki,"[{u'text': u'Hi, it would be nice if you could just mention which partitioning techniques actually was proven helpful so that we can try implementing it.

I tried searching only from the top-left 5x5 sub-board for the first few moves, because that's the easiest way to do--you just create another copy of the game board and scale down the size--but it doesn't seem to work...

I also tried implementing caching and it doesn't make much difference, too...

It would really benefit us if you could be MORE clear about what techniques the best winning strategy so far actually uses, so that we can prioritize our time more efficiently.', u'responses': []}]","We might not be able to answer this question. I would ask you to think about it yourself, since that is all part of your strategy - after all, this part of the assignment is meant to be completed with your own skill.",0.0,191.0,233,,How this partitioning technique works?,[a1]
5ad7d4450d63974e20c390f3,"This assignment was one of the toughest I've had in the OMSCS program - and it's not because it's intrinsically difficult.  The whole submit-and-wait-two hours thing is really blowing-up the time that I've got set aside for schoolwork.  I don't think I'm alone in this feeling, so I'd like to share a few things that could hopefully improve this experience for future semesters:
some sort of sliding scale for grade.  I've been hovering around 50% on the last section - and if I can't push its perf above 65%, I get zero points for that section.  That seems a little unfair to me.faster feedback.  One of my submissions essentially had a typo in it.  I know, it's my own fault.  But now I have to wait two hours to try again.  Another idea would be to try fewer games.  If the grader ran half the games, that would still give it a good idea of how strong out agents were - with way less overhead.the hidden timing constraints are a real bummer.  We're building-in buffers into our agents so that they don't go anywhere near the time limit - and the grader still times-out.  And when that happens... you've got to wait two hours again.",jc6w44hrp9v2ki,"[{u'text': u'One other major issue and perhaps a suggestion for further iterations in the class is to break the submissions down in to smaller parts.  There should be separate submits for 1b Custom Vs ABID w/ OpenMoveEval and Custom Vs K.  It seems like a waste of time and resources to test Custom Vs K if Custom Vs ABID was not successful.', u'responses': [u'Seconded. This is a common issue as a bad run will lead to losing the 20 points when you try to score the last 5. A lot of people have just given up on the last 5 so as not to put the first 20 at risk. This is compounded at the end of the assignment since server load is so high one cannot guarantee a good run. Splitting the task would halve server load. ', u'
Yep.  I abandoned working to best K's bot as it's been called simply because I didn't want to risk losing my 20 points on part 1b.  It would be nice to either break all of them into individual submissions, or to allow us to identify which submission we wish to be graded; not just the most recent.  I didn't have much of an issue with the 2 hour wait time, it was inconvenient and meant that if I set aside 2 hours each evening to work on my project it wasn't very productive.   It would be nice if we were able to do more verification locally and submit for grading less frequently, but with the current set up having to submit and try to debug based on the black box grader it was a bit frustrating regardless of the delay between submissions. ']}, {u'text': u'
If it's any consolation, this was done differently last semester wherein all parts of the assignment were evaluated using one submit.py file.  I was glad to see that this time there were multiple submit files which allowed us to continue working other parts of the assignment without risk of losing our score from previous submissions.  Hopefully next semester the last 25 will also get broken up into two separate submissions, but I wanted to mention that this was actually an improvement from last semester.
', u'responses': []}, {u'text': u'One suggestion I have is to remove the ability to mess with the eval function. Frankly speaking I have no real interest in spending the time allocated for this course in analyzing the intricacies of isolation. I would rather that we have one standardized eval function and the effort goes it researching and implementing generic AI mechanisms/optimizations for searching the tree deeper like pvs, negascout , zobrist hashing etc. ', u'responses': [u'i agree', u'+1']}, {u'text': u'I'd also request that future startup codes be well documented. I was left guessing during the early part of this programming assignment as to what each function does, and the return types for the various functions.

If a short, precise description of what the function really does, and what it returns were given, I would have saved a few hours', u'responses': []}, {u'text': u'+1 for the sliding scale for grading.
Lot of effort would be for nought, even if we managed to reach 60%. e.g on IDAB part.

In one of my other courses, the target for finding malware traffic was 80% and if you found lesser, your grade would be proportional to how many you detected, so long as you were above the required lower limit of detection.

I do appreciate the improvement from last semester.', u'responses': []}]",,0.0,220.0,234,,feedback for instructors on assignment 1,[a1]
5ad7d4450d63974e20c390f4,"What was the maximum search depth for your iterative deepening and did you beat Bonnie?
 [o] 2
[o] 3
[o] 4
[o] 5
[o] > 5",jc6w44hrp9v2ki,"[{u'text': u'Not a good poll as depth depends on whether it's early game or late game. You can search > 10 levels late in a match, but max 4-5 levels on turn 1. ', u'responses': []}]",,0.0,208.0,235,,How deep you did you go in iterative deepening?,"[a1, polls]"
5ad7d4450d63974e20c390f5,"After sailing through 1 and 1 a with just Minimax, I’m stuck at 1b for the last 5 days. Tried iterative deepening , reorder while deepening,conditional deepening. Eval FN that uses reachable area instead of moves. Condition eval fb based on number of moves of the game. And also the combination of above . But I could never cross 0.3 win ratio. Am I the only one who finds the 3rd part of the assignment too tough to crack with 2 hrs Bonnie cycle. Finally after completely getting exhausted and no further ideas I have, surrendering. Unless some ta or professor hint me with the correct approach, I’m done with 75%. ",jc6w44hrp9v2ki,"[{u'text': u'The hints on the ReadMe file will allow you to search deeper with your alpha beta for iterative deepening', u'responses': []}, {u'text': u'Some have stated in the slack that with a correct implementation, ABID w/ OpenMoveEvalFn should net 40% to 50% wins on 1b.  Personally, best I have ever gotten was 25% and most range between 5% and 15%.  I'm pretty sure I have some sort of bug somewhere, but I'm in a similar boat to you.', u'responses': [u'I used a/b with deepening and open move evaluation (forgot to use my custom one) and scored 65% on the first part of submit 1b. But, like a lot of people, I have given up trying on the challenge bot. Beating it 50/50 is not too hard, but the 85% win ratio is just too much ', u'best I've gotten is 65% on K, have not gotten above 55% on other portion of _b; and unless I'm totally gone at this point, the same code gets different scores when run again...', u'That's a common experience to have +/-15 on the same code. I also find doing better on the secret bit leads to worse performance on the other one and vice versa. My first couple of submits saw steady progress against the 20 points, but worse and worse results on the last 5. When I finally took a break and did major changes to the code, both improved, but  it was a lot of work. ']}, {u'text': u'I totally agree. It's the toughest one I ever had. I already spent two full weekends and 4+ nights on this and almost get part2 done.', u'responses': [u'same here. Spend 50+ hrs to complete just 1b.

Completed 1 and 1a in just 4-5 hrs but 1b is almost impossible for me. Tried to implement all the techniques mentioned on read me.', u'Same here... 20+ hours working on 1b and I still can't figure out what I'm doing wrong.']}, {u'text': u'I have had the same experience, with a good 20+ hours and still have not cracked the 1b barrier.  However, I just found that I had an incorrect mental model of the eval function output which still produced valid results for the OpenMoveEvalFn, but cause me to chase rabbits with partitioning and other eval functions.  I had to debug a 4 x 4 game to get my head right.  Now that I have righted the ship, I am hopeful to get there. 

I have to disagree with a post I read somewhere in this site.  I believe it most important to go deep into the tree.  That said, they reached the goal and I have not, so not sure I have credibility yet.

Awesome assignment!  I now understand alphabeta searching?  At least until the test question coming up.  :-)', u'responses': []}, {u'text': u'Persistence with best scoring code may be the best strategy for _1b. I took code that had previously gotten 55% and ran it with a very minor bug fix and got 45%... :(

I ran it again with the same bug fix plus a small tweak to the opening move when my agent was player 1--so that it would not always be the same opening move--and got 65%. :)

Good luck everyone--as it appears luck is a bit of a factor on this one.', u'responses': []}, {u'text': u'No, you're not alone, but this is one of my last two courses, in which I need at least a B in this one and a C in the other, so I am not going to panic about a 75.  Fortunately, there is a good chance 75 will be the median on this assignment.  I think it's almost impossible for it not to be the mode, unless a bunch of people just don't do it.', u'responses': []}]",,0.0,240.0,236,,surrender,[a1]
5ad7d4450d63974e20c390f6,Is it possible to submit the AI.txt file without redoing an entire submission to Bonnie?,jc6w44hrp9v2ki,"[{u'text': u'Great question. I too would like to know if we can take part in the bit fight without putting the currently recorded scores at risk. ', u'responses': [u'@Kshitish Deo  ', u'Adding my name to this list. I didn't have the AI.txt file attached to submission 3, I only uploaded it to T-square, but would like to participate in the botfight if at all possible.']}, {u'text': u'Thanks Kshitish!', u'responses': [u'@Kshitish

Any update on how we should submit code for the botfight?']}, {u'text': u'Why not just download your winning code from Bonnie and submit again? The results should be reproducible unless your code uses some kind of randomization...', u'responses': [u'Well, as I have seen, sometime the beat percentage could be very close, especially for the RandomBot.
So, since there are only twenty tests done per run, it could be that one run gives 90% and other 85%. That would mean a risk of 30 points !']}, {u'text': u'I disagree with the collective student's response above. I think the problem was that it wasn't clear on how to submit the AI.txt file to compete in the botfight. I submitted with my assignment on T-square, but not on bonnie, for example. Also, the instructor answer explicitly said during the submission period not to resubmit in order to get the player added to the botfight. So, it's not the case that this is changing the rules after the fact.

In order for this to be unfair, you would have to assume that resubmitting to pass the final 5 points somehow makes those submissions less likely to fair well in the botfight, but I see no reason for that to be the case. Instead, I think the student suggestion of having anyone who passed 3b automatically getting an advantage in the botfight to be very unfair since that would be a rule change after the submission period.

I doubt that what's described in the student response will be the official approach, but just wanted to express my thoughts. If it turns out that those of us who misunderstood how to submit AI.txt don't get to participate, so be it, but I don't think that we should set up different categories of competitors after the fact when that was never communicated ahead of time.

EDIT: Another possibility would be to have those who didn't submit the AI.txt file through Bonnie but still want to participate in the botfight forfeit the possibility of earning bonus points while still being able to participate. I am more interested in competing for fun than for the points.', u'responses': []}]","WAIT. dont submit Bonnie for AI.txt only if you are not comfortable . 

Others-IF you have still to finalize last submission- ensure you submit with AI.txt.

I will check what we can do. Worst case- I will ask you to send privately to me. I will add it to Botfight. Lets see what we can do. 
However, dont risk your scores for this. We definitely will have to take that last submission which ever it is.",0.0,197.0,237,"Would that be fair to people who tuned their agents to defeat Kshitish's secret eval function $$\ge 0.85$$ ? It would seem that changing that rule at this stage would be similar to changing the rule that the last submission counts

Here's a suggestion that could be the fairest, incidentally: make 3 qualifying competitions. Everyone in the top 10 of those who defeated K's secret eval function $$\ge 0.85$$ with their most recent submission, would get at least the 'top 10' bonus points. The top 10 of those who couldn't defeat K's secret eval function who sent in an AI.txt with their most recent agents to Bonnie, qualify for the finals. The top 10 of everyone who didn't submit an AI.txt, qualifies for the finals.

Then there's the question of whether the finals would be knockout or league. Knockout it seems difficult to rank people, so possibly league is appropriate. However, in case of knockout boost the number in the finals to 32. The additional 2 places to make 32, plus unfilled places in either league or knockout system, in case some categories are less than quota, are filled from the ranks of in order of priority & in order of their ranking in the qualifiers, those who defeated K's secret eval function $$\ge 0.85$$, those who sent an AI.txt to Bonnie, those who sent in an AI.txt not to Bonnie.

The top 10 in the finals get the bonus points for being in the top 10 too (though no-one gets that twice), the top 3 in the finals get the respective additional bonus points",Submitting AI.txt,[a1]
5ad7d4450d63974e20c390f7,"I am running the line of code ""python submit.py"" and it seems to just hang. Is this what was referenced where it will take 2 hours? I was under the impression that 2 hours is the time to actually test, not to simply upload to Bonnie. Any help on this would be appreciated.
Thanks",jc6w44hrp9v2ki,"[{u'text': u'I've tried 3 times now... 
I have all of the requirements installed and my solution compiles. The ""Bonnie"" folder has all of the files from github in it. I have used Bonnie before and a zip file is generated. That is NOT happening now. I see that there is academic honor stuff in the submit files, but that doesn't pop up either.
Anything else I can try?', u'responses': [u'When you run ""python submit.py"", you should be able to see the academic honor stuff, in which you will have to respond in order to submit it. If that's not popping up, then I'm not sure what's wrong. 
In terms of your other concerns, yes, there is a limit on how often you can upload each assignment. For just submit.py, you can upload once every 30 minutes. For parts 1a and 1b, there is a cap of once per 2 hours. So once you get to the part of uploading the submission, you will have to wait for a while for it to go through. Note, it did take me a couple minutes, for me to upload the submission, however definitely not the whole 30 minutes or 2 hours. ', u'Thanks William. I don't see any academic honor stuff, I only know it's there because I looked at the files..', u'I just stepped through assignment_1\Bonnie\submission.py and I wasn't prompted to input my username or password.

Again, I used Bonnie last semester and never had any problems with it.

I also can't log in to deepthought. Could this be a related issue? I can log in to buzzport, etc. with no problems.

Instructors, do you have any ideas?', u'The files are submit.py for first part, submit_a.py for second part, submit_b.py for the last part. These are in assignment_1 not assignment_1\Bonnie', u'are you sure you are using python 2.7? i have both 2.7 and 3 installed and i had to manually force it 2.7 for it work.']}, {u'text': u'I was prompted to input my username, then it got stuck there. It never ask me for password, nor can I do anything.', u'responses': [u'I had this issue when I tried to run them from inside PyCharm but they worked for me from command line, if you haven't already tried that.', u'Thanks. Let me try it.']}]",I can't see you submission on Bonnie. Try to submit it again. ,0.0,198.0,238,,Python submit.py,[a1]
5ad7d4450d63974e20c390f8,"The readme gives a hint to improve results to store the evaluation scores for past moves. I don't understand how to do this. If every game is played fresh, where would you store the previously calculated scores? Are we allowed to keep memory from one game to another? Am I thinking about this in the wrong way?",jc6w44hrp9v2ki,"[{u'text': u'Storing eval score for past moves would help with move ordering.  This has to do with iterative deepening.', u'responses': []}, {u'text': u'How do you store the eval score of past moves? What is the key in the key => value pair. Another words, if I store the score in a dictionary, how do I link that to the state of the board?', u'responses': [u'Philip - the same board can be reached via multiple paths. Eg a queen moving from A->B->C will result in the same board state as a queen moving from B->A->C. So at the same depth saving the eval function output for the board would help you avoid the same calc again. This would help with  iterative deepening if you record for each board state what was the best move at depth n-1 and expand that first. Doing that may help your pruning work better. 

The key point is being able to have an efficient way to compare two boards - I used zobrist hashing to generate hashes for each board. The hash was the key which I used for look up. 

As amentioned above there there are two cases for when you have seen the board before. If you have seen this board at the same depth you can just returned stored eval , if you have see this board only at depth n-1 then use the best move from previous iteration to key off the successor checks. ']}, {u'text': u'Are we allowed to save all possible moves to a book? (Assuming we spent eternity calculating every possible solution)', u'responses': [u'There's not enough memory or time to do that.']}]",,0.0,207.0,240,"The same board can be reached via multiple paths. Eg a queen moving from A->B->C will result in the same board state as a queen moving from B->A->C. So at the same depth saving the eval function output for the board would help you avoid the same calc again. This would help with iterative deepening if you record for each board state what was the best move at depth n-1 and expand that first. Doing that may help your pruning work better.

The key point is being able to have an efficient way to compare two boards - I used zobrist hashing to generate hashes for each board. The hash was the key which I used for look up.

As amentioned above there there are two cases for when you have seen the board before. If you have seen this board at the same depth you can just returned stored eval , if you have see this board only at depth n-1 then use the best move from previous iteration to key off the successor checks.",How do you store the evaluation score for past moves?,[a1]
5ad7d4450d63974e20c390f9,"I've played around 20-30 games of isolation with my roommates, and I can't figure out what killer moves are. Does it mean having a great start? Does it mean looking out for a particular situation and making that next move.

I believe finding out killer moves is luck at this point and not computer science skill: aka did you run into a killer move or not.",jc6w44hrp9v2ki,"[{u'text': u'I feel like killer moves are those that close off the opponents ability to keep moving.   If you can make a move that corners them, then it comes down to who will run out of moves first.', u'responses': []}, {u'text': u'yeah, the partitioning off of an opponent seems to be one of the strategies mentioned in the videos, but only if you have the longest path of moves after the partition. It's not clear to me how you would actually implement this though. The algorithm seems complex to recognize the partition, and then count the number of moves and assign a heuristic value to this.', u'responses': []}]",,0.0,223.0,241,"Ability to wall off your opponent in a subset of spaces is a killer move. At that point she has only a finite number of moves she can make. This a move that may not stand out when using open move eval but is something you may need to consider in the util function. So so my interpretation of killer move is anything that is a shortcut that you want to be looking for in addition to the eval function. My interpretation from the book/wiki: The killer move heuristic is simply choosing moves in which you have seen positive outcomes in the passed, and then running your alpha-beta or minimax algorithm on it before the other outcomes. This can take many shapes. One such use is to vastly improve your alpha-beta algorithm. If in a prior move when foreshadowing future moves you noticed a move that pruned a ton of nodes, it would be wise to start with that node first next time because it has the potential to prune a lot of nodes again saving you a lot of computational time allowing for a deeper search.",What is a killer move?!,[a1]
5ad7d4450d63974e20c390fa,"I know many people are maxed out getting the assignment done.

However, are there any folks in the northern parts of the Valley interested in a coffee to compare notes, meet in person, discuss this and other OMSCS courses?. Northern valley like San Mateo, Redwood City etc is what I can do.

Thanks
David

",jc6w44hrp9v2ki,"[{u'text': u'I'm in Redwood City. I would like to attend an AI study group in this area. ', u'responses': []}, {u'text': u'Sounds good. Let's use LinkedIn to schedule a time. So my LinkedIn is https://www.linkedin.com/in/davidmurphy5/

We could start with an introduction coffee - best location for me would be downtown Redwood City and during the weekdays. I can also often do lunchtimes in Redwood City some weekdays.', u'responses': [u'Great! I agree with coffee in downtown Redwood city, during weekdays! I'll connect with you on LinkedIn.']}, {u'text': u'I am in Santa Clara. Just added all your guys. 
Weekends group would be great.', u'responses': [u'Awesome! ']}, {u'text': u'I put a link to this thread in 'group study'. That's where it should have been first.
@285

Anyone interested to meet in Redwood City next week - either lunchtime or maybe around 5:00?
', u'responses': []}, {u'text': u'I live in Daly City, and am interested in meeting up in the San Mateo/Redwood City area. www.linkedin.com/in/william-wu-aa081359 ', u'responses': [u'Awesome! ']}, {u'text': u'Hi William.

So everyone - let's see if we can get a coffee group together next week in Redwood City.

So all on this thread - post here if a) you are interested and if so, b) what days/times work for you in downtown Redwood City next week.
', u'responses': [u'a) Interested!
b) I'm available on Sunday Feb 4th in the afternoon until end of day', u'I'm interested and for the next week Thursday and Friday (Feb 8 & 9) works best for me. This weekend (Feb 3 & 4) also works for me if you wanna have a meeting for this week.
', u'I can do Friday 9th in downtown Redwood City around 11:30 or 12:30
', u'I can be there around 11:30 or 12:30. Both works for me.
', u'Hi Azade - so good, let's shoot for Friday 9th at 12:00 in Redwood City. Could we meet at Peets in Redwood City at 2600 Broadway, Redwood City, CA 94063 at 12:00pm
Anyone else on this thread please feel very free to join us. The more students the better in the group.

Azade - please confirm back on this thread that you can do Friday. Or we can check in again mid-week to confirm.
Thanks
David', u'Sounds great! I'll meet you Friday, 9th, at 12:00 at Peets. 
Thank you,
Azade', u'excellent - thanks Azade. Confirmed for Friday 9th at 12:00 at Peets in Redwood City
as always - if anyone else can make that time and location please join us :-)
', u'Hi Azade - sorry to change .. can we make it 12:30 same place, same day (i.e. this Friday)?', u'Hi Azade - didn't hear back.. is 12:30 (not 12:00) good for tomorrow in Redwood City?', u'Sorry. I didn't see your message. That's fine for me. see you 12:30 tomorrow.']}, {u'text': u'Does anyone want to meet from San Francisco or the East Bay?', u'responses': []}]",,1.0,189.0,242,I am from Sunnyvale. I guess we can do that.,Silicon Valley group?,[other]
5ad7d4460d63974e20c390fb,"Hello, I have a problem where i have an interview next week on friday.  I have been memorizing interview books but just absolutely have no time to dedicate to the first homework.  Would future homeworks be based on assignment 1 material?  or are there plenty of opportunities for further challenge questions in future homeworks?  thanks",jc6w44hrp9v2ki,"[{u'text': u'@161 No, future assignments will not be based on assignment 1. ', u'responses': [u'thanks']}]",Resolved.,0.0,200.0,243,,Question on Future Homeworks,[gradescope]
5ad7d4460d63974e20c390fc,"Good luck to everyone still working on Assignment 1!

Once you're done, I highly recommend watching the documentary on Google's game-playing AI that can beat top-tier Go players. The film doesn't get very technical, but you will see concepts from Assignment 1 like adversarial search and evaluation functions. I followed the match against Lee Sedol a couple of years ago as it unfolded, but still I was on the edge of my seat watching this film.

https://www.alphagomovie.com/

And it's on Netflix (in America).",jc6w44hrp9v2ki,"[{u'text': u'Having gone through assignment 1 and also having read about Alpha Go / Alpha Zero, I'm curious if anyone has opinions on deep reinforcement learning vs. search as the future of AI game playing? DeepMind seems to think their reinforcement learning approach is the future and they've obviously demonstrated some impressive results. Is alpha-beta pruning / minimax going to become obsolete for AI game players or are there more efficiencies / advances to be made for search-based game players that could rival the reinforcement learning approach?

P.S. The alpha zero paper is really interesting in its own right (and not hard to understand). There are also a lot of cool YouTube videos where chess experts break down games between Alpha Zero and Stockfish (one of the best traditional AI chess players). Here's one: https://www.youtube.com/watch?time_continue=3&v=lFXJWPhDsSY. ', u'responses': []}]",,0.0,186.0,244,,AlphaGo Documentary,"[a1, other]"
5ad7d4460d63974e20c390fd,"Credit to Nick Jackson for posting this in the slack.

""If anyone is still dealing with the issue where ID seems to make their results worse - make sure you change the utility function. It takes the maximizing_player parameter but doesn't pass it to score()....""

I didn't notice this either.  I just submitted to bonnie, so will stay up late and hopefully try again.

Original starting code was incorrect, it should look like this.

    def utility(self, game, maximizing_player):

        return self.eval_fn.score(game, maximizing_player)
",jc6w44hrp9v2ki,"[{u'text': u'Hmm... I don't use that anywhere in my code (I just call the eval function directly).

Not sure it's used anywhere by bonnie.', u'responses': [u'I was using it as middleware.  Put my state checking in there that would be common across all eval functions, that way I could test and swap out eval functions easily.']}, {u'text': u'I also never used this function. I just never got time to research what it is supposed to do and my stuff seems to work fine without it', u'responses': [u'Just fixing the return portion got me from 15% to 55% vs ABID.  I also wish I would have never used it.']}]",,0.0,185.0,245,,util function issue,[a1]
5ad7d4460d63974e20c390fe,"Hi,

I am trying to submit the first section of the assignment but I'm having issues when I do 'python submit.py'

Traceback (most recent call last):
  File ""submit.py"", line 7, in <module>
    from nelson.gtomscs import submit
ImportError: No module named nelson.gtomscs

Any help will be greatly appreciate it!",jc6w44hrp9v2ki,"[{u'text': u'Download those requirements!! Check the git instructions', u'responses': [u'How?', u'I downloaded the requirements as git instructed before running it and it's giving me that error.
', u'This is when I run the command with the requirements again:

Requirement already satisfied: future==0.16.0 in /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages (from -r requirements.txt (line 1))
Requirement already satisfied: nelson==0.4.0 in /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages (from -r requirements.txt (line 2))
Requirement already satisfied: requests==2.13.0 in /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages (from -r requirements.txt (line 3))
Requirement already satisfied: requests-toolbelt>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages (from nelson==0.4.0->-r requirements.txt (line 2))', u'The path is referring to python3.5 you should be using python2.7']}]",,0.0,175.0,246,"do :
pip install -r requirements.txt

if you have already done that then try( to cover the case where you have both python 3 and python 2.7 installed):
pip2.7 install -r requirements.txt
python2.7 submit.py",Module import error,[a1]
5ad7d4460d63974e20c390ff,Do I need to implement customEvalFunction to win the game with some different strategy. I am never able to win more than 65% with openEvalFunction . Any pointer would help here.,jc6w44hrp9v2ki,"[{u'text': u'I was at 50-50 odds when I had alpha-beta iterative deepening implemented. At that point you have 2 choices
1) improve the eval function using your intuitive understanding of the game or by optimizing the opening moves
2) make tweaks to the AB routines that allow you search deeper than the opponent.
 
I was able to tweak the AB routine , specifically i did ""Store the evaluation scores for past moves."" as stated in the README.
 ', u'responses': []}, {u'text': u'I'm converting the board array of arrays to a String and then hashing that string to get a unique key to store in a dictionary. Is this efficient? Will it not improve my game play? Do I need to wait two hours before I can test the damn thing? Have I been working on this for 15 hours straight and my eyeballs are red and about to fall out? Do I regret grad school?

Yes to all of the above.', u'responses': [u'I cant agree with you more! its been an angst filled week of experimenting.

but then two weeks ago i just had a vague handwavy notion of how computers played games and now I can implement , an admittedly rudimentary, game playing program. its been a tough week but the learning has been great. ']}, {u'text': u'I was able to get a 65% win ratio against IDAB with Open Eval function.', u'responses': []}, {u'text': u'It can certainly help. I found using even a very similar heuristic, there were large gains to be had. I found a depth 2 search could defeat the agents from section 1a with a very minimal eval function change.
Remember, all of the problems (but the last worth 5 pts), you can assume the other player is going to minimize your score using the OpenMoveEvalFn. You can use this to your advantage. You know which method they are using but they do not know yours. Think of methods that would defeat someone attempting to simply maximize the difference between their moves and your moves.', u'responses': []}]",Making it resolved,0.0,212.0,247,,cutomEvalFunction,[a1]
5ad7d4460d63974e20c39100,"After submission of q3, I got this:

Traceback (most recent call last): File ""submit_b.py"", line 92, in <module> main() File ""submit_b.py"", line 89, in main submit('cs6601', 'assignment_1b', filenames) File ""C:\Users\DL\Anaconda3\envs\VisionHomeWork\lib\site-packages\nelson\gtomscs.py"", line 46, in submit return abstractsubmit(submission, refresh_time = refresh_time) File ""C:\Users\DL\Anaconda3\envs\VisionHomeWork\lib\site-packages\nelson\abstract.py"", line 39, in submit sys.stdout.write(""\rWaiting for results... {}"".format(next(wheel)))IOError: [Errno 0] Error

Usually when I go to Bonnie even though I get the error message it still has score and feedback, but this time there is none. Seriously need help.",jc6w44hrp9v2ki,"[{u'text': u'Jesse, You shouldn't put a question in a student response.  Add it as a follow up or make a new post.  Putting it into the student response prevents others from actually adding an answer there.

From your last error (a permissions error on a file on your system) it seems like you don't have things configured/setup correctly on your own system.  Not sure how this should be setup on windows.  ', u'responses': []}]",,0.0,179.0,248,"I am having the same issue..
When I click ""N"" to save jwt..
Traceback (most recent call last): File ""submit.py"", line 92, in <module> main() File ""submit.py"", line 89, in main submit('cs6601', 'assignment_1', filenames) File ""C:\Python27\lib\site-packages\nelson\gtomscs.py"", line 46, in submit return abstractsubmit(submission, refresh_time = refresh_time) File ""C:\Python27\lib\site-packages\nelson\abstract.py"", line 29, in submit print("""")IOError: [Errno 0] Error

When I click ""y""...
Traceback (most recent call last): File ""submit.py"", line 92, in <module> main() File ""submit.py"", line 89, in main submit('cs6601', 'assignment_1', filenames) File ""C:\Python27\lib\site-packages\nelson\gtomscs.py"", line 36, in submit session = build_session(environment, id_provider, jwt_path) File ""C:\Python27\lib\site-packages\nelson\gtomscs.py"", line 25, in build_session jwt_path).new() File ""C:\Python27\lib\site-packages\nelson\sessionbuilder.py"", line 54, in new self.save_the_jwt(jwt)
File ""C:\Python27\lib\site-packages\nelson\sessionbuilder.py"", line 87, in save_the_jwt with open(self.jwt_path, ""w"") as fd:IOError: [Errno 13] Permission denied: u'C:\\Users\\Jesse\\AppData\\Roaming\\nelson\\gtomscs_jwt'

I tried to run as admin, but that doesn't help.

Instructors, I have been trying to submit code since yesterday afternoon. I have used bonnie before, from the same computer, with the same credentials. What is going on?",Bonnie Error,[a1]
5ad7d4460d63974e20c39101,"I have the following error

""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_tjxmnbul/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 102, in test_beats_random\n    self.evaluate_against(RandomPlayer(), 0.9)\n  File \""run.py\"", line 55, in evaluate_against\n    win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n  File \""run.py\"", line 36, in simulate_games\n    winner, move_history, termination = game.play_isolation()\n  File \""/home/vmuser_tjxmnbul/workspace/isolation.py\"", line 255, in play_isolation\n    raise e\nAttributeError: CustomPlayer instance has no attribute 'time_left'\n"",

When I run the local test, it is the same issue.

Do I need to add time_left function to the initialization of CustomPlayer()?",jc6w44hrp9v2ki,[],,0.0,179.0,250,"You appear to have code that is referring to time_left as an element of CustomPlayer. 

This should be a parameter to your function but it is a function, not a variable, so you would use it as time_left()",Strange Error For Submission,[a1]
5ad7d4460d63974e20c39102,"I have a question about how many leafs should we examine for each layer. Suppose Queen 1 has 10 legal moves and Queen 2 has 8. They do not have common moves. Do we have to go through each combination(80 in total)? I implement minimax in this way and find out that if we have search depth more than 2, there will be time out. Anybody has the same confusion?",jc6w44hrp9v2ki,"[{u'text': u'I also tried to submit to Bonnie. The reply is very strange.

Waiting for results... \Traceback (most recent call last):
  File ""submit_a.py"", line 92, in <module>
    main()
  File ""submit_a.py"", line 89, in main
    submit('cs6601', 'assignment_1a', filenames)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nelson/gtomscs.py"", line 49, in submit
    return abstractsubmit(submission, refresh_time = refresh_time)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nelson/abstract.py"", line 37, in submit
    while not submission.poll():
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nelson/abstract.py"", line 125, in poll
    r = self.s.get(self._get_poll_url())
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/requests/sessions.py"", line 521, in get
    return self.request('GET', url, **kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/requests/sessions.py"", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/requests/sessions.py"", line 618, in send
    r = adapter.send(request, **kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/requests/adapters.py"", line 521, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='bonnie.udacity.com', port=443): Read timed out. (read timeout=None)

There is no useful information at all. I cannot submit for another two hours. Do you know the reason?', u'responses': [u'This looks like a networking problem between you and the bonnie server at some point *after* the code was submitted to bonnie while it was waiting for the results to return.  You should check on https://bonnie.udacity.com to see if your run continued or if it died.']}]",,0.0,190.0,251,"You're trying to figure out the best move.  So if you don't look at all 80 you could leave some valuable paths unavailable.  However, if you don't have enough time to search them all, you should make due with what you can search and return the best of those. ",Question regarding time out of minimax,[a1]
5ad7d4470d63974e20c39103,"Can you please help me understand why below error might be coming
""traceback"": ""Traceback (most recent call last):\n File \""/home/vmuser_twmylahe/AIResult.py\"", line 26, in func_wrapper\n ans = func(self)\n File \""run.py\"", line 102, in test_beats_random\n self.evaluate_against(RandomPlayer(), 0.9)\n File \""run.py\"", line 55, in evaluate_against\n win_ratio, num_timeouts, num_invalid_moves = simulate_games(test_player)\n File \""run.py\"", line 32, in simulate_games\n student_agent = CustomPlayer() # Force the reinitialization of the player after every game\nTypeError: __init__() takes at least 2 arguments (1 given)\n"",",jc6w44hrp9v2ki,"[{u'text': u'getting the same error', u'responses': [u'This may be related to setting a default value for the depth in the CustomerPlayer __init__ function.  I think bonnie expects you to fill this in with a value of your choosing.']}]",,0.0,180.0,252,This has come up repeatedly... search for __init__ in the search box to the left.,Understanding Bonnie error,[a1]
5ad7d4470d63974e20c39104,"Hey - I have gotten to 40% for winning section 1b but have stalled.  I have been reading others have implemented storing past node scores at a particular depth to help with node ordering while evaluating the node underneath (n+1).  I am struggling to understand this.  If anyone has time to write a quick explanation of how one might do that, I would be grateful.  Thanks",jc6w44hrp9v2ki,"[{u'text': u'

when I enter Min/Max i calculate a hash of the board state and see if it is a state i have seen before. If so i retrieve the value that was returned for the that board state at depth n-1 and expand that first. I then proceed with the remaining nodes. When i am ready to return from Max/Min I store the hash along with moves that generated the best eval outcome.

The hash i used was a zobrist hash but others have used other hash functions.', u'responses': [u'Thank you for your help!']}]",,0.0,212.0,253,"A score for a board is an evaluation of the board with the current queen positions and blocks on all former queen positions.  If you find yourself with the same board again, the score will be exactly the same.  So you need to figure out how to store enough information to remember the important parts of the board such that you can look it up when it comes to get a score to see if you've already scored it.

There are limits to how much memory you can use.  We don't know exactly how much, but if you end up using too much, your program gets killed on bonnie, so you need to be efficient with how you are storing the data.",Using past node calculations to improve pruning,[a1]
5ad7d4470d63974e20c39105,"I submitted my assignment 1 for section 3, and while I was waiting for the results, I got disconnected from internet. Is there a way to check my results without the JSON file?
",jc6w44hrp9v2ki,[],,0.0,195.0,254,you can check on https://bonnie.udacity.com,Network disconnected while waiting for results,[a1]
5ad7d4470d63974e20c39106,Wonder if it is possible to mark this assignment based on our best performance on bonnie. As the load on bonnie is rather dynamic and I found my code without any change can get pass or fail depending on the time of submitting. Can we submit on T-square the UTC time of our best submission on Bonnie for marking? Otherwise the grade relies greatly on timing other than the real code performance. ,jc6w44hrp9v2ki,"[{u'text': u'I totally agree on that. ', u'responses': []}, {u'text': u'Thanks for the student's answer. As the answer mentioned, the lack of this type of policy discourages continuous effort. Worth of considering for future assignments. for example, building the challenging part (5% in this case) as a separate submit. ', u'responses': []}, {u'text': u'There's benefits to both sides. This approach, though sometimes frustrating, makes you really think about your strategy and put thought into your submissions. I'm not advocating one or that other, bc I've had both and there's really benefits with either. I'm sure Professor, doing this for as long as he has, knows some insights we can't see.

I do side with the splitting off the sections though. I heard that they improved on last semester's suggestions and split up the asgn for us this sem. Don't know the full story though.', u'responses': []}]",,0.0,232.0,255,"At this point in time it would be unfair to those who stopped working early in the week to preserve a score. There are some who did not go after the last 5% so as not to risk the 20 points that they earned in part 1b.  Had accepting 'best score,' rather than last  submission, been announced at the beginning of the project they might have continued, while announcing it in ""the 11th hour"" might not be of any benefit for them. 

While I agree that taking the best submission for each part is the better approach, especially given that there are multiple aspects to each part, in fairness to all  the last submission policy needs to remain. ",best performance instead of the last submission on bonnie?,[a1]
5ad7d4470d63974e20c39107,"After the submission period is over, can we have an open hour to discuss the best approach for 2 queen isolation problem. A lot of us struggled to find solution for 1b.
It could just be one live session which you can broadcast so that people like me can find out what we missed in those lectures or book which we couldn't implement.",jc6w44hrp9v2ki,"[{u'text': u'That's a really good idea. Due to time constraint, I didn't get a chance to work on my custom eval function and other clever tricks so this will be very helpful.', u'responses': []}, {u'text': u'I would 100% second that also. In addition to just the basic recommendations also some discussion on the types of techniques for assignment 1 that would help our player defeat Bonnie at the more advanced levels.

During this project, I've been reminded that you can waste a lot of time coding up some new concept idea that seems good at the time but ultimately turns out to be wrong at the concept level. i.e. best to make sure you think very clearly about any concept idea before committing time to coding it.', u'responses': [u'Definitely good advice, I learned it the hard way in this project!']}]","We will have a discussion on piazza after the botfight winners are declared. That time we ask the winners to discuss their strategies. 
Live session- I will discuss with other TAs and will let you know.",0.0,243.0,257,,Can we have an open hour for 2 queen solution?,"[a1, office_hours]"
5ad7d4470d63974e20c39108,"Hi There,

Just wondering whether we can submit two depths configuration for two separate sections on bonnie?

For eg depths = 2 for section1 and depths = 10 for section 2?

Thanks
Jiaji ",jc6w44hrp9v2ki,"[{u'text': u'Great! that helps thanks!', u'responses': []}, {u'text': u'You have an algorithm that can handle depth = 10??!! Can you please share your secret post-due date?!!??!

Depth = 2 is overkill for part 1. But yeah, obliterate that RandomPlayer!', u'responses': []}]",,0.0,201.0,259,Yes.  You can submit totally different code for each part of the assignment. ,Submit different depths for different submissions,[a1]
5ad7d4470d63974e20c39109,"I got a bit confused with depth in a game tree while working on the project.
Isn't the below example supposed to searching through depth of 1?
If the below example is correct with the depth of 2, depth of 1 would never know which action to take.
So then, for our project, the depth where we specify for the min-max, the depth will always be 2 or greater?

",jc6w44hrp9v2ki,[],,0.0,216.0,260,"The way I look at it, at a depth of 1 I look at all of the possible moves that can be made on the current board and return the one that has the highest value (assuming I'm a maximizing node like your example above).   That would mean I look at each of the moves in your second row.

At a depth of 2, I then look at the possible moves for the next layer down and would assume that the other player will want to minimize those scores.",Depth in game tree,[a1]
5ad7d4480d63974e20c3910a,"I found this site while looking for some additional alpha-beta practice. Just wanted to share.

http://inst.eecs.berkeley.edu/~cs61b/fa14/ta-materials/apps/ab_tree_practice/",jc6w44hrp9v2ki,"[{u'text': u'Nice! This is a great find.', u'responses': []}, {u'text': u'Thank you!', u'responses': [u'Nice one ! Thanks for sharing it']}]",,0.0,211.0,261,,Alpha Beta practice,[lesson1]
5ad7d4480d63974e20c3910b,"It was working before. See following errors now: 
Anyone solved same issue? Thanks

Traceback (most recent call last):
  File ""submit.py"", line 7, in <module>
    from nelson.gtomscs import submit
  File ""/Users/GavinXie/anaconda2/lib/python2.7/site-packages/nelson/gtomscs.py"", line 3, in <module>
    standard_library.install_aliases()
  File ""/Users/GavinXie/anaconda2/lib/python2.7/site-packages/future/standard_library/__init__.py"", line 483, in install_aliases
    import test
  File ""/Users/GavinXie/.Trash/assignment_1-master 6.32.16 PM/test.py"", line 366
    """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""",jc6w44hrp9v2ki,"[{u'text': u'                                        ^
SyntaxError: EOL while scanning string literal', u'responses': []}, {u'text': u'this folder may be deleted by you since it's referencing to .Trash/', u'responses': []}, {u'text': u'Is there a reason for all this anonymity?', u'responses': [u'See this interesting article for some reasons why people might post anonymously:
https://www.npr.org/2015/11/06/454970591/app-allows-shy-students-to-ask-questions-anonymously', u'Then there are more possible reasons even than that http://bit.ly/2EmHEDm

:-D', u'Haha @Mark!

And thanks for the share, Melanie. It was an insightful read.']}]",resolved,0.0,199.0,262,,Submit.py error,[a1]
5ad7d4480d63974e20c3910c,"Hello, I have a question regarding the syllabus.  What is the recommended way to study for this course?  watching the videos and reading the book? or reading every recommended reading as per the syllabus?  Usually i see, watch the video, read the RN slides and read the book.  The reason I ask is because so far i have only read the chapters in the book and given my work constraints, i want to maximize using my time as efficiently as possible.  Thanks",jc6w44hrp9v2ki,[],"This is usually enough to gain a good understanding of the topics in the course. For some of the assignments and for the midterm and final, it may be necessary to look at the additional readings given along with the videos and in the schedule as well. We will do our best to point you to these sections as and when the time comes.",0.0,222.0,264,,recommendation on how to read the syllabus required reading,[other]
5ad7d4480d63974e20c3910d,"Hi,

I've encounter an issue during submit_a.
It is running for over 20mins (with ""-"" keep rotating during submit terminal) and then it stopped, no rotating.

And when i check my bonnie, it is showing empty.
Is anyone know what is going on there?
",jc6w44hrp9v2ki,"[{u'text': u'got similar issue and error in my terminal:
requests.exceptions.ConnectionError: ('Connection aborted.', error(50, 'Network is down'))', u'responses': []}, {u'text': u'Just wait for the results in Bonnie. Check again later (or in this case, check now).', u'responses': []}]",,0.0,217.0,265,"That means it's still running on Bonnie. It will continue to run on the server, so if you kill the process running in your terminal, it won't affect server execution. Results will show up in Bonnie when it's done running. ",submit_a running then stopped with empty output on bonnie,[a1]
5ad7d4480d63974e20c3910e,"This week you should watch Lesson 3, Simulated Annealing, and read Chapter 4 in AIMA (Russell & Norvig). 

Assignment 1: Game Playing
Due: January 28 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 1 is due soon! Please check @57. Note that as per T-Square, the deadline is given as 8AM EST which corresponds to 1AM AoE. We will be honoring the deadline given on T-Square, however, we will switch back to midnight AoE from Assignment 2.

Assignment 2: Tridirectional Search
Due: February 11 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 2 will be released soon. Keep an eye out for an announcement when it is out - we hope for it to be released in the next two days.

Office Hours:
Here is the OH calendar.  

As always, here are the syllabus and the schedule.  

",jc6w44hrp9v2ki,"[{u'text': u'Thank you for sharing this info. ', u'responses': []}, {u'text': u'Please, please keep doing this. This information is supremely useful in keeping organized. Thank you, thank you!
-Q.', u'responses': []}, {u'text': u'Thanks for the info. May I make a request in advance, that the project code is linted before release? Fixing the linting errors before releasing it saves such a lot of unnecessary aggravation (as well as allowing the TA who manages the code, to learn best practices) in what are basically fun projects – thanks for the enjoyment incidentally :-)', u'responses': [u'Yes to this.  The inconsistent use of spaces and tabs ruins the project when imported into an IDE such as PyCharm.', u'I third this. PyCharm really hated the tabing/spacing issue in the code. It also made it really difficult to read. I'd say some of the method naming could have been more clear and consistent too. Example, some places referred to active player and inactive player and others referred to the same thing as legal player and opponent player. This was very misleading as I would expect opponent to always be the person I was playing and not the person's whose turn it wasn't. I think it would have been clearer if it was consistent meaning just active and inactive. Also, wish there were some easier debugging methods to help figure out what was going on. I many times had to print out internal objects and such to see what was going on.

I'd also like to say this project did take a ton of work. However, it was really entertaining and fun. Overall a great project but some minor tweaks could make it easier to work with without taking out the challenge.', u'We're already on it - Assignment 2 should be much better in this regard, and we'll do our best for the future assignments as well. Sorry about the inconvenience.', u'Thank you for hearing. I love it when TA's are working on doing better too. :)', u'Initial git repo code should also be in fact, correct.  There was incorrect code in the git repo for the first project.', u'Thanks Ravi, that's really good to hear. As Eric says, the legacy codebase was a main cause of the difficulty, so the task of making a change to the task for this semester while trying to clean up the legacy code too, would be unenviable. We're not pointing fingers :-)']}, {u'text': u'I just started watching Lesson 2. There is no sound from section 9: Quiz:Tree Search to section 21: Quiz  Uniform Cost Search 4. Anyone facing the same problem?', u'responses': [u'I had some issues with sound while listening with earbuds and realized that there was sound in my left earbud but not the right - any chance that's your issue too?', u'Please set your computer to mono sound or use the left channel.  We brought up the issue with Udacity a while ago, but there was no good solution.  I was hoping they could remix the audio to the same to both channels, but no go so far.  Sorry!']}, {u'text': u'There are six assignments up on the course GitHub repo. Are these assignments from past semesters? Will they be modified extensively for this class? Or would starting to work through the ones that are already up help us get a jump start on the official assignment when it is released? https://github.gatech.edu/omscs6601 ', u'responses': [u'We do have modifications in mind, and the code is also a work-in-progress. I would advise against going through them now. It has the potential to cause more confusion than anything.']}]",,0.0,305.0,267,,Week 4 Announcement,[announcements]
5ad7d4490d63974e20c3910f,"All three submit scripts recognize the flag ""--enable-face-off"". In order to participate in the optional face-off, does this flag need to be present for all three submissions, or only submit_b.py?",jc6w44hrp9v2ki,[],,0.0,185.0,268,I would presume only submit_b.py given that's the one that's required to have the best AI and considered the final portion of the assignment.,Command line flag to participate in the optional face-off,[a1]
5ad7d4490d63974e20c39110,"In my run of submit.py, I accidentally left a debugging flag on in the code. While the AI is still correct with it and I got full credit, it does slow things down slightly.
For my run of submit_a.py and submit_b.py, as well as my TSquare submission, this flag is set to False as intended.
Do I need to rerun the the submit.py so it ran with the exact same source file as the others? Or do only the points count from the submits?",jc6w44hrp9v2ki,[],,0.0,203.0,269,You do not need to run each part with the same source.  You can submit different source modules for each of your three submissions.,Accidentally left debugging flag on in one of the submits,[a1]
5ad7d4490d63974e20c39111,"
Just interested in seeing how much time other people took to develop their final code. I realized implementing it took very little time. Getting it right took a LOT of time.

 [o] Less than 5 hrs
 [o] < 15 hrs
 [o] < 25 hrs
 [o] < 35 hrs
 [o] < 45 hrs
 [o] More than 45 hrs",jc6w44hrp9v2ki,"[{u'text': u'I would have spent more, except that I didn't think it was worth reducing my score to try to go after the last 5% task.  There was enough variability between runs of the same code that with the threat of bonnie becoming bogged down on the weekend that I wasn't willing to risk it.  ', u'responses': []}, {u'text': u'I wonder if the folks who spent less than 25 hours would share their approach in tackling the assignment.', u'responses': [u'I read the book and watched the lectures before starting. After that it was just a programming exercise until 1b, which required some thinking.', u'Same as Zachary. Just read the book and watched the lectures before I started. I spent a good amount of time writing tests. I used the python multiprocessing module to run through a lot of tests faster.', u'Most of my time was stuck debugging code.  My implementation that passed 1b was all just implementing pseudo code.', u'Same boat as Zachary as well. While I was concerned coming out of the gate, in the end having watched the lectures and read the book made the initial parts straightforward after realizing how to do the open move evaluation correctly. 1b was tricky, but the time between submissions gave time for thinking.One of the things in learned from HPC was correctness is critical before you even think about performance']}, {u'text': u'Saw a few polls out there but is there a final score poll now that the assignment is over?', u'responses': [u'Both of the polls allowed for revoting so you can go back and update it to reflect your final score', u'Oh ok, thanks Conor! Just curious. Asgn1 killed me, while some people killed it. So just wanted to see the spread out of curiosity; changes nothing.']}, {u'text': u'Wow. People spent a lot of time on this assignment. Are all the assignments going to require this much time?', u'responses': [u'Glimpsing ahead at the next assignment, I do think it might. But hard to say.']}]",,0.0,229.0,271,,How long did you spend on assignment 1?,[a1]
5ad7d4490d63974e20c39112,"Is it only me or do others find his presentations much clearer and easy to follow?

Plus his voice oozes authority in matters of AI!",jc6w44hrp9v2ki,"[{u'text': u'I've been enjoying all vids so far. But yes, PNorvig is quite impressive, in authority, presentation skills, and height. Haha.', u'responses': []}, {u'text': u'For what it's worth, I found the first section of videos to be really engaging and easy-to-follow as well - some of my favourite Udacity/OMSCS content so far. 

Peter Norvig videos are also interesting, but a funny step back in MOOC time - worse sound quality, lower production values. Buuut, also great content from a seminal thinker in the space.

Overall I think it's great to have multiple lecturers in a course like this - adds variety, caters to different learning styles, and keeps things fresh.', u'responses': []}, {u'text': u'I liked how he presented search algorithms but I found the difference in production value distracting (I kept hearing a krinkling sound in Norvig's lectures) and overall preferred the other lectures.

That said, I agree with Owen. I like having a variety of lecturers in the course.', u'responses': []}]",,0.0,219.0,272,,Peter Norvig,[lesson2]
5ad7d4490d63974e20c39113,"I submitted assignment 1_b late last night and allowed it to run while I went to sleep. This morning the assignment 1 submissions were completely removed from Bonnie and I couldn't see the scores. Is it possible to tell if I obtained the last 25 points or not? In my last OMSCS class, the TAs were able to keep the assignments visible to collect grades but closed submission. Could we do something similar?",jc6w44hrp9v2ki,"[{u'text': u'8 was the same for me.  The other parts are available at:

part 1 (submit.py): https://bonnie.udacity.com/student/course/8/quiz/61part 1a (submit_a.py): https://bonnie.udacity.com/student/course/8/quiz/100', u'responses': [u'For others:

Assignment 2: https://bonnie.udacity.com/student/course/8/quiz/67
Assignment 3: https://bonnie.udacity.com/student/course/8/quiz/72
Assignment 4: https://bonnie.udacity.com/student/course/8/quiz/78
Assignment 5: https://bonnie.udacity.com/student/course/8/quiz/79']}, {u'text': u'Needed this. Thank you guys!', u'responses': []}]",,0.0,257.0,274,"My 1b submissions are visible at https://bonnie.udacity.com/student/course/8/quiz/101; of course the 8 in that URL may vary from student to student, just look at the URL for assignment 3 4 or 5",Assignment 1 score,[a1]
5ad7d4490d63974e20c39114,"Hi,I found this assignment very interesting and challenging. Seeing how the bot improved score against bonnie by small changes make it also fun and competitive.Sadly, I did not beat the 1b part by 65% or more as my biggest win was 60% (1 win shy of passing grade).As I’m taking this course for the learning experience I was wondering if bonnie could be available after deadlines just to keep trying and see if we could finally beat bonnie.I think that will help the learning experience as it won’t stick to only the 1.5-2 weeks of the assignment, meaning that if you don’t make it by then, then you dont not learn how to properly implement a solution.is just a suggestion for those who want to keep trying even without improving the final score set on the deadline.",jc6w44hrp9v2ki,"[{u'text': u'Yes, it would be great if it is available. I was barely able to put in the time to do the first 4 sections (75/100) . I have some ideas that I would like to try for the last two sections , even if there's no credit for that', u'responses': [u'In the same boat here..It's a fascinating assignment, I really hope after the grading cycle of assignment 1 we can try some ideas to fix our bot  and resubmit to Bonnie.', u'I agree.  I didn't beat that last section and want to keep trying', u'I would like to continue as well.']}, {u'text': u'This wouldn't be the same as Bonnie, but maybe the next best option and have a quicker turn-around time. Copy your alphabeta agent with iterative deepening to a new renamed file and have it use the OpenMoveEval function.  Then setup your test file to play against this agent.', u'responses': [u'I used this suggestion when testing my 1b part before submitting and always passed with more than 80%.Maybe the CPU in my laptop was not matching the one from bonnie, or my alphabeta was missing something.Anyways, your suggestion is a good idea as an alternative.Thanks']}]","Thanks for the suggestion. But we will not be able to keep Bonnie active. There are other assignments coming up. Assignment 1 and 2 both consume a lot of processing power. The load of class is also huge. Plus we share the Bonnie resources with other classes as well. I hope you understand. 

If time permits- We can keep it active sometime later in the semester. ",0.0,224.0,275,,Bonnie availability after assignment,[a1]
5ad7d4490d63974e20c39115,"Just out of curiosity, would it have been better from a learning standpoint if we had started of with the chapters on search before going into game playing? 

In a sense they both talk about search algorithms. One on a general problem solving the other on adversarial searching. Trying to understand the rationale on why the lessons where ordered this way

Thanks,",jc6w44hrp9v2ki,[],,0.0,191.0,276,"My guess would be for the thrill value. As the book describes, game playing is the formula 1 of AI; or it was when the 3rd edition was published. Now, it is arguable that self-driving cars & robotics are contenders too",Order of lessons,[lesson2]
5ad7d44a0d63974e20c39116,"For anyone in the DC metro region who lives or works near Reston...
Two of us are going to meet up on Monday Feb 5  at 6:30 PM to discuss the challenge questions and latest course topics. 
http://lakeannecoffeehouse.com/ This is Lake Anne Village Center, 1612 Washington Plaza N

Please reply back if you plan to join so I can grab the right size table/area. Hopefully that evening we can coordinate future sessions as well. If you can't make this session but are interested in others please let me know.",jc6w44hrp9v2ki,"[{u'text': u'I live in the area, work in Herndon and I wouldn't mind syncing up, but I'll be heading out to Seattle on the 4th.', u'responses': []}, {u'text': u'NOVA!  I’ll try to make this...', u'responses': []}, {u'text': u'I won't be able to make this one, but I'll try to make some in the future!', u'responses': []}, {u'text': u'I'll be there!', u'responses': []}, {u'text': u'
Mhh... I'm in Richmond,VA and tempted to attend, I'll leave this open to confirm later this week.

I'll be there

', u'responses': []}, {u'text': u'Do my best to make it as well.', u'responses': []}, {u'text': u'I'll be there too..', u'responses': []}, {u'text': u'Great to see so many people available! Look for the table with the course textbook, I will bring mine and make it visible. If you are not able to make it but want to join in the future please send me an email at sva6@gatech.edu. In the email please include any days that you are NOT available to meet.   -Sandy', u'responses': []}, {u'text': u'Sorry I wasn't able to make it - I JUST got sick and I figured that shouldn't be my first impression on everyone ;)', u'responses': []}, {u'text': u'Hey everyone, two of us had a good meeting this past week. Our next meeting will be Friday Feb. 16 at 6:30 at the Spectrum Center Starbucks. Address is  1857 Fountain Drive, Reston, VA 20190. This is NOT the Starbucks in the Reston Town Center, it's the one by Best Buy and Container Store. This is the last post I'll make on this thread, going forward will just email those interested. So... if you are interested in this or future meet-ups (and have not already emailed me) please send me your email at sva6@gatech.edu', u'responses': []}]",,0.0,176.0,278,,Northern VA study group session Feb 5,[group_study]
5ad7d44a0d63974e20c39117,"

 [o] <= 0.10
 [o] 0.15 to 0.30
 [o] 0.35 to 0.50
 [o] 0.55 to 0.70
 [o] 0.75 to 0.80
 [o] >= 0.85",jc6w44hrp9v2ki,"[{u'text': u'I thought that the number ranges in this poll were incomplete, but then remembered that only discrete win rates are possible for a fixed number of games. It's been a long weekend.... :)', u'responses': []}, {u'text': u'Actually surprised people were able to beat this easily. What were the special tricks required? ', u'responses': []}]",,0.0,229.0,281,,What&#39;s your best winning ratio against K&#39;s Evil Function?,[a1]
5ad7d44a0d63974e20c39118,"Here are the links to all the Challenge questions that are posted till now. We'll keep this post pinned at all times. (Only the more recent challenge questions will remain pinned, older ones can be found here.)

1. Game Playing 
Challenge Question 1 - [solved]: @128 - Minimax and Alpha BetaChallenge Question 2 - [solved]: @188 - Node re-ordering / 3 playerChallenge Question 3 - [solved]: @216 - Expectimax

2. Search
Challenge Question 4 - [solved]: @321 - Grid SearchChallenge Question 5 - [solved]: @387 - Word MorphingChallenge Question 6 - [solved]: @389 - Puzzle8 & Rubik's cube

3. Optimization Algorithms
Challenge Question 7 - [solved]: @452 - Hill ClimbingChallenge Question 8 - [solved]: @466 - Simulated AnnealingChallenge Question 9 - [solved]: @474 - Genetic Algorithms
4. Constraint Satisfaction Problems
Challenge Question 10 - [solved]: @497 - SudokuChallenge Question 11 - [solved]: @523 - Menu CSPChallenge Question 12 - [solved]: @541 - Futoshiki

5. Probability
Challenge Question 13 - [solved]: @591 - Disease TestingChallenge Question 14 - [solved]: @597 - Deck of CardsChallenge Question 15 - [solved]: @599 - Lottery

6. Bayes Net
Challenge Question 16 - [solved]: @620 - D- SeparationChallenge Question 17 - [solved]: @628 - Cough & ColdChallenge Question 18 - [solved]: @632 - More Practice

7. Machine Learning
Challenge Question 19 - [solved]: @633 - No Free LunchChallenge Question 20 - [solved]: @634 - k-Nearest NeighborsChallenge Question 21 - [solved]: @635 - Decision TreesChallenge Question 22 - [solved]: @636 - XOR


     ====================
     ===== MIDTERM ======
     ====================

8. Pattern Recognition Through Time
Challenge Question 23 - [solved]: @1037 - Dynamic Time WarpingChallenge Question 24 - [solved]: @1043 - HMMsChallenge Question 25 - [solved]: @1054 - Viterbi Trellis

9. Logic & Planning
Challenge Question 26 - [solved]: @1171 - Logic MapsChallenge Question 27 - [solved]: @1176 - Logic Spies

10. Planning under Uncertainty
Challenge Question 28 - [solved]: @1205 - Value IterationChallenge Question 29 - [solved]: @1206 - Policy IterationChallenge Question 30 - [solved]: @1207 - MDPs

BONUS
BONUS 1 - [solved]: @1208 - Triplets, D-Separation (BAYES NETS)

#pin",jc6w44hrp9v2ki,"[{u'text': u'Can you add the links for the solutions here too?', u'responses': [u'Hi Brett, we want to encourage you to first try the challenge questions on your own before going to see the solutions. Posting the solutions here would do the exact opposite!']}]",,0.0,316.0,283,,Challenge Questions Megathread,[challengeqtns]
5ad7d44a0d63974e20c39119,"adding a link to the original thread (which should have been in this folder..)

@242",jc6w44hrp9v2ki,[],,0.0,176.0,285,,Study group - northern Silicon Valley area,[group_study]
5ad7d44b0d63974e20c3911a,"
Setting up Gradescope (So you can submit your midterm & final)
PLEASE READ THIS CAREFULLY AND FULLY BEFORE PROCEEDING.
Hi everyone! Like last semester, we will be using Gradescope for grading both your midterm and final because it allows us (the TA's) to grade the exams quickly and you can see the feedback through your accounts. Your midterm and final will be open book, open note and will be uploaded as a pdf to Gradescope. Since we have to comply with FERPA regulations, we have some guidelines/steps on how to create your account.


Go to 10MinuteMail on one tab (tab #1)

Using the email you see, create an account on Gradescope on a different tab (tab #2).

Please do not use your actual name or student id in the fields when signing up. Use something else, type random letters, pick your favorite character, Gradescope will accept it.

The entry code is: 94PWP6


Gradescope will send a verification email to the 10MinuteMail tab (tab #1).
Open the email and click on ""set your password"" in a new tab (tab #3)

Set your new password and you're good to go! You should see CS 6601 AI Final under SEMESTER YEAR.  Write down this information for later, you'll need to log in again when submitting your exams.


Now go to T-square and complete the assignment named Gradesope. Please read the instructions on how to submit the assignment on T-square very carefully. 

A couple of notes:

This should all take maybe 5 minutes total but 10MinuteMail does have the option to increase the time limit if needed (the two arrows in the 2nd circle).

If you don't want to use 10MinuteMail, you can use a personal account but we ask that it's not your gatech account or any email that is identifiable (like billgates@gmail.com).

Please don't create multiple gradescope accounts. Once you've successfully created a Gradescope account, submit your info on T-square immediately.

If 10MinuteMail doesn't work, use Nada (https://getnada.com/) instead.

If you are auditing this class, please let me know immediately so that I keep track of you!


Deadline: the day before the midterm opens (March 4) Anywhere on Earth.  Midterm is Mar5-11.

If you do not submit to Gradescope, we will not be able to grade your exam. Please don't make us send you constant emails reminding you to sign up (we had to do this last semester).
IMPORTANT: SAVE YOUR GRADESCOPE LOGIN INFORMATION


",jc6w44hrp9v2ki,"[{u'text': u'I can't paste my e-mail or password into the T-Square submission text box. Is this a known issue that they disable copy/paste? I had to manually type in the randomly generated e-mail and then my randomly generated password.', u'responses': [u'

Press the highlighted icon, a new window should popup. Paste your content there. I have tested on Chrome and it works fine.', u'I got that too, just type enter, then paste, then delete the <return>  that you had typed', u'For anybody else having issues: Chrome and Safari were not helping, even using the paste popup suggested above. The text box seemed to be completely disabled. I was able to paste directly into it using Firefox though. Oddly enough, the paste popup icon was not enabled. ', u'When I click the icon highlighted above, an input box appears. After I paste the email and password, clicking 'OK' doesn't do anything. I'm in Chrome. Anyone else having this issue?', u'I have chrome 63 and I too had a to use the paste popup.

I also found that I could not TYPE anything in the submission box. 
When I log in to Buzz Port, and click on the T-Square link, it opens in the same tab underneath the Buzz Port menu. 

I found that opening T-Square in another tab would allow me to type in the submission box.

', u'I used Firefox. none of the other browsers worked for me', u'FYI, I also found I needed to directly navigate to t-square.gatech.edu (not link from buzzport, as mentioned by Stanton), go to this class, then the ""plain text paste"" trick Sumeet mentions above, to be able to submit this.Was able to use Chrome this way.', u'It worked for me using the ""source"" icon.']}, {u'text': u'Incidentally, how is it more FERPA compliant that we need to type our passwords into t-square that then sends us an email containing the password – thanks! As I tend to think when some plums do that, luckily the moment I noticed I was putting my password into t-square I had changed it to a less 'reusable' password type – compared to simply linking the gradescope accounts many of us have already that are linked to our @gatech.edu email addresses?', u'responses': [u'The FERPA compliance has to do with the fact that Gradescope is not linked to your gatech account. To link the two would be to give Gradescope information on your  grades, which is in violation of FERPA.', u'Ah no, Noah, that's simply wrong. Firstly Gradescope is FERPA compliant itself https://gradescope.com/tos
You authorize Gradescope to access and process Student Data solely for the purposes of providing the Service, as an outsourced institutional function pursuant to FERPA 34 CFR Part 99.31(a)(1). As between Gradescope and School or Teacher, School or Teacher owns right, title, and interest to all Student Data you provide or otherwise make available to us, and Gradescope does not own, control, or license such Student Data, except so as to provide the Service described herein. You acknowledge and agree that, as between the parties, you are solely responsible for any and all Student Data, whether provided by Teacher, School, Student or any other third-party.Secondly, as a matter of fact, Georgia Tech now has an institutional subscription with Gradescope allowing for canvas integration too

Maybe you should tag prof. Starner as I'd be happy to share the details with him in private', u'The issue is with the fact that the College of Computing takes time to verify FERPA compliance - which means that as far as CoC is concerned, Gradescope isn't FERPA compliant until they verify that it is.
This is the solution that works until that time, and the one that satisfies our administrative needs best.

You can still make a private post for the instructors, and Prof Starner will have a look at it.', u'I could write him an email, it's not specifically my problem though, is it? I think you could invite him to chime in on a matter of communal concern; should it so happen that he publicly shows interest in having the actual facts put before him, I'm happy to do so.

Personally I had been giving you the benefit of the doubt that the reason for using the somewhat dodgy Rube Goldberg system was for anonymous grading – that gradescope does not support yet – though now that I've heard your side then I'd tend to say when you're in a hole, stop digging & call for assistance :-)', u'I asked you to make a post/mail since you said you'd like to share the details in private. He's always open to suggestions on how to improve anything related to the course and makes changes each year (like the office hours link, which didn't work as well as we'd hoped). But the truth is that he knows the facts stated so far. More on this below.

Also, anonymous grading is definitely a part of the reason why we use temporary email. If it was purely a matter of not being able to link the information to your student records, we would've asked you to use personal email IDs.

I have spoken about the situation in my reply to Cory's follow-up below as well. We know they're FERPA compliant but our hands are tied until it's approved. We're doing our best in that regard. It's not something you'd get to see until it's actually fruitful, I'm sure you understand that.', u' 
<watches the digging>
right, whatever, suit yourself
</watches the digging>']}, {u'text': u'I signed up on Gradescope using 10MinuteMail ID, It sent me a url on that email immediately which I clicked to set my password and finally I submitted the details in T-Square. However It's still showing In-Progress. Does it mean I am done here with setup?

Also an advice to get copy/paste work on T-Square. I did right click on text area and clicked paste, It did open a Pop-up windows where I was able to paste the email id and enter other details , which got delivered to main text area soon after I clicked ok.', u'responses': []}, {u'text': u'I'd like to understand why you need my password for the site.   This makes it very hard for you to claim that the work that was done on the site was done by me -- anybody with access to that data could have logged in as me.   What does having the password do to help since I should be connected to the class by entering the course entry code and just having the email associated with the account should be sufficient to connecting the account to me in your backend.', u'responses': [u'Every semester we have a few people who forget their password, and going about retrieving everything is incredibly time consuming (more so then you would guess), especially since we aim to receive, grade, and return everything in the span of 48 hours. We ask for the password not because we ever need to log in as you, but because inevitably, someone, even with the best intentions, loses their password. What you've brought up is something we have discussed in length as well.

There is also the case of bad intentions as well. ""I forgot my password"" can be an excuse made by people who submitted late or did not submit and want to submit a day late. It happens. And this prevents that from being an issue we run into.', u'I wont forget my password (it's already recorded in several locations which are backed up in several locations).   I'll accept the risk that if I do I won't be able to use it as an excuse as to why I did not turn in my midterm or final on time (though this would be less of an issue if you didn't push hard on using disposable emails for registration).

I don't like giving out a password to an account that I have accepted a terms of service for.  I can't enforce/protect the use of that account to remain within the terms of service if I give out the password to others.

So this all becomes moot if I just give you a fake password.... your tool works... my comfort is met... everyone is happy (unless all of the many copies of the password that I have made go awry and I'm unable to re-establish connection to my account on gradescope -- in which case I'm the only one who suffers for my own stupidity).', u'That' fine Conor. We just want to make sure you don't forget your password. ']}, {u'text': u'How does this exam process work. Should we sit in front of computer(monitoring) during the exam and finish it with in specific time(3 hours)?', u'responses': [u'Nope, you will have the full time, from when the exam is publish to when it closes, to work on it. No time limit at all.']}, {u'text': u'For a course in the #3-ranked computer science school in the world, this is extraordinarily unprofessional. Is this ""sign up with a fake email and email us the password"" policy okay with the department? Or do they not know?', u'responses': [u'Hey Cory,
It's the policy that best suits our administrative needs. The reasons for this are explained in the other followups. Please bring it up with David White and with Prof. Starner looped in if you wish to raise a complaint on this - people are aware of this workaround and we are trying to get Gradescope approved as soon as possible.']}, {u'text': u'I already have a Gradescope account that I created last semester for CS-8803 Graduate Algorithms. 
I signed up using my slee###@gatech.edu email address and my student id as slee### from the email address.

Do I need to create a new account?

Why was this OK last semester but it is not OK this semester?

Can't I just add this course using the entry code?

', u'responses': [u'FERPA regulations prohibit us from sharing personally-identifiable information with third parties such as Gradescope. Using an account registered to your GATech email would be in violation of those rules. Hence we have this system in place each semester.

We would recommend that you create a new account.

Please refer to Noah's answer above.', u'Ravi, Noah's answer is wrong', u'Please refer to my answer above.']}, {u'text': u'
Can I use my GradeScope account from last semester?  I'm repeating this class...

Please let me know, thanks.
', u'responses': [u'@Sumeet Jain  ', u'No, you have to make a new account
', u'Okay, thanks...
']}, {u'text': u'There seems to be an issue w/ mail delivery right now from Gradescope.  I've had to hit the refresh-for-another-10-minute button twice, still have not received the email.  I still have the Gradescope request screen up and made sure my copy-paste was correct.  Hopefully it comes through soon, but a heads up for those who may just now be doing this like me...', u'responses': []}, {u'text': u'My apologies for not reading the instruction carefully, but I used my GT email incidentally.

What should I do? Should I just create another account with 10minemail?', u'responses': [u'Yes. Also, please pm me your gt email id.', u'Thanks, I made a private post for you.']}, {u'text': u'is 10minemail working for anyone? it is keep loading in my browser. Tried different browsers, same issue.', u'responses': [u'Same here. Looks like it's down?', u'It wouldn't work for me, so I used Nada (https://getnada.com/) instead (listed under Notes as another option).']}, {u'text': u'Why don't you just create a bunch of fake accounts and send each of us the login details for one of them?', u'responses': [u'That's pretty smart. Actually, in my other classes it doesn't matter that we use our Gatech credentials for gradescope. Go figure..', u'if I remember correctly, the confirmation process makes that option not possible.']}, {u'text': u'Oops, terms of service do not allow us to use fake names, etc.


', u'responses': [u'This is what concerned me. Most ToS specifically reject anyone using a services under fake names, false emails, etc. Gradescope certainly does. As noted above, https://gradescope.com/tos specifically states:

You agree not to engage in ... hiding or attempting to hide your identity

Yet, you've specifically forced us to hide our identities. I'm really not comfortable with this at all and I've been hoping a response would be posted to the comment above before the deadline but there's been nothing and time has run out.

First, violation of a website's terms of service is a breach of contract in most jurisdictions (yes, I'm an attorney by day -- so I do mean this and I do take it seriously).

Second, some jurisdictions might even consider it Computer Fraud and Abuse Act violation (or similar local jurisdiction statutes). The Ninth Circuit seems to say no ( https://www.eff.org/deeplinks/2018/01/ninth-circuit-doubles-down-violating-websites-terms-service-not-crime ) but GT and myself are both in the 11th. I don't think the 11th has ruled on the issue yet, but to be completely honest I haven't checked and until SCOTUS weighs in, it's still an open issue Federally -- not to speak of local jurisdictions.

I've just gone ahead and signed up because there's no other way to take the midterm apparently but I sure hope you all had this vetted by GT's legal team because I'm sure as hell not comfortable with it at all. 

It doesn't pass the smell test one bit in my opinion. I was hoping someone would respond to this post from 12 days ago with a reasonable answer but at this point, I can't wait any longer.

Best regards,
Tyler', u'This issue should be resolved next semester as Gradescope is in official trials right now by GT.  At the beginning of the semester we did not realize that there was a new agreement that would take hold in time for the midterm.  

I have not been pleased with this situation at  all ... administrivia kept us from doing what is right and most easy for the students. Our alternative, until recently, was using tsquare for the same purpose, which students have found to be buggy and would delay us getting grades back to students by about a week.  It would also make regrades almost untenable with a class this size.

Another option we had was a combination of proctortrack and tsquare.  That was a pretty hideous experience, and I had a moral objection to requiring students to show their ID and PII on video on a platform that I had not verified was secure nor followed a Privacy by Design framework. (I am happier with there privacy aspect now, but it is still buggy and a bad experience).

SOoooo,. we chose the lesser of evils.  The Gradescope people have worked with me personally and were quite sympathetic to the situation. 

There are options you have personally, of course. We just could not officially be seen to support them. Thus, I am still not discussing them on an open forum, but they are pretty obvious and simple and have already been followed by some students in private posts to us.

Of course, the anonymous grading is a plus, so the current system does have some benefit.

Again, the issue should go away next semester.', u'Let's be fair, too, you studiously ignored my accurate warnings at the appropriate time']}]",,0.0,376.0,287,,IMP: Setup Gradescope Account (nessesary to take Midterm &amp; Final),"[midterm, final, gradescope]"
5ad7d44b0d63974e20c3911b,Anyone in the St. Louis area taking this class and want to form a study group?,jc6w44hrp9v2ki,"[{u'text': u'Same state, but I'm afraid that's about 4hrs away from me... :/', u'responses': []}]",,0.0,144.0,291,,Study group - St. Louis Area,[group_study]
5ad7d44b0d63974e20c3911c,I'm forming a study group for anyone located in Atlanta. Feel free to respond with your GT email and I'll coordinate :),jc6w44hrp9v2ki,"[{u'text': u'hbindra3@gatech.edu', u'responses': []}, {u'text': u'consult.karthik@gatech.edu', u'responses': []}, {u'text': u'aruth3@gatech.edu', u'responses': []}, {u'text': u'myerger3@gatech.edu', u'responses': []}, {u'text': u'henryw@gatech.edu', u'responses': []}, {u'text': u'Contacted each of you via email! Excited to connect and kick things off :)', u'responses': [u'Hi AJ,
I did not get an email, can you please try consult.karthik@gmail.com']}, {u'text': u'pkhu@gatech.edu sorry I'm a little late.', u'responses': []}, {u'text': u'A little late, but abella@gatech.edu
', u'responses': [u'Hey Christopher, I just sent you a slack invite to our group. ']}]",,0.0,148.0,293,,Study group - Atlanta,[group_study]
5ad7d44c0d63974e20c3911d,"Assignment 2 is now live and active on Bonnie. You can find the git repo here.

Please read the readme thoroughly. Everything you need to know is in there.

For this assignment, you are allowed two submissions every thirty minutes.

Assignment 2 contains a chance for bonus points (which will be added to your assignment 2 score) in which your algorithm will race against your fellow peers' algorithms through the streets of Atlanta! This is not live yet, but will be turned on within the next few days.

I will be hosting an hour long Youtube Live event this Thursday at 8pm eastern time to go over the assignment and take any initial questions you might have.

Best of luck!
-Noah

",jc6w44hrp9v2ki,"[{u'text': u'Thank you!', u'responses': []}, {u'text': u'Exciting !', u'responses': []}, {u'text': u'Are there any restrictions on packages e.g. numpy? Or is it just base again?', u'responses': [u'Stick to just pythons standard library. No imports, such as numpy, will be supported.', u'Just an FYI, Numpy is a requirement of Matplotlib, which is including in the assignments requirements.txt and thus is installed during initial setup.', u'So we can import numpy as an extra package to use or it's only allowed as a requirement for matplotlib? And of course, importing math is fine right?', u'In regards to Numpy, they answered that above. Math is part of the standard library, so, yes, importing it is fine.']}, {u'text': u'The date's (year) off on the Readme, but I assume we all know the correct date/year.', u'responses': [u'It's that time of year were I write last years date half the time. Thanks for the catch :D']}, {u'text': u'Is there a record for the Youtube Live on Thursday? Cause it may not be a good time for me...', u'responses': [u'Yes, it'll be recorded. ']}, {u'text': u'sudo ip install -r requirements.txt explodes...


', u'responses': [u'That's a local issue on your end.', u'You're running OSX yeah? This is an issue that has happened recently with Python:

http://marcelog.github.io/articles/mac_osx_python_pip_install_operation_not_permitted.html

Basically my understanding (residual from when i grappled with this a while ago) is that a OSX security upgrade eliminated the ability to write to certain folders that it expects to be able to.

Suggest trying VirtualEnv: http://docs.python-guide.org/en/latest/dev/virtualenvs/']}, {u'text': u'Is Assignment 2 up? I don't see a the entry in T-Square.', u'responses': [u'The git repository is available.']}, {u'text': u'Regarding the note about grading:

We will provide some margin of error in grading the size of your 'Explored' set, but it should be close to the results provided by our reference implementation.

Is it only the size of the explored set that we are being graded against? Are there time restrictions? Must the shortest path (when applicable) be returned, or any path found that connects the start and goals be acceptable?', u'responses': [u'All of the algorithms we ask you to implement are, if implemented properly, guaranteed to find the optimal path. So yes, we expect the optimal path. The race is an exception.

There is a timeout of 30 minutes per run (as well as two submissions allowed per 30 minutes) but most people's code runs in a fraction of that time. Mine took less than a minute to finish.

The purpose of grading against the explored set is to make sure you aren't implementing some other brute force algorithm and returning the answer found there. This helps us make sure you've actually implemented A* when we ask you to. The margin of error allows us to have trivial differences, such as whether you use a > or a >= in certain comparisons, or how you order ties (both of these are common issues you come across in these kind of algorithms.)

I hope that clarifies your question.s', u'And the explored set is something your code tracks. We don't have to return it. Is that correct?', u'Correct']}, {u'text': u'What is The Race? Could there be more description of this?Is it based on shortest path or fastest search?
Is it between 2 points, or is it a tridirectional search?

A lot more detail here would help to clarify what our custom search is intended to do.', u'responses': [u'I'll make a post expanding on this when we release it late this week. I'll try to discuss it during the youtube live session as well.']}, {u'text': u'What is the link for the youtube live session?', u'responses': [u'I'll make a piazza post about that shortly before it starts.']}, {u'text': u'Installation issues...
I run pip install -r requirements lot installs but I get this error:
  Found existing installation: six 1.4.1
    DEPRECATION: Uninstalling a distutils installed project (six) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.
    Uninstalling six-1.4.1:
Exception:
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/req/req_set.py"", line 778, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/req/req_install.py"", line 754, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/utils/__init__.py"", line 267, in renames
    shutil.move(old, new)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 302, in move
    copy2(src, real_dst)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 131, in copy2
    copystat(src, dst)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 103, in copystat
    os.chflags(dst, st.st_flags)
OSError: [Errno 1] Operation not permitted: '/var/folders/ml/_pjwychj1n1bzbt95vqx699r0000gn/T/pip-tBRl8R-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info'

Also, after this I try running unit test I get assuming because of the failed netorkx import which I am guessing isn't getting installed due to the requirements.txt not running cleanly:
Launching unittests with arguments python -m unittest discover -s /Users/brett_yerger/ai/AIassignment_2 -p search_unit_tests.py -t /Users/brett_yerger/ai/AIassignment_2 in /Users/brett_yerger/ai/AIassignment_2
ErrorTraceback (most recent call last): File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/case.py"", line 331, in run testMethod() File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 32, in testFailure raise exceptionImportError: Failed to import test module: search_unit_testsTraceback (most recent call last): File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests module = self._get_module_from_name(name) File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name __import__(name) File ""/Users/brett_yerger/ai/AIassignment_2/search_unit_tests.py"", line 7, in <module> import networkxImportError: No module named networkx

Ran 1 test in 0.001s
FAILED (errors=1)
Process finished with exit code 1
', u'responses': [u'run into the same issue on my mac (:sad) ditched mac and went on linux - it worked', u'Got it working on windows by reinstalling python. Mac issue still exists.', u'Anyone able to get around this on macs?', u'This works for me on a Mac using brew:

brew install python   # this is a new laptop, so didn't have brew's python on it yet
pip2 install -r requirements.txt', u'So, you are saying reinstall python with brew? ', u'I have reinstalled python twice, I have run pip pip2 as both myself and sudo and sudo -H but no matter what I do I still get the following trying to uninstall six...

Exception:
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/commands/uninstall.py"", line 76, in run
    requirement_set.uninstall(auto_confirm=options.yes)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/req/req_set.py"", line 346, in uninstall
    req.uninstall(auto_confirm=auto_confirm)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/req/req_install.py"", line 754, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pip/utils/__init__.py"", line 267, in renames
    shutil.move(old, new)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 302, in move
    copy2(src, real_dst)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 131, in copy2
    copystat(src, dst)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 103, in copystat
    os.chflags(dst, st.st_flags)
OSError: [Errno 1] Operation not permitted: '/tmp/pip-5fASfT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info'


', u'I had zero problems with a Mac installation - easy solution is just to use Virtualenv.

http://virtualenv.pypa.io', u'https://github.com/donnemartin/haxor-news/issues/54', u'I'm assuming that since there has been no followup, the issue has been resolved.', u'sudo pip install matplotlib==2.0.2 --ignore-installed six

This works for me.', u'thanks for the suggestion @Owen Scott . I'm om mac, was having these issues, and Virtual Env works for me', u'Sorry, I should have posted as I did in another thread.
I got passed it by passing --user to the install. None of the other solutions worked for me.
']}, {u'text': u'I posted a question that doesn't fit in this topic, and now I can't figure out how to delete this post.', u'responses': [u'You can't delete posts.']}]",,0.0,356.0,294,,Assignment 2 Released,"[a2, announcements]"
5ad7d44c0d63974e20c3911e,"Discussion thread for Assignment 2's warmups.

",jc6w44hrp9v2ki,"[{u'text': u'For Warm-up 1 (Priority Queue), the hint says: "" The heapq module has been imported for you. Each edge has an associated weight."" I assume heapq is meant as an example to reference, not for us to use, correct? The reason I ask is because the comments in the code template ask that we prioritize by max weight. The heapq is a min heap, not a max heap.

Nevermind. I misinterpreted the comments.', u'responses': [u'Please share.  I was confused as well, do they intend for us to use heapq?', u'I imagine they do, since they imported it for us. By no means are you required to use it, but it sure seems like a good starting point.', u'I'm a little confused too. It's just a couple lines of code to fill in the methods if you leverage heapq. Was that what the hint was suggesting?', u'I took the hint to mean to read the section about priority queues in the heapq documentation. It addresses requirements that heapq alone cannot satisfy in a priority queue.', u'Are we able to use the heapq remove implementation that the docstring links to in the python docs?', u'Yes, you can use the heapq to implement the Priority Queue. If used properly, you'll find your priority queue code is quite succinct.', u'@Noah Bilgrien one other question: The O(1) and O(logn) performance requirement in the instructions is for push and pop. Correct? The remove by index method can be O(n) I'm hoping...', u'Just to clarify. The heapq docs linked in the assignment have a code implementation of a priority queue. Are we able to use this implementation?', u'just to clarify PriorityQueue.append should accept a tuple (priority, value). Is it correct?', u'Yes Alex.

The def __contains__(self, key) method gives it away by checking to see if the key passed into the function is equal to the 2nd element of the queue.

        return key in [n for _, n in self.queue]

A list of size 2 might work as well', u'thanks', u'The pop() method documentation implies the priority queue should return the highest priority, while the test case expects pop to return the lowest.

Any official word which is correct?', u'You misinterpreted the comments just as I did. The highest priority does not mean the highest weight. The highest priority is the node with the lowest weight.', u'Thanks Brett, it's not the most clear wording.', u' ""The heapq module has been imported for you. Each edge has an associated weight."" Based on this hint, i used heapq inside PriorityQueue and it passed the bonnie test. But i had to do was just alter two functions in PriorityQueue class with heapq methods. Is it right or am i doing something wrong?', u'anyone passed Bonnie test Priority Queue implementation with remove node? I passed Bonnie test without Remove implementation. But the local tests always appends same node with different priority. With remove node implementation , it always overrides if there is existing with the same key. Should i have simple PQ implementation pass bonnie test and separate full PQ with removal implementation for UCS?', u'I did pass. You need to check at the time of append whether the same node with different priority exists. In the UCS example the path F-B with 450 cost will be already there in the queue. when checking whether the new cost of path to B is lower than existing is to be seen and if yes, remove the existing F-B off the queue and then add the P to B (being lower cost). I passed UCS also with bonnie. used iteration.

Find the answer for the instruction  ""the data structure you implement should have an amortized O(1) insertion and O(lg n) removal time""and you would have done it. (it took me a full 2 days to comprehend but  in reality it is a very simple maneuver). ']}, {u'text': u'For Warm-up 1, the comments mention that the remove function may be used in uniform-cost search, but, if we don't use it in its current implementation, we're free to redefine it as we see fit? In other words, I can modify the function parameter data type from an integer to an object if I wanted to?', u'responses': [u'You can just create a new function within the class if you wish to do so and use that in your UCS ']}, {u'text': u'Am I just really bad at math, or do the straight line distances not match up with the numbers in the udacity lectures (a* search heuristic)?', u'responses': [u'ok, math is right, but looks like the different numbers in the assignment don't affect admissibility or anything. resolved.']}, {u'text': u'Warm-up 2..says its BFS, but we need to return a path. What is considered as best path? Least number of nodes, lowest total cost (sum of weights)?
At moment I am assuming we need to take into account weights, thus use an algorithm that is based on BFS, i.e. something like Djikstra?', u'responses': [u'The submission test for BFS does not give you any weights. The best path is the path that reaches the goal first (the fewest number of nodes).', u'BFS always gives you shortest path since it explores the tree level by level.', u'I think BFS is implemented correctly, including the optimization mentioned in lecture. All the local tests pass and the graph looks correct but I keep getting this response from Bonnie and I'm not sure what it means. Any clarification on what the requirements are regarding the explored set, frontier, path returned?
""Breadth first search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum""
', u'I think the breadth_first_search() need a clarification there,because after viewing the graph,I find there are 2 routes at least could be returned as the list for the BFS result via  ""the fewest number of nodes"" approach.So I doubt if this guess is OK,because in that case we may have to return 2 lists as the path.

The note for the function is as below:
def breadth_first_search(graph, start, goal):    """"""    Warm-up exercise: Implement breadth-first-search.    See README.md for exercise description.    Args:        graph (ExplorableGraph): Undirected graph to search.        start (str): Key for the start node.        goal (str): Key for the end node.    Returns:        The best path as a list from the start and goal nodes (including both).    """"""

So please @Noah Bilgrien or anyone who has a better answer,please give a hint. Thank you in advance.', u'@Chenxi Yu

I'm right there with you. I'm failing a local test even though my BFS is returning a valid path from the start to the goal that is the same size as what the unit test is looking for. ', u'@Jim +1 to your question, I got the same result, maybe is a bonnie error?', u'This thing is killing me, it's so embarrassing, I can't seem to pass the test and I could swear I have things right, what could I be missing, I tested the path for each goal and I think these are right, what could I be missing?

I wrote a unit test that checks the path for each node starting from 'a'...

('a', ['a'])

('z', ['a', 'z'])('s', ['a', 's'])('t', ['a', 't'])

('o', ['a', 's', 'o'])('f', ['a', 's', 'f'])('r', ['a', 's', 'r'])('l', ['a', 't', 'l'])

('m', ['a', 't', 'l', 'm'])('c', ['a', 's', 'r', 'c'])('p', ['a', 's', 'r', 'p'])('b', ['a', 's', 'f', 'b'])

('u', ['a', 's', 'f', 'b', 'u'])('g', ['a', 's', 'f', 'b', 'g'])('d', ['a', 's', 'r', 'c', 'd'])

('v', ['a', 's', 'f', 'b', 'u', 'v'])('h', ['a', 's', 'f', 'b', 'u', 'h'])

('e', ['a', 's', 'f', 'b', 'u', 'h', 'e'])('i', ['a', 's', 'f', 'b', 'u', 'v', 'i'])

('n', ['a', 's', 'f', 'b', 'u', 'v', 'i', 'n'])', u'Ah, finally... rtfm ... The readme states: ""If your start and goal are the same then just return [].""

Therefore

('a', [])', u' I think the breadth_first_search() need a clarification there,because after viewing the graph,I find there are 2 routes at least could be returned as the list for the BFS result via  ""the fewest number of nodes"" approach.So I doubt if this guess is OK,because in that case we may have to return 2 lists as the path.
 
The note for the function is as below:
def breadth_first_search(graph, start, goal):
    """"""
    Warm-up exercise: Implement breadth-first-search.

    See README.md for exercise description.

    Args:
        graph (ExplorableGraph): Undirected graph to search.
        start (str): Key for the start node.
        goal (str): Key for the end node.

    Returns:
        The best path as a list from the start and goal nodes (including both).
    """"""
 Let me make it clearer here.

As it was in the test case,""a"" and ""u"" are the start and goal node respectively.
There,we can do it by a-c-p-b-u   OR   a-s-f-b-u,
And they are of the same length.
So which one should I return or should I return both?

Please instruct!. Thank you.
', u'Chenxi, if you return ['a', 's', 'f', 'b', 'u'], you will be good.', u'Just notice that the unit tests are simply a student contribution from a couple of semesters back, nothing too 'guaranteed'. So as, in fact, it'll be comparing the results of a bidi search with your BFS results, sometimes the actual nodes may differ locally.', u'bfs. stuck with the same 'Nodes explored should be from a valid frontier and should be kept to a minimum'. As far as I understand the issue is that some nodes are visited few times. I double checked it looks like I'm tracking already visited nodes and current frontier nodes. Are any things which I'm still missing?', u'Same here,No idea...', u'@Carlos,I have returned the  ['a', 's', 'f', 'b', 'u'] at the local machine and this has yet passed Bonnie, have u passed Bonnies with that result locally at the same set starting from ""a"" and ending at ""u""?', u'Yes, I passed Bonnie with the test cases above.', u'@Carlos,have it happened to you that you returned the  ['a', 's', 'f', 'b', 'u'] at the local machine and yet failed by Bonnies?
I am just stuck here with the feedback  'Nodes explored should be from a valid frontier and should be kept to a minimum'.', u'I finally figured out what this was. For others struggling with this. It isn't mentioned anywhere that I saw but you need to implement a strict FIFO queue for BFS to break ties. You can't just use a PriorityQueue based on cost that randomly orders equal costing nodes. I think this could be made more explicit in the documentation and instructions. But that's what ended up solving it for me. ', u'Probably it will be useful to somebody (about 'Nodes explored should be from a valid ...'). I had FIFO frontier but my issue was that I hadn't added optimization described in 'Breadth First Search 5' video.', u'Thank you,but I need more push,I think.
I have double checked everything and observed mine returns the list via the FIFO rule once a solution is reached.
But it just has ""'Nodes explored should be from a valid ..."" all along.', u'what confused the most is that when my bfs on the unit test, the test case reference is  ['c', 'r', 's', 'f'], mine is with  ['c', 'p', 'b', 'f']
and it claimed ['c', 'p', 'b', 'f'] != ['c', 'r', 's', 'f'] and believe mine as wrong,however I observed that ""r"" actually comes late,so it ought to be disregarded.

Am I right?', u'Chenxi, 

Don't trust the unit tests. My BFS fails local unit tests, passes Bonnie', u'Thank you,Anthony,I just got it working and the unit test for this one is not reliable.Yet,and simply that took away 4 hrs of my life.Anyway, :)', u'So is the answer that unit tests are not reliable?...

BFS uses the shortest path. If two paths have the same length, what should be our tie breaker? 
 
Using FIFO as the tie breaker does not seem to be sufficient for passing all unit tests and my current understanding is that weights are not used with BFS.', u'Just paying extraordinary attention to the lecture's psudocodes will work.', u'can we store time.time() in the node to break ties???', u'@Saalis
I'm keeping an entry count, so keys are really (key, count). When the keys are identical the first to be entered (lower count) wins.', u'Don't get mislead with ""OK"" in unit test.  It says ""OK"" even if you return empty list. Visually check the map whether you have the right path.', u'I like to share few of my learning

1. Return empty list when start == goal
2. use FIFO
3. Check frontier before add into FIFO ', u'Watch the videos again.
If already expanded don't expand again(a,s,f,b) depth of b is 3.
in  (a,s,r,p,b), b is depth 4. Hence the path a,s,r,p,b will not be taken by the bfs.
if it is UCS then it is different. you remove an entry in the frontier (PQ) with the lower cost entry and you will change the frontier entry of ""b"" from (450,b) to (418,b).
Remember only when you pop the goal off the frontier, the goal is reached not when adding to the frontier', u'I was also receiving the error: ""Nodes explored should be from a valid frontier and should be kept to a minimum"" and corrected it by adding the optimization mentioned in the ""Breadth First Search 5"" video.', u'@Piers Thanks. Actually, I already figured that out already that count could be a better alternative than time.', u'I could have saved hours if I read through the instructions on git for BFS. Now I practice that for the rest of the assignment.']}, {u'text': u'Are UCS and A* meant to use the graph weights for g(n)? Or are these meant to be euclidean distance between states? It seems like euclidean distance is meant to be used for h(n) in A*, but not sure about the step costs for g(n). The weights and euclidean distance between two states don't seem to be the same, and it is unclear which is intended.', u'responses': [u'You're assuming that the path cost between any two places should be the straightline euclidean distance, which is a false assumption.', u'In the lecture that appeared to be the case. What would the correct assumption be in this case? That the edge weight is the path cost? I don't see this specified anywhere.', u'The edge weight between a node a and b is the path cost between a and b.', u'Thanks.', u'The A* search videos very clearly explains the concept. 
You can check by graph[start][end]['edges'] which is the actual distance between the start and end points of an edge.']}, {u'text': u'It's asked in a resolved thread above already, but just to make sure it gets answered: I've used the priority queue implementation from the heapq docs as a template before. Is that allowed here, or will that raise plagiarism flags? Would of course cite the source in a comment.

Related: Can I use my own implementation of A* or other algorithms (from previous OMS CS classes) in 6601? I can't imagine this is a problem, but best to be sure.', u'responses': [u'Yes, this is fine.', u'I've also sued a similar implementation to the heapq documentation. My A star works fine , but the Priority Queue tests fail because I am enforcing uniqueness in my priority queue.  Should I use a separate UniquePriorityQueue class for A star and UCS to get around passing the PQ tests ?', u'You can use a separate queue for your a*, but I'm not sure you need to.  I just used the same PriorityQueue for all of the portions of this assignment without change.    Though I did do other things to check keep the things in order.']}, {u'text': u'Is this line in test_bfs(self) supposed to draw the graph based on path returned from breadth_first_search ?
self.draw_graph(self.romania, node_positions=node_positions,                        start=start, goal=goal, path=path)
I do not see anything drawn on my virtual box shell that is ssh'd to using vagrant. ', u'responses': [u'I faced a similar problem with my setup (using Docker instead of VB).  Last semester in CV I was able to set up my Vagrant box to draw using X across the network, but after a while of trying to get Docker set up similarly last night I gave up.  I don't remember exactly what was involved, but just letting you know that with some googling and persistence, you can probably get this working (err... Maybe I should preface with on a Mac - No idea if the same is possible in Windows; On a Mac, start with downloading and installing XQuartz, and then ssh into your VM using xterm).

Alternatively I found that if you replace the call `plt.show()` with `plt.savefig(<filename>)` (replacing <filename> with a valid image file name, like 'figure1.png'), it'll write the image to the filesystem where you can view it.', u'Thank you! I used the plt.savefig tip to move forward now.']}, {u'text': u'Are we allowed to use deepcopy in coding the assignment?

Thanks,
Travis', u'responses': [u'
to do what exactly?  I was able to copy a list   b  with a plain  a = list(b)  , but I'm not cleat about what you are trying to clone...', u'That was cool. Probably i am from dinosaur world.  There was a time when we can clone a list only by creating a new list and appending elements from the existing list one by one or by using deepcopy from copy module
a=list()for item in b:    a.append(item)ora = copy.deepcopy(b)
']}, {u'text': u'When I run the search_submission_tests.py file, the BFS test seems to fail before it even gets to the part that is testing my BFS function. It appears that the line causing the problem is:

node_positions = {n: self.romania.node[n]['pos'] for n in self.romania.node.keys()}

and the error is: 'Graph' object has no attribute '_node'.

Is anyone else running into this problem with the provided code?', u'responses': [u'Yes, I ran in to this on my Mac. It is to do with an older graph library call being used in the code that is not compatible with newer version on my box. I switched to vagrant virtualbox instance to overcome this. ', u'I have the same issue. Even I switched to vagrant... same error.. anyone can help?', u'Check to make sure you have exactly the same version of networkx.', u'I’m also on a Mac and hitting the same issue. We should have 
networkx 1.11 right?', u'Yes', u'I am on windows and have same issue', u'I think it's the problem of networkx version is newer than the assignment's requirement.
After reinstall requirements.txt, I use python IDLE instead of spyder/pycharm/command_window, and it works.']}, {u'text': u'Is it ok to use the Queue.PriorityQueue from python standard libraries', u'responses': [u'They hint at using the heapq. Stick with that.']}, {u'text': u'How do you follow the path from the goal back to the start node? Typically nodes should have a parent attribute, but in this assignment it does not. Am I missing something from the Graph library that helps follow the path back up the search tree?', u'responses': [u'You can implement your own custom node class as described in the book or you can keep track of the path as part of whatever data structure you use in your Queue.', u'Jim I would love to do that, but it appears the first warmup exercise that tests the priority queue expects the queue to take the tuple (int, key) or else it will fail.', u'Yeah. I completely changed the queue implementation to work with nodes instead of tuples.', u'I would think the built-in PriorityQueue (heapq) should be able to take any data type (tuple, list, dict, class or whatever) as long as all entries in the queue are the same type. I think you can also in Python override the comparison operators for your custom node (or path) class. That way the PriorityQueue will return your nodes or paths in whichever order you need.', u'If you store the full node in the visited list, you can backtrack from node_id to parent_node_id.
', u'Every one has a trick for this. I always use a dictionary and name it 'cameFrom'. where key is the successor and value is the parent. ']}, {u'text': u'What is the right path from 'a' to 'u' for A* search? ', u'responses': [u'never mind got it right.', u'was it [a, s, r, c, p, b]
']}, {u'text': u'Hi, are the neighbors given in any particular order?I see that for node 'a', the neighbors are returned in this positions ['s', 'z', 't'], while I would expect to have ['z', 's', 't'] or ['t', 's', 'z'] instead.The order that we process each neighbor will affect which path reach the goal first.Would that be an issue of Bonnie tests?', u'responses': [u'I actually have a similar question. Due to the order of the neighbour nodes, I didn't pass 
test_bfs_romania(self)
in the search_unit_test.py due to the pair of (c,r,s,f) and (c,p,b,f) is a tie in BFS. My BFS returns one and the reference path is the other. 

So same question here, how to break the tie or should we worry about it to pass Bonnie tests?', u'I passed Bonnie's BFS with error on the BFS ""unit test"". It's OK, the test must be pulling the neighbors or frontier nodes in different order  for some reason (not sure why, I followed a strict FIFO).

Work to pass BFS in Bonnie, then forget about it; I couldn't re-use code for any of the other searches.', u'The PriorityQueue handles this for you. Each node you pop is guaranteed to be the lowest cost. When iterating over the neighbors, you want to see all of them anyway, so order isn't important there. And of course, the nodes that make it into the frontier are then ordered due to the frontier being the PQ.

For the BFS, you can enforce strict FIFO by assigning an arbitrary incrementing index as the weight.']}, {u'text': u'May we write another PriorityQueue class? I would leave the original PriorityQueue class as well so that it passes the Bonnie section for PQ.  I wrote a new class to represent the cities like what was described in the Search lectures and would like to write a new PQ class that takes advantage of that structure. I was confused by the text in search_submission.py that states ""Do not add any classes or functions to this file that are not part of the classes that we want.""  
', u'responses': [u'Not answering your question, but note that you can use any combination of properties in a tuple to use as the node metadata. For example: (node_id, parent_node_id, action) or (node_id, parent_node_id). The key would be the edge cost. I've been using it this way with no problems.
', u'Just going to mark this as resolved as I've already finished the assignment using the first assumption :). ']}, {u'text': u'When I run the search_submission_tests, I do not ever see the graphs being displayed. I am using the Vagrantfile provided in the lab as well as vagrant ssh to access to environment. My host OS is Windows 10. Any help is appreciated!', u'responses': [u'Usually, when accessing a command line environment that isn't a full blown VM, then the plotting won't work. You can save to file instead of show plot and then copy/paste the images back to your Windows environment to see.

On the other hand. I've been running all the code natively in Windows 10 with no problems. I use a python 2.7 anaconda virtual environment.']}, {u'text': u'""The heapq module has been imported for you. Each edge has an associated weight."" Based on this hint, i used heapq inside PriorityQueue and it passed the bonnie test. But all I had to do was just alter two functions in PriorityQueue class with heapq methods. Is it right or am i doing something wrong?', u'responses': [u'That's correct. You may want to implement the third method too though. It makes it easier to swap out a node on your frontier if you find one with a lower cost.']}, {u'text': u'I have an error when trying to run the test file.

Lisbeths-MacBook-Pro:assignment_2 keah$ python search_submission_tests.py 
Traceback (most recent call last):
  File ""search_submission_tests.py"", line 7, in <module>
    import networkx
ImportError: No module named networkx

I have two python versions; 2.7 and 3.5. I realized that the requirements were installed under the 3.5 version so I installed them under 2.7.

Lisbeths-MacBook-Pro:assignment_2 keah$ python search_submission_tests.py 
Traceback (most recent call last):
  File ""search_submission_tests.py"", line 7, in <module>
    import networkx
ImportError: No module named networkx
Lisbeths-MacBook-Pro:assignment_2 keah$ sudo -H pip2.7 install -r requirements.txt
Requirement already satisfied: future==0.16.0 in /Library/Python/2.7/site-packages (from -r requirements.txt (line 1))
Collecting matplotlib==2.0.2 (from -r requirements.txt (line 2))
  Downloading matplotlib-2.0.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (12.8MB)
    100% |████████████████████████████████| 12.8MB 97kB/s 
Requirement already satisfied: nelson==0.4.0 in /Library/Python/2.7/site-packages (from -r requirements.txt (line 3))
Collecting networkx==1.11 (from -r requirements.txt (line 4))
  Downloading networkx-1.11-py2.py3-none-any.whl (1.3MB)
    100% |████████████████████████████████| 1.3MB 873kB/s 
Requirement already satisfied: requests==2.13.0 in /Library/Python/2.7/site-packages (from -r requirements.txt (line 5))
Requirement already satisfied: python-dateutil in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from matplotlib==2.0.2->-r requirements.txt (line 2))
Collecting cycler>=0.10 (from matplotlib==2.0.2->-r requirements.txt (line 2))
  Downloading cycler-0.10.0-py2.py3-none-any.whl
Collecting subprocess32 (from matplotlib==2.0.2->-r requirements.txt (line 2))
  Downloading subprocess32-3.2.7.tar.gz (54kB)
    100% |████████████████████████████████| 61kB 3.4MB/s 
Requirement already satisfied: pytz in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from matplotlib==2.0.2->-r requirements.txt (line 2))
Collecting six>=1.10 (from matplotlib==2.0.2->-r requirements.txt (line 2))
  Downloading six-1.11.0-py2.py3-none-any.whl
Collecting functools32 (from matplotlib==2.0.2->-r requirements.txt (line 2))
  Downloading functools32-3.2.3-2.zip
Requirement already satisfied: numpy>=1.7.1 in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from matplotlib==2.0.2->-r requirements.txt (line 2))
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from matplotlib==2.0.2->-r requirements.txt (line 2))
Requirement already satisfied: requests-toolbelt>=0.7.0 in /Library/Python/2.7/site-packages (from nelson==0.4.0->-r requirements.txt (line 3))
Collecting decorator>=3.4.0 (from networkx==1.11->-r requirements.txt (line 4))
  Downloading decorator-4.2.1-py2.py3-none-any.whl
Installing collected packages: six, cycler, subprocess32, functools32, matplotlib, decorator, networkx
  Found existing installation: six 1.4.1
    DEPRECATION: Uninstalling a distutils installed project (six) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.
    Uninstalling six-1.4.1:
Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py"", line 778, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py"", line 754, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py"", line 267, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 302, in move
    copy2(src, real_dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 131, in copy2
    copystat(src, dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 103, in copystat
    os.chflags(dst, st.st_flags)
OSError: [Errno 1] Operation not permitted: '/tmp/pip-QJVxlz-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info'

The problem continues. Any idea how can I fix it?

', u'responses': [u'I had issues importing networkx and resolved it by running: 
""sudo -H pip install --user networkx==1.11""
', u'Welcome to my world. I posted this elsewhere. It is El Capitan. There are numerous work arounds none of which worked for me. I did finally get passed it by using --user in the install.', u'And note, there seems to be alot of posts about this issue with different fixes. None of which worked for me but the last one I just posted. However, ymmv. I'd try the solution of installing python via brew first as that one seems to work for most people. Do google searches and you will see what I mean. I didn't get much help from the community here but google did alright.', u'Thank you, @William Wu. I'm still not able to resolve my issue. I ran the command you told me. This is the output.

Lisbeths-MacBook-Pro:assignment_2 keah$ sudo -H pip install --user networkx==1.11
Password:
Requirement already satisfied: networkx==1.11 in /private/var/root/Library/Python/2.7/lib/python/site-packages
Requirement already satisfied: decorator>=3.4.0 in /private/var/root/Library/Python/2.7/lib/python/site-packages (from networkx==1.11)

When I run I get the same issue as before.

Lisbeths-MacBook-Pro:assignment_2 keah$ python search_submission_tests.py 
Traceback (most recent call last):
  File ""search_submission_tests.py"", line 7, in <module>
    import networkx
ImportError: No module named networkx

Any suggestions?

', u'Thank you, @Brett Yerger. I installed brew fist and the python 3.5, and now python 2.7. I've tried several things that I found in Google but nothing has worked so far. :(
', u'I already solved it. Thank you all for your help :)']}, {u'text': u'Curiosity question—not blocking me on the project. 

I'm curious about heapq. It talks about implementing the heap data structure, but it seems that the data is stored in a vanilla Python list the whole time. Is it the case that the library implements the functions to make it act like a heap? Is there even a meaningful distinction?

I get the sense from the documentation that removing an element from the ""heap"" using list.remove() would be dangerous, but I don't really understand why. The docs say something about it breaking the ""heap invariants"" but I didn't follow that. Can someone ELI5?

EDIT: I did a little poking around (added 1 and 100 to a heap, and then added repeated 10's and kept checking the heap after each one) and I think it's storing it in a vanilla list but keeping the order as it should be based on the tree! IE it's only pushing the 100 down once it gets pushed off the end of the row in a tree diagram.

I was trying to figure out what the tree nature of the heap had to do with the project, but now it seems like it's a coincidence—since we're just popping the best element, it doesn't really matter what lies underneath. The tree just allows heapq to quickly put new elements in the correct place. Neat! (pun intended)', u'responses': [u'Like everything in Python heapq is way cool :)

I did this example code below to play with it some.. The heapq is not an object in its own right but a function wrapping a list like in the example. Note that you need to pass the underlying list to each heapq call since there is no 'heap queue' instance object per se.

When you pop a value off the heapq it returns the minimum value in the underlying list and then reorders the underlying list so that the next current minimum is first (on top). See the binary heap algorithm. It keeps the underlying list (conceptually a 'flattened' tree) binary-tree ordered so that it can binary-search for the minimum in O(log n) (which is obviously nice for very large priority queues). You can see the ordering of the underlying changing to keep the next minimum on top if you just print it like in the example code.

So if you go and delete something in the underlying list the result depends on what you are doing. If say, you list.pop(0) on the underlying list then you get the minimum queue value returned from the pop(). The code below fails if it assumes that the priority queue will pop the same number of entries as were pushed. But if you simply keep popping till the queue is empty that will not throw any exception.

All that said, I'm not coming up with any reasonable example where you would want to mess with the underlying list.

import heapq
inputs = [100, 88, 99, 11, 77, 22, 66, 33]
underlying_heap_list = []
for value in inputs:
    heapq.heappush(underlying_heap_list, value)

ctr=0

for i in range(len(inputs)): # this will fail with an IndexError
#while len(underlying_heap_list) > 0: # this wont fail
    try:
        pop = heapq.heappop(underlying_heap_list)
        print 'pop:', pop, ' underlying:', underlying_heap_list
    except IndexError as err:
        print '  -->underlying heap len now != inputs length ' + str(err)
    if ctr==2:
        # the smallest value of a min-binary heap is always guaranteed to be at index 0
        top_of_heap = underlying_heap_list.pop(0) 
        print '  -->popped underlying top:', top_of_heap
    ctr += 1
Result
===> No Fail
pop: 11  underlying: [22, 33, 66, 77, 88, 99, 100]
pop: 22  underlying: [33, 77, 66, 100, 88, 99]
pop: 33  underlying: [66, 77, 99, 100, 88]
  -->popped underlying top: 66
pop: 77  underlying: [88, 99, 100]
pop: 88  underlying: [99, 100]
pop: 99  underlying: [100]
pop: 100  underlying: []

===> With fail 
pop: 11  underlying: [22, 33, 66, 77, 88, 99, 100]
pop: 22  underlying: [33, 77, 66, 100, 88, 99]
pop: 33  underlying: [66, 77, 99, 100, 88]
  -->popped underlying top: 66
pop: 77  underlying: [88, 99, 100]
pop: 88  underlying: [99, 100]
pop: 99  underlying: [100]
pop: 100  underlying: []
  -->underlying heap len now != inputs length index out of range
', u'@Sasha Heapq is simply an implementation of a min heap where the underlying data structure is an array (list). The nodes of the tree are easily computed by 2n+1 for the left node and 2n+2 for the right, for every index position of n. This helps achieve its performance measure of O(1) for peeking at the minimum node and O(log n) for inserting/removing an item. If you remove an item manually from the underlying list, you must heapify the list again to maintain its invariant - that every node in the tree is greater than the value of its parent - otherwise, it all falls apart.

As to the remove function of the priority queue, I made sure not to mess with the underlying heapq list. I used a separate dictionary to track the nodes in the queue. And when a node is asked to be removed, I marked it as removed in the heapq list, but I didn't actually remove it. It remains in the list, but is essentially skipped when pop is called. I implemented this logic based on the priority queue example given in the heapq documentation.', u'Aha, both of your responses have illuminated another little corner of heapq for me. It's so neat!', u'@Brett saved me some hours. Thank You :)']}, {u'text': u'For bfs algorithm, I am using heapq to build the frontier, and I can reach the goal node, but  I am missing something when it comes to outputting the path as a list, for instance when I print path at the end of my algorithm, I only have the starting node. 

', u'responses': [u'What data structure are you printing the list from? Your heapq contains only nodes on the frontier. The nodes that constitute the best path have already been popped off. So, you need to provide a way to track which nodes are on the path and the node they were reached from.', u'Yes, I guess I am not quite sure how to do that... I currently have it set up to pop the node, then it adds to the frontier the neighbors of that node, then it pops the next node, and adds the neighbors of that node, etc. So I see how heap is popping the node and iterating through the frontier. I have been stuck on how to save the path while the algorithm is iterating through the frontier, and for some reason getting nowhere thinking it through... What kind of data structure would be the most efficient for this? Hash table? Maybe tomorrow will be a better thinking day...', u'@Dawn A hash table (e.g. dictionary) is a good choice.']}, {u'text': u'For UCS and A*, at what point in the loop are you all tracking the explored nodes? I tried keeping a global list of explored nodes, but that had a major problem: because all paths had to go through B to get to U, whichever path got to B first marked it as explored and then no other paths could go through it, even if they were cheaper. 

I solved this by just checking to make sure individual paths weren't backtracking to nodes they'd already explored, which passed the Bonnie tests for the warmups, but is leading me to performance problems on bigger graphs and issues with bidirectional UCS so I think I need to revisit this.', u'responses': [u'I place a node into my ""visited"" (what you are calling explored) dictionary when I pop it off the frontier and before I explore its neighbors.  I keep a separate visited dictionary for each frontier, though I'm not sure that's really necessary.  You shouldn't have to explore past the explored edge of your other frontiers.', u'With UCS/A*, once a node becomes explored, no other path to that node should be shorter (cost-wise), so I just ignore anything that's been explored, personally']}, {u'text': u'How do you get the index of the node in the queue? I am trying to figure out what this means so that I can use the remove function, but what I have resulted to is passing the node ( say 'a') and enumerating the queue within that function to get the index of what needs to be removed. Then I am using that index to remove that item from the queue and using heapify to return my queue with that node removed. 

I am asking because this seems cumbersome... and I am wondering if there is something I am missing?', u'responses': [u'think of what you can do to the value of the element in the queue in order to make it pop(). your answer is just a google away', u'I am using pop() to remove my element in the queue by index. However, in the function definition it says that I should pass the index of what I want to the remove function. I do not see how to get the index of the items while in the algorithm. For instance in the remove function I can see the queue with self.queue, is there a way to see the queue while in the ucs function so that I can get an index to pass?', u'@Dawn I ended up cycling though my PQ popping/pushing until i found my frontier node. I could not find a way to use the index. Initially tracked the index as i iterated over my heap. However, when iterating over heap, heap will yield items in order of priority, but index in the PQ list itself may be different.  I don't know the answer to your question, but hoping that sharing my experience can be helpful in some way', u'I have completed the assignment (from the point of view of Bonnie scoring) and have not made any use of remove.  Nor have I found a need to use the index in the queue... just pop() and append(). 

Of course, it's always possible I'm not doing it right.']}, {u'text': u'', u'responses': []}, {u'text': u'Are we supposed to use heapq to build priority queue? 
It seems everybody agrees with it but the insertion from heapq (heappush) is not O(1). while this assignment has this requirement: ""the data structure you implement should have an amortized O(1) insertion and O(lg n) removal time"".', u'responses': [u'Yes. Utilizing heapq will be simple enough that you'll wonder if it's too good to be true. Remove can be tricky.']}, {u'text': u'Hello, im confused about this whole heap implementation.  For the pop function, I first called on heapify and then used heap pop to remove the highest priority queue.  

But for the next function, remove, Im kind of confused.  Are we removing item from the heap or are we removing item from the queue?  Im assuming we are removing item from self.queue.  do we need to use the pop from the previous definition?  i.e rather than self.pop() can i just use heapq.heappop?  reason i ask is because using self.pop() implicitly calls heapify and removes the highest priority queue but im assuming this is not what we want for this area?  Please correct me if im wrong.  We want to remove an item from self.queue.  Hence I move the index of the number to the front of queue and then called heapq.heappop.  

Thanks', u'responses': [u'The heapq documentation covers the reasons why remove is different from pop in a priority queue implementation. https://docs.python.org/2/library/heapq.html#priority-queue-implementation-notes', u'I did not call or use heapify nor use remove in any code and I have completed all of the required portions of the assignment.']}, {u'text': u'my a star search is failing with the only error being ""path is longer than optimal path""...

testing locally everything looks good... I've moved the start and goal around a lot and every time it returns the best path.... so I'm not sure what could be wrong at this point...

anyone have any ideas of what else I could try?', u'responses': [u'Are you changing the start and goal nodes manually for testing? Did you try running the search_unit_tests.py and see if all the tests pass ? It tests your implementation for all permutations of nodes in the graph .', u'Yeah, I've changed the start and goal nodes manually to test when running everything through the ""search_unit_test.py"" code.  Everything passes locally on that code.', u'replied too soon, I actually somehow missed that file... I'll run those tests now, thanks', u'so using these unit tests I am specifically failing on the a-g path apparently...

but when I do it by hand I get the same solution...

the unit test says to take the the path a-s-f-b-g, but the shorter distance path is a-s-r-p-b-g...

this doesn't make any sense...', u'nevermind, I'm still not sure the path makes sense to me, but I got it passing on bonnie...
']}, {u'text': u'I’m having trouble figuring out how to append a priority queue in O(1) operations.  Can this even be done?  @Brett, instructions say to have insertions amoritized in O(1).  ', u'responses': [u'I don't think that's even possible. I think the best average runtime you can get for insertion is log n. From what I've learned, heap appends the node to the end of the tree and then heapify, which in average takes log n time. 

Someone please correct me if I'm wrong. ', u'Thank u. That’s exactly what I did.  ', u'But even in the 2nd problem wqrmup Calling heapify is a O(n) operation. I’m not sure how to maintain the priority unless I heapify at the beginning.  What I did was do heap.heapify(self.queue) then go ahead and remove the node in O(log n). But like I said calling heapify is O(n). So worse time complexity is O(nlogn).  Am I right ?', u'But I think heappq.heappush() takes care of heapifying, which ofcourse will not affect the runtime but you don't have to call heapify again.', u'Are you talking about appending or remove operation?', u'Why do you have to call heapify before removing a node? And in my previous post, I was talking about appending.', u'Because you are sending a list.  How do you maintain a priority before pushing or removing anything?Self. Queue is a list.  So I always heapify it first as I’m assuming the question is asking to remove an item from a heap rather than a list', u'So when you insert an element in the PQ, your list is reordered to satisfy the requirements of a heap. So your heap is maintained in the list. 

But heappq doesn't provide remove operation. So you traverse through the list, remove the element and then heapify. So when you're removing, heap is already maintained.', u'I do not remove any elements other than pop()ing.']}, {u'text': u'The test for PQ failed on Bonnie because of it's popping from an empty queue, while all other 3 warmup algorithms leverage my PQ and passed the tests...I can't really tell what's being tested on Bonnie for my PQ that caused the error. Any idea on this or is there any 'expected' behavior when popping a empty queue? I'm raising an error now...', u'responses': [u'I return None if my queue is empty.   Defensive programming.  Not sure it's written as a requirement anywhere.', u'I did try returning None as well...but it seems the test program tries to access the returned value by index which threw exception when it got None.....', u'That is likely because you are not finding a path when there is in fact a path (so you're returning None when there is a solution).  Also you can get an error about None if you are returning a path that is not valid (you have sequential nodes in your path that are not neighbors).  This can happen when you're putting paths together and they don't go together the way you are putting them together.']}, {u'text': u'Im actually struggling with Breadth first search and its somewhat embarrassing.  I haven't taken course in algorithms, and im confused how the graph argument helps with breadth first search.  Is the graph argument actually the implementation of the graph search from networkx?  Intuitively i figured we would construct a tree function and then expand function etc before doing breadth first search.  Would it be better if i dropped this course and spend the next few months self studying an algorithms based python course and then retake this class~over the summer?  

Thanks', u'responses': [u'The graph argument is a class that contains the vertices and edges contained in the graph. The breadth first search would follow the edges from the start to expand neighboring nodes until it found the goal node.', u'Thanks for some reason I didn’t see the graph file so I was freaking out.  Smh', u'Don't drop the course just yet. They drop one assignment. Plus you'll never be fully prepared for a course. I have taken algorithms in my undergrad and I know python pretty well still, this project is challenging for me.

You can print values and use pycharm debugger to understand what each piece of code does. Also, don't start coding unless you can solve the problem on a paper. I wasted a lot of time doing that.', u'Hi Harmeet, thanks for your reply.  By the way, is there anyway you would like to share your contact info so that we can talk about the assignment ?  Just to share ideas etc?  ', u'Nm I didn’t know you were the instructor haha ', u'I am not the instructor :P 

My email is hbindra3@gatech.edu ']}, {u'text': u'Inside definition of breadth first search, can I call graph.node[][pos] to get the neighbors or would that not be allowed?  Thanks', u'responses': [u'Only use what's recommended in the Readme for the BFS section. That's how Bonnie will track you're explored nodes.', u'Yeah, that's a must:

You can access all the neighbors of a given node by calling graph[node], or graph.neighbors(node) ONLY. 
Note the ""ONLY"" at the end']}, {u'text': u'Hi
I tried to call graph.explored_nodes() function.But I got error saying ""TypeError: 'set' object is not callable.Can't I use it?
Thanks, ', u'responses': [u'explored_nodes is not a function.  If you want to see a list of the nodes explored, use:

explored = list(graph.explored_nodes)

that's what's done in search_submission_tests.py', u'If you were not aware, you cannot use explored_nodes or reset_search when submitting to Bonnie. As stated in the hints for Warmup 2: ""WARNING, these functions are intended for debugging purposes only. Calls to these functions will fail on Bonnie.""']}, {u'text': u'I cannot have the figure shown in my command window. It says there is no draw_graph. self.draw_graph(self.romania, node_positions=node_positions, start=start, goal=goal, path=path).
I have seen post regarding this but I still dont know how to fix it. Any body know the fix?', u'responses': []}, {u'text': u'My BFS works in most cases except one of the unit tests.

It says:

['c', 'r', 's', 'f'] != ['c', 'p', 'b', 'f']Expected :['c', 'p', 'b', 'f']Actual   :['c', 'r', 's', 'f']

However both the paths are shortest, anyone faced similar issue?', u'responses': [u'I believe that they are not actually using BFS for their search and I had the same exact difference in the unit test and I fully pass Bonnie.', u'Thanks Conor Cahill, I finally figured out the optimization trick and bonnie passed. The unit test did send me on a tangent for long']}, {u'text': u'Im really having a hard time with the uniform cost search and the algorithm given in the book doesn't really make it clear what to do.  Im trying to follow it step by step, but confused about the part ""for each action in problem.actions(node.state) do"" part.  

path_cost = 0 node = (path_cost,[start]) frontier = PriorityQueue() explored = PriorityQueue() frontier.append(node)  while True:   if len(frontier.queue) == 0:      raise Exception(""Failure"")   path = frontier.pop()[1]  //choose the lowest cost node in frontier   node = path[-1]  // choose that node    if node == goal:      return path   explored.append(node) //add node state to explored
// im stuck in this part of the code and if someone can help. that would be appreciated.  

for each action in problem.actions(node.state)...

can i not use the graph.neighbors(node) in this part of the exercise?  i.e only graph[node][node]['weight']?  if thats the case how do i even access the neighbors?
', u'responses': [u'I think you missed a trick from lectures-create own Node class with the attributes explained in lecture. Also, the explored nodes need not be priority queue. A simple set or dictionary would do. The algos given in book are just an indicative of what to do. Exact implementation you have to think which datastructure to use.', u'oh.  i didn't think we had to create our own node class.   i thought our implementation was limited to what was provided.  so you are telling me within uniform_cost_search, i have to create a node class? ', u'i thought graph.neighbors(node) would give all the neighbors of a node.  I wasn't aware that we had to create our own node class for this', u'You can create node class in search_submission file. Basically node.parent will help to trace the path you found out. Though implementations can vary.', u'theres no way i have the time to do all this.  i have spent well over 30 hours and stuck in warm-up 2.  are future assignments this programming heavy?  if they are, i think i should spend the next 3 months going through a python algorithms course before taking this.  that way i won't feel like im asking stupid questions.  ', u'You should be able to call graph.neighbors(node) to get all the neighbors without writing a node class necessarily. You could choose to use a different data structure like a tuple as the PriorityQueue suggests. graph.neighbors just takes a string representing the current state i.e. graph.neighbors(‘a’) will give all the neighbors to state ‘a’ representing Arad.', u'Thanks Jim ']}, {u'text': u'After warmup you can do a star and bidi a star. UCS and bi ucs can be done by passing bull heuristic. Yes, I found this course to be very programming heavy as well as a lot of study needed beyond videos. You can go through basic python course. But I would recommend not to go anywhere beyond suggested book chapters and papers apart from python.', u'responses': [u'thank you.  My first step is to perhaps go through an algorithms book.  Is this AI course offered over the summer?  If not, atleast i will spend the next few months going over my algorithms book and read the AI book (follow the syllabus).  Plan is to take ml4t in the summer.  then perhaps this course in the fall.  by then, i think my algorithms knowledge would be pretty sharp.  ', u'One of my friends took it in summer.']}]",,2.0,358.0,295,,Assignment 2- Warmup 1-4 discussion thread,[a2]
5ad7d44c0d63974e20c3911f,"Discussion thread for Exercise 1: Bidirectional uniform-cost search.

",jc6w44hrp9v2ki,"[{u'text': u'I got the following error in Bonnie when running bidirectional UCS, can anyone help?

""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_npoklgrv/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 117, in test_biucs\n    tests_pass, feedback, lose_ratio, node_flag = bidirectional_tests(bidirectional_ucs)\n  File \""/home/vmuser_npoklgrv/workspace/search_tests_biucs.py\"", line 96, in bidirectional_tests\n    path_is_correct = get_path_cost(romania, path) <= get_path_cost(romania, right_path)\n  File \""/home/vmuser_npoklgrv/workspace/search_tests_biucs.py\"", line 51, in get_path_cost\n    edge_weight = graph.get_edge_data(path[i], path[i+1])['weight']\nTypeError: 'NoneType' object has no attribute '__getitem__'\n"",

Looks like the culprit is trying to get the weight between 2 nodes that don't have weights, but I'm not sure if this is the right track

edge_weight = graph.get_edge_data(path[i], path[i+1])['weight']', u'responses': [u'I did see this in the assignment ""Frequent issues and solutions"" section:

Most 'NoneType object ...' errors are because the path you return is not completely connected (a pair of successive nodes in the path are not connected). Or because the path variable itself is empty.

But since this is only happening on Bonnie, I am wondering if something like graph[node][neighbor]['weight'] is a good place to search for a culprit.', u'I'm getting this too (only on Bonnie). Trying to figure it out...', u'
I fixed mine. I found the bug after testing different coordinates for the bidirectional_ucs test. (ex: 69581003 to 1346119692) and printing out my path/edges.

You are correct that somewhere in the graph there is a set of nodes (or node) in your path which does not have an edge to either another node or itself. ', u'nvm, finally passed.', u'I was able to find many bugs by basically creating the cartesian products of all points on the atlanta map and running all 400 tests through ucs and biducs, highlighting the ones that were wrong (or flat out failed). I explore too many nodes but at least get 14/15 on Bonnie.', u'Lily, I see 252791 nodes in the Atlanta map. How did you get only 400 tests?

Oh, I see, you meant Romania (that has 20 nodes).', u'I got this error too. I figured out that I had added the same node twice to the path I was returning, hence the error.']}, {u'text': u'is there a way to turn the JSON output from the bi-directional search tests into a visualization--am I missing something in the docs?', u'responses': [u'Paste your json contents into this site. It's listed in the assignment readme. http://geojson.io/
', u'It saves a file (for example atlanta_search_bidir_ucs.json).

Head to http://geojson.io/.

In the upper left corner of the screen click on ""open"" and navigate to your output file.']}, {u'text': u'I passed the warmup 1-4 using the vagrant virtualbox setup. However, when running Exercise 1 on the same vagrant virtualbox, even with default bidirectional_ucs (not implemented) I see the following error thrown when running the below script:

vagrant@vagrant-ubuntu-trusty-64:/vagrant$ python search_submission_tests.py 
Killed

Any idea on why this is happening? ', u'responses': [u'Increased memory to 1024MB on the VM to get past.']}, {u'text': u'When submitting my bi-directional UCS search, I pass 0.97 percent of test cases for 10/15 points. This is easy enough to understand, but the message I get back is:

Path is longer than optimal path\nOn average, number of nodes explored more than the benchmark = 0.0

It sounds to me like it is saying I explored 0 more nodes than I should have. Is this a correct interpretation? Would this mean that Bonnie has an issue?', u'responses': [u'I'm in a similar situation. I think it means you exited too soon before you actually found the shortest path. I'm at 99.5% pass ratio and am banging my head against the wall as to where my bug could be. I'm passing the unit test but Bonnie is failing me somewhere.', u'My suggestion is to create your own unit tests by creating a list of all possible pairs of start-goal in Romania and running each against both your regular UCS and BIDUCS. I was passing the given test locally but found differences in many other cases...']}, {u'text': u'Question around explored_nodes set inside graph object.
Are we supposed to use this set in code or create our own set? 
While this is accessible from local tests and code runs fine if I use graph._explored_nodes or graph.explored_nodes in my implementation. However, when we submit on Bonnie, it errors out with ath = bidirectional_ucs(romania, start, goal)\n  File \""/home/vmuser_klfjeazv/workspace/search_submission.py\"", line 460, in bidirectional_ucs\n    explored = graph._explored_nodes\nAttributeError: 'Graph' object has no attribute '_explored_nodes'\n""

I got similar error for warm up exercises, and I used a different set variable inside program to pass that.

However for the bidirectional graph, test code seems to refer this collection from graph object in plot_search function.

My local search seem to plot good (json plots a connected path on geojson.io. Though Bonnie gives a ""NoneType object.."" error, and I was thinking if we need to ensure that graph.explored_nodes is populated explicitly.
', u'responses': [u'In the notes for Warmup 2: BFS, it states that the explored_nodes and reset_search functions are for local testing only. ""WARNING, these functions are intended for debugging purposes only. Calls to these functions will fail on Bonnie.""

Your search must keep track of its own explored nodes.', u'aha.. I missed that. Thank you!']}, {u'text': u'I'm trying to find a stopping criteria that gets me from ~80 pass rate to 100% in bidirectional UCS.

Looking at slides 9 and 10 of Bi Directional A Star - Slides, it states the following about a stopping condition:

1. initially, µ = ∞
2. when scanning an arc (v, w) in the forward search and w is scanned in the reverse search, update µ if df (v) + ℓ(v, w) + dr(w) < µ.
3. Stop when the top heap values of both forward and reverse queues is greater than µ

My question is, when they say scanned, do they mean when we add a new node to a frontier, or do they mean when we explore a node?', u'responses': [u'I only just started this section, but my guess would be when you apply the goal test, which for UCS is when you take the node off the frontier.', u'by 'scanned' they are referring to explored nodes here. ', u'What was the definition of l(v,w)?', u'l(v,w) means the length between node v and w.']}, {u'text': u'Just an FYI. Note that you can use the Romania data to test your bi-directional code. A couple of the unit tests do this.', u'responses': []}, {u'text': u'
What is Pr(t)?', u'responses': [u'I posted this in the wrong exercise. It should have been posted in Assignment 2 - Exercise 2. I reposed on the main page and tagged it with a2.', u'You can find the definition for Pr(t) on the previous slide. But the way I understand it is that you are calling the P function used for the reverse heuristic and passing the t node, which is the goal node.']}, {u'text': u'Any one faced below error?

 ""Traceback (most recent call last):\n  File \""/home/vmuser_hltwqoad/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 117, in test_biucs\n    tests_pass, feedback, lose_ratio, node_flag = bidirectional_tests(bidirectional_ucs)\n  File \""/home/vmuser_hltwqoad/workspace/search_tests_biucs.py\"", line 83, in bidirectional_tests\n    path_is_valid = is_path_correct(romania, start, goal, path)\n  File \""/home/vmuser_hltwqoad/workspace/search_tests_biucs.py\"", line 17, in is_path_correct\n    if not (path[0] == start and path[-1] == goal):\nIndexError: list index out of range\n"",', u'responses': [u'Also saw this on submission to bonnie; am trying to work back through local unit tests', u'That error message probably means the path you're returning doesn't have a 0th or -1th element—sounds like you're returning an empty list for the path where it shouldn't be empty.', u'Hi Sudharshan.


How did you manager to debug the error below? Facing same issue on Bonny even after passing local tests:

if not (path[0] == start and path[-1] == goal):\nIndexError: list index out of range\n""', u'list index out of range for that evaluation (path[0] and path[-1]) most likely means that you returned a path that is empty when it was not expected to be empty.']}, {u'text': u'Also, If goal is neighbor of start, what should we return? Should we return [] as the below rule?
You do need to include start and goal in the path.', u'responses': [u'In every point-to-point section rule 2 is to return []', u'i trired and it fails locally when i return []. it  expect start and goal', u'my mistake, I misread your question. that only applies if start and goal are the same. You should return [start, goal] if they are immediately adjacent.', u'If a goal is a neighbor of start, you would return [start, goal]... e.g. with romania start 'a' and goal 's', the response would be ['a','s']']}, {u'text': u'is there a way to compare explored nodes from your algorithm with the networkx one?seems like unit tests only compare cost and not explored nodes, while bonnie shows benchmark=1.6', u'responses': [u'You can see the path from networkx, but I haven't figured out how you can see the explored nodes (the networkx library doesn't appear to be ""touching"" the nodes in such a way that they are marked as explored).   I tested this with:

    def test_bidirectional_networkx(self):
        """"""Test and visualize BD UCS search""""""
        start = 'g'
        goal = 't'

        node_positions = {n: self.romania.node[n]['pos'] for n in
                          self.romania.node.keys()}

        self.romania.reset_search()
        path = networkx.shortest_path(self.romania, start, goal, weight='weight')

        self.draw_graph(self.romania, node_positions=node_positions,
                        start=start, goal=goal, path=path)

added in search_submission_tests.py.  Got a nice graph of the result, but no nodes marked as explored. ']}, {u'text': u'For this assignment, do we have bidirectional graphs (no one way streets) already built in, or will we have to compute the reverse of the graph?', u'responses': [u'I can confirm this assumption works for exercise 1.']}, {u'text': u'Can anyone give an explain of what the result of the geo json is supposed to look like for the base unit test?  I feel like I'm doing something terribly wrong because all of the nodes that appear are on one street...

http://bl.ocks.org/d/a9de62e3aef2440e2b43867d0dc5c2b1

', u'responses': [u'Black nodes are explored nodes, and orange are on the path. The black line is the edge between path nodes. When I plot mine, I get the same street too—I think they're giving a test case with just a few iterations so it runs quickly.']}, {u'text': u'When i run locally atlanta unit test, i get the below perfect score. But when i run in Bonnie, i get 75% pass rate claiming i exploring 2 more nodes by average. Any one have any idea what i am doing wrong?

print ""path_len:"" + str(path_len) + "" ref_len:"" + str(ref_len)
path_len:15.8023126923 ref_len:15.8023126923path_len:41.6964615867 ref_len:41.6964615867path_len:36.3331708349 ref_len:36.3331708349path_len:36.3798128495 ref_len:36.3798128495path_len:11.5531738282 ref_len:11.5531738282path_len:2.24674964891 ref_len:2.24674964891path_len:36.9327483034 ref_len:36.9327483034path_len:46.6486746397 ref_len:46.6486746397path_len:13.9692265484 ref_len:13.9692265484path_len:19.7430487869 ref_len:19.7430487869path_len:26.5443991769 ref_len:26.5443991769path_len:47.2955592641 ref_len:47.2955592641path_len:33.9815826682 ref_len:33.9815826682path_len:4.96970867745 ref_len:4.96970867745path_len:15.4629784236 ref_len:15.4629784236path_len:26.7586348949 ref_len:26.7586348949path_len:19.4098251638 ref_len:19.4098251638path_len:33.6911298168 ref_len:33.6911298168path_len:24.4835595717 ref_len:24.4835595717path_len:47.466017239 ref_len:47.466017239', u'responses': [u'The unit tests do not evaluate the number of nodes explored. So, even though you return the route with the shortest path cost, Bonnie is telling you that your algorithm explores too much.']}, {u'text': u'I am struggling to find this last point for bi-directional UCS. Has anyone come across this?

{    ""output"": {        ""points_available"": 15,        ""points_awarded"": 14,        ""autograder_comments"": ""Bidirectional uniform cost search fails benchmarks searching from start to goal node\nPath is longer than optimal path\nOn average, number of nodes explored more than the benchmark = 0.0\n"",        ""pass_ratio"": 0.99    },    ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_nsjdvczb/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 135, in test_biucs\n    self.assertTrue(tests_pass, \""Bidirectional UCS Tests\"")\nAssertionError: Bidirectional UCS Tests\n"",    ""description"": ""Test the bi-directional uniform cost search implementation""},', u'responses': [u'Did you find solution? I have the same problem.', u'This means your solution was not optimal in a minimum of one case and you need to rework something in your algorithm. Your frontier does not exceed the frontier limit, so we know it has to be your path. Have you made sure to return [] when start == goal?']}, {u'text': u'I have a question about how the stopping criteria Tf + Tb >= mu is supposed to be implemented. I have an example where the way I implemented it doesn’t work. I am trying to implement it according to how it is described in the resources, but since it’s not working, I must be doing something wrong. I just can’t figure out what it is. If anyone can point me in the right direction, it would be much appreciated!

In my example, start is ‘d’ and goal is ‘s’. The path that my code finds is [‘d’,’c’,’p’,’r’,’s’], even though the correct shortest path should be [‘d’,’c’,’r’,’s’]. The problem I’m seeing is that [‘d’,’c’,’p’,’r’,’s’] is found first, and the stopping criteria is met, so [‘d’,’c’,’r’,’s’] is not found. Here is the order in which the nodes get expanded.
 
Forward expands ‘d’, cost: 0
Backward expands ‘s’, cost: 0
 
F expands ‘m’, cost: 75
B expands ‘r’, cost: 80
 
F expands ‘c’, cost: 120
B expands ‘f’, cost: 99
 
F expands ‘l’, cost: 145
B expands ‘a’, cost: 140
 
F expands ‘t’, cost: 256
B expands ‘o’, cost: 151
 
F expands ‘p’, cost: 258
B expands ‘p’, cost: 177
 
At this point, F and B meet at ‘p’ and a path is formed: [‘d’,’c’,’p’,’r’,’s’]
The cost of this path is 258 + 177 = 435 = mu.
 
The next items in the F Frontier and B Frontier are ‘r’, cost: 266 and ‘z’, cost: 215, respectively. My understanding is that these should be Tf and Tb. Summing those together would be 481. The condition Tf + Tb >= mu is met and [‘d’,’c’,’p’,’r’,’s’] is returned, even though there is a path through 'r' that is shorter.
 
Any thoughts on how I’m setting this up incorrectly?

', u'responses': [u'We need to see your frontier.

When I run this on my agent, both frontiers have node c added to them as the first node that touch. Even though we have not popped c off the frontier, it is still in both frontiers so we must set mew.', u'After what I listed above, I have:

Forward queue: 'r', cost 266; 'b', cost 359; 'a', cost 374
Backward queue: 'z', cost 215; 'c', cost 226; 't', cost 258; 'b', cost 310

So in my case, 'c' is not getting expanded by the backward search for a few more steps. Is your path of expansion a lot different than mine?', u'It doesn't need to be expanded, it simply needs to be on the frontier. Change your goal to be when the node is placed on the frontier and see what happens', u'Thanks for clarifying!']}, {u'text': u'My agent gets 15 on the BI-UCS and 10 on UCS, however when running the two functions separately on the Atlanta set between node 69581003 and 1346119692 I get an odd outcome.

The BI-UCS algorithm explores more nodes than the UCS algorithm. My .json file generated when using the BI-UCS is 22506 lines while the UCS generates a .json file that is 22006 lines long.

I thought the BI-UCS was supposed to reduce the amount of nodes explored by a square factor over UCS?

 path = bidirectional_ucs(self.atlanta, '69581003', '1346119692') #22506 Lines .JSON
 path = uniform_cost_search(self.atlanta, '69581003', '1346119692') #22006 Lines .JSON
', u'responses': [u'In a real world, relative node density around start & goal states respectively could be a cause of that. Have you looked at the map view of the json?

I'm seeing, for ucs & bidi-ucs respectively:
            
Incidentally, your implementation could be wrong, too, as I get 19,669 sloc json for ucs & 16,589 for bidi-ucs', u'That was my concern. Bonnie however does not tell me I have an overly large frontier so it is hard to tell if my BI-UCS is actually correct or not. Thank you for testing it on your end.']}, {u'text': u'I am getting the below error in Bonnie. I follow the UCS algorithm given on both forward and reverse side and check whether they are in each others explored list to close. In such case how i explore extra nodes? any edge cases to cut explored nodes?


Bidirectional uniform cost search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum\nOn average, number of nodes explored more than the benchmark = 2.48421052632

', u'responses': [u'Finally solved and got full score.

Please watch the video https://www.coursera.org/learn/algorithms-on-graphs/lecture/7ml18/bidirectional-dijkstra to understand issue with bidirectional and follow the below steps from the document shared by Instructors to get it correct.

• We must maintain the length µ of the best path seen so far: – initially, µ = ∞; – when scanning an arc (v, w) in the forward search and w is scanned in the reverse search, update µ if df (v) + ℓ(v, w) + dr(w) < µ. – similar procedure if scanning an arc in the reverse search.

• Stronger stopping condition: – Let topf and topr be the top heap values (forward and reverse). – Stop when topf + topr ≥ µ. – Previous stopping criterion is a special case.', u'Great resource. Thanks for sharing. This plus the video posted by another class mate (https://www.youtube.com/watch?v=CHvQ3q_gJ7E) helped.']}, {u'text': u'For stopping conditions, or most using (backward_min + forward_min) >= mu?       

Has anyone had any luck with max(backward_min, forward_min) >= mu as suggested in the ""Bidirectional A* Search with Additive Approximation Bounds""?
', u'responses': [u'I used the  second condition that you suggested in bidirectional ucs, but instead of max I used min as seemed more appropriate here.']}, {u'text': u'In the slides I see references to setting the dist[] for nodes outside of start and end to ""inf"".
How are others implementing this? When I set the dist for each node by a query to the graph, it gets registered as explored...



', u'responses': [u'Resolved by checking if key exists...though makes assumption that not exist = inf.']}, {u'text': u'I'm just wondering if anyone has found any weird gotchas for the bidirectional search grading function. I'm thinking back to the equivalent with the very first exercise where Bonnie would fail valid solutions that didn't use a FIFO queue, even though that requirement wasn't specified.

My BD-UCS solution matches the built-in Networkx shortest_path_length result for every permutation of nodes on the Romania graph, but still gets ""Path is longer than optimal path"" errors on Bonnie... Continuing to try to engineer edge cases with new unit tests, but that FIFO situation from the warm-up has shaken my faith :(', u'responses': [u'I did not find any strange surprises (and I didn't run into the FIFO queue issue, but that was because I implemented my priority queue with support for in-order processing of nodes at the same priority and use the priority queue on my BFS).']}]",,3.0,339.0,296,,Assignment 2- Exercise 1 Discussion Thread,[a2]
5ad7d44c0d63974e20c39120,"Discussion thread for Exercise 2: Bidirectional A* search

",jc6w44hrp9v2ki,"[{u'text': u'On both bi-directional algorithms, I get the following on Bonnie:

 ""autograder_comments"": ""Bidirectional null_heuristic a star search fails benchmarks searching from start to goal\nPath is longer than optimal path\nOn average, number of nodes explored more than the benchmark = 0\nBidirectional euclidean a star search fails benchmarks searching from start to goal\nPath is longer than optimal path\nOn average, number of nodes explored more than the benchmark = 0.0\n""
This is resulting in a 1 point penalty in both sections. Could this be an error with the grader, or do I have a very small number of nodes incorrect?', u'responses': [u'(EDIT: Problem solved)
', u'Looks like I found the problem. I added a lot of unit tests and found a discrepancy between standard and bi-directional search. Disregard my question on the auto-grader's correctness.', u'Can you elaborate on your problem @Edwin Bearss?

I'm in the same predicament as you with a 99.5% pass ratio and unsure where to go next. Comparing my uniform_cost_search with my BI UCS, they are spitting out the same values in my unit tests. ', u'For anyone experiencing the same problem, check the test case for ""c"" to ""r"".   ', u'For me c to r is also working correctly but still my pass rate is 98.75. Any idea on how to debug further. I have tried all the combinations of nodes and compared with ucs and all results match.']}, {u'text': u'Are we allowed to add helper functions?', u'responses': [u'yes']}, {u'text': u'For both bidirectional, I get minus 1 point but the number of nodes I'm exploring more than the benchmark is 0. Is this a bug?

      ""output"": {
        ""points_available"": 20,
        ""autograder_comments"": ""Bidirectional null_heuristic a star search fails benchmarks searching from start to goal\nPath is longer than optimal path\nOn average, number of nodes explored more than the benchmark = 0\nBidirectional euclidean a star search fails benchmarks searching from start to goal\nPath is longer than optimal path\nOn average, number of nodes explored more than the benchmark = 0.0\n"",
        ""points_awarded"": 19,
        ""pass_ratio"": 0.995
      },', u'responses': [u'Same here! Maybe because our ""Path is longer than optimal path""?', u'I've taken this to mean that you are finding a sub-optimal path and exiting before you find the shorter path. 
This is something I have been battling with and it seems like a fine balance to get correct. Either I'm exiting too soon or I'm finding the optimal path but exploring too many extra nodes.', u'When your code fails, we output all metrics so that you can figure out where you're going wrong. For some people, that means their path is suboptimal but their search proceeds correctly (indicating the final path may have been constructed incorrectly) while for others both may have been incorrect. If you use a bi-UCS instead of a bi-A*, that would mean your path is optimal but number of nodes is more than benchmark.

Here, the issue is with the optimality of the path.']}, {u'text': u'What would be the best approach to test atlanta data? My bi_ucs and bi_a_star passed Bonnie, and before submission, I could only test on romania using unit test. Whenever I use unit test on Atlanta, the code keeps running for hours and never end. I realized that because some pairs of nodes are just too far, and the calculation are too long. E.g. u'2481617243' and u'4053123732'.', u'responses': [u'you could modify the unit test code so it never tries any pair of nodes > distance d apart. I had basically the entire graph expanded once. took about 10-20 mins
']}, {u'text': u'I am getting the following error for my bi-directional A* implementation. All local tests run fine. Anybody else got this?

Traceback (most recent call last):\n  File \""/home/vmuser_xstvmwlr/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 145, in test_bistar\n    tests_pass, feedback, lose_ratio, node_flag = bidirectional_a_star_tests(bidirectional_a_star, null_heuristic, euclidean_dist_heuristic)\n  File \""/home/vmuser_xstvmwlr/workspace/search_tests_bistar.py\"", line 109, in bidirectional_a_star_tests\n    path_is_correct = get_path_cost(romania, path) <= get_path_cost(romania, right_path)\n  File \""/home/vmuser_xstvmwlr/workspace/search_tests_bistar.py\"", line 51, in get_path_cost\n    edge_weight = graph.get_edge_data(path[i], path[i+1])['weight']\nTypeError: 'NoneType' object has no attribute '__getitem__'\n', u'responses': [u'I'm currently getting that for BI UCS', u'Me too, I just saw this in the readme file: ""4. Most 'NoneType object ...' errors are because the path you return is not completely connected (a pair of successive nodes in the path are not connected). Or because the path variable itself is empty.""  My error was the latter.', u'Thanks!']}, {u'text': u'I am experiencing a strange problem with both Bi-Directional search tests on Bonnie. I reimplemented my priority queue to check on append whether the state already exists in the queue. If it exists and the old one has a higher path cost I replace it with the new one with lower path cost and rebuild the heap. With this change I am able to get 100% credit for both Bi-directional UCS and Bi-Directional A* and I think this is the correct implementation. However, it causes me to get 0 points for the Priority Queue implementation, with this error:
""Priority queue ordering incorrect""
When I change the PriorityQueue back to the one that passes, which just appends any node to the queue without testing for existence, I get 1point off of both Bi-directional UCS and Bi-Directional A* with a confusing error message:

""On average, number of nodes explored more than the benchmark = 0.0"" 
""pass_ratio"": 0.9975
Can a TA please shed some light on what all this means?', u'responses': [u'Hi Jim, did you manage to figure out what was going on here?', u'I used the above implementation inside different functions like, push and take and used them inside my code, leaving append and pop with basic implementation. removing old node with high cost is not default PQ implementation', u'I also have this issue, and am planning to work around it by using a separate class (e.g. PriorityQueue2) in my actual search functions for my final submission. The unit tests, at least, use the same node (""a"") for all appends, which causes my current implementation to fail the unit tests. Bonnie also fails, presumably for the same reason.

As Sudharshan says, this is adding some extra logic beyond a simple priority queue, but it makes the code more dry and readable. I also suspect it's more performant than the way I'd handle priority updates if I were testing/updating from my search functions, instead of internally to PQ.']}, {u'text': u'Hi everyone, which reading materials/lectures/videos talk about stopping conditions and merging forward and backward paths for bidirectional searches in detail? I wasn't able to find it. Thank you.', u'responses': [u'Check out the linked reading materials in the Github repo for assignment 2. The Microsoft paper and the Princeton slides were particularly helpful for Bi-Directional Search. I would say all the papers are must reads though to get a sense of how to do the improved tri-directional search.', u'Thank you.']}, {u'text': u'Maybe I'm just brain-dead, but isn't the calculation for distance between two data points in Atlanta different from the Romania data? i.e. lat/long pairs vs. coordinates?

Is employing a lat/long based formula the correct method?', u'responses': [u'As far as I know, it's generally safe to treat lat/long pairs as cartesian coordinates, especially just for estimation purposes such as serving as heuristics.', u'That makes sense, but I was worried about scaling. Also, I was rounding to whole numbers and so for Atlanta was getting 0 for most heuristic results. I implemented Haversine distance calculation, but it's kind of heavy.', u'Were you able to figure out if the distance units were comparable do using the lat/long heuristic in the same way as the Romania data?', u'It appears that as long as you don't round the result, you can treat the lat/long as x/y coordinates and it works.', u'I did some debugging and it looks like the Delta's between the lat/long and the distances are not on the same order of magnitude, leading to your heuristic being valid, but not getting you much closer to the goal. I think the generation code is in osm2networkx.py and they use the haversine function to compute the distances between a the lat/long for a pair of points, so we should probably be using a similar approximation.']}, {u'text': u'Hi, having a bit of trouble tracking this one down:

{ ""output"": { ""points_available"": 15, ""points_awarded"": null }, ""traceback"": ""Traceback (most recent call last):\n File \""/home/vmuser_whnisdqu/AIResult.py\"", line 26, in func_wrapper\n ans = func(self)\n File \""run.py\"", line 117, in test_biucs\n tests_pass, feedback, lose_ratio, node_flag = bidirectional_tests(bidirectional_ucs)\n File \""/home/vmuser_whnisdqu/workspace/search_tests_biucs.py\"", line 83, in bidirectional_tests\n path_is_valid = is_path_correct(romania, start, goal, path)\n File \""/home/vmuser_whnisdqu/workspace/search_tests_biucs.py\"", line 17, in is_path_correct\n if not (path[0] == start and path[-1] == goal):\nTypeError: 'NoneType' object has no attribute '__getitem__'\n"", ""description"": ""Test the bi-directional uniform cost search implementation"" }

It looks like an error with the path (is it saying path is NoneType?), but I haven't been able to produce it locally in either Romania or Atlanta.  My paths are returning the start and end nodes in my local tests, as well as correct paths.  Any help much appreciated.', u'responses': [u'I think what's happening is that `path[0]` is doing `path.__getitem__(0)` under the hood, and that path is None so it doesn't have that a `__getitem__` method. I'm currently debugging the same issue.', u'One clue: although my code was returning a correct path for Romania, it was reporting a nonsensical (looping back on itself) path for Atlanta. I think there's an issue with how I track nodes I've visited before.', u'Ok I got rid of the NoneType error and have moved on to a different error. My particular issue was I was calling list.reverse() on the backwards path to join it to the forwards path, but I was calling it once in a print statement and once in the return statement. It was reversing the list twice which meant the joined path wasn't necessarily continuous. So many things could be going wrong but maybe this helps you!', u'@Sasha Not sure if you noticed, but print path.reverse() will output None because reverse() is an in-place operation with no return value. If, however, you want to print the reversed list in one line, use print list(reversed(path)).', u'Sasha, thanks for the tips.  I think my problem may be different than yours.  It sounds like we are doing some similar stuff though.  For the search starting at the end - when I combine it with the forward search - I am slicing off the last member and then using list(reversed(path)) and combining it with the forward search and then return the path.  This removes the duplicate member and creates the full path.  

I am also playing around with a mu value so that it doesn't return the first path found, but the optimal path.  When I just return the path without considering the optimal path, I get a 89% pass score for 10/15 points.  When I add mu I get this error message.  It works locally but there must be some edge cases on bonnie I am not considering.', u'I figured this out.  I was only returning if a condition with mu (best score) was met.  I needed to return something if it wasnt met.  Now passing both bi directionals.  A lame way to spend a couple days troubleshooting, but happy its resolved.']}, {u'text': u'Did anyone test with Romania (g-t) ?', u'responses': [u'I get ['t', 'a', 's', 'r', 'p', 'b', 'g'] but my implementation is not currently passing on Bonnie.', u'I have the same as Sasha for g,t, though I would put it in the opposite direction (starting at g) :-)']}, {u'text': u'Any one advice on what is a break point for bidirectional a*?', u'responses': [u'I use a similar break condition as bidirectional ucs, with offset of the heuristic. That gives me a score of 19/20', u'I use the same break condition i used in bidirectional UCS. But my Bidirectional UCS pass optimal path but explores 2 extra by average. Bidirection a start doesn't explore extra but returns sub optimal route.', u'Fixed and got full score. Lesson learned, if we don't check start == goal and return empty list , you could loose upto 10/20 points.', u'I checked, still get 10/20. Struggling of debugging 0.0']}, {u'text': u'Important note! Read the code for the tests provided. They don't actually check anything, just run your code and output a map. If your code runs without errors and you're not paying attention, you may think that means that your code has been checked and is correct.', u'responses': [u'the tests in search_unit_tests.py do actually run tests and tell you when you got something wrong. 

You can run specific tests from the command line.  For example:

python search_unit_tests.py SearchUnitTests.test_tri_upgraded_euclidean_romania

runs the romania tests (many ?every? sets of goals) on your upgraded tri-directional algorithm.']}, {u'text': u'I'm a bit confused based on the different approaches outlined in multiple sources.  The lecture notes ""efficient point-to-point shortest path algorithms"" appear to combine the symmetric and consistent approaches, no? 

For the life of me, I cannot get the consistent approach as outlined in ""a star meets graph theory"" to work using the given pt(v) and ps(v) functions.  Are we supposed to combine the approaches?  The consistent approach by itself, as I read it, does not require a modified stopping criteria since the functions are consistent...', u'responses': [u'For this problem, just looking at ""Bidirectional A* Search with Additive Approximation Bounds"" and the ""Efficient P2P shortest path algorithm"" slides should get you a pretty clear picture.', u'FWIW, I got it to work, but my question still remains...;(']}, {u'text': u'In ""Efficient Point-to-Point Shortest Path Algorithms"" slides, they introduce pi_r() and p_r(), and show that the stopping condition is topf +topr ≥ μ+pr(t).

It looks like p_r is half the difference of pi_f and pi_r, but I don't have good intuition about how that fits together with the heuristic function we're using here (euclidean distance from t). Could someone help me connect the dots?', u'responses': []}]",,2.0,330.0,297,,Assignment 2- Exercise 2 Discussion Thread,[a2]
5ad7d44c0d63974e20c39121,"Discussion thread for Exercise 3: Tridirectional UCS search

",jc6w44hrp9v2ki,"[{u'text': u'I got this error message, does that mean my code gives different path than Bonnie's? There is no autograder_comments, so very difficult to understand why...

{ ""output"": { ""points_available"": 19, ""points_awarded"": null, ""autograder_comments"": """" }, ""traceback"": ""Traceback (most recent call last):\n File \""/home/vmuser_icmpoaqg/AIResult.py\"", line 26, in func_wrapper\n ans = func(self)\n File \""run.py\"", line 208, in test_tristar\n self.assertTrue(tests_pass, \""Tridirectional Search Tests\"")\nAssertionError: Tridirectional Search Tests\n"", ""description"": ""Test the tri-directional search implementation"" },', u'responses': [u'Looks like the problem I had yesterday. If you have a lot of return statements (e.g. for edge cases) before the main body of your code this is what Bonnie says.', u'I get the exact same error message despite passing all local unit tests.

I do not have a ""lot of return statements"", so I don't think this is relevant.', u'I had this problem too; but once I got the tri directional searches to return a correct answer for all of the combos in the unit test, I began to get a positive score on bonnie', u'I was calling bidirectional_ucs from within tridirectional_search. Creating a copy of bidirectional_ucs with a different name solved the problem for me. Thanks to van in the slack channel for helping me out.', u'Thanks Giacomo! Very smart move, and I did the same and got 18/19 of this exercise (pass ratio at 0.9972...), and 15/15 of 4th!

Do you mind pinging me the slack channel. I'd like to have a more direct way to discuss with my classmates. Appreciate it!', u'What is the Slack group for this class? How can I register as a member of the class Slack group?', u'omscs-study.slack.com, the channel is #cs6601', u'Thanks, Giacomo!  I've been banging my head on this one and this moved me from 0/19 to 18/19.']}, {u'text': u'Also having this problem. The answer above doesn't really apply to my case as far as I can tell. Any other thoughts?', u'responses': []}, {u'text': u'I'm also having this problem and don't think it's related to returning early.

I posted a private question with a link to my Bonnie submission, which I believe includes my code submission.', u'responses': []}, {u'text': u'I have it too. My search seems to work locally.', u'responses': [u'I also get the same error if I try the same code on the improved tridirectional tests']}, {u'text': u'Hi Everyone,

QQ: Readme says:  keep expanding until two of the three searches meet. How deep it's required to search? Just until frontiers intersect? or it's required to perform additional search to find the most optimal path like it's done for bidirectional.

Thanks 
Alex', u'responses': [u'Nevermind.']}, {u'text': u'Can we just use the same code from our upgraded tri search for this part? (i.e. does this part have to use UCS, or can we use ""something better""; I was stuck at 99.69% using strictly UCS, and was only able to get the full points using the ""better"" approach.)', u'responses': [u'Me too, stuck at 99.72%. ', u'I want to know this as well.', u'Anyway we can get an instructor response here before the weekend?', u'@Jerry Can you help with edge cases i have check?

 I implemented Tri search with 3 queues and choose the one with minimum top looking for two additional points. I am handling (a, ,a ,a) and (a, b, b) cases. Still i am not able to move beyond 90% pass rate. Am i missing any other case?
 
 
{
    ""output"": {
        ""points_available"": 19,
        ""points_awarded"": 10,
        ""autograder_comments"": ""Tridirectional search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum\nOn average, number of nodes explored more than the benchmark = 1.86816\n"",
        ""pass_ratio"": 0.908625730994152
    },
    ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_klptifqs/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 208, in test_tristar\n    self.assertTrue(tests_pass, \""Tridirectional Search Tests\"")\nAssertionError: Tridirectional Search Tests\n"",
    ""description"": ""Test the tri-directional search implementation""
},', u'at 10/19, I think you are exploring too far on both you completed edges and your uncompleted edge.   so you need to look at your completion tests to make sure you're not continuing to explore further than necessary.

I tracked the edges where I had found the minimum path and when I had 2 edges complete, I then looked at the minimum length I could achieve on the 3rd edge and stopped when that minimum edge was greater than the max of the 2 completed edges (e.g. the edge could no longer replace the existing edges).']}, {u'text': u'Is this a reasonable claim:
For a tri-city UCS search, we just need to run 3 bi-directional UCS, and find the 2 (out of the 3 bi-directional UCS) with lowest cost, and then combine into one?

Or am I missing anything here?', u'responses': [u'as per my understanding we need to run 3 UCS but for each of them we need to track 2 possible connection points - not sure whether you meant the same or not.', u'That's essentially what I've done. The performance could be better though.', u'Yeah, I ran 3 UCS, get 3 meet points, choose the 2 points with the lowest path cost.', u'Think about the scenario where search A has met B,  B has met C, but A has not met C.

At this point, could you find a way to ensure that the unfound path (A<->C) couldn't possibly be any smaller than the two you have already found?']}, {u'text': u'I'm facing the same error for my tridirectional search. Its passing the local tests.', u'responses': [u'how to test tridirectional search locally?', u'see the search_unit_tests.py file, comment out the irrelevant code, and run the algo for the tri-ucs on romania map.']}, {u'text': u'Same error...', u'responses': [u'Using different method names for ucs and astar bi-directional search fixed the problem with getting 0/x points on the tri-directional search (assuming you're trying to leverage them to at least get a version 1 working).']}, {u'text': u'Same error here, passing everything locally, not even 1 point on Bonnie on this.', u'responses': []}, {u'text': u'stuck on 10 points out of 19, has Anybody faced the same? what can be a possible input goal for which I'm not finding an optimal path?', u'responses': [u'I was stuck there for a while. I think the description in the README is not accurate. Implementing a very naive UCS (end as soon as two connecting paths are found) will not produce an optimal solution. However, bonnie appears to be grading in such a way that you need to find an optimal solution.

I'm now getting 18/19 and interestingly, I'm using the exact same algo for the improved tridirectional search and getting 14/15.', u'thank you very much, changed my code to search for the most optimal path between 3 nodes and got 18.', u'My code finds the most optimal path but am only getting 10/19 due to over-exploration. I think I am finding the optimal path but not stopping soon enough.', u'Nick,I was testing 1000 iterations of random points on romania and getting optimal solutions while still only getting 10/19 on bonnie. It wasn't until I started testing against atlanta paths that I was able to discover some cases in which I was not producing optimal paths.', u'@Alex What are the test cases you have been checking. I am using three UCS going a-b, b-c, c-a and taking one move from each at a time. I will stop if i have two paths found and third path cost is great than max cost of two paths found. I am testing case (a,a,a), (a,b,b). Any other special cases?', u'previously when I was searching only  for 2 first paths, my implementation was not able to handle this path appropriately (i,g,e), but I guess it's not your case


PS: is it fine to share test cases?']}, {u'text': u'So I ran into the same issue above of being stuck on a 10/19 on part 3.

I tried implementing it as described in the read me. Then I tried using some of the bidirectional logic I came up with in part 2. Same issue.

Out of curiosity, I ran the upgraded version that I made (and have been getting 14/15 on). This is not utilizing the UCS algorithm though. Is this allowed? Or does the part 3 algorithm need to utilize UCS as it says in the README?', u'responses': []}, {u'text': u'Pass Ratio is 99.57 and got the below message. Did not get this message for UCS, any possible cases i am missing?

""Tridirectional search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum\nOn average, number of nodes explored more than the benchmark = 1.37931034483\n"",', u'responses': [u'It's all about your stopping/terminating conditions.  Look at how you're exploring forward and see if there's a way that you can stop sooner.']}, {u'text': u'Are we allowed to use Bidirectional UCS algorithm for this assignment , should we only use one directional UCS algorithm?', u'responses': [u'@369', u'The intent is for you to use tridirectional UCS (not binary or unary directional  UCS). ']}, {u'text': u'Could you give more hints on how to reduce the number of explored nodes for tri-usc? I passed the unit test (successfully generated shortest path for all triplets of goals), but could not think of a way to further reduce the number of explored nodes.

I am currently using an approach similar to the ""stronger stopping condition"" in the Bi Direction A Star slides:
      topf + topr ≥ μ.

I.e.,  when min(top_a + top_b, top_a + top_c, top_b + top_c)  ≥ μ

Is this the right approach?', u'responses': [u'I think so. mu will provide a floor on shortest path found so far and the min() function will prevent you from looking any further once the minimum of all pairs of paths are longer than that shortest path.']}, {u'text': u'I gave up using BiUCS for this and tried true tridirectional search with 3 UCS taking one move from each front at time. I am also stoping once i found two paths and 3 path is great than max cost the paths found already. I am handling edge cases (a,a,a) and (a,b,b). I got 10/19 with the below error. Should i cover any other edge case?
On average, number of nodes explored more than the benchmark = 2.00713648528', u'responses': []}, {u'text': u'Implement tridirectional search in the naive way: starting from each goal node, perform a uniform-cost search and keep expanding until two of the three searches meet. This should be one continuous path that connects all three nodes.
tridirectional_search() should return a path between all three nodes. You can return the path in any order. Eg. (1->2->3 == 3->2->1). You may also want to look at the Tri-city search challenge question on Udacity.

I don't think 1->2->3 is a continuous path. Shouldn't it be 1->2->3->1 ?', u'responses': [u'Continuous means connect the three, not create a loop. e.g. 1,2,3 stop. 1,3,2 stop. ']}, {u'text': u'

Best way to get from o to d is:  o -> s -> r -> c -> d (497)
Best way to get from d to e is:  d -> c -> p -> b -> u -> h -> e (628)
Best way to get from e to o is:  e -> h -> u -> b -> p -> r -> s -> o (698)

What would you return in this case? Udacity makes it seem like they want the path as a continuous triangle, which would be concatenating the above 3 paths: o -> s ->r -> c -> d -> c -> p -> b -> u -> h -> e -> h ->u ->b ->p -> r ->s -> o', u'responses': [u'Should be your 497 and 628 paths concatenated. So o,s,r,c,d (remove duplicate),c,p,b,u.h,e.']}, {u'text': u'Theoretically speaking, the shortest possible path will always be two straight lines. I can think of a couple of ways to lower the number of nodes to search, but I can't see how using a tri-directional algorithm would optimize this over just re-using the bi-directional algorithms.

Meaning, what exactly would a tri-directional algorithm offer that would improve the search pattern. For instance, simultaneously searching from all three starting points until a common meeting point (or visited set) was found would return a longer path than finding the shortest path between each node (search might be quicker, but path cost will not be optimal). Simple triangle inequality makes this so. 

Does anyone have a better way of thinking about this?', u'responses': [u'Theoretically you will not have to visit as much nodes or do as much work in many cases and you should result in the optimal path (assuming you set your stopping conditions correctly.', u'So is it kind of like (super simplified) meet in the middle of the triangle somewhere, then expand toward the triangle edges (paths should be getting shorter), and then stop once we detect that all paths are getting larger?
', u'Not so much meet in the middle as much as spread out from each goal exploring the closest node each time and when they touch you've found your path (using the correct termination conditions).

bi-directional search works the same way.  The difference here is that you shouldn't have to explore the same nodes repeatedly in the different searches since they will share exploration of some of the same nodes. (in trying to figure out the path from A to D and from A to F, I will explore Z in both searches in multiple bi-direcitonal searches, while I will only explore S once in a tri-directional search.', u'Ah, ok. I think I get it. In practical terms, you're saying instead of 6 data structures (2 for each bi-directional search), we'll have just 3. And to do it properly, we should generalize to 2+n (re-usable code!), where tri-directional is simply n=1. Meaning, instead of a factorial explosion of data structures, we keep it linear.
']}, {u'text': u'
Hi, I implemented Tri search with 3 queues and choose the one with minimum top looking for two additional points. I am handling (a, ,a ,a) and (a, b, b) cases. Still i am not able to move beyond 90% pass rate. Am i missing any other case?


{    ""output"": {        ""points_available"": 19,        ""points_awarded"": 10,        ""autograder_comments"": ""Tridirectional search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum\nOn average, number of nodes explored more than the benchmark = 1.86816\n"",        ""pass_ratio"": 0.908625730994152    },    ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_klptifqs/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 208, in test_tristar\n    self.assertTrue(tests_pass, \""Tridirectional Search Tests\"")\nAssertionError: Tridirectional Search Tests\n"",    ""description"": ""Test the tri-directional search implementation""},', u'responses': [u'My jump from 10 to 18 was around setting my stopping condition for the edges that connected correctly (I had been exploring too many nodes).   My jump from 18 to 19 was around limiting my last edge to only far enough that it's shortest possible path (the part completed on each end) was longer than the two solutions I already had.', u'Conor...you are the best!  You saved me an entire night of sleep.  The assignment is due at 4am tomorrow (my time) and I was planning to stay awake until the end to make sure I got every point possible.  Thanks again!']}, {u'text': u'I am getting the following error on submission
 ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_zpysgnmr bash -c \\\""cd /home/vmuser_zpysgnmr; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_2 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""EEEEEEE\"", \""stderr\"": \""bash: line 1:    28 Killed                  python run.py assignment_2 > run_stdout.txt 2> run_stderr.txt\\n\""}""', u'responses': [u'See @444']}, {u'text': u'I am having an issue with deciding when to construct my path. Currently I run three UCS instances and when two searches meet I construct the path and return. However this sometimes returns a non valid path, example would be when goals are: a,c,f. The a and f searches connect at the s node, but the only way to get a valid path is for the f to go toward b. Does this have something to do with the time at which I evaluate?', u'responses': [u'If your UCS searches are working correctly, you should have complete paths from start to finish between two nodes (or, as I like to say, along 2 edges).   The problem is that when you put those paths together, they may not go together as path1 + path2.  Sometimes it will be path1 + reverse(path2).  Sometimes it will be reverse(path1) + path2 and sometimes it will be reverse(path2) + path 1.  

Note also that when you join the paths, you'll have a common node in both paths at the point of juncture -- you will need to only have a single copy of the node (so a, s, r + r, p, b would result in a, s, r, p, b).', u'Well my issue isn’t really constructing the paths, it is more that my Tridirectional search prematurely selects a path that does not make a valid path through the middle node. All three goals are included but it is not a valid path.', u'I think I am running into the same issue.  any help would be greatly appreciated.  Most likely need to explore some more.  May be I am confused about when two of the searches meet.  In my case, if I am about to add a node to the frontier, I check to see if it exists in one of the other two frontiers.  If match, generate a path but that just tells me there is a path between two nodes and does not say much about the third node.  I know this may not generate an optimal path but unable to construct a valid path indicates some overall issues. 

For this case: [f s r c] would work for mid goal.  so, 's' intersection may be correct.       ', u'In a tri-search you almost always have to find at least 2 paths - sometimes 3.  then you put the necessary paths together for your solution.

If your stopping at the first path, you are likely just connecting 2 nodes in your response which won't meet the requirements.', u'Thanks.  Also re-watched 2.45 lecture. Makes sense.  ']}, {u'text': u'What should be the output if running the trisearch on romania with these goals:

test case #1 - goals = ['a','a','z']
test case #2 - goals = ['a','s','o']
test case #3 - goals = ['a','a','a']

I think I have things working, I have a good number of romania's test working and I'm getting a cryptic null in the points_awarded with no explanation :(. I'm wondering if I'm missing the empty cases.', u'responses': [u'
#1: [a, z] or [z, a]
#2: [s, a, z, o] or [o, z, a, s]  because a->z->o (146) is shorter than s->o (151)
#3: [] (empty set)', u'Actually, AZO is 146 but SA is 140 and SO is 146. Strange ', u'SO is 151 as far as I was able to check. I’m not sure what you want to change in my responses.', u'Weird. Must have a mistake in my path summing. Thanks. It's always the stupid mistakes that get overlooked.', u'oh my goodness! the answer for the first one is [] ! The readme does say that if ""any"" of the goals are the same, the whole thing should be an empty array...... well at least I figured it out!', u'That isn't correct.   the answer for the first one is as I outlined.  The readme.md for tridirecitonal search says:

If any goals are the same then just return [] as the path between them. 

Note the ""between them"".   In the first example a was there twice so the path between the two 'a's would be [].  Then you have the path between a and z.   so the answer would be as I outlined above.']}, {u'text': u'Sigh, I'm struggling at merging the paths, it seemed easy.

I'm struggling when the goals are 'a', 'c' and 'f'

I get two best paths:
['a', 's', 'r', 'c']
['a', 's', 'f']

but the tricky thing is how to merge them, it's not enough to just remove the 'a'.

I'm trying to figure out how to tell the code the right way to merge it but I can't think of something generic, ideas?', u'responses': [u'take a look at reversed(list) in python', u'Thanks! I was generating the paths wrong :(', u'I just realized that.']}]",,16.0,330.0,298,,Assignment 2- Exercise 3 Discussion Thread,[a2]
5ad7d44c0d63974e20c39122,"Discussion thread for Exercise 4: Upgraded Tridirectional search.

",jc6w44hrp9v2ki,"[{u'text': u'Just had a quick skim of the landmarks materials - when we use a landmark, we need to compute the shortest path from each  landmark to all nodes. Doing so would mean expanding all nodes on the map. Wouldn't computing landmarks automatically put us over the explored node count for the benchmark? If we know the map before hand, landmarks make a lot of sense, but on bonnie, we could be tested on an arbitrary graph. ', u'responses': [u'That's actually also my concerns. For each landmark, we need to explore the whole map to calculate the shortest path cost between each node and this landmark. So the pre-processing definitely takes a lot time.

Since we need to submit code to Bonnie, I suspect we should pre-process landmarks locally and save the path data somewhere, and then upload to Bonnie as well, when we submit search_submission.py. But I don't see there is option to attach any other data files when submitting assignments... Unless we want to embed the path cost data in the main ""search_submission.py"" file, but given the size of nodes, I am hesitant to do it.', u'I see a load_data() function in the submission file. Presumably it can be run (and load a data.pkl file that's included in your submission package). The problem is, we don't know what map we'll be tested on, so how can we prepare a data.pkl. Yes, you could assume that it's Romania or Atlanta, but for all I know, we'll be tested on Rio or  Tokyo.', u'If you look at submit.py code, only search_submission.py will be loaded, unless we want to change the code in submit.py?', u'same question here. I only found ""The Race! will be based on Atlanta Pickle data."", but for all 4 exercises, no mention on the maps. Again how to upload the pre-computed distance between landmarks and all graph vertices?']}, {u'text': u'Is the race based on # of nodes explored or how fast your search returns?', u'responses': [u'The TA private messaged me and said they will make a post about the race soon. I'd imagine # of nodes.', u'The post is here @406']}, {u'text': u'On Bonnie, this test of improved tri-directional against landmark search has points_available = 0. I assume it is just comparing our tridirectional_upgraded() with their tri-directional search that uses landmarks. Is it part of exercise 4 and what is the purpose of this test if the points available is zero? ', u'responses': []}, {u'text': u'can we use bidirectional A* here ?', u'responses': []}, {u'text': u'It seems that for tridirectional a star to work mathematically, we need to find heuristic function that is 'consistent' for all three point. In bidirectional case this can be done by the average trick. However I struggle to find anything similar for tridirectional search. Am I on the right track to approach this problem? Any other ideas?', u'responses': []}]",,4.0,332.0,299,,Assignment 2- Exercise 4 Discussion Thread,[a2]
5ad7d44d0d63974e20c39123,"Does any one have problem to clone assignment 2 repository from the Github? I tried several times, all failed. The receiving objects is very slow. Below are error messages: 
Pinglings-MacBook-Air:assignment_2 angela$ git clone https://github.gatech.edu/omscs6601/assignment_2.git
Cloning into 'assignment_2'...
remote: Counting objects: 984, done.
remote: Compressing objects: 100% (18/18), done.
error: RPC failed; curl 56 SSLRead() return error -36B/s      
fatal: The remote end hung up unexpectedly
fatal: early EOF
fatal: index-pack failed
Pinglings-MacBook-Air:assignment_2 angela$ git clone https://github.gatech.edu/omscs6601/assignment_2.git
Cloning into 'assignment_2'...
remote: Counting objects: 987, done.
remote: Compressing objects: 100% (21/21), done.
error: RPC failed; curl 56 SSLRead() return error -36KiB/s     
fatal: The remote end hung up unexpectedly
fatal: early EOF
fatal: index-pack failed
Pinglings-MacBook-Air:assignment_2 angela$ git clone https://github.gatech.edu/omscs6601/assignment_2.git
Cloning into 'assignment_2'...
remote: Counting objects: 987, done.
remote: Compressing objects: 100% (21/21), done.
error: RPC failed; curl 56 SSLRead() return error -9806iB/s   
fatal: The remote end hung up unexpectedly
fatal: early EOF
fatal: index-pack failed",jc6w44hrp9v2ki,"[{u'text': u'Things are looking good here...

$ git clone https://github.gatech.edu/omscs6601/assignment_2.gitCloning into 'assignment_2'...remote: Counting objects: 987, done.remote: Compressing objects: 100% (21/21), done.remote: Total 987 (delta 12), reused 0 (delta 0), pack-reused 966Receiving objects: 100% (987/987), 57.73 MiB | 4.16 MiB/s, done.Resolving deltas: 100% (351/351), done.Checking out files: 100% (24/24), done.', u'responses': []}]",,0.0,180.0,301,"From a google search of that error message, it looks like it's a network issue exacerbated by pushing a large repo (the one for this project is HUGE). You might have success if you try again later, or on a different internet connection. If not, here are instructions on adjusting your git buffer that might work: https://www.backarapper.com/fix-git-push-curl-sslread-error/",Error happened when clone assignment 2 repository,[a2]
5ad7d44d0d63974e20c39124,"Maybe it's just late, but would someone point out where the seventh pair is in this diagram?


",jc6w44hrp9v2ki,"[{u'text': u'Don't the left-most and right-most queens on row 2 also count as a pair?', u'responses': [u'Ah, that's it. Thanks!']}]",marking resolved as per the comments below. ,0.0,169.0,302,,Pairs of attacking queens,[lesson3]
5ad7d44d0d63974e20c39125,"Since we're going to have to do this six times in the course, and probably also for future courses, I finally wrote down exactly what I do for each new github repo we get. Sharing in case it's useful to others! ",jc6w44hrp9v2ki,"[{u'text': u'Sasha, thanks for providing these instructions. When I followed the steps, I received this error. Do you know what that means?

git push -u origin master
error: src refspec master does not match any.
error: failed to push some refs to 'https://github.gatech.edu/phu30/ph_ai_assignment2.git'
', u'responses': [u'I'm not sure what that error means, but my understanding of refs is a little fuzzy. From a quick google search, it looks there are a few different possible causes.

My original post left out ""cd into the repo directory"" in step #1, could that be the issue here?', u'After skimming the refs section of this excellent git book, a ref is a pointer to a specific commit. Each of your branches has a ref that points to the most recent commit, and there's a special HEAD ref that points to the ref of the branch that's currently active.

I think this error message basically means that it can't match up the ref of your local repo to the ref of your github repo for some reason—either the master ref doesn't exist because you haven't made any commits yet, or you mistyped the branch name and they don't match.

In any case, lmk when you figure out the issue and I'll update the instructions, if needed.', u'Thanks Sasha, cd into the repo directory created in step 1 fixed it. Thanks for your help!']}, {u'text': u'I actually do not do this. I create a repo in my ga tech account and put my code there as I share between computers. Here is what I did to create my new repo:

git clone https://github.gatech.edu/omscs6601/assignment_2.git
cd assignment_2
git push --mirror <my private repo on ga tech git hub>
cd ..
git clone <my private repo on ga tech git hub>
cd <mydirectory>
git branch develop
git checkout develop

And I work off that from there :)
This way I can share between computers and not lose a step.', u'responses': [u'Also, like to add that if there is an update in main branch then I get it off there and copy it into main on my area and do a 
git pull origin master 
in the develop branch.
', u'Also, reread the post and realize it accomplishes the same thing in a cleaner way so ignore my post I guess :P
', u'Haha! Thanks Brett and Sasha :)', u'Yep, sounds like we're aiming at the same end goal, and there are many different ways to get there. I forgot to include the `cd` step and hadn't used the `--mirror` option before, I'll add those, thanks!', u'Yep Sasha,
I would also like to add that it is VERY important that you create it in a PRIVATE repo. Otherwise it could be found and would be a violation of the honor code for you if it does.', u'Agreed, that's why I put it in all caps', u'I need to read more closely, second time now :P', u'I got a plan, Sasha, you write some instructions out. Then I will repeat them and act as if they are my own. Sound good?']}, {u'text': u'I think that's still too complicated...

I have ONE repo using bitbucket (unlimited free repos) and have one repo per class...

Then I do:

git clone https://github.gatech.edu/omscs6601/assignment_2.git
rm -rf assignment_2/.git
cp -r assignment_2 ~/repo/ai

', u'responses': []}]",,0.0,167.0,303,,Git repo setup instructions,[other]
5ad7d44d0d63974e20c39126,"This is the solution for Challenge Question 1 - @128. Refer to this thread @283 for all the other Challenge Questions. 

A) Solution using MiniMax.
 
 



B) Solution using Minimax with alpha-beta pruning. 
",jc6w44hrp9v2ki,[],,0.0,217.0,305,,[Solution] Challenge Question 1 - Game Playing,"[lesson1, challengeqtns]"
5ad7d44d0d63974e20c39127,"Quick Question regarding required python Libraries for A2

Creating my venv project interpreter for this project and verifying/installing required packages.  venv is based on anaconda 2.7 release of python.

packages for ""networkx"" and ""requests"" are already including in anaconda bundle, BUT their versions are:
networkx -- v2.0, but A2 requires v1.11
requests -- v2.18.4 but A2 requires v2.13.0

does anyone know if it is required, or recommended, to downgrade to the explicit releases noted in the 'requirements.txt' file as noted?

Thanks,
Rick A. (farmanino3)",jc6w44hrp9v2ki,"[{u'text': u'I would say that it is very likely you need to downgrade. I was making an attempt at BFS last night and I got errors for very simple things like just reading in the graph and looking at nodes. The errors were for missing methods inside the networkx data structures which leads me to believe there is some kind of incompatibility. ', u'responses': [u'Great, thank you; that is the recommendation/confirmation I was looking for.']}]","When I was testing Assignment 2, I actually ran into an error with networkx because I had a newer version. So make sure you're using the networkx version specified in the project, or else it will fail when you submit it.",0.0,208.0,306,,A2 -- Required Library Versions,[a2]
5ad7d44d0d63974e20c39128,"Any one from South Silicon Valley (San Jose, Sunnyvale etc other nearby areas ) would want to join me to meet and discuss this course material ? you can email me on my personal email id vsaxenag@gmail.com",jc6w44hrp9v2ki,[],,0.0,152.0,307,,study group for South Silicon Valley,[group_study]
5ad7d44d0d63974e20c39129,"
Will the distribution of grades be released for assignments and exams?",jc6w44hrp9v2ki,"[{u'text': u'I know the course grade is relative with respect to median. Is the assignment grade also relative to median?', u'responses': [u'It seems that assignment grades are raw/absolutes -- you get the grade that you achieved.  The curve is applied at the end of the course to your final grade.', u'Correct, the curve is applied at the end.']}, {u'text': u'Any news on Assignment 1 grade distribution?', u'responses': [u'With Assignment 1 grades now released, any chance we can get the grade distributions?', u'Grade distribution released! Thanks.']}, {u'text': u'I got 75 marks on Bonnie submission in Assignment 1. Why is it showing 0/100 on T-Square????', u'responses': [u'You might want to post a private message to the instructors about this.']}]",Yes,2.0,254.0,308,,Assignment 1 Grade Distribution?,[a1]
5ad7d44d0d63974e20c3912a,"Hi everyone,

Hangouts isn't letting me join the usual hangouts call, so please join this one instead for today's meeting:

https://hangouts.google.com/call/ZsZwAK-zYuak--rDamAXAAEE

Sorry for difficulty, I'm not sure why hangouts is having an issue. In the future we will not be using this link, unless we have the same issue as before.

-Noah
",jc6w44hrp9v2ki,"[{u'text': u'What time this hangout starts??', u'responses': [u'My office hours are every Wednesday from 4 to 5 oclock. The calendar of all office hours is here: 

https://calendar.google.com/calendar/embed?src=7f5agh74re4ldpkddoqa91ce4s%40group.calendar.google.com&ctz=America/New_York', u'Ok, Thank you!! Looks like I missed it this time. :)']}, {u'text': u'Are these office hours not recorded?', u'responses': [u'Office hours are not recorded, but the youtube live session before every assignment is recorded.', u'Opps. I missed so many office hours. I'm used to watching the recorded office hours.', u'could you share link for recorded Office Hours', u'I second Vish's request. Is there a folder or a link? ', u'Once the Hangouts On Air session is over, the link to join the call points to the recording. ']}]",,0.0,179.0,309,,New Link for Noah&#39;s Office Hours,[office_hours]
5ad7d44e0d63974e20c3912b,"[Asking privately to instructors to avoid impropriety]
Is heapq a hint or a gift?

The heapq docs provide some implementation detail and analysis, so you might be expecting us to read those and then roll our own implementation based on it.

On the other hand, you actually gave us heapq as an import, which implies to me it's okay to go ahead and use it, and I'd prefer to do so.

Is it legitimate to use heapq directly in our PriorityQueue implementation?

Hint: The heapq module has been imported for you. Each edge has an associated weight.

",jc6w44hrp9v2ki,"[{u'text': u'great - thank you - can i make this conversation public?', u'responses': [u'Done!', u'anon strikes again!  thanks anon!', u'That happens automatically when you post privately initially, then change the visibility to public', u'^if that's true, that explains a lot. I've noticed this and wondered why it does that. Thanks for that.']}]",It's okay to use heapq directly.,0.0,203.0,313,,Okay to just use heapq?,[a2]
5ad7d44e0d63974e20c3912c,"Hey everyone,At the start of the semester, we had decided to adopt a common link for use across Office Hours sessions. However, we found that it was doing us more harm than good, with multiple students and TAs being unable to join the link. As a result, we've decided to revert to having individual links for each Office Hours session. The new system is simple enough:
Visit the Office Hours Calendar at https://calendar.google.com/calendar/embed?src=7f5agh74re4ldpkddoqa91ce4s@group.calendar.google.com&ctz=America/New_YorkClick on the relevant Office Hours session and on 'More Details'Click on 'Join Video Call' or 'Join Hangout'
We apologize for the inconvenience. This should be a far more reliable system, however.This will take effect from 1st February. The previous link will no longer be used.

Please also refer to the Office Hours section of the syllabus document for details.

#pin",jc6w44hrp9v2ki,"[{u'text': u'This does not work for me.

When I click on ""More details"", it opens in a new tab and in few, there is a hangout link (I have seen in only one till now). All others don't have any such option like 'Join Video' or 'Join Hangout'

I personally liked it, when there was a new temporary ( 2-3 hrs) post pinned for each OH with the video link. I hope this can still be done.
', u'responses': [u'Hey Anil, that's because a few TAs are still in the process of updating their Hangouts links. It will work for everyone as it does for my OH in the screenshot.
The previous system did not work. It was simply not possible to continue with it. The temporary posts were simply an accommodation by us, and this is the same thing in a more uniform manner.']}, {u'text': u'Is today's office hours canceled?', u'responses': []}, {u'text': u'office hours happening today? its 5pm and I am an only one on the call', u'responses': []}]",,0.0,273.0,316,,Office Hours System Changed,"[announcements, office_hours]"
5ad7d44e0d63974e20c3912d,"I just finished the warmup questions and got the below result after passing local tests, but I got 0 scores from all four tests from bonnie.Is these the optimal path? Any tips on how to debug for bonnie? Maybe with more test cases? Thanks a lot!

BFS: (Edit: answer should be ASFBU)

UCS:

A*:

Bonnie messages:
Null heuristic A star search fails benchmarks searching from start to goal node\nPath is longer than optimal path\n
Breadth first search fails benchmarks searching from start to goal node\nPath is longer than optimal path\n
Priority queue insertion should be amortized O(1),\n        but performance significantly differs from that of reference queue.\nAverage insertion time for PQ: 0.000639833235741\nAverage insertion time for ISQ: 0.000275488328934\n
Uniform cost search fails benchmarks searching from start to goal node\nPath is longer than optimal path\nPath cost is incorrect",jc6w44hrp9v2ki,"[{u'text': u'My understanding for BFS is that it should take the fewer nodes path. ASFBU. Your uniform cost search looks correct, but I have a bug in my code, so can't confirm yet.', u'responses': [u'Oh right! Let me see which part of my code went wrong. Thanks!', u'David is correct. BFS should return [a,s,f,b,u] while UCS should return [a,s,r,p,b,u]. As for A*, I haven't gotten that far yet. ;)', u'I fix the code such that it return ASFBU, but now I got the below message from bonnie:
Breadth first search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum
', u'My BFS is giving ASFBU but is still scoring 0 on Bonnie', u'Same here, what error you got?', u'""Breadth first search fails benchmarks searching from start to goal node\nPath does not go from start to goal node or is invalid\nPath is longer than optimal path\n""', u'In my case I get the right BFS path but grading says 'Nodes explored should be from a valid frontier and should be kept to a minimum'. Looks like the call to graph.neighbors() stores which nodes you explored so grading can check what you explored. But not clear what the result message indicates..', u'David, I have the same error too. I've explored these nodes below. I think it's already minimum in this test case?
', u'Now, i'm also getting ""Breadth first search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum\n""
', u''nodes explored should be kept to a minimum..' So after some tweaking I get -

which has less explored nodes than my previous attempts and still returns the correct BFS path - a s f b u. I need to make some time to verify the implementation is correct but I think it is.

However, the result is 'Path does not go from start to goal node or is invalid\nPath is longer than optimal path'

So -
'Path does not go from start to goal' - well it does - it starts in a and ends in u
'or path is invalid' - looks valid to me. i.e. all node to node  paths look fine
'Path is longer than optimal path' - just eyeballing the path I don't see any path with fewer segments

Possibly there are other conditions this fail description means? Any hints on what is wrong here?


', u'I'm seeing the same graph as you, David, and am also failing the BFS test. I don't understand why the error states that my path does not go from start to end because it obviously does on my local machine. It might be worth trying it on the VM to verify.In case other people missed this, there's a link to a document explaining the Bonnie messages in the github readme: https://docs.google.com/document/d/1hykYneVoV_JbwBjVz9ayFTA6Yr3pgw6JBvzrCgM0vyY/pubBonnie’s Error Messages ExplainedPath does not go from start to goal node or is invalidThe path returned by your algorithm does not have start and end goals at their respective positions; does not have the correct start and end goals; is not the shortest path to the goal; is not a complete/connected path.Path is longer than optimal pathYour path cost is greater than optimal path cost/benchmark you need to beat.Nodes explored should be from a valid frontier and should be kept to a minimumYour algorithm is exploring more nodes than necessary or is exploring nodes that should not be explored in that particular test. This is independent of whether your path is correct.On average, number of nodes explored more than the benchmark = xyzThe average number of nodes explored in excess by your algorithm (includes only failure cases of exploring excess nodes).Path cost is incorrectThe cost of your path is incorrect (for UCS type searches).', u'Thanks Lalitha, yes I did miss the doc explaining the Bonnie messages. Thanks for posting it.
With such a (relatively) simple graph as we are given in the BFS question, it's clear that none of the conditions described in the Bonnie result can be true. Just by viewing the result graph the unit test generates from my code one can eyeball the result and see that none of the result conditions are true. I'm thinking there must be some other error in our result which is not described in the Bonnie description.   

And just an aside - do you have a doc URL for how to run our code on the VM.. that's a good suggestion also :)', u'Actually on second thought, I don't think the VM will make a difference for debugging this. Try looking at thread @295, specifically the below comment. This helped me get past BFS! As long as you do this and add the optimization from the lecture, your test should pass.

Jim Winquist 11 hours ago I finally figured out what this was. For others struggling with this. It isn't mentioned anywhere that I saw but you need to implement a strict FIFO queue for BFS to break ties. You can't just use a PriorityQueue based on cost that randomly orders equal costing nodes. I think this could be made more explicit in the documentation and instructions. But that's what ended up solving it for me.', u'From the Student answer above (thank you @Ming Choi). This is what fixed it for me:

For Uniform cost search: I didn't consider the historical shortest path of a node when the node pop again in the queue (which cannot be seen from the image above). Passed the test after considering that.', u'Thanks Lalitha - I'll give it a try. But I got the impression in the lectures that ties can be broken with a random selection. Must have missed this somewhere along the line in the lectures.. Thanks also to Jim Winquist for the idea (and I'm impressed how he thought of it since as he said 'it's not mentioned anywhere'..)
', u'Thanks Lalitha, I passed BFS after using FIFO. Here's my graph when passing bonnie, for others' reference
', u'do we need to consider the weights when doing BFS?
I think it should go one level then another. how you can avoid exploring m and d which is in red?', u'As far as I understand, green means you expanded the node. In this case m and d don't get expanded because they are put on the frontier after [a,s,f,b]  and when [a,s,f,b] is expanded you are done. I get the same graph as Ming Choi, but Bonnie still fails me saying 
Nodes explored should be from a valid frontier and should be kept to a minimumPath is longer than optimal path
I return [a,s,f,b,u], any ideas? :(', u'Ok, I figured it out. Make sure your algorithm works correctly if start and goal are adjacent...', u'Thanks @Lalitha, you just rescued what was becoming an afternoon of frustrating. Had it working but without the strict FIFO implementation it wasn't passing. Was starting to lose my cool on this one ;).

(Would suggest to instructors to allow the set of all possible solutions based on different ordering of the frontier at each stage.)', u'Why are m and d not expanded?', u'@David Make sure you are doing your goal test in the right spot. In BFS, check for your goal when a node is generated, while in UCS check for your goal when a node is to be expanded.', u'

Bonnie still reports this as a failure with the message: ""Nodes explored should be from a valid frontier and should be kept to a minimum""', u'@Brett Thanks for that tip, I forgot about that.  My other change I had to make was using a list as a FIFO.']}, {u'text': u'Ming - is the UCS state in your original post the latest you ended up with for your UCS test? (and did you pass the Bonnie UCS test with it?)
Your original post has this for UCS state and node G is not explored.

In my case G is being explored so I'm thinking it should not be.
Thanks', u'responses': [u'Yes that is the correct graph for UCS']}, {u'text': u'Is the below right for the A star graph?I have debugged for 4hrs and absolutely stuck at the moment?
That ""Null heuristic A star search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum\n"" keeps bugging me.
And according to Lalitha's earlier post,I guess that I might have explored unnecessary nodes,so I wonder if someone could give a hint on the proper graph after the end search. By the way,my code does take account the accumulated cost =estimated cost + experienced cost per route..

Thanks in advance.
', u'responses': [u'Below is also failed:
', u'How does it measure the green and red states there? I saw the top post is with ""o""and ""c"" in red and still was not optimal.
What I did to my ""o"" and ""c"" was merely when s expanded to ""o"" and z expanded to ""o"" identically  ""r"" to ""c"" and ""p""to""c"".Were those nodes not necessary to explore?

Please advice.', u'o and c don't need to be explored in my successful bonnie submission. You can see my A star graph on the question, top of this page.', u'I got it now, thank you for your regard.']}, {u'text': u'Could someone further explain this from the solution above:
""For Uniform cost search: I didn't consider the historical shortest path of a node when the node pop again in the queue (which cannot be seen from the image above). Passed the test after considering that.""

I am getting the correct graph output for UCS but I'm not passing bonnie.
Should U also be explored?', u'responses': [u'The key is to avoid checking neighbors at all for a node that is obviously not going to improve the total cost of the path. This can be avoided in two ways: 1. avoid adding to the frontier in the first place, and 2. avoid checking it's neighbors after visiting.

If you do a test from 'p' to 'b', you should be able to see the edge case I'm referring to.

edit: and 3. if you find the same node, but with a different parent, in the frontier, swap the weights if the new one is lower than the old. This is where the 'remove' method in the PriorityQueue can be utilized.
', u'Thanks, that all makes sense and I am avoiding to check unnecessary nodes and I'm swapping the weights.
I am receiving the exact graph pictured above but it doesn't pass bonnie.', u'Here is the path I'm taking, I can't find anything wrong with the logic
exploring a with cost 0    adding s cost:140     adding z cost:75     adding t cost:118exploring z with cost 75     adding o cost:146exploring t with cost 118     adding l cost:229exploring s with cost 140     adding r cost:220     adding f cost:239exploring o with cost 146exploring r with cost 220     adding p cost:317     adding c cost:366exploring l with cost 229     adding m cost:299 exploring f with cost 239      adding b cost:450 exploring m with cost 299      adding d cost:374 exploring p with cost 317      swapping c cost:455      swapping b cost:418 exploring d with cost 374      swapping c cost:494 exploring b with cost 418      adding u cost:503      adding g cost:508 exploring c with cost 494 solution:['a', 's', 'r', 'p', 'b', 'u']', u'What's your error from bonnie?', u'    {
      ""output"": {
        ""points_available"": 10,
        ""autograder_comments"": ""Uniform cost search fails benchmarks searching from start to goal node\nPath is longer than optimal path\nPath cost is incorrect\n"",
        ""points_awarded"": null
      },
      ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_admwlgfo/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 91, in test_ucs\n    self.assertTrue(tests_pass, \""Uniform Cost Search Tests\"")\nAssertionError: Uniform Cost Search Tests\n"",
      ""description"": ""Test the uniform cost search implementation""
    },', u'looks like i did have a bug in my code when calculating weights,
i was able to find it when running search_unit_tests.py']}, {u'text': u'after hours and hours, I finally breached BFS and got my more than deserved 5 points!!! I first read that you require strict FIFO in order to pass Bonnie, but suddenly add optimization to strict FIFO in order to limit explored nodes??? ""m"" and ""d"" should be explored in strict FIFO. I feel like instructions should mention things like this

', u'responses': [u'^ +1 +1 +1 +1 +1', u'Thank you so much Jenny. I solved the problem after reading your response.']}, {u'text': u'I keep failing even with the lowest edge distance for BFS or lowest number of nodes.', u'responses': [u'Do number of nodes and edge distance both matter? I seem to fail either way. Why would path CRSF be better than CPBF with BFS?', u'Doesn't seem to matter what you turn in as long as it doesn't go too far.']}, {u'text': u'Keep failing on the A*.  Can somebody post what your working solution looks like?  Here is what my solution looks like:  

""A star null_heuristic search tests passed\nEuclidean heuristic A star search fails benchmarks searching from start to goal node\nPath is longer than optimal path\n<img s', u'responses': [u'your plot  looks correct. I think you are not checking ""If your start and goal are the same then just return []""', u'Or it can be that while you are solving a->u correctly, you have some edge cases where other paths are not being solve correctly (one of which is the one Vishwadeep mentions above).']}]",,1.0,270.0,318,"For Priority queue insertion: I passed the test by changing my algorithm to do append faster (or you can use heapq)
For Breadth first search: Changed the code to get path ASFBU, able to pass the test by using FIFO queue
For Uniform cost search: I didn't consider the historical shortest path of a node when the node pop again in the queue (which cannot be seen from the image above). Passed the test after considering that.
For A star: same as ucs",Is this optimal path?,[a2]
5ad7d44f0d63974e20c3912e,"Hi all,

Looking for help for using vagrant. I run the command and built up VM.

Then I run python search_submission_tests.py, and got the following error:


I have this package installed in machine. I don't know why I got this error. Then I tried to install it again under VM using
pip install matplotlib (also tried pip upgrade matplotlib) and got the following error:



Can anyone help me and let me know what I should do to run the test? Thanks",jc6w44hrp9v2ki,"[{u'text': u'Hi Anan,What is your output upon the following command?
pip show matplotlibIf it shows installed with the correct version as required, then check if your pip is configured to the python version that you are using. Let me know if you need more help. ', u'responses': []}]",,0.0,159.0,320,,vagrant help,[a1]
5ad7d44f0d63974e20c3912f,"Check out the previous Challenge Questions here @283. We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.

We finally start with Search! One of the best ways to understand search algorithms is to try them out, on your own, with pen and paper.
 
Having said that, here's a Challenge Question:
10x10 grid search (four directions)Blue Dot is the Start and Red Dot is the Goal. Order of expansion is clockwise - 12 o'clock - 3 o'clock  - 6 o'clock - 9 o'clock
 



Your challenge is to determine the returned path, the shortest path, and number of nodes explored by each of the following search algorithms:
(Of course, you could program it to compute the answers, but for this exercise to benefit you, please try to work it out with pen and paper.)
 
1) Depth-first search2) Breadth-first search3) Iterative deepening depth-first search4) Bi-directional breadth-first search5) Uniform Cost Search6) Bidirectional Uniform Cost Search7) A* Search with a manhattan distance heuristic.
[Manhattan distance is a heuristic where you simply count the smallest number (not cost) of line segments remaining to reach the goal.]
 


----------------------Food for thought ------------------ 
 
Pay special attention to the stopping criterion for bidirectional searches: Is the stopping criteria same for bi-directional BFS and UCS?
 
Does UCS and bidirectional UCS give the same path or different? Which one explores more nodes?
 
How would you implement a bidirectional UCS? Would you keep a common frontier or separate ones? What difference would it make in the optimal path found and the number of explored nodes? 
 
-------------------------------------------------------------------

Solution: @543",jc6w44hrp9v2ki,[],,0.0,305.0,321,,Challenge Question 4 - Search,"[lesson2, challengeqtns]"
5ad7d44f0d63974e20c39130,"when I do sudo -H pip install -r requirements.txt I just keep on getting 
Collecting matplotlib==2.0.2 (from -r requirements.txt (line 2))
  Retrying (Retry(total=4, connect=None, read=None, redirect=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x10161d410>, 'Connection to pypi.python.org timed out. (connect timeout=15)')': /simple/matplotlib/

Anyone else faced same ?",jc6w44hrp9v2ki,"[{u'text': u'I had some issues installing this on my Mac using Pycharm. I had to add the --user flag at the end of the expression to get it to install.
', u'responses': []}]",,0.0,148.0,323,marking it solved. It was a connection issue from my place,issue with installing matplotlib on my Mac High Sierra,[a2]
5ad7d44f0d63974e20c39131,"When I run ./search_submission_tests.py I get following error on import : 
./search_submission_tests.py
./search_submission_tests.py: line 2: import: command not found
./search_submission_tests.py: line 3: import: command not found
./search_submission_tests.py: line 4: import: command not found
./search_submission_tests.py: line 6: import: command not found
./search_submission_tests.py: line 7: import: command not found
from: can't read /var/mail/explorable_graph
from: can't read /var/mail/search_submission
from: can't read /var/mail/visualize_graph
./search_submission_tests.py: line 16: syntax error near unexpected token `('
./search_submission_tests.py: line 16: `class TestPriorityQueue(unittest.TestCase):'
 
Did any one faced this ? Any suggestion would welcome.






",jc6w44hrp9v2ki,[],,0.0,186.0,324,I tried sudo -H pip install --user networkx==1.11 ==> it works. I think due to permission and restrictions I had to use --user option.,issue with search_submission_tests.py,"[a2, python, lesson2]"
5ad7d44f0d63974e20c39132,"Time: 8pm Eastern
Link: http://youtu.be/cVyxMpO3uxI

We'll be going over a run down of Assignment 2, walking through the git repo, talking about some common issues people run into, and taking questions. The link is live now, but I won't start until 8.

EDIT: updated the link. Having tested the previous one I broke it somehow in the process.

",jc6w44hrp9v2ki,"[{u'text': u'Do we get partial marks for algorithm implementations?', u'responses': [u'You can receive partial marks if you return the best path but have a few too many explored nodes- we have a bit of wiggle room there that we will deduct some points from proportional to how many extra nodes you explored.', u'Thanks']}, {u'text': u'After running unit tests I get the following assertion error for my BFS  implementation: Lists differ: ['c', 'p', 'b', 'f'] != ['c', 'r', 's', 'f'] ...

Both are the same length. Any tips? Thanks. ', u'responses': [u'The unit tests can be wrong. I think someone said they were made by a student last year.

I fail this unit test but pass Bonnie with BFS.

Let me know if you discovered otherwise.', u'Same results as you. I failed some local unit tests but passed bonnie. It only seems to be an issue with BFS unit tests. Thanks.', u'same']}, {u'text': u'', u'responses': []}]",,0.0,312.0,325,,"Youtube Live Event, Assignment 2","[a2, announcements, office_hours]"
5ad7d44f0d63974e20c39133,"Hi all

I am stuck in unexpected traffic and will be a little late today (10-15 mins). I will extend my office hours if needed.",jc6w44hrp9v2ki,[],,0.0,145.0,326,,Sumeet office hours delay,[office_hours]
5ad7d44f0d63974e20c39134,"Instructors,

Can I design my priority queue to only allow unique nodes? For example, if an attempt is made to add the same node twice to the frontier, it deletes/ignores the lower priority one and adds/keeps the higher priority one.

Your testing is designed to add random numbers to the priority queue and an array, then you sort the array, then iterate on the array to see if each element matches up with each item popped from the priority queue. I will fail that test if there are duplicate nodes added.",jc6w44hrp9v2ki,"[{u'text': u'Hmm, I'm not sure why you would want to do that. Generally speaking, a queue should add whatever you tell to it, regardless if it was the same item before.', u'responses': [u'I could be wrong. I was thinking it would be useful to override the priority. Why would we want to have two of the same nodes on the frontier?', u'It seems like you would always want to have the ""version"" of the node with the shortest distance/highest priority in your frontier.  In the case of BFS, if you find a direct path A->D with cost 100 and subsequently find a path A->B->C->D with cost 50, you would want to update the D node to use the second path and cost 50.  Correct?', u'BTW my above assumptions are true, but it appears they should _not_ be implemented as part of the PriorityQueue.  A simple PriorityQueue that allows duplicates passes bonnie.', u'Isn't the priority queue the correct/clean place to implement this ? I suppose I could use a wrapper around the given PriorityQueue class to get around this. Where are you adding the logic for updating priority and enforcing unique keys ?']}]",,1.0,212.0,328,"What you are asking for is an update method for your priority queue, which is a commonly supported operation for a heap. It would take a key of the item to update and its new priority and would then find the key in the heap, update its priority and re-establish the heap invariant. The heapq document touches on this a bit, but doesn't give a full implementation, so that's a good start (plus an algorithms text).",Priority queue should only contain unique nodes,[a2]
5ad7d4500d63974e20c39135,"I'm confused what the data structure for a node looks like. I see that we have access to an ExplorableGraph object which is passed in to the search function, but how do you get the path cost from one node to another node?",jc6w44hrp9v2ki,"[{u'text': u'I had the same question. I eventually used the graph.adj dictionary which holds the costs between nodes. However, I asked about this in Noah's video today - specifically is it ok to use any object.attribute we like in the solution. He said probably not so it remains unclear the best way to get the segment cost. But at least temporarily it works to get the data and move on with the coding.', u'responses': [u'Ah, I found it! You call 
graph['node_1']['node_2']['weight']
and that is the weight between node_1 and node_2.', u'excellent.. thanks for posting..
(btw - how did you find out to do this?)', u'https://github.gatech.edu/omscs6601/assignment_2#warmup-3-uniform-cost-search
Notes:
1 You can access the weight of an edge using: graph[node_1][node_2]['weight']']}]",marking as resolved. (see comments below),0.0,184.0,330,,Getting the path cost from one node to another,[a2]
5ad7d4500d63974e20c39136,"In the lectures with Peter, he states that a node data structure contains four main attributes:
State field, state at the end of the path.
Action was the action it took to get there.
Cost is the total cost.
Parent is the pointer to another node
The nodes in this assignment have 2 attributes and we are forced to use this data structure. I attempted to make my own Node data structure, but the priority queue requires (int, key) or else the first warm up test will fail.

How do we trace the path from the goal back to the root if we don't have a parent attribute?",jc6w44hrp9v2ki,"[{u'text': u'Read the documentation for heapq about implementing a priority queue. It shows you one way to store additional information for each of your nodes.', u'responses': []}, {u'text': u'@Philip Dayboch - You can still use same priority queue function. You can pass priority as a first parameter and your custom data structure node as a second parameter.', u'responses': []}]",,0.0,187.0,331,"Your key can be a node object of a class that you create. To make the ""node in PQ"" function work, you'll need to overwrite the  __eq__ function and have it return the nodes name.",Following the path,[a2]
5ad7d4500d63974e20c39137,"Sorry if this was asked before, can we add functions to the priority queue class?

thanks
Ivan",jc6w44hrp9v2ki,[],,0.0,182.0,333,"Yes, I have and pass Bonnie so yes definitely. ",add functions to PriorityQueue class?,[a2]
5ad7d4500d63974e20c39138,"I'm getting the following error on Bonnie when testing BFS:

AttributeError: 'Graph' object has no attribute 'explored_nodes'.

Mo code runs fine locally. Am I missing something here? I saw in the instructions on how to access explored_nodes - I am calling something to the effect of:

if node not in graph.explored_nodes:
    do something

I'm confused as to how I can troubleshoot this given that my code runs without issue whenever I am testing.",jc6w44hrp9v2ki,"[{u'text': u'In the notes of the readme it says you can only use that function for debugging but it fails on Bonnie. You have to manage your own explored set and update the graphs explored set through graph.neighbors. It is because they check your explored set when grading.', u'responses': []}]",,0.0,191.0,335,"This is from the README file:
To measure your search performance, the explorable_graph.py provided keeps track of which nodes you have accessed in this way (this is referred to as the set of 'Explored' nodes). To retrieve the set of nodes you've explored in this way, call graph.explored_nodes. If you wish to perform multiple searches on the same graph instance, call graph.reset_search()to clear out the current set of 'Explored' nodes. WARNING, these functions are intended for debugging purposes only. Calls to these functions will fail on Bonnie.
I'm doing my own bookkeeping for that.",AttributeError - graph.explored_nodes on Bonnie,[a2]
5ad7d4500d63974e20c39139,"In lecture 41, it is said that ""heuristic 2 will always be longer than heuristic one"" and therefore an A* search using heuristic two will always expand fewer paths. I don't really understand that connection. Can anyone share some insight?",jc6w44hrp9v2ki,"[{u'text': u'The example they give where they remove constraints to relax the heuristic really highlights Donovan's explanation. The more constraints you have, the more accurate the heuristic and thus the fewest # of nodes to be explored. The fewer the constraints, while staying more optimistic than the true cost, the more nodes to be explored.

Once you start reading some of the papers, you'll find that coming up with an optimal heuristic is not so easy.

', u'responses': [u'Thanks--That helps']}]",,0.0,162.0,338,"I find it helpful to think of things in terms of the rule that a heuristic for A* search will only lead to an optimal solution if the heuristic is admissible, meaning it can't overestimate the actual cost to get from a node to the goal. So, coming up with a heuristic is a balancing act of trying to find a maximal heuristic that never over estimates.

For instance, Uniform Cost Search can be though of using a heuristic of 0 at each node, which doesn't skew the search toward the goal node at all. On the other extreme, the book mentions that you could get a perfect heuristic by running BFS ""on the sly"" at each node to compute the true cost at that node, but obviously this is not computationally efficient which is the whole point of a heuristic search.

So, if an admissible heuristic $$H_a$$ dominates another heuristic $$H_b$$, meaning that $$H_a \ge H_b$$ always, then it will skew the search more toward the goal, expanding fewer nodes, but also guarantee an optimal solution because $$H_a$$ is an admissible heuristic.",Sliding Block Heuristics,[lesson2]
5ad7d4510d63974e20c3913a,"Where can I find office hour recordings for assignment2?
",jc6w44hrp9v2ki,[],"Office hours are NOT recorded. The youtube live session specific for each assignment IS recorded. You can find the one for assignment two here:  http://youtu.be/cVyxMpO3uxI

The link to this is also in a pinned post.",0.0,157.0,343,,OH recordings,[a2]
5ad7d4510d63974e20c3913b,"I've created my own Node class within the search_submission.py.  I just noticed the comment at the top:

....Do not add any classes or functions
to this file that are not part of the classes that we want.
I was defining a Node class within the search_submission.py which seems to run afoul of the above comment.  Am I reading that comment correctly, that we should not add a new class to that file, and if so, if we define it elsewhere won't that be a problem for bonnie?
",jc6w44hrp9v2ki,"[{u'text': u'Nevermind, I've solved this indirectly.', u'responses': []}]",,0.0,173.0,344,"Nevermind, I've solved this indirectly.",Where to define our Node class,[a2]
5ad7d4510d63974e20c3913c,"With only two assignments in, I'd like to say thank you for making the assignments interesting. 

That is, I find pretty cool that for the second assignment, we are provided with real data. While I was aware of openstreetmap, I now know a bit more about it, I find pretty cool that I can inspect ""nodes"" and their ids and that the assignment matches a problem that we are well familiar with.
Or in other words, you could have very well given us a humongous graph and we would have had just to implement the algorithms and that would have been it, and that would have been ok, the algorithms themselves are obviously interesting. But taking the effort to take real data, show us how to visualize it and such, makes the homework even more interesting and fun!

Same thing with the first assignment.",jc6w44hrp9v2ki,[],,0.0,194.0,345,,Note of appreciation,[a2]
5ad7d4520d63974e20c3913d,"I was having trouble with running our assignment 2 code on OSX and didn't find a clear description of what to do, so I figured I'd post what I used to get code to run:

Initial error trying to install requirements:
    DEPRECATION: Uninstalling a distutils installed project (six) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.
    Uninstalling six-1.4.1:
Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py"", line 778, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py"", line 754, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py"", line 267, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 302, in move
    copy2(src, real_dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 131, in copy2
    copystat(src, dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 103, in copystat
    os.chflags(dst, st.st_flags)
OSError: [Errno 1] Operation not permitted: '/tmp/pip-gzYg1z-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info'

And error running tests:
RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of 'python' with 'pythonw'. See 'Working with Matplotlib on OSX' in the Matplotlib FAQ for more information.

Fixing:
1. Installed conda from https://conda.io/miniconda.html
(links are downloads to installer, run installer script in terminal to install conda)
2. Import python.app using conda https://matplotlib.org/faq/osx_framework.html#osxframework-faq
conda install python.app
3. Import libraries using pythonw
pythonw -m pip install -r requirements.txt

4. Run tests using pythonw
pythonw search_submission_tests.py
",jc6w44hrp9v2ki,"[{u'text': u'Had the same issue (even running in VirtualEnv). Maybe a simpler solution which worked for me:https://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python', u'responses': []}]",,0.0,150.0,348,,running matplotlib on OSX with conda,[a2]
5ad7d4520d63974e20c3913e,"Hello,

I am implementing Bi-directional A* search and there is just one case where my algorithm does not return the expected path. I am getting 19/20 on Bonnie.  When I perform test for the path from 'd' to 'o', my implementation choses the ['d','m','l','t','a','z','o'] which has total path cost of 497 instead of ['d','c','r','s','o'] with total path cost of 520. On analysis, I observed that the Euclidean Heuristic is smaller for the former path and therefore, it results in 'total cost' for the former path (['d','m','l','t','a','z','o']) being lesser than that of latter( ['d','c','r','s','o'] ). Hence it returns ['d','m','l','t','a','z','o'] as its best path instead of ['d','c','r','s','o']. Am I missing something?

",jc6w44hrp9v2ki,"[{u'text': u'The path cost (not including the heuristic) of travelling through [dcrso] should be less than [dmltazo]. It was only when I considered this, did my algorithm pass this particular test.', u'responses': [u'Thank you for the suggestion, it really helped me clear the test :) ']}]",,0.0,187.0,351,,Bidirectional A* search fails for this one edge case,[a2]
5ad7d4520d63974e20c3913f,"Everyone,

Don't be dumb like me.

When adding nodes to your frontier, DO NOT find your weights with graph[current_neighbor][current_node]['weight']!

It will add current_neighbor to the explored list for Bonnie testing.

Instead use graph[current_node][current_neighbor]['weight'], which WILL NOT add the neighbor to your explored list.

",jc6w44hrp9v2ki,[],,0.0,194.0,352,,Accidentally Increasing Explored Nodes in Bonnie Tests,[a2]
5ad7d4520d63974e20c39140,"From the slides, what does Pr(t) represent? I'm not fully understanding the slides.
",jc6w44hrp9v2ki,[],"P is the potential function, which estimates the distance between two nodes (e.g euclidean distance, Manhattan distance).
'f' (forward) and 'r' (reverse) refer to the two sides of the bi-directional search, which expand in parallel.
't' is a node. Generally 's' node is considered 'start' and 't' is considered 'terminal', however in bi-directional search both are used as their own starting points.
 
Pr(t) is an estimate of the distance from the 't' node to the opposite goal. Since 'r' indicates we are in the reverse search (from terminal (t) to start (s)), the opposite goal is 's'.
So Pr(t) is an estimate of the distance |s-t|.",0.0,174.0,353,,Slide formula question,[a2]
5ad7d4520d63974e20c39141,"I am implementing BFS. Results look good. I tested for various start and end  nodes. All the time path were optimal. However bonnie still gives below error. What could be wrong? What should I check more? Any pointers would help.

""Breadth first search fails benchmarks searching from start to goal node\nPath does not go from start to goal node or is invalid\nPath is longer than optimal path""",jc6w44hrp9v2ki,"[{u'text': u'Did you try the unit tests? They are a little more challenging for this one because there are several ties in some cases and the checker will fail if you didn't get the same one even though they have the same length. You can just comment out the assert equal and visually inspect the results if you want more test cases.', u'responses': [u'Thanks for the advice. I took out the assert equal and print my path as well as correct path. 

All of the following cases have the same number of nodes in both paths. Maybe i  should not break the while loop the first time reaches a goal? I really appreciate it if anyone can help me on this. 

my_path ['c', 'p', 'b', 'f'] correct_path ['c', 'r', 's', 'f']my_path ['d', 'c', 'p', 'b', 'f'] correct_path ['d', 'c', 'r', 's', 'f']my_path ['f', 's', 'r', 'c', 'd'] correct_path ['f', 'b', 'p', 'c', 'd']my_path ['f', 's', 'a', 't', 'l', 'm'] correct_path ['f', 'b', 'p', 'c', 'd', 'm']my_path ['m', 'd', 'c', 'p', 'b', 'f'] correct_path ['m', 'l', 't', 'a', 's', 'f']my_path ['m', 'd', 'c', 'r', 's', 'o'] correct_path ['m', 'l', 't', 'a', 's', 'o']my_path ['o', 's', 'a', 't', 'l', 'm'] correct_path ['o', 's', 'r', 'c', 'd', 'm']my_path ['s', 'a', 't', 'l', 'm'] correct_path ['s', 'r', 'c', 'd', 'm']

Eg) For the first one in the above list, I have the below graph to help visualize.
For my queue, i have two elements : (node, path_get_to_the_node). 
Right before adding ('f',['c', 'r', 's', 'f']) the queue. This is what the queue looks like. 
('queue before', [('m', ['c', 'd', 'm']), ('u', ['c', 'p', 'b', 'u']), ('g', ['c', 'p', 'b', 'g']), ('f', ['c', 'p', 'b', 'f']), ('a', ['c', 'r', 's', 'a']), ('o', ['c', 'r', 's', 'o'])])
My assumption is if there is already a f in the queue we don't add the same node.
My end result would be ['c', 'p', 'b', 'f'], not   ['c', 'r', 's', 'f']. I am not sure what i did wrong here. 

￼

By the way, the error message on Bonnie is:
Breadth first search fails benchmarks searching from start to goal node\nNodes explored should be from a valid frontier and should be kept to a minimum\n"",', u'[C,P,B,F] is a valid BFS result if you use a strict FIFO queue following the node ordering that is default generated from the Romania graph. That's what I get for BFS too. I don't know why the unit test says it is wrong (must be using a different tie breaker / node ordering and not recognizing other valid results).

I will say my BFS passes the tests on Bonnie even though it returns [C,P,B,F] to the C-->F search. I thought it wasn't working due to this but I forgot to put [] for cases where start = goal. Once I fixed that, it passed.', u'Thanks for the reply! You are right. The unit test is not accurate. 
I changed when to return the path.  Now i passed the bonnie test. 
Thank you!']}, {u'text': u'I was able to solve the problem after correcting first==goal part in my logic. Now I pass the Bonnie. Thanks for pointers here.
However how to run unit tests. Looks like I miss some instructions about it.', u'responses': [u'python search_unit_tests.py', u'thanks']}, {u'text': u'I was stuck on this for a while.  Main issue in terms of passing vs failing was when to return the path once the goal node was found.', u'responses': []}, {u'text': u'

What's wrong with this path? Too many nodes searched?


Even with minimum nodes, it fails...
', u'responses': [u'It was that damn []. I thought [goal] was okay.']}]",,1.0,248.0,354,"There are a few threads (can't find the links detailing this right now). Bit of a hiccup on the assignment. Two things to worry about:

Despite mentioning in the assignment that we could use priority queue, Bonnie's assumption around what makes a solution ""optimal"" seems to assume a strict FIFO queue for the frontier. Thus many valid solutions are rejected.Make sure that you're returning `[]` in the case of a path that starts and ends at the same goal, as mentioned in the assignment.

These two considerations (in particular the first one) seem to be tripping a lot of people up...",Breadth first search fails start to goal node,[a2]
5ad7d4530d63974e20c39142,"I am having an issue where the “_explored_nodes” set variable is never actually being reset or emptied when the function “reset_search()” is called.  Without clearing this variable it will appear as if ALL the nodes were visited (see BFS result below).  Is anyone else having this issue? 

",jc6w44hrp9v2ki,"[{u'text': u'I only get this result if I'm debugging. If I don't set any breakpoints and allow it to run without pause, this doesn't occur. Now, if this is occurring when you let your search algorithm run normally, then I'd say your code is exploring too much.', u'responses': []}, {u'text': u'Hello Erik, 
is this the result of your algorithm, or just the the effects of reset_search()? Since no one else is having this issue, could you try debugging it on your end and give us an update?', u'responses': []}]",,0.0,164.0,357,,reset_search() Function,[a2]
5ad7d4530d63974e20c39143,"After lots of struggle I could get pass BFS on Bonnie. Going ahead with UCS. Any thing one should be careful to make it pass on Bonne. (asking because local tests do not test as good as Bonnie, at the same time Bonnie error messages are not very helpful all the time)",jc6w44hrp9v2ki,"[{u'text': u'Also, add that UCS is easier than BFS.', u'responses': []}, {u'text': u'The search_unit_tests.py doesn't do too terrible a job of preparing you to pass Bonnie.', u'responses': [u'you are right. this unit test is catching bug in my code.']}, {u'text': u'We should explore all routes TO the end node though, right? Not just stop once we've found the end node along one route', u'responses': [u'You should stop searching once you have found the shortest route.   You do not need to explore all routes.', u'+1 on Conor's answer.

Note this is NOT the case with bidi_UCS..']}, {u'text': u'thank you folks. Finally I was able to resolve it using unit test. ', u'responses': []}]",,0.0,216.0,359,One thing I have noticed is that Bonnie doesn't actually test your algorithm. It just looks at your result and explored nodes. For BFS make sure as soon as you find the end node to stop. If you follow the pseudocode on wikipedia it doesn't do this and ends up exploring more nodes than necessary. That was my problem for a while and I suspect is your problem too. The book one doesn't make this mistake and should be compared to see what is different.,Uniform Cost Search -  before start hints,[a2]
5ad7d4530d63974e20c39144,"As a follow up to @344, why are we not allowed to add any helper functions or classes?",jc6w44hrp9v2ki,[],,0.0,179.0,361,"Hi Jacob, I believe you can add as many helper functions or classes as you want as long as they are inside the search_submission.py file.",Why can we not add helper functions/classes?,[a2]
5ad7d4530d63974e20c39145,"In the starter header it states
Do not add any classes or functions
to this file that are not part of the classes that we want.
Is it ok to have additional helper functions?  In my current implementation, I am finding it easier to refactor out repeated sections in to functions in order to minimize needless copying and pasting of code.",jc6w44hrp9v2ki,[],,0.0,178.0,363,"From @297


Le Van 3 days ago
Are we allowed to add helper functions?



 Xuewen Yao 3 days ago
yes

",project 2 additional classes / functions,[a2]
5ad7d4530d63974e20c39146,"After having a few failed test on bonnie with my code i attempted to use the virtualbox environment and ran into with Vagrant up issue. The link provided shows that repo is no longer available. Does anyone know how to resolve this?

",jc6w44hrp9v2ki,"[{u'text': u'why do we need vagrant for this assignment?', u'responses': []}]",,1.0,155.0,364,,Vagrant up not working,[a2]
5ad7d4540d63974e20c39147,"Outside of office hours and the assignment live event, how do you contact the instructors if you need some clarification on class material such as papers and formulas? In my past OMSCS classes, the TA were extremely active on Slack and helped whenever and where ever they could. In this course I don't seem to be getting any responses from TAs/instructors on Piazza. I can only read so much material while balancing lectures, textbook readings, programming the actual assignment and working full time. I've read about 50-60% of the material they have posted in the Readme. Some questions do bubble up from this material and I could use clarification from experts or folks who have experience in this subject to help me learn further.",jc6w44hrp9v2ki,[],"Hi Philip, let me answer this as best as I can.

A lot of the recent questions that have been posted are very homework specific questions. Unless we feel like there is something that needs to be clarified for everyone, or is a reasonable extension of class material that doesn't give anything away that is too homework specific, we refrain from answering these questions (especially in such an open setting as Piazza). We want you to get as much out of these projects as possible, and many of the struggles people are facing are not problems with the project, but are fundamental learning lessons in AI. This class isn't easy, and it would be a disservice to make it so. Let me give you an example: last semester, the MiniMax player on Bonnie did not include any elements of randomness. What this led to was two agents (the custom player and the bonnie player) that were deterministic playing against each other (the fact that bonnie was deterministic was not told to us). Many many people were stuck at a 50% win rate, including myself, and couldn't figure out why. What I learned was that I wasn't playing 20 games agains't my opponent- I was playing 2, one where I went first, and one where they went first, and playing each of those games 10 times. This was a phenomenal learning lesson for me, but took me (literally) days to understand. The teaching staff also refused to answer my questions about i because they knew it was a learning opportunity.

There are also a lot of unanswered questions from the previous couple of days. The teaching staff has said before that we don't answer questions on weekends, with few exceptions. If we do see something that is either our mistake or something that needs to be clarified immediately, we will.

That all being said, what you're saying is not entirely dismissed by my two reasons above. Running these massive online courses (this semester is close to the largest we've ever tackled) is an ongoing learning process for us to, and I thank you for bringing this up. Might you link to a few of the posts on Piazza that you felt should have been answered by the teaching staff but weren't? We also do our best to encourage students to learn together on piazza and answer questions as a team. This teamed, remote learning is something we are continually trying to improve on and encourage, and we greatly appreciate the people who have been organizing local meetups in various locations across the globe.",0.0,190.0,367,,Contacting instructors for questions,[feedback]
5ad7d4540d63974e20c39148,"I want to test some custom routes instead of the default route in search_submission_tests.py. I tried typing in random node IDs that begin with 6958**** but I'm getting back that the node does not exist.

How do you obtain the node IDs from the Atlanta map? When I plug my output into geojson, it only gives me lat + long coordinates and not the node IDs.

I looked over the Readme and it doesn't mention anything about getting the node IDs from the Atlanta map. The pickle file looks compiled and I can't make sense of it. When I attempt to stringify the graph object passed into the search function, it just prints the name of the class. I am stuck.",jc6w44hrp9v2ki,"[{u'text': u'Did you try graph.nodes() or graph.keys()?', u'responses': []}]",,0.0,187.0,368,,Obtaining the Atlanta map node IDs,[a2]
5ad7d4540d63974e20c39149,"TAs,

Are we allowed to call and use the results of our bidirectional search functions: bidirectional_ucs() & bidirectional_a_star()
inside of our Tri-directional search functions?

Thank you!",jc6w44hrp9v2ki,"[{u'text': u'I don't see why not. All necessary code to make the searches work is contained in the same file. It would seem silly to me if you weren't allowed to, considering copy & paste is a non-DRY way to do the same thing.', u'responses': [u'It is not doing the same thing. A bidirectional search finds the optimal path between two nodes using two searches. Likewise, a tridirectional search should find an optimal path between three nodes with three searches. To find a 3 node optimal path using the bidirectional searches, you would need to do three bidirectional searches and pick the best two of those three. As mentioned earlier, each bidirectional search is two searches and thus a tridirectional search which relies on calling bidirectional search would actually end up performing six searches. I think the purpose of the tridirectional search problem is to expose the general problem of an n-directional search.', u'Except in pathological cases, I think you can do it with 3x bidirectional searches, if you order your bidirectional searches right. This also involves terminating early when you can tell a bidirectional search will not be fruitful. Using techniques like this, 3x bidirectional is equivalent to ""true"" tridirectional search on a grid-world like map. Now, real maps don't resemble grids, but as long as point to point relative distances are well approximated by euclidean distance (for example, in a real world mapping exercise because roads are not in general unnecessarily circuitous), it should be close - the worse the euclidean metric is at approximating distances between nodes, the worse the bidirectional searches will do.I am one of those who have completed tri_upgraded and tri_ucs by calling bidirectional_search multiple times. As Thad says: ""do the stupid thing first and add intelligence as necessary.""

I would like to request some sort of instructor response to the anon questions below. The ""do not call bidirectional search"" requirement was not specified in the assignment readme, nor widely made known to students (I wouldn't have noticed this post if I had not stumbled upon it). Moreover, it doesn't seem right to change the policy this late in the assignment. If the teaching staff needs to change how they grade (a fairly large chunk of) this assignment, it would really be best if they let us know as soon as possible. ', u'I agree with John Fenske above. Please refer to my responses below. The 'do not call bidirectional searches' requirement is implied.']}, {u'text': u'What if the goals are [a,b,b]? Shouldn't you call bidirectional search then?', u'responses': [u'then we should return [] as mentioned in readme', u'I understood the readme to mean that only [b,b] will have [] as the path, so effectively, it would be a bidirectional search to find [a,b]. 

from the readme:  If any goals are the same then just return [] as the path between them.', u'I'm pretty sure Julie is correct. Path ['a','b'] is still a valid request, while ['b','b'] should not be explored.', u'Your tri-search must function such that it returns the path between A and B. Given [a,b,b] your tri-search should return the same result as a bi-search, and not call that directly.
It's similar to how a null heuristic in A* returns the same result as UCS - you do not explicitly call UCS in such a case.', u'Can you clarify that last sentence? ""you do not explicitly call UCS in such a case.""....? Do you mean we shouldn't call A* for UCS?', u'I think he's saying that if you had an A* implementation you wouldn't test if your heuristic was the null_heuristic and if so just call usc_search. Along those same lines, if you are given [a,a,b] goals in the tridirectional, you shouldn't solve that by calling bidirectional_search, your tridirectional should just handle it like a normal case and return the correct result.']}, {u'text': u'Ravi/TAs,

You say that it is not allowed, so how and will this be enforced?
Several students on Slack have been able to get full marks on both Tri-directional search problems by leveraging calls to bi-UCS and b-A*. Isn't the Bonnie auto-grader the final determination of the student's score?

Thanks.', u'responses': [u'It isn't the final determination. There are a number of reasons for us to change the grade before making it official, such as illegal approaches and plagiarism. I believe this falls under the former.', u'Nowhere in the assignment write-up is the approach the OP is asking about forbidden. So if it is truly the case that graders intend to remove points from students who go this route, then that should be made clear in the assignment write-up.', u'What are the illegal approaches? (Trying to avoid them, but hard to do that if we don't know what they are, thanks!).', u'I completely agree with Nick Jackson here. If these are the rules you plan to enforce, they must be stated clearly within the assignment instructions.', u'Please see my answer above.', u'Incidentally, to automate the detection of 3 bidis vs 1 tridi, I'd suggest 2 'testing' graphs;

One is a gridworld with diagonals as well as Manhattan connections between the nodes, with 3 goals at 0:(0,0), 1:(100,0) & 2:(50,50), so that the optimal path lengths are (0,1):100, (0,2):50√2, (1,2):50√2; a proper tridi won't open the node at (50,0) for instance.

However, as people could implement 'best 2' bidis with a heuristic ordering in advance, then you need a specialist graph that foxes the natural Euclidean heuristic. As before, let's say the goals are found at 0: (0,0), 1: (100,0), 2: (50,50), though this time it is a more 'real world' type graph with slaloming optimal paths; then the actual optimal paths between the different goals are of lengths (0,1): 115, (0,2):95, (1,2):200. None of the 3 optimal paths intersect or have cross-branches, while all of the paths have additional nodes peripheral to them so that they are marginally non-trivial & monitoring opened nodes discloses appropriate information. A proper tridi search would not open the nodes in the middle of the (1,2) path, although the heuristically reordered best 2 of 3 bidis would, unless the logic were modified to such a level that it very closely resembles a true tridi.', u'Having implemented a best 2 of 3 bidi solution, and having discussed this with Mark on Slack, I agree this case will catch out the hidden bidi implementations. Ultimately, what will trigger a test failure by the 2 of 3 bidi approach is that the searches are not truly interleaved and cannot share information.', u'In view of impending events, those slaloms should be called ""downhill"", ""super-g"" & ""giant"" respectively :-)', u'FWIW, I reimplemented as ""proper"" interleaved searches, and it's very slightly worse than the 3x bi-directional searches I originally tried. Enough to get past bonnie, but for example, the tridirectional A* went from 0.55 pass ratio on the 0-point landmarks test to 0.45.']}, {u'text': u'Ravi, Instructors,

Can you clarify, it isn't allowed? Does this mean that if an implementation invokes bi-UCS or bi-A* (or the implementation is copied and pasted into tri-directional functions), points awarded in Bonnie will be removed explicitly during grading?

Regards.', u'responses': [u'It may not be removed explicitly during grading on Bonnie, but can be removed after.', u'Can this ""other list"" of grading factors be published somewhere please? I have a 100/100 on Bonnie, but if there are factors other than plagiarism that will affect our grades, I and the other students would like to know. Thanks!', u'Please see my answer above.']}, {u'text': u'This post has really confused me. I am really unsure what I am to do here.
I am to find a route through points 1, 2 and 3.
So, I want to get shortest from 1 to 2, 2 to 3 and 1 to 3, correct?  Once I have found the shortest and I am sure the last one I am searching isn't shorter than I should stop and return that combined set. Meaning the route could be 3-s-t-1-a-2 or something like that.
So, I will need to exhaust through at least 2 of the searches and make sure the last one is longer.
In order through each, I shouldn't do it in a bi directional way? How would a single direction be faster than a bi-direction? I understand about ending the last search early or maybe step searching through all at same time, but I still would expect a bi direction for 1 to 2, 2 to 3 and 1 to 3 would still be quicker and more efficient.
I know that it is being said that it should be implied that bi won't work but I have really racked my brain and it seems like the best strategy to me. Note, I have not gotten anything to work yet but have started it and my approach was similar to others which is wondering what I am missing.', u'responses': [u'A single direction is not better than a bi-direction. Additionally, a bi-direction is not better than a tri-direction. I would recommend reviewing the Udacity lecture that discusses the problem: Lesson 2.45', u'Thanks John, I think I see the solution, but I don't think this is obvious in the least. But it does make sense and I can see how it is more efficient than bi-directional. Well, now that I realize it, I guess it makes sense but it never occurred to me and do not feel it was obvious.
I think the problem is that we naturally want to approach the problem as what we need to go from A to B and B to C and not deal with both at the same time. 

', u'Marking resolved.']}, {u'text': u'Agreeing with many of the posts above, it doesn't seem fair to take off points for something that passes Bonnie and is not in violation of anything written in the readme or setup files.  This feels like one of those, ""Let's make sure we say something in the readme file next semester"" situations.  However, if you are going to take off points please 1) make an announcement in Piazza, I only stumbled upon this post by accident and I imagine I am not the only one  2) Fix Bonnie, assuming Bonnie checks for expanded nodes using explored_nodes, we are getting away with tribidirectional search because it uses a set, if that is the case it should be a relatively easy fix to change it to a list and that way when we expand node 'a' three times it will count three times, and not once as I assume currently does.

Either way, thanks for all of your hard work.', u'responses': [u'I completely agree with this. I highly doubt that everyone will happen to see this thread. I fully understand that tridirectional search is different than bidirectional, but the case that Giacomo mentioned (goals = ['a','b','b']) is the one where it seems obvious to me to just call bidirectional search.

The problem is that there are conflicting instructions in all cases where goals are equal. All of the function headings in the search_submission.py file say:

Returns:    The best path as a list from the start and goal nodes (including both).

And then the readme file says to return [] in cases where the start/goal is the same, which directly contradicts the above. That means you have to write in a special exception to not return the normal path including start and end goals whenever the start and end goals are the same. For the tridirectional case, we then basically have to write a bidirectional search exception when one or more of the goals are the same, and the code is much cleaner/simpler if you just catch that special case and call bidirectional search at the outset to handle cases with two or fewer unique goal states. Seems really unfair to penalize this when it's only mentioned off-hand in the bottom of some thread on Piazza.', u'I agree with James, though I would say ""announce on T-square"" as piazza announcements only work if students are checking while T-square ones come with an email broadcast. Whatever the case is, I hope instructors can provide a clear, written, official policy as soon as possible. As Professor Starner said ""we expect students to act in good faith"" - those of us who ran afoul of this issue were acting in good faith in response to the assignment as written and not deliberately abusing bonnie. ', u'Please see my answer above.', u'Also noting that I may have had a *wrong* interpretation of tridirectional search.  I interpreted it as the growing of frontiers from three different cities and when the paths meet, identify the appropriate path.

Tri-BD search seems like an implementation of that specification.

From the README:

""Implement tridirectional search in the naive way: starting from each goal node, perform a uniform-cost search and keep expanding until two of the three searches meet. This should be one continuous path that connects all three nodes.""

Conjoining the two paths is explicitly a strategy you have to use in bidirectional search, so it seems any implementation where you are maintaining multiple frontiers is spiritually very similar to BD search.']}, {u'text': u'Like to clarify between two statements

From Thad's response ""To be explicit, yes, if you pass Bonnie's checks using a variant of bi-directional, we will count it."" , 

From Ravi's response to one thread ""It may not be removed explicitly during grading on Bonnie, but can be removed after.""

So, is  Bonnie score final if there is no plagiarism issues? or Not?', u'responses': [u'No. Also from Thad's response: ""General note: Bonnie is *not* the final arbiter of grades.""']}, {u'text': u'How does cycle starving work?', u'responses': []}]","Thad speaking:

Improving upon tri-directional UCS is one of the more ""researchy"" parts of the course. As I mentioned in the ""How to Succeed in OMSCS 6601"" post, we expect students to follow the spirit in which the assignment was given. I believe it is pretty clear from the assignment we are expecting the student to think creatively about how to improvetrue tri-directional search (not bi-directional).

Will an optimized tri-directional search beat several optimized bi-directional searches? Yes, most of the time. However, I suspect there are a class of situations where several bi-directionals may beat the equivalent tri-directional. I believe proving the bounds of these situations would be a theoretical contribution to the field. Showing it empirically is also probably a contribution.

Given that we are optimizing these algorithms pretty finely, it is difficult to create tests on Bonnie that can differentiate between a tri-directional and several bi-directional searches, if they are done carefully. We can always just visualize the nodes visited, but that code is not ready yet.

Thus, it is possible to get past Bonnie's checks in not the intended way. This semester we will accept such solutions, though I believe students who take this option are missing out on an opportunity. In subsequent semesters we hope to explicitly contrast bi-directional solutions with tri-directional.

To be explicit, yes, if you pass Bonnie's checks using a variant of bi-directional, we will count it.

General note: Bonnie is *not* the final arbiter of grades. It is aservice we provide for students so that they can get feedback morequickly on their assignments. We will alter grades if we find studentsdid not follow the spirit of the assignment - for example, cyclestarving the competition on Assignment #1 (even though that has acertain number of style points) or plagiarism (which has no style). Wetry to make it clear in the main assignment what is expected forcredit (but give more room for creative hackery in the extra credit).",2.0,276.0,369,,Tri-Search: Are we allowed to call Bi-Search?,[a2]
5ad7d4540d63974e20c3914a,"Ordinarily, taking the euclidean distance to be a straight line between two points, I'd use the coordinates (vectors) of the two points to calculate the distance.

In the graph presented here, is the information on the coordinates (or something similar) available?

Or could someone point me to a document that mentions this?",jc6w44hrp9v2ki,"[{u'text': u'Thanks Jonathan for that, I hadn't seen it.

"" to check if the key is available""

So there's a possibility that information is not available? in that case what happens?


', u'responses': [u'If n is in graph, there will be a position. ']}, {u'text': u'Can you please provide an example? I don't understand it.', u'responses': [u'Nevermind, I saw it. Thanks.']}]",,0.0,223.0,370,Quoting the Readme for the assignment:Hint: You can find a node's position by calling the following to check if the key is available: graph.node[n]['pos'],Any hint on Euclidean distance,[a2]
5ad7d4540d63974e20c3914b,"Is there a Slack channel for this class in the OMSCS Slack group? Is it private? I didn't see one. If it is private, is there an admin who can invite me?",jc6w44hrp9v2ki,"[{u'text': u'Thank you kind sir!', u'responses': []}, {u'text': u'please add me jenny.j.eckstein@gmail.com', u'responses': [u'You need to add yourself... just join the #cs6601 channel.']}]",,1.0,189.0,371,#cs6601,Slack Channel,[group_study]
5ad7d4540d63974e20c3914c,"Could I get input from a TA? I'm debugging my bi-dir A*.

Is it reasonable to assume in the following Bonnie feedback that I'm --not-- exploring too many nodes since the figure given is zero? (where it says more than the benchmark = 0)

If that's true I won't spend time trying to further minimize the number of nodes explored in the bi-dir search. Instead, I'll go after the other issues listed..

Thanks

Bidirectional null_heuristic a star search fails benchmarks searching from start to goal
Path is longer than optimal path
Path does not go from start to goal node or is invalid
On average, number of nodes explored more than the benchmark = 0

Bidirectional euclidean a star search fails benchmarks searching from start to goal
Path is longer than optimal path
Path does not go from start to goal node or is invalid
On average, number of nodes explored more than the benchmark = 0.0
",jc6w44hrp9v2ki,"[{u'text': u'What is your pass ratio? I think this message is just giving you every possible information about the performance of your code - in your case, it looks like you're not exploring too many nodes but your path is not the optimal one and is sometimes invalid.', u'responses': [u'Right - that was my assumption too. But it's only an assumption at this point. Could a TA confirm? - specifically re 'explored more than the benchmark = 0'

I only ask for clarification because I don't want to waste time trying to minimize the number of explored nodes if I'm close to the minimum already. Whereas I will spend time working on reducing the path length of the final result.
']}, {u'text': u'Thanks Ravikiran. Good point that the explored node count will clearly vary with the approach. Seems like this is hitting the sweet spot between finding the best path but with the least number of node explores.
', u'responses': []}]","As Lily says below, our output shows all possible information. In this case, the bug seems to be with your path. Keep in mind that fixing that issue might result in a different number of explored nodes.",0.0,237.0,372,,Grading bi-directional A*?,[a2]
5ad7d4540d63974e20c3914d,"Hey everyone!
This week you should watch Lesson 4, Constraint Satisfaction, and read Chapter 6 in AIMA (Russell & Norvig).

Assignment 2: Tridirectional Search
Due: February 11 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 2 is active! Please check @294 for details.

As always, here are the OH calendar, the syllabus and the schedule. 

",jc6w44hrp9v2ki,"[{u'text': u'Hi, what is the time zone used in the OH? 

I can see there is one section starting at 9 am on 2/6/2018, but I'm not sure whether it is east time or my local time (mountain time). Can anybody please clarify this? Thanks', u'responses': [u'Never mind I see what you're asking.  Need sleep.  I think it's EST.', u'Yes, the office hour calendar linked above shows the times in EST.']}]",,0.0,278.0,374,,Week 5 Announcement,[announcements]
5ad7d4550d63974e20c3914e,when I run graph[node_1][node_2]['weight'] I am not getting any output. In order to test I tried following : graph['a']['c']['weight']. Am I doing anything wrong ?,jc6w44hrp9v2ki,"[{u'text': u'In your example, you are trying to get the weight for an edge that doesn't exist.

Try:
graph['a']['s']['weight'] or graph['d']['c']['weight']

Those are valid edges and will return a correct weight.', u'responses': []}, {u'text': u'Student's answer may work but it's not recommended. Use the hint provided (Carlin's answer above).

graph[node_1][node_2]['weight']', u'responses': []}]",,0.0,204.0,376,"use 
graph.get_edge_data(node1, node2)['weight']",calculating the weight of an edge,[a2]
5ad7d4550d63974e20c3914f,"I must be missing something in the bi-dir submit search unit tests .. anyone else seen this or know what is going on?

For Romania start = 'b', goal ='s'
- my A* returns [b,p,r,s] which the unit test passes as correct and a visual check of the graph confirms is correct.
- my bi-dir A* returns the same -[b,p,r,s] . The shortest path b->s should be the same for A* and bi-dir A*.

However, the unit test passes [b,p,r,s] for the A* test but fails it for the bi-dir A* test claiming that [b,f,s] is shorter which it is not.

AssertionError: Lists differ: ['b', 'f', 's'] != ['b', 'p', 'r', 's']

the code
def test_bi_a_star_null_romania(self):
    """"""Test Bi-A* search with Romania data and the null heuristic.""""""
    print 'TEST bi_dir A* h=null\n'
    #self.run_romania_data(self.reference_path, a_star, heuristic=null_heuristic)
    self.run_romania_data(self.reference_path, bidirectional_a_star, heuristic=null_heuristic)

Also, as an aside, do the unit tests just stop running when an assert fails or do they keep running through all the tests after a test fails?",jc6w44hrp9v2ki,"[{u'text': u'I may be getting it backward, but I think the left side of the inequality is your path.', u'responses': [u'Thanks - you are right. I checked the unit test code and its impossible for the unit test reference code to return different paths for the same [start, goal] pair.']}]",,0.0,206.0,381,,A* vs. bi_dir A* - different correct result in unit test?,[a2]
5ad7d4550d63974e20c39150,"For those using a heap as underlying implementation for the Priority Queue and still struggling to validate if their priority queues are working as expected, I have found this small web app very good to verify if your implementation works as expected: https://www.cs.usfca.edu/~galles/visualization/Heap.html",jc6w44hrp9v2ki,[],,0.0,192.0,382,,PriorityQueue - Heap Visualization UI,[a2]
5ad7d4550d63974e20c39151,"Hello all, i just finished reading the notes on informed search and uninformed search.  I see that assignment 2 material doesn't involve anything from week 4 readings (simulated annealing and local search chapter 4).  Is this correct?  ",jc6w44hrp9v2ki,[],,0.0,188.0,385,Yes,Question on assignment 2 and reading material,[a2]
5ad7d4560d63974e20c39152,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.


WORD MORPHING
 
Consider the problem of morphing one word into another by making one character change at a time. You want to write a program that does this for two, random, 6-letter words. Note that all the intermediary words have to be valid.

A few examples:
1.) ThinkablePuzzles 2.)​ Wordplays​
Let’s say you represent every word as a node and all words one character change away as its children. Then, you can use a search algorithm in this word space to go from the start to goal node. Note that every step of the path has to be a valid word. However, not all combinations are valid words, so you have an API call that will tell you if an input is a valid word. Assume no more resources than those explicitly mentioned.
Part A You want to try using an uninformed unidirectional search first. Which method will you use (taking into consideration time and space constraints) under the following conditions?1. It’s guaranteed that a valid solution will be found with exactly 6 changes.2. It’s not guaranteed that a valid solution will be found with exactly 6 changes. (A valid solution is guaranteed.)
Part BNow, you want to try using an informed unidirectional search method.1. What heuristic will you use? (must be admissible)
Which method will you use (taking into consideration time and space constraints) under the following conditions?2. It’s guaranteed that a valid solution will be found with exactly 6 changes.3. It’s not guaranteed that a valid solution will be found with exactly 6 changes. (A valid solution is guaranteed.)
 
Part C Will a bi-directional search work better? Why or why not? If it works better, what would be the termination condition?
 
Part D  
Let’s say a given problem has N valid heuristics - h1 through hn. Which of the following are valid heuristics for the same problem?  Choose multiple;

max(h1,h2,...hn)

min(h1,h2,...hn)

sum(h1,h2,...hn)

avg(h1,h2,...hn)

 
Given a choice between them, which one would you choose and why? 


Solutions: https://youtu.be/xz4ovRUe_zk?t=29m21s  and https://youtu.be/O0-f1j5_X0A?t=41m42s
Also check Saalis' answer below (with Parth's correction)",jc6w44hrp9v2ki,"[{u'text': u'
Part A  You want to try using an uninformed unidirectional search first. Which method will you use (taking into consideration time and space constraints) under the following conditions? 1. It’s guaranteed that a valid solution will be found with exactly 6 changes. - depth first search with depth limit = 6 2. It’s not guaranteed that a valid solution will be found with exactly 6 changes. (A valid solution is guaranteed.) -> Iterative deepening or breadth first Part B Now, you want to try using an informed unidirectional search method. 1. What heuristic will you use? (must be admissible) - total number of wrong characters at positions Which method will you use (taking into consideration time and space constraints) under the following conditions? 2. It’s guaranteed that a valid solution will be found with exactly 6 changes. - a star 3. It’s not guaranteed that a valid solution will be found with exactly 6 changes. (A valid solution is guaranteed.) 0 bi directional a star from start and goal Part C  Will a bi-directional search work better? Why or why not? If it works better, what would be the termination condition? yes, bidi search can be used with heurestic as number of invalid characters in the string. if search in both direction meet a string, then the search terminates. Part D  Let’s say a given problem has N valid heuristics - h1 through hn. Which of the following are valid heuristics for the same problem?  Choose multiple;      1.    max(h1,h2,...hn) - VALID     2.    min(h1,h2,...hn)     3.    sum(h1,h2,...hn) - VALID     4.    avg(h1,h2,...hn)  Given a choice between them, which one would you choose and why? 1, because… summing of all the heuristic serves no purpose, it just adds duplicate conditions in the heuristic function.', u'responses': [u'Why is sum an admissible heuristic? I think sum of all heuristic can overestimate the cost to reach the goal. I think it should be max, min and avg.', u'Agree....', u'Well done Saalis and Parth! ', u'Also, I'd say that you'd want to choose the max() heuristic because it provides a maximum lower bound on the total cost without overestimating. min() and avg() would both be less than or equal to max().']}, {u'text': u'Re part B.3, I wonder if we can just simply use A*?

Arguments:
1. The solution space is infinite, but the cost of the solution should be still finite, let say the cost is Y
2. Solution space of cost <= Y is finite in this game.
3. A* start finish off searching cost <= X in each iteration, and X should be increasing in each iteration.
So eventually we should reach the goal in finite steps?

Am I missing something? Thanks.', u'responses': []}]",,1.0,276.0,387,,Challenge Question 5 - Search,"[a2, lesson2, challengeqtns]"
5ad7d4560d63974e20c39153,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


PUZZLE 8 and RUBIK'S cube
 
When we talk about Search in the field of AI, it's easy to get stuck with tunnel vision and think about it from the navigation/pathfinding perspective. However, a multitude of AI problems involve searching for solutions through a massive search space, and A* is one of the best algorithms to do so - which means it's very important to be able to generate a valid (admissible) heuristic for a problem we want to solve. One of the ways to do this is by relaxing a problem.
 
A. Consider Puzzle8 - a puzzle in the form of a 3x3 grid, where 8 spots are occupied by tiles numbered 1-8, and the remaining space is blank. You can slide a block adjacent to a blank space into the blank space, and need to use this to arrange the tiles in order from 1 to 8. For example, the following board:
 
 1 | 3 |
-----------
 2 | 8 | 5
-----------
 7 | 4 | 6
Can have two moves, involving moving 3 and 5 to the blank space, which could lead to the following states:
 
 1 |   | 3		 1 | 3 | 5
-----------		-----------
 2 | 8 | 5		 2 | 8 |  
-----------		-----------
 7 | 4 | 6		 7 | 4 | 6
 
What heuristic would you choose for Puzzle 8? How did you arrive at it?
 


B. Now, consider the classic Rubik's cube puzzle, with a 3x3 cube. According to Korf's Rubik's Cube paper, the total number of possible Rubik's cube states is approximately 43 quintillion. To put that into perspective, that's 5 times the number of grains of sand present on our Earth. Obviously, we can't search through all these states to get to a solution (we could, but might reach the heat death of the universe first). Therefore, we'll need a nice heuristic to nudge us in the right direction.


 
Give an admissible heuristic for the Rubik's Cube problem.
 
 
 
======== Food For Thought ========
 
What would you refer to as a move when designing an algorithm to search the space of Rubik's Cube solutions? Would a 180 degree twist be one move or two?
 
How good do you think your heuristic is? Can you think of any admissible heuristics that might dominate it? How might you have arrived at those?
 
Why does Korf say, ""A better heuristic is to take the maximum of the sum of the Manhattan distances of the corner cubies, and the edge cubies, each divided by four.""?

===============================

Solution: @542
",jc6w44hrp9v2ki,"[{u'text': u'For Puzzle 8, it is mentioned in book and videos.... sum of distance from the correct position of a number could be a heuristic or no of incorrect numbers could be a heuristic.

For Rubic's cube, I can think of...
* summation for all colors (distance of all x colored cubes at edge with x colored cubes at center) .. distance is no of rotations away - does it overestimate?? probably not.....
* summation for all faces of cube(no of cubes of the color similar to central cube) - admissible and consistent I think
* summation of max no of similar cubes on each face.... admissible and consistent i think...
', u'responses': [u'Consider this state:



A Hamming distance type of heuristic (sum of all wrong colors/cubes) would not be admissible here, since it would count 12 squares when the cube is 1 move away from being solved!']}]",,0.0,291.0,389,,Challenge Question 6 - Search,"[a2, challengeqtns]"
5ad7d4560d63974e20c39154,"I'm trying to read through the resources attached to Assignment 2, but I'm seeing them rotated and cut off, which makes them hard to read. I can rotate them to the correct orientation, but the left side of each slide is not visible.

See below for example. Is anyone else having this problem? If so, can we have these re-uploaded to the GitHub to fix the formatting issues?

Thanks!

",jc6w44hrp9v2ki,"[{u'text': u'It also shows rotated and cut off on my screen', u'responses': [u'I have the same problem. Seen with both xreader and Foxit on Linux Mint 18.3.', u'+1', u'+1']}, {u'text': u'Awesome, thank you!', u'responses': []}, {u'text': u'Same issue with the Search Algorithms Slide Deck PDF for me.', u'responses': [u'Search_Examples.pdf']}]","Preprocessing_For_Search.pdf

I will upload it to GitHub later tonight.",0.0,179.0,391,,Resources / Slides Cut Off,[a2]
5ad7d4560d63974e20c39155,"the comments on the head of search_submission.py says: ""Do not add any classes or functions to this file that are not part of the classes that we want.""

I've seen similar question being asked about whether we can add extra functions, and TA's answer is ""Yes""
How about extra class? can we add extra class to search_submission.py?
I add an extra Node class and my warmups part pass the Bonnie. In my understanding as long as I pass Bonnie then everything is O.K. right?
Just want to make sure.


",jc6w44hrp9v2ki,"[{u'text': u'Thanks for clarify. I need to change my code then.', u'responses': []}, {u'text': u'I have used some classes and it is going thru on Bonnie. Is it safe to assume that this should be fine because no additional tests are required?

Thanks & regards,
', u'responses': [u'I would love an answer to this too. I have implemented classes and functions outside of the course defined ones, because it is much easier to work in this way. Everything passes on Bonnie, but it would be great to get a final answer on whether this is allowed because it would mean a lot of refactoring if I need to change it for some reason. For instance, having a Node class instead of using tuples everywhere is super useful in the Priority Queue.', u'If it's passed on Bonnie, it should be fine']}, {u'text': u'Would it be acceptable to have a class defined within one of the main functions?', u'responses': [u'That should be okay. I don't see any issues with it.']}, {u'text': u'I think it's unreasonable to disallow functions that provide pretty basic utilities, like:

- Returning  a path from a data structure you pass in
- Computing path costs

I think other TAs have suggested that those sorts of things are ok, but it feels like we're getting mixed messages.', u'responses': [u'Basically, as long as these functions are within the class and pass on Bonnie, it should be fine. They're just not officially supported (meaning we can't help fix it if they don't work).

I hope that makes sense!']}]","Please do not add extra classes. Extra functions themselves are discouraged but they might work. We do not guarantee that they do.
Same goes for classes. We import the submission classes directly for some of our tests so if your custom class does not get imported your code may break.
Again. It may work. But we do not guarantee anything if you use extra classes.",0.0,187.0,392,,Can we add extra class to search_submission.py?,[a2]
5ad7d4560d63974e20c39156,"For our current project #2, will there be other factors for deciding our grade other than the Bonnie submission? i.e. things like code style (like duplicated code), etc., or are we good to go once we reach 100/100 points?",jc6w44hrp9v2ki,"[{u'text': u'Discussions in @369 implies there will be. Which is quite confusing. Would love some clarity given there are a good number of separate parts in this assignment. Thank you, thank you!', u'responses': []}]","""Bonnie is *not* the final arbiter of grades. It is a service we provide for students so that they can get feedback more quickly on their assignments. We will alter grades if we find students did not follow the spirit of the assignment - for example, cycle starving the competition on Assignment #1 (even though that has a certain number of style points) or plagiarism (which has no style). We try to make it clear in the main assignment what is expected for credit (but give more room for creative hackery in the extra credit).""",0.0,207.0,393,,Project #2 grading rubric question,[a2]
5ad7d4570d63974e20c39157,"The direct path from a node to the goal for euclidean_dist_heuristic should be identical as in the video, so s-253, z-374, and t-329? My algorithm works correctly, with the numbers that I return from heuristic, but they are different than what is in the video. My algorithms work correctly with the numbers I return, but Bonnie fails me since I explore too many nodes. So I figured the issue must be in the direct path.",jc6w44hrp9v2ki,"[{u'text': u'Hi Jenny,

I'm not sure what video you're referring to, or causing the failures exactly but for the euclidean distance, you can confirm your calculations locally using SciPy's euclidean():

https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.euclidean.html', u'responses': [u'thanks a lot, now i know for sure that my numbers are correct, so i guess i will be debugging the algorithm now']}, {u'text': u'bonnie won't pass for me... doing the path manually I get the same outcome as in the lecture video, but bonnie says the path is not optimal...

I am running through the search_unit_tests.py file and it is telling me the path from a-g should be a-s-f-b-g, but I come up with a-s-r-p-b-g as the shortest distance path...

I can't think of anything I'm possibly doing wrong at this point as the lecture video even gives the same result...

any ideas?', u'responses': [u'nevermind, I'm still not sure the path makes sense to me, but I got it passing on bonnie...']}]",,0.0,192.0,397,I got full points on the A* and mine did not match the video numbers.,euclidean_dist_heuristic A*,[a2]
5ad7d4570d63974e20c39158,"
 [o] Warmup 1: Priority queue
[o] Warmup 2: BFS
[o] Warmup 3: Uniform-cost search
[o] Warmup 4: A* search
[o] Exercise 1: Bidirectional uniform-cost search
[o] Exercise 2: Bidirectional A* search
[o] Exercise 3: Tridirectional UCS search
[o] Exercise 4: Upgraded Tridirectional search
[o] Done",jc6w44hrp9v2ki,[],,0.0,223.0,398,,What are you up to?,"[a2, polls]"
5ad7d4570d63974e20c39159,"In the book (chapter 4 summary) it says “Standard search can be applied directly to belief-state space to solve sensorless problems, and belief-state AND-OR search can solve general partially observable problems”So this leaves me with two questions#1. Why can’t standard search be applied to partially observeable problems if the solution of the sensorless problem is also a solution for the partially observable one?#2. Why can’t the AND-OR tree be used for the sensorless problem (i.e. the tree will just have MANY and-nodes to encompass the big belief states) ",jc6w44hrp9v2ki,"[{u'text': u'I am not quite sure I'm right, and I am too far behind in Assignment 2 to go too deep on this, but I believe the difference is where the uncertainty is encoded. If you're searching the belief state space, then uncertainty is encoded in the nodes. If you're using AND-OR search, then uncertainty is encoded in the edges leaving an AND level.', u'responses': []}]",,0.0,167.0,399,,Confusion on applicability of Standard Search vs AND-OR trees,[lesson3]
5ad7d4570d63974e20c3915a,"Folks-

We have caught 8 cases of plagiarism so far on assignment #1. Please remember that we only allow whiteboard level collaboration in this class. If you are looking at someone else's code or posting your own code, you are in violation of the honor code.

Detection of plagiarism is an interesting AI problem: on turned in code, on social media sites, and on code-for-hire sites. I am an AI professor, teaching an AI class. I have access to several thousand AI students who have completed my class and who may be interested in getting research credit for creating AI programs to seek out instances of cheating. Much of the OMSCS program has been created by AI professors, who enjoy a good challenge and like an excuse to work together. You get my point. Do not cheat.

Please review the syllabus on this topic, copied below for convenience:

Collaboration & Academic HonestyIn general, we strongly encourage collaboration in this class. You are encouraged to discuss the course material, the exercises, the written assignments, and the projects with your classmates, both before and after assignments are due.

However, collaboration should be at the “white board interaction” level. We draw the line at the following:

You may not copy any code directly from anyone else. To this end, you are explicitly prohibited from looking at public GitHub repositories for the purposes of the assignments. If you are looking at someone else's code, whether it be that of a fellow student or a public GitHub repository, you are cheating. In this regard, we are emulating the rules of behavior in corporate environments like Google. Looking at other people's code can and will be considered equivalent to plagiarism. You may use others' ideas to inform your own designs, but your project must be your own work.
You may not post your assignment code on a public platform such as GitHub. Please use a private repository (available free through Georgia Tech) if you wish to use git.

You may not directly copy any text from anyone else's written assignments. This includes paraphrasing. Again, you may use others' ideas to inform your own writing, but your assignments must be your own work.

You may not collaborate with anyone at all on the midterm or final. Do not discuss or share the questions and answers with your classmates or any other parties until after the tests are due.

The program has mechanisms in place to prevent plagiarism. Starting this semester, we are also enlisting the help of OMSCS students in detecting such cases and will act upon any evidence that we find. We have successfully caught instances of plagiarism each semester. Please don’t be the next person; we can assure you that the consequences for a poor grade. are far, far less than the consequences for plagiarism. It isn’t worth the risk. Any instances of violation of this policy will be referred to the Dean of Students. If you are unsure of whether a certain type of collaboration is acceptable, please ask first, preferably on Piazza. The full Georgia Tech honor code is available on-line.

#pin
",jc6w44hrp9v2ki,"[{u'text': u'May we ask, what are the official / unofficial false positive rates for the plagiarism detection system in place, please? At least the 'automatic' phase of it, & claimed detection rates etcetera, as I think that sounds a good Bayesian question :-)', u'responses': [u'We use MOSS for detection. It highlights similar parts in code and shows the percentage of similarity. It does not tell whether a person plagiarizes or not. It just tells how similar the codes are.

I examine all results returned by MOSS and confirm the cases of plagiarism. Then we send out emails to involved students.', u'Sounds good to me, thanks for the clarification :-D']}, {u'text': u'So the public github repo keeps getting brought up and looking at other students code. I understand that it’s cheating to follow what someone else has done to answer the assignment. But what about resources unrelated to this course...for example a blog post pertaining to minimax implementation with code snippets—is this considered cheating? I’d be very curious because this is how cs careers work...source the resources available to you for previous implementations and iterate on what has been done before you. ', u'responses': [u'Perhaps a question more pertinent to assignment 2. I was messing around with custom_search and found that I really needed a fast delete operation on my priority queues. I know that an implementation for such an operation is in the Python docs. So, is it plagiarism to use code from the official Python documentation? ', u'IMO, you should reference it, at the very least.']}, {u'text': u'Have the grades been released yet?', u'responses': [u'It will be released soon. @Kshitish Deo  ']}, {u'text': u'Have the grades still not been released yet? I haven't received anything yet on tsquare.', u'responses': [u'Nothing on my end as well.', u'We had T-Square issues after grading was done, but it's all been sorted out now.
Thanks for your patience, and apologies for the delay!', u'All good. Thank you for the follow up!']}]",,0.0,353.0,401,,Plagiarism detection,[announcements]
5ad7d4570d63974e20c3915b,"The partial credit is driving me insane. I'm fairly certain my searches are exiting too early, therefore the path is not optimal.

Any hints?

Thank you, thank you!
-Q.",jc6w44hrp9v2ki,"[{u'text': u'Thanks, Efty. I feel kind of silly. I've been referencing the exact slide you provided, from the instructions. Just scrolled a few pages down and got my answer.. *facepalm

Thanks again!', u'responses': []}, {u'text': u'Thank you, Efty for posting this. It has definitely helped me finding where my algorithm was falling short.', u'responses': []}]",,0.0,204.0,402,"For both UCS and A-Star bi-directional you need to ensure you have the correct stopping conditions. 
Once you have determined the stopping conditions you still need to find the optimal path.
Check out this video from MIT on the subject
https://www.youtube.com/watch?v=CHvQ3q_gJ7E


Specifically for bi-directional A-star you should look at the slides in the additional resources on what is a proper heuristic for bi-directional.
https://github.gatech.edu/omscs6601/assignment_2/raw/master/resources/Bi%20Directional%20A%20Star%20-%20Slides.pdf
",How to get the cheapest path for the bidirectional searches?,[a2]
5ad7d4570d63974e20c3915c,"How complicated would it be to create an interactive 2 Queens Isolation game interface, and then set it up for people to play against the agent I coded in assignment 1?

I was thinking it could be a fun way to show coworkers something I did in this class.",jc6w44hrp9v2ki,"[{u'text': u'Thanks! I will check it out.', u'responses': []}, {u'text': u'I built a UI after the assignment was due just so I can keep exploring with different heuristic functions by playing against the AI myself. I could undo a move to see how AI reacts to different moves etc.

I used Pygame. It's pretty easy and straightforward.

Here is a good tutorial if you are not familiar with pygame, and to do a UI like this, that's pretty much all you need
http://www.nerdparadise.com/programming/pygame/part4


', u'responses': [u'Awesome, thanks!']}]",,0.0,166.0,403,"Check out TkInter https://wiki.python.org/moin/TkInter.

It's a really simple GUI toolkit and comes with Python.

I played at work the hard way by making my colleagues point to the spot on the grid they wanted to go and I would enter the (row, col) coordinates manually. No one played two games...",Creating game interface to play against assignment 1 agent,"[a1, lesson1, other]"
5ad7d4580d63974e20c3915d,"I promised an updated on how to compete in the Race with an opportunity for bonus points, and here are the details:

To enter into the race, all you need to do is complete the ""custom_search()"" function with the best search function you can. You're latest submission will be taken.

You will be ranked on path length, time taken, and number of explored nodes, and in that order. That is, time taken is the tie breaker for two people who found the same path length, and explored nodes is the tie breaker for two people who found the same path length and had the same amount of time taken (which statistically should never happen). The implication here is that if 10 people all find the optimal path, then you will be ranked on time; hence, a race.

You are welcome to use any search algorithm you want, but we expect that some version of bidirectional A* will be the best option. 

A reminder that bonus points are added to your grade for this assignment, not for your course grade overall.

Happy coding!

",jc6w44hrp9v2ki,"[{u'text': u'def custom_search(graph, start, goal, data=None):
Where
data : Data used in the custom search.
Should we call the load_data() function in custom_search? But if graph data is already passed in, what is the point of calling the load_data() function? ', u'responses': [u'I believe this is a data.pickle file that you create to help your search, I just can't figure out how to get Bonnie to upload it.', u'I'm confused by the data argument as well. What should we do with the data argument if graph is already passed in? All of the other search function signatures have graph and start/goal. None of them have data.', u'Ignore the ""data"" argument. It's part of something that a previous TA was trying to implement. I apologize for the confusion.', u'Thanks for the update, I learned a lot about landmark searches and a little bit about pickle as a result of the confusion.  Though the learning was good, I guess the code is useless now. ', u'I do apologize for not communicating this better, but am also super glad you learned something out of it! You could probably just paste the text into your submission and parse it from there, for what it's worth.', u'Yeah, I thought about that, but the tie breaker is speed first and while the landmark search is fast once the landmarks are loaded, it takes a bit to load them so I submitted something else.  Thanks for the suggestion.']}, {u'text': u'Is the race between 2 points or 3 points or n points? Is it only on the Atlanta graph? Can more info be provided about the graph and load function?', u'responses': [u'Yes, it will be the Atlanta graph, and it will be between two points not three.']}, {u'text': u'Is there any way to calculate Reach for the whole graph without exploring all nodes? Looking at the explorable_graph api, it looks like to iterate over all nodes and calculate reach for a vertex I would need to use graph.nodes_iter. But it looks like that would mark all the nodes as explored which defeats the purpose. I guess that is the last consideration though over optimal path and time, so maybe exploring all the nodes to calculate Reach is OK. Anyone else have thoughts on this?

I can't figure out how we can preprocess and store reach and landmarks calculations offline given the Bonnie setup.', u'responses': [u'You can store the data in a pickle. However, it appears that Bonnie has a 8MB limit on filesize uploads. Hence you can't store much data. Maybe 4 landmarks, or 3 landmarks + reach data. That said, I am finding 16 landmarks generally greatly improves bidi-A* run time, but 4 landmarks often makes it worse..

I uploaded my data file and ATL shortest path code to T-square, for what it's worth.']}, {u'text': u'', u'responses': []}]",,0.0,325.0,406,,Update on Assignment 2 Bonus Points- the Race,[a2]
5ad7d4580d63974e20c3915e,"My BFS passes all unit test but is still failing on bonnie.  I've also checked it for handling start==goal.  Since bonnie doesn't give any sort of info about what is not passing, I'm kind of at a loss.",jc6w44hrp9v2ki,"[{u'text': u'bonnie does give some errors. it took me about 3 hours to figure out popping the frontier node does not show that you explored the node. and you have to use the commands in the instructions.', u'responses': [u'What commands are you referring to? I'm already using graph.neighbors(node), which is the only one i see.  Maybe I'm missing it.', u'that was the one. if it is the node error. there was a brief mention in the lecture about optimizing bfs for the final node', u'Which command?

Are you saying that using this command ""marks"" it explored within Bonnie? My Bidirectional searches are still not at 100%.

Thank you, thank you!', u'when I used the neighbors command it solved my explored node issue with bonnie', u'I have the same issue (tests passing but not in Bonnie) for BFS but I don't understand what you guys are talking about. Can you please clarify.', u'First which error are you getting? I could pass a local test in UCS but it was the wrong path. for BFS I would make sure you understand when to return and make sure you use the two commands in the instructions graph.node and graph.neighbors. I had to rewrite by program because bonnie uses the graph explored node functions. return the [] if start and goal are the same. optimize the last BFS search. The lectures are helpful for determining how the algorithm should run.', u'I have no errors while running BFS with the search_submission_tests.py. However, when I run Bonnie I get 0/5.
I didn't understand the optimization of the last node in BFS. Can you please explain the main idea?




', u'Btw, why should I use the graph.node command for? I just need the 'start' node to start my iteration through the graph.', u'In doing a breath first search starting from a, you should explore z, s and t before you get to f, b or u.  However, your image shows that you are not exploring z or t.  Either you are not visiting those nodes, or you are not using the correct mechanism to reference the neighbors of those nodes.  From the readme, you must use:

You can access all the neighbors of a given node by calling graph[node], or graph.neighbors(node) ONLY. 

both of these will give you the neighbors of ""node"" (in other words, graph['a'] will give you 'z', 's', and 't' -- though I'm not sure of the order).', u'Thank you, Conor. I do explore the neighbors of 'a'. I'm not sure what I'm missing. Do you have an email that I can contact you?

for neighbor in graph.neighbors(currentNode):    if(neighbor not in frontierNodes.queue and neighbor not in exploredNodes):        if neighbor == goal:            #get path        #add neighbor to frontier', u'Nevermind, solved my issue. I was using a priority queue instead of a regular queue for BFS. Thank you all :)', u'I used priority queue for all of the parts of this assignment.  With BFS, the base priority should be the depth at which you found the node and the secondary priority should be the order in which the node was found.']}, {u'text': u'My implementation finally passed after I changed where it returns the path.', u'responses': []}, {u'text': u'That seems to be the 3 main things you need to do or it will fail without really telling you why. Return an empty list, [], if you're at the goal already. Don't search more nodes than you need to get to the goal for the specific method. Return the path you get once you're sure you've got the shortest path to the goal (caveat being that some methods have different definitions of how the shortest path is determined).

And someone mentioned that ""searching"" an node means that you write it like this, graph[node1][node2], where node1 counts towards your ""searched"" nodes that turn green in the visualization.', u'responses': []}, {u'text': u'One of the things that caught me was:
If your start and goal are the same then just return [].', u'responses': []}]",,1.0,183.0,407,"Things that have been noted:

If start == goal, return empty path []remember that your priority queue should return the items in added order when they are added with the same priority.  For example, if, when exploring 'a', you add 'z', then 's' then 't', the next item that you should pop off the queue is 'z'... and the subsequent one should be 's'.In the class they talk about an optimization that allows you to return your result sooner in a BFS search.  The Bonnie tests require that optimization.
",BFS help,[a2]
5ad7d4580d63974e20c3915f,"
I'm having trouble getting my queue selection correct using current_score + step_cost + heuristic_cost for Astar where the heuristic_cost is the distance from the frontier node to the goal. The local testing is failing at ASFB vs ASRPB. I know ASRPB is the shorter path but since the heuristic is distance to goal, smaller steps are penalized so I'm choosing ASFB. Should I be subtracting the heuristic_cost for the previous step when heapifying the queue so that the heuristic costs aren't compounded for small steps?

Also, does it make sense that ASF is shorter than ASR? Are edge weightings not the same as euclidean difference? I get ASF as the shorter Astar cost at 626.32 vs ASR at 639.18. For the edge weighting from F => B, I get 211 but the euclidean distance I calculate for F => B is 154.62. Given that distance from R => B is 186.48, it searches ASF first for me.",jc6w44hrp9v2ki,"[{u'text': u'when you say
For A-*, the score for a node should be path_distance_to_node + euclidean_distance_to_goal. 
does it mean the ""accumulated path_distance_to_node + the euclidean_dist"" ..  and that the accumulated path distance should not include the heuristic value .. is this correct ?', u'responses': [u'I actually am just using the current cost weighting to the next node + euclidean heuristic. Seems to work for getting the order right. If you do the accumulated you'll run into the same problem I was having where it prioritizes nearby nodes to the start node rather than nodes closer to the goal. ', u'Yes accumulated path_distance to the node.   So if you started at 'a' in Romania and your goal was 'b', when you add 's' to the frontier the ""score"" for 's' should be 140 (path cost from 'a' to 's') plus euclidean distance from 's' to 'b'.  When you later visit 'r', the ""score"" should be 220 (path cost from 'a' to 'r') plus euclidean distance from 'r' to 'b'']}, {u'text': u'I am having the same issue. When I calculate the the Euclidean distance and the current path cost I get that s,f,b as a better path. My UCS funds the correct path, which makes me worried that I am applying the heuristic at the wrong place in the code.', u'responses': [u'You need to add the heuristic to the value you put in the queue so the ones with smaller heuristic plus cost will be guided toward the goal. But when the two sides meet up the shortest path is determined by the sum of the costs without the heuristic.', u'It looks like Euclidean Distance is indeed different from the Edge Weighting. Perhaps to show the path cost difference like from travelling on a dirt road or a highway? It didn't effect my solution once I corrected the scoring to NOT keeping adding on the the total score from the previous path though. Just a good note to remember in case a solution doesn't look logical.', u'euclidean distance will be ""as the bird flies"" -- as in the straight line distance from point A to point b as if you were able to fly between the two points   Path cost will be the actual miles that you drive along the road (most roads have curves and go around obstacles, etc and easily exceed the  straight line distance.', u'I got it! Thanks for the help, I was applying the heuristic incorrectly! ']}]",,1.0,178.0,409,"Actually. Subtracting the previous step's heuristic worked. It sounds stupid, but is that right or is there something wrong with my heuristic?

--- Added by Conor...

For A-*, the score for a node should be path_distance_to_node + euclidean_distance_to_goal.   You should not be using the prior score for the entry.   Your subtracting  the previous step's heuristic is essentially re-calculating the path_distance_to_node, so it should work out (assuming you are adding the new distance along the way.",A-star euclidean distance path different from edge weighting path?,[a2]
5ad7d4580d63974e20c39160,"I compared my tri UCS vs tri A* implementations.

With Tri UCS I yield:
Test the tri-directional search implementation:                         10.00/19

If I substitute my Tri A* implementation for Tri UCS, I yield:
Test the tri-directional search implementation:                         18.00/19

Will I be docked points if I submit the same implementation for both exercises?",jc6w44hrp9v2ki,"[{u'text': u'Probably, maybe. Technically, you aren't using a UCS implementation for a task that specifically asks for one. It's like if I asked you to code me a bubble sort, but instead you gave me a merge sort. Sure, they both sort, but it's not what I asked for. Or, more humorously, I asked for a Pepsi and you gave me a Coke. :)', u'responses': [u' In terms of success / failure on bonnie, the difference in my implementation is 1 line of code (calculating the heuristic) and it looks like i'm failing due to the number of nodes explored.  I'm still trying to figure out the plain old vanilla solution.  However, I saw elsewhere that using BD UCS / A* inside of the tri search function is now allowed.  If that is the case and similar considerations are now being allowed for the other exercises, I'd hang up my hat and call it a day on this one.']}, {u'text': u'UCS is a special case of A* where the h(n) is zero.', u'responses': [u'I think the point here was he wasn't using h(n) -> zero.   He was using the heuristic to limit the explored nodes.', u'Swapping out the euclidean heuristic for a null heuristic was only netting me 85% passing on bonnie.  To be perfectly honest, I just may have gotten the concepts wrong, but tri A* seems quite a bit different to me than the ""naive tri ucs"" that we were to implement in the exercise.  Tri A* seems to have direction and goal, where as the point of the naive tri UCS was to find optimal intersections with the other searches.']}]",,0.0,197.0,410,"Disregard, I figured out a good ol' fashioned plain vanilla tri UCS solution.",tri-search grading,[a2]
5ad7d4580d63974e20c39161,"Hello, i haven't taken a course on data structures.  so i was trying to get up to speed on priority queues heaps.  I have a question.  Given an array, [1,9,6,10,5,8]

Calling heapify results in [1,5,6,10,9,8]

But when i drew the diagram on a piece of paper, why can't the order [1,5,6,8,9,10] work?  Or am i mis understanding how heaps work?  thanks

Like wise, when i try x = [35,33,42,10,14,19,27,44,26,31]

on paper, i get [10,14,19,26,27,31,33,35,42,44]

but calling heapify i get 
[10, 14, 19, 26, 31, 42, 27, 44, 33, 35]",jc6w44hrp9v2ki,"[{u'text': u'Thanks professor', u'responses': []}]","You are misunderstanding a bit how heaps work. I would recommend two things. The first is to find some resources and learn about heaps just a little. The second is to not worry about how they work all to much. As long as you utilize it correctly, you will be okay.

Python's heapq documentation will get you most of the way there.

I think this article should answer your above questions.",0.0,166.0,411,,priority queue question,[a2]
5ad7d4580d63974e20c39162,"Can anyone advise on how to run the search_unit_tests.py and search_submission_tests.py in pycharm? The tool is new to me and I am struggling on how to use either properly when I need to specify command line arguments for unit_tests

Also, I'm struggling to understand what is being returned by graph[node] and graph.neighbors(node) referenced in the readme. I see a set() initialization in explorable_graph but trying to reference any data in the return of these calls is not working. I may be missing something completely here.

Any useful tutorials or explanations would be greatly appreciated. I have a lot of work ahead on this assignment.",jc6w44hrp9v2ki,"[{u'text': u'These are tough questions over the web, Chad. Best way is to grab a node and start printing this out and see for yourself. It took me a while to become conversant with the project set up so I believe that's normal.

I didn't use the unit tests for but search_submission_tests.py, just run it normally. It calls your submission file. Note that everything will fail if you haven't implemented it yet.

For graph[node] and  graph.neighbors(node), one returns just a list of the nodes while the other returns a dict with the nodes and weights. I can't recall which is which, but again, just print it out and see for yourself.

', u'responses': [u'My trouble was messy configuration names in pycharm. I couldn't actually test my BFS implementation to see the printout that you are describing. Now it makes more sense.

Thanks for the prompt reply']}, {u'text': u'Just to add my two cents:
1) You can go into the test files, go to the test function you want to run, right-click inside that test function, and you should be able to click either 'Run ""Unittests for...""' OR 'Debug ""Unittests for...""
2) You can then set breakpoints throughout the code and look at the current values for variables.

Additionally you can right click on the file itself, from within pycharm, and run/debug all the tests in the file.', u'responses': []}]",,0.0,157.0,413,I figured out the pycharm issues. All good,Simple PyCharm and Python Questions,[a2]
5ad7d4590d63974e20c39163,"Not a big deal but any hints on getting those last points? Haha.

Thank you, thank you!

<update> Nevermind, got it. Just like Julie said below, all about them return-conditions... Thanks, Julie and good luck, everyone!!",jc6w44hrp9v2ki,"[{u'text': u'I'm in the same boat as you, but with tridirectional. According to bonnie, my issues are mostly because of extra nodes, so I'm rethinking my stopping conditions.', u'responses': []}, {u'text': u'I was stuck where you were for a long time. I kept looking at the solution about ending condition based on top+top>score. This function is a bit misleading at least to me. I couldn't get passed the same issue till I realized another way of solving the routes. I watched some different youtube videos on bi-directional searches to solve this which did it differently than that and they worked giving me my two extra points.
However, my tri is another story :(', u'responses': [u'Tri_dir is taking time off my lifespan.... Haha.

For bi-dir, that stopping condition makes sense. Had to read the slide a few times over. I had another return condition, which was stupid, so after I removed my other ""quick-exit/returns"", all went smoothly. The unit-testing helped.']}]",,0.0,197.0,414,,14/15 and 19/20 for the Bi_dir searches..,[a2]
5ad7d4590d63974e20c39164,"Hi,

When I run unit tests on my local for BiDi A* , i see that the nodes explored by my function and the reference implementation match up for all cases.. here is a sample output : But bonnie error report says too many nodes explored .. how can I even begin to debug this

Num Explored Nodes =  20 Ref nodes explored =  20['a', 's', 'r', 'c'] ['a', 's', 'r', 'c'] Num Explored Nodes =  20 Ref nodes explored =  20['a', 's', 'r', 'p', 'b'] ['a', 's', 'r', 'p', 'b'] Num Explored Nodes =  20 Ref nodes explored =  20['a', 's', 'r', 'p', 'b', 'u', 'h', 'e'] ['a', 's', 'r', 'p', 'b', 'u', 'h', 'e'] Num Explored Nodes =  20 Ref nodes explored =  20['a', 't', 'l', 'm', 'd'] ['a', 't', 'l', 'm', 'd'] Num Explored Nodes =  20 Ref nodes explored =  20['a', 's', 'r', 'p', 'b', 'g'] ['a', 's', 'r', 'p', 'b', 'g'] Num Explored Nodes =  8",jc6w44hrp9v2ki,"[{u'text': u'<deleted>', u'responses': []}]",,0.0,179.0,415,"well anyone has any insights on this ?
seems like the networkx APIs are not sacrosanct.. even though they use an optimized bidirectional A*

The fact that the two explored values match on your machine does not mean they are the optimal number. Someone else may have a more elegant way to deal with this, but my approach was to tweak parameters so that I explored fewer and fewer nodes until I broke the optimal path. Then backed off a little and it passed Bonnie this way.",BiDi A* search : Unit tests versus Bonnie results,[a2]
5ad7d4590d63974e20c39165,"I did UCF and I get following graph with Bonnie error Message 
""Uniform cost search fails benchmarks searching from start to goal node\nNodes explored should from be a valid frontier and should be kept to a minimum"". Any pointers will help. Is path coming out correct.?",jc6w44hrp9v2ki,"[{u'text': u'Others will correct me if I'm wrong but I believe it should be: a,s,r,p,b,u

Try returning/exiting when you move on from the goal, not when you've reached the goal. So you can ensure you find all paths that leads up to it and return the lowest.', u'responses': []}, {u'text': u'I got correct results after making code change. Though it still fails in bonnie. ""Uniform cost search fails benchmarks searching from start to goal node\nNodes explored should from be a valid frontier and should be kept to a minimum"".
not sure what's going on.', u'responses': [u'See if @402 helps you with that. It has helped me.', u'Pulling from memory, nodes m and d shouldn't be explored. Maybe c as well.', u'I am in the same boat as you. I have no idea what's going on.', u'... but why?  i felt that more nodes than necessary are being explored, certainly.. but there's no measure or way to know if its pure UCS.. I feel I'm missing something painfully obvious.
', u'for UCS on romania from 'a' to 'u' I have:

', u'Wait... that was Bi-directional UCS.....  for basic UCS I have:


Which matches what Vishwadeep has.  And I've passed this on Bonnie.', u'I am having issues with passing the basic UCS on Bonnie even though I pass it locally. I keep getting ""Path is longer than optimal path"" and ""Path cost is incorrect"" errors.', u'There's likely some edge case that your not handling correctly and returning a less than optimal path.  Try running the following locally:

python search_unit_tests.py SearchUnitTests.test_ucs_romania
Which will test uniform_cost_search on many/all pairs of nodes in romania', u'Thank you sir! Got it fixed; was looking at more nodes than necessary.', u'Hmm..  That graph is what I got yet bonnie is not happy.  Still quite put my finger on why...
Just running out of time on this project (again).. sigh.

Wait.. my graph the dotted line between b and g is gone! .. why would my algorithm wipe out a relationship in the original graph? ', u'Fixed that... still no dice.  My graph is the same and I cannot for the life of me think of why or how I would be exploring more nodes than needed.
', u'That's one path.  I have found that sometimes I would get the exactly correct graph for some entries and totally broken graphs for other entries.  That's why running the unit tests like I outlined above (which runs many or possibly all sets of goals helps (finds alternative edges you need to fix).  At least it kept doing so for me.', u'For some reason, it completely passes the unit test with Romania... no errors! .. Like I said, i just don't get it.  But I'll sleep on it.  Thank you!']}]",marking resolved for housekeeping.,1.0,173.0,416,,UCF error help,[a2]
5ad7d4590d63974e20c39166,"Just wanted to share this paper that I used to implement Bidirectional UCS.

Choose pdf

https://academic.oup.com/comjnl/article/9/3/275/406281

The paper describes Nicholson algorithm. Basically it prefers to expand the queue (front queue or back queue) that has covered the least distance. 

The front and back queues are not explored in turn. Instead, on each iteration, if the minimum value on top of the front queue is less than the minimum value on top of the back queue, it explores the front queue and vice versa. If there's a tie, both queues are explored in turn. This continues until the most optimum path is returned.

I implemented this algorithm and was able to pass Bonny on first attempt (after fixing a few nuances on adjacent start and goal nodes etc).

Since I didn't implement the other Bidirectional search where front and back queues strictly alternate, I'm not able to verify if indeed my implementation explores fewer nodes than the other. But it explored enough nodes to pass Bonny.

Note: The graph used in the paper has a missing link between one of the nodes. The correct graph is below:

The start node is 1 and the goal node is 9

",jc6w44hrp9v2ki,"[{u'text': u'Good note. I like the idea of not alternating but wouldn't that force one side to be more heavily searched just because it has more branches (and thus take longer)? Also, would it be possible to do this in one queue then if we just kept track of whether it's a forward or a backward search (by checking the first element)? That way it is always searching the shortest distance first and then it will just compile the final path once the last element of two queues match AND the first element of each is equal to the start and end respectively.', u'responses': []}, {u'text': u'And as a follow up question about Bidirectional, is there a more efficient way to search start-queue and end-queue to see if the current node is an element of the other queue than just iterating over the entire path of each path in the other queue for EVERY step?', u'responses': [u'
Just create a new set or dict to keep track of it.

each lookup is O(1) rather than O(n), the tradeoff is memory but I don't think that would be an issue here

Source * https://wiki.python.org/moin/TimeComplexity']}]",,0.0,189.0,418,,Additional Material on Bidirectional UCS,[a2]
5ad7d4590d63974e20c39167,"I'm getting partial score for Bi-directional A*, as below.

I suspect I'm exploring just a few more nodes than necessary, but cant figure it out!

Any hint what to prune? My stopping criteria is l_min < max (min front_queue, min back_queue) where the priority of the queue is the f-score and l_min is the shortest distance of the full path discovered so far

{            ""output"": {                ""points_available"": 20,                ""points_awarded"": 10,                ""autograder_comments"": ""Bidirectional null_heuristic a star search fails benchmarks searching from start to goal\nNodes explored should be from a valid frontier and should be kept to a minimum\nOn average, number of nodes explored more than the benchmark = 317.8\nBidirectional euclidean a star search fails benchmarks searching from start to goal\nNodes explored should be from a valid frontier and should be kept to a minimum\nOn average, number of nodes explored more than the benchmark = 0.0967741935484\n"",                ""pass_ratio"": 0.845            },
",jc6w44hrp9v2ki,"[{u'text': u'Run the search_unit_tests.py with the test for only bidirectional a*test method for romania data on. It will run all the unit tests possible and you will exactly be able to tell which paths are resulting in additional nodes or longer paths in your code.', u'responses': [u'I pass all unit tests and still get 10 points only!!!']}, {u'text': u'In which document of the ones provided should I look for the stopping criteria?', u'responses': []}]",,1.0,212.0,419,Check out the stopping criteria from the provided slides.,Bidirectional A* partial score,[a2]
5ad7d4590d63974e20c39168,"I see now that we are to upload our assignment code to T-Square for ""back up"" purposes. If we didn't upload our code for past assignments (i.e. assignment 1), will we still receive a grade based on our Bonnie test results (as opposed to a 0 for not uploading to T-Square specifically)?",jc6w44hrp9v2ki,"[{u'text': u'I forgot to upload my assignment-2 to T-Square, but it is present on bonnie. Will it be considered?', u'responses': [u'Yes, T-square is for backup. Having said that, please upload it on T-square next time onwards - it's good to have backups! :)']}]",Yes. T-square is for backup.,0.0,209.0,421,,Uploading Assignments to T-Square,[grades]
5ad7d4590d63974e20c39169,"Keep failing on the A* despite trying the following.  Can somebody help me sort out why I'm failing?  or post what your working solution looks like.
      -Implemented and tested Eculidean Heuristic  - sqrt((x1-x2)^2 + (y1-y2)^2))
      -When first path is found, checking all nodes in queue whose projected cost is less than cost of found path to make sure there are no other paths that are cheaper
              -Tried terminating the search as soon as first path is found - still failed (only difference was node T wasn't explored)
      -Weight of each node = cost to get to that node + euclidean distance to goal
      -Did not sort nodes of equal weights by alphabetical order when popping from queue (Is this necessary?)
      -Returning [] if start and goal are same


Here is what my solution looks like:  
 
""A star null_heuristic search tests passed\nEuclidean heuristic A star search fails benchmarks searching from start to goal node\nPath is longer than optimal path\n",jc6w44hrp9v2ki,[],,0.0,174.0,422,Found the bug:  I was adding U to the queue despite it  being the Goal.  Added a check to not add the goal to the queue.  ,Help with A*,[a2]
5ad7d45a0d63974e20c3916a,"It must be a basic question. I am sorry. I really couldn't find the answer here.
Do I submit a json file I got from Bonnie? or search_submission.py?
I got confused in assignment1 and I just attached both python script and final json. 
For assignment 2, it seems like I can only attach one file. So I am asking.
Thanks in advance. ",jc6w44hrp9v2ki,"[{u'text': u'Since the Tsquare submission is serving as a back up, I'm believe it is the search_submission.py file.
-Q.', u'responses': [u'I assumed the same thing as well, but hopefully we can get a TA confirmation?']}]",,0.0,171.0,423,"As Q. indicates below, it's the search_submission.py.   I'm just submitting the zip file that I pulled from Bonnie so that it's the exact file that was submitted and used on Bonnie.",What files should I submit to t-square for assignment 2?,[a2]
5ad7d45a0d63974e20c3916b,"I'm running through unit tests on the tri search and I seem to be encountering cases where the priority queue runs out before the search ends...

Now, I'm not just doing a bunch of bi-directional searches... though I may resort to that if I can't get this figured out...

I'm just wondering if anyone else encountered this and if you can give any ideas as to what you did to solve it?  I've been unsuccessfully trying out different ideas for the past few hours.

",jc6w44hrp9v2ki,[],,0.0,159.0,424,"You can possibly run out of nodes in one graph before another graph depending on how you're coding the solution.   The general reason why this would happen is if you are not putting new entries into the list (perhaps because you've hit your termination condition, or perhaps because of a bug where you're putting nodes into the wrong frontier).

This typically means that you have something wrong since you should meet the search coming from the other direction long before you run out of nodes in your frontier (assuming you are continuing to add nodes as you explore).

So examine your terminating conditions to see where you should stop searching.  Make sure you're putting nodes into the correct frontier. There are probably many other ways this can happen but the all are one bug or another.",trisearch nodes not connecting?,[a2]
5ad7d45a0d63974e20c3916c,"Even though my test function is passing, I'm getting this error on Bonnie - 

line 19, in is_path_correct\n if not (path[0] == start and path[-1] == goal):\nTypeError: 'NoneType' object has no attribute '__getitem__'\n"",
Keeping the instruction in mind, I'm using neighbors(node) to add to the explored set. Is my path not getting returned properly?",jc6w44hrp9v2ki,[],,0.0,150.0,425,See item 4 at the very end of the README.md.,BFS Bonnie __getitem__ error,[a2]
5ad7d45a0d63974e20c3916d,https://stackoverflow.com/questions/12806452/whats-the-difference-between-uniform-cost-search-and-dijkstras-algorithm,jc6w44hrp9v2ki,"[{u'text': u'Additionally, when talking about bidirectional search, people often interchange Dijkstra with UCS. For example, the Bidirectional A* slides mention Bidirectional Dijkstra but with a stopping condition. This contradicts the answer in the Stack Overlflow link that states Dijkstra has no goal node.

I find this confusing.

', u'responses': [u'That wiki page being quoted has been redirected to Dijkstra's algorithm. I think it really doesn't matter that much here. It's just the same algorithm in different context with possibly minor variants.

All we need to understand is Dijkstra/UCS uses a  priority queue to always pick the vertex with the shortest known distance to source and relax its edges to update the known distances to source of its children.

The latest wiki page has a more accurate description:


In some fields, artificial intelligence in particular, Dijkstra's algorithm or a variant of it is known as uniform cost searchand formulated as an instance of the more general idea of best-first search.[5]

']}]",,1.0,170.0,428,,What&#39;s the difference between uniform-cost search and Dijkstra&#39;s algorithm?,[a2]
5ad7d45a0d63974e20c3916e,https://youtu.be/KyRSJRMz818?t=15m44s,jc6w44hrp9v2ki,[],,0.0,158.0,429,,Resource on Bidirectional Search,[a2]
5ad7d45a0d63974e20c3916f,"when I run unit test, one test always fails with message: 
Failing Test A* search with Romania data and the Null heuristic.
AssertionError: Lists differ: ['a', 's', 'f', 'b'] != ['a', 's', 'r', 'p', 'b']

However same test always pass with my heuristic function with correct path ['a', 's', 'f', 'b'].
What is Null heuristic function ? any pointer to get rid of this issue ?",jc6w44hrp9v2ki,[],,0.0,145.0,430,"That's a test which uses a heuristic that returns a zero for the distance and therefore your system should behave like straight up ucs. 

I don't know if you need to handle that case to pass Bonnie.  I do and I did pass, but that doesn't mean that if I didn't it wouldn't have.",Failing Test A* search with Romania data and the Null heuristic.,[a2]
5ad7d45a0d63974e20c39170,"
Just wondering if there is one today? Didn't seem to connect to the one in the calendar.",jc6w44hrp9v2ki,"[{u'text': u'
PQ1:[[310, ['b', 'f', 's']], [344, ['b', 'p', 'r', 'c']], [319, ['b', 'u', 'v', 'i']], [359, ['b', 'p', 'c', 'd']], [385, ['b', 'p', 'c', 'r']], [418, ['b', 'p', 'r', 's', 'a']], [429, ['b', 'p', 'r', 's', 'o']], [377, ['b', 'p', 'r', 's', 'f']]]
PQ2:[[295, ['z', 'a', 's', 'r']], [304, ['z', 'a', 't', 'l']], [314, ['z', 'a', 's', 'f']], [366, ['z', 'a', 's', 'o']], [362, ['z', 'o', 's', 'a']], [302, ['z', 'o', 's', 'r']], [321, ['z', 'o', 's', 'f']]]



So suppose this was my current queue when my code stopped while scanning the Romania map. Because it found a common visited node between PQ1 and PQ2 which is node F, it stopped and I now know that I should be able to find a path between the two. The current path costs are correct and I know the optimal path is BPRSAZ. My code returns BFSAZ because BFS is first in the queue. Should I save this solution and just CONTINUE popping elements from the queue to find a better solution or can I stop here? From what I understood, it seems better to save the best current solution and utilize heapq to keep searching for alternate solutions (like BPRSAZ) until the queue is exhausted of solutions where the combination of any values in PQ1 and PQ2 is less than the current solution.
 
I ask because I know it's possible to simply splice the solution of PQ[1] and PQ2[0] to get an optimal solution of BPRSAZ for a cost of 639 (without removing the cost over overlapping nodes) but I would have to iterate over the queue and find the cost of each possible solution.', u'responses': [u'Correct, you should keep going and whenever you find an alternate path with smaller cost you should keep that instead.

When your stopping conditions are met you just return the best path up to that point.', u'Wouldn't the cost of any path in PQ1 or PQ2 always be less than the total cost of any solution since it's the sum of the two paths to a common point rather than just a leg like each of the elements of a PQ? In other words, it would behave just like a UCS with two independent points?

Basically, doesn't this just ensure that both sides search all the way to the other point before returning a solution?', u'Well, I finally passed the di-directional testing. I ended up needing to write a separate function for calculating the path cost of a combined solution. Then I kept the stopping condition where it stops once both of the search legs is at least as long as the combined solution (aka the top of both PQs reach the other side). Still unsure how this is more efficient than two separate UCS searches and simply taking the lower one.

Also, as long as our code passes the Romania test for bi and tri-directional tests, it should be okay in the Atlanta data, correct? I will try the Atlanta data of course once I finish the tri-directional code. Just wanted to make sure I didn't need to do robust testing with the Atlanta data and that it was more of a showcase for the tools we're developing.', u'There is no point in doing 2 separate UCS searches, since 1 would be enough (you find the optimal path). Bi-directional UCS has the advantage of being much faster (most of the times), as it reduces the amount of required exploration. 

If the code is correct, it will do well in the Atlanta graph as well! Test it and check the results.
']}]","Hi Minh,
Office hours today as normal -> https://hangouts.google.com/hangouts/_/4cvolw4cxzhpbo3qixnp36x4xme",0.0,149.0,431,,Office hours today?,[a2]
5ad7d45b0d63974e20c39171,"Hey Everyone,

My name is Chirag Tailor. I am one of Thad's former students, and for the past two semesters, have been working on a tool to make your life a little bit easier - the Piazza Automated Related Question Recommender (or PARQR, for short). PARQR is a tool designed from concepts learned in Thad's AI course with the aim to improve user experience on Piazza and make the information across thousands of posts more readily accessible. As a frequent user of Piazza while at Tech, I remember having a hard time finding posts pertinent to the issue I was facing on a homework assignment or related to a topic I had a question about. Often I would comb through dozen's of posts in the Piazza search before finding what I was looking for. We are working to develop a tool that is more effective than Piazza's default search and more user friendly.

PARQR works by recommending posts that are similar to the question you are currently typing. As you are in the process of typing out your question, PARQR analyzes your text and searches for similar questions in the course post history. The more you type, the better recommendations it will provide. Once it finds similar posts, it will provide links to them right under the summary of your post and color code them appropriately to show if the linked post has been answered by a student or instructor. The TA's have been using this tool for weeks, have found it extremely useful, and we think it can help you all as well. Here's how to get it up and running:Installation Instructions:
PARQR is available as a Chrome Extension, and after receiving numerous requests from students in last semester's AI course, we have also made it available as a Firefox Add-On.
Download PARQR as a Chrome Extension (https://goo.gl/TLoVUa) or as a Firefox Add-On (https://addons.mozilla.org/en-US/firefox/addon/parqr/). Click the 'Add To Chrome' or 'Add To Firefox' button.You should now see the PARQR Logo (a little tuxedo) on the top right of your browser.

Using PARQR
Close out all existing tabs and restart your browser.Visit Piazza and start a New Post.Start typing our your question for the class. As you type, PARQR will provide suggestions under the Summary bar of your post. The more you type, the better recommendations it will provide.To view one of the recommendations, simply click the link provided. It will open the recommendation in a new tab and preserve your original post in the existing tab.Posts are highlighted green if they have a student answer and yellow if they have an instructor answer present. Instructor answers take precedence.You do not need to post a question for PARQR to work! Please do not post a new question if you find a related one that answers it :).

A few things to note:
PARQR has reached a stable stage, but is still very much a work in progress.If you find any bugs, usability issues, or have feature requests, please leave us feedback at this Google Form: https://goo.gl/forms/GQckTje3niP0IU7G3. It is currently only available for a small set of classes, of which this class is one. We are working with other professors to make that a reality. If you would like for it to be available in one of your other classes, please let us know through the above Google Form.

The development of PARQR has been a collaborative effort between myself, Dr. Thad Starner, Dean Zvi Galil, and the CS6601 TAs. This semester, the development team has also expanded greatly to a group of Thad's current and former students. We hope that you find PARQR useful, leave us your feedback, and possibly join the development team in the future.

Regards,

PARQR Dev Team
Chirag Tailor, Girish Murali, Noah Bilgrien, Girish Mohandass, Abhishek Mangal
#pin",jc6w44hrp9v2ki,"[{u'text': u'Is it open source? I'll give it a try!', u'responses': [u'It is not open source at the moment, but we are looking into posting a video to explain how it works. Stay tuned! Thank you for giving it a try. We'd love your feedback on usability and general impressions!']}, {u'text': u'Why does it require permissions to edit data on my AWS sites?', u'responses': [u'Hey Nick! I believe that permission is poorly worded. We have our backend running on an AWS EC2 Instance that computes the recommendations. The extension needs permission to ping our REST API on AWS, but we do not have the ability to edit any of your AWS content. ']}, {u'text': u'Please help us test out this new tool!!  If it looks useful to y'all we'll keep pushing for wider adoption.', u'responses': [u'One problem I see with testing this tool is it only seems to run when posting a new topic. However, most of the time we are responding to existing posts such as under Assignment 3-Exercise 2. So, it is not entirely useful the way we are using Piazza. Be nice to have options to use in different ways. Please note, this isn't a criticism as this app is pretty impressive just pointing out that different classes uses Piazza in different ways which can change the way this is most effective.']}]",,0.0,320.0,432,,PARQR - A Piazza question recommender to save you time!,[parqr]
5ad7d45b0d63974e20c39172,"Are we allowed to re-use haversine formula in our euclidean distance heuristic?

I started off with the the standard euclidean distance formula - but that doesn't appear to work with the ATL graph.  The haversine formula does appear to work, however, and I would like to make sure that I'm not committing plagiarism by looking at existing implementations of a boilerplate piece of code...",jc6w44hrp9v2ki,"[{u'text': u'Good question. I was wondering about this too. I have used haversine in other classes but always have to look it up. Is this ok?', u'responses': []}]","Hi Mathew,We believe that the given search can be solved only by using the Euclidean heuristic. However, you are free to choose a different one if required. In that case please see to it that all the implementations work well producing desired outputs on Bonnie. Looking up at the documentation for an understanding of the code is fine. However, we strongly discourage copying code from sources. In this case, if the implementation of the heuristic function is difficult and necessary to your search algorithm, you may use the boilerplate code, but please reference it. We may excuse you for that heuristic function only if plagiarism is detected on your assignment. I hope this answers your question. ",0.0,158.0,433,,haversine formula,[a2]
5ad7d45b0d63974e20c39173,"Hello, im having trouble passing the bonnie test with breadth first search.  Not sure what the error is.  Upon using the unit test with start = 'a', and goal = 'u'

I then did 

romania = pickle.load(open('romania_graph.pickle', 'rb'))romania_test = ExplorableGraph(romania)romania_test.reset_search()

romania_test.neighbors('a') gives me ['s','z','t']

breadth_first_search(romania_test,start,goal) gives me ['a','s','f','b','u']

But in bonnie, i see a score of 0.  Can anybody help?  Or is my path completely off?",jc6w44hrp9v2ki,[],,0.0,154.0,435,"This is what I get when I run bfs on a - u:



You can run this same test in search_submission_tests.py using test_bfs if you change the start and goal to be a and u, respectively (not sure if they started that way).

You can run this test from the command line using:

python search_submission_tests.py TestBasicSearch.test_bfs

Note that it isn't so much about the exact path (because you may get that one right luckily while you are missing others) but about the nodes you are visiting and whether you are visiting them in the right order.    There's also a dependency that you employ the optimization that they discussed in the lecture.

Also look at @407 for some other hints (you can try searching on BFS to the left to see other discussions about this one).",not passing breadth first search,[a2]
5ad7d45b0d63974e20c39174,"{
      ""output"": {
        ""points_available"": 0,        .        .        .
      },
      ""description"": ""Test the improved tri-directional search against landmark search""
    },",jc6w44hrp9v2ki,[],,0.0,151.0,437,"It seems to mostly give you a feel for how well you do against a really good search (so you have an idea about how well you might do in the race - seems that the race will just be two points, so it has nothing to do with the race)

At least there seems to be no points associated with it.",what is this section? &#34;Test the improved tri-directional search against landmark search&#34;,[a2]
5ad7d45b0d63974e20c39175,"I'm implementing A*. When I try to compare the old f and the new f of a node in the frontier, a really weird error occurs. After this error occurs, the algorithms restarts and the h function is zero. I have no idea why this is happening. PLEASE HELP!!!
 
Error: Eobjc[5941]: Class FIFinderSyncExtensionHost is implemented in both /System/Library/PrivateFrameworks/FinderKit.framework/Versions/A/FinderKit (0x7fffa9f4cb68) and /System/Library/PrivateFrameworks/FileProvider.framework/OverrideBundles/FinderSyncCollaborationFileProviderOverride.bundle/Contents/MacOS/FinderSyncCollaborationFileProviderOverride (0x113451cd8). One of the two will be used. Which one is undefined.",jc6w44hrp9v2ki,[],,0.0,137.0,439,Solved - it was a type mismatch. Thanks.,A* Algorithm - Weird Error: Eobjc[5941]: Class FIFinderSyncExtensionHost is implemented in both,[a2]
5ad7d45b0d63974e20c39176,"My Bi-directional UCS keeps getting timed out on Bonnie.  The search works fine on my local set-up completing the Atlanta unit test (69581003 to 68177582) in ~180s.  I've decreased the number of O(N) computations to a minimum and am out of ideas on how to improve speed.

Anybody else facing a similar issue? 

Anybody have any tips on how to improve speed?",jc6w44hrp9v2ki,"[{u'text': u'I haven't run into time out issues myself. But I can think of multiple things that can improve your speed.

1. how do you handle remove in PriorityQueue? Are you going through the list to find the index and then remove it?
2. how do you put together the path once you terminate your search?
3. is your algorithm visiting too many nodes?

If i'm not mistaken, querying dictionary in python is an O(1) operation. So maybe you can think of ways to save your results in dictionaries as you do your search. 

you can always profile your code to see which portion is taking most of the runtime.

I just tried your src and dst in unit test, and it takes 12.125s.

Thanks
', u'responses': [u'Thank you for the tips!  Replaced explored nodes and weights/previous node lists with sets and it works much faster now.  Checking if x in list is much slower than checking if x in set.']}, {u'text': u'I noticed that too. I think it's impossible for a unidirectional UCS for large distances since it takes so much time. I guess the more basic algorithms are really impossibly inefficient for large distances (the same way even bi-directional is useless compare to Astar for even larger distances).

Make sure to check that your stopping condition is triggering by ensuring you know the maximum distance your algorithm should be searching and see if it is passing it. So say a UCS would search 1 mile for a optimal path. Astar would search 1 mile with ~a quarter the nodes explored. Bidirectional UCS would search 0.5 miles with ~half the nodes of UCS. Bidirectional Astar would search 0.5 miles with far fewer nodes than any of the other algorithms so far... ect...', u'responses': [u'Thank you, Minh.  In my case, the delay was due to too many list operations.  Replaced my lists with sets/dict and it worked much faster.']}]",,0.0,141.0,440,"The only time I ever encountered a timeout error was when I had a non-terminating loop. When checking for your end condition are you *sure* there are no cases where you'd spin forever?It can be helpful to try all combinations of nodes on the Romania data - as its much quicker to load and go through all the cases.

FIXED:  Replaced explored nodes and weights/previous node lists with sets and it works much faster now.  Checking (if x in list) is much slower than checking (if x in set).",Timeout on Bonnie,[a2]
5ad7d45c0d63974e20c39177,"Hey everyone. For the warm ups, I'm currently passing all the unit tests locally but I got 0 points on everything except the PriorityQueue when using submit.py.

Has anyone run into something similar or know why this might be? 
",jc6w44hrp9v2ki,[],,0.0,150.0,441,"I asked the question earlier and am following up as I got it resolved -- for me, the issue was my return format was not correct for some of the edge cases

Also check out: https://docs.google.com/document/d/1hykYneVoV_JbwBjVz9ayFTA6Yr3pgw6JBvzrCgM0vyY/pub ",Passing unit tests locally but not getting any points on Bonnie,[a2]
5ad7d45c0d63974e20c39178,"For UCS in warm up, can we use graph.neighbors to get neighbors of a node?  ",jc6w44hrp9v2ki,[],,0.0,146.0,442,Yes,Uniform cost search,[a2]
5ad7d45c0d63974e20c39179,"I spent more hours in Assignment 1 than Assignment 2. But I couldn't get full points on assignment 1 whereas I hit full on the second assignment. I felt the Search assignment should be the first one for this course. The code implementations and material makes the second assignment more intuitive and better to start a course. The minimax/alpha beta assignment could be a natural progression from search. However, I want to know if other's in the class feel the same:

Which assignment you found easier and more intuitive :
 [o] Assignment 1
[o] Assignment 2",jc6w44hrp9v2ki,"[{u'text': u'I found Assignment 1 harder than Assignment 2, but I don't see how that should be considered in the ordering of assignments unless you think that you learned something in this assignment that would have helped you with the prior assignment.  Nothing like that comes to mind for me.', u'responses': [u'Iterative Deepening was core of assignment 1 which could have been covered beforehand with Ch 3. Also, I think assignment 2 start of course would have given the non-python or non-coders a good workout before entering recursive function calls of alpha-beta. Though I may be incorrect, but I feel first assignment should be relatively easier than what it was.', u'This is all going to be opinions and we all have them.  I'm not trying to dismiss yours, but I do disagree somewhat.   There's nothing I've learned in this assignment that would have helped with assignment 1 (I didn't use any iterative deepening in this assignment nor is anything I did in this assignment what I would call iterative deepening).  

Yes, the python coding seemed to be more complex with assignment 1 (especially dealing with the randomness injected in the gaming simulator).  However being comfortable with Python is listed as a prerequisite for the course, so coding is expected to not be an issue.  And I'd have to say that we all probably are doing better with the programming on this assignment due to the experience we gained in the first assignment. ', u'There are many things that I learned from the first project that helped with the second project, and for all of them it would have helped if the projects were reordered. 

- Getting used to Bonnie is distracting enough, but limited runs to every two hours and introducing non-deterministic tests made using Bonnie on the first assignment significantly harder.
- Getting used to a new workflow and new expectations in a new course is also work. This course could not be more different than the last course I took
- Figuring out how much external research is needed was a new challenge

It's not that the topics point to a particular order, but that the conceptually easier project first would give people time to learn and adjust to the other expectations in the course. I've taught for five years and I was pretty baffled by the project order and am honestly curious about why they're ordered this way. Is it to encourage people to withdraw early? Or because of how much the professor likes the topic of gameplay? maybe it's because that's the way the book is ordered? The course is really thoughtfully constructed so I'm sure there is a reason but it's not obvious to me at this point in the course.']}]",,0.0,222.0,443,,Difficulty Level,"[a1, a2, polls]"
5ad7d45c0d63974e20c3917a,"I am getting the following error on submission
{    ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_ywvfgqdm bash -c \\\""cd /home/vmuser_ywvfgqdm; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_2 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""\"", \""stderr\"": \""bash: line 1:    28 Killed                  python run.py assignment_2 > run_stdout.txt 2> run_stderr.txt\\n\""

The code is compiling and executing in my system.Any idea what can be implication of the error.",jc6w44hrp9v2ki,[],,0.0,149.0,444,If you're getting killed with return code 137 -- which many people ran into with Assignment 1 -- it seems to be caused by running out of memory.   Perhaps you are storing too much data or getting stuck in an infinite loop that is endlessly adding data to one of your data structures.  Total guess.,Error on Submission,[a2]
5ad7d45c0d63974e20c3917b,can someone post A Star A to U plot. I am still struggling with A Star though my search results are often coming correct. I want to use that for a reference to understand if I am exploring more nodes than needed. My plot is here.,jc6w44hrp9v2ki,"[{u'text': u'Thanks for help. I found that my calculation of function f() was wrong because I was not considering previous nodes. Finally it could get full mark in Bonnie for A* but it took my kind of whole week and no time left do do other Exercises.

I think if there was no Piazza, people like me who have no one to discuss questions would have scored nothing bug zero.', u'responses': [u'
Well... there's Slack , channel #cs6601 on https://omscs-study.slack.com/ (use your @gatech.edu email to register). Not an official forum, obviously has the same no code, only discuss ideas policies, but still useful for many.
']}]",,0.0,161.0,445,"This is what I have for unidirectional A* for 'a', 'u':

",A Star : A to U Search Plot,[a2]
5ad7d45c0d63974e20c3917c,"I see from the syllabus that the midterm exam will be made available from March 5-11. Will students be able to access the exam during that entire time period (such as accessing it on the 5th and then submitting it on the 11th)?

Or will you have some time limit during that window in which to complete the exam, such as choosing to access it on the 5th and then having 48 hours to submit it?",jc6w44hrp9v2ki,"[{u'text': u'I have never given a take away test?
What is the midterm/final term exam exactly like?
Is it an objective/subjective/programming test?
Submit any number of times means, is it a code based exam?', u'responses': [u'@586
', u'They've said that challenge questions give a good sense of what the exam questions will be like, so start there. 

Because we have more time to think, research, and work through the solutions, they will likely be more in depth questions than they would if it were a proctored, short test. They'll likely take a concept we've covered and ask us to apply it and maybe extend it. It's not so much recall or memorization, but a test of whether you really understand the concepts. I'm focusing my studying time on making sure I understand the core ideas of the material and doing challenge questions, and that I know where to find things in the text and papers when taking the test.']}]",You have the whole period for the midterm. You can submit any number of times during that period as well.,0.0,226.0,446,,Will the Midterm/Final Have a Time Limit?,[midterm]
5ad7d45c0d63974e20c3917d,My function  a_star passed all the test cases in search_unit_tests.py but is evaluated as zero score in submission . Is there any thing I am missing in submission format,jc6w44hrp9v2ki,"[{u'text': u'Make sure you're handling cases of identical goals as noted in the instructions.', u'responses': []}, {u'text': u'Probably failing the null heuristic.', u'responses': []}, {u'text': u'probably a check that start is equal to goal. remember ""If your start and goal are the same then just return []""', u'responses': []}]",,0.0,193.0,447,Submission is *only* your search_submission.py file.   The json file returned should give you some ideas about what to look at for why you got zero points.,Zero Score for A*,[a1]
5ad7d45c0d63974e20c3917e,"Hello, 

Running submit.py seems to be working well, but I am getting 0's for all the tests. This is happening even for the ""Test the student printed their name"" test. The local tests via search_submission_tests.py work fine. Has anyone ran into this issue or have any suggestions?

Thank you, Juan",jc6w44hrp9v2ki,"[{u'text': u'What does the returned json file say', u'responses': []}, {u'text': u'Are you making all of your changes in exactly one file:  search_submission.py?  ', u'responses': []}, {u'text': u'Hi Willie,Conor, 

Thank you for your help. I followed Willie's recommendation (look at result json) and found that there was an import that did not resolve on the server (from explorable_graph import ExplorableGraph). I was playing with this object early on. It seems that this library, although available in the assignment's GitHub repo, is not available in the Bonnie env. After removing the reference I am seeing the expected results. 

Thank you again,
Juan', u'responses': []}]",marking resolved as per the discussions below.,0.0,170.0,448,,Bonnie submission not returning scores,[a2]
5ad7d45c0d63974e20c3917f,"Instructors,

Going over the Midterm Topic List, I see that Random Algorithms (Simulated Annealing, Beam Search, Hill Climbing, etc) and Constraint Satisfaction are on the list. I also see that Search is on the list, in particular Tridirectional Search, along with Adversarial Search that contains Mulitplayer games and Probabilistic Games.

My question is in regard to priority and what we should spend our time on. How much of the midterm will focus on subjects covered by readings and lesson videos vs what our projects have focused on (Minimax, Alpha-Beta Pruning, Search, and coming up, Bayes Nets Sampling and Decision Trees)? Should we focus on subjects covered only by the Challenge Questions and Projects, as an indicator of what will be on the midterm?

Regards",jc6w44hrp9v2ki,[],"Videos and Readings will get you familiar with the material. Challenge Questions will give you an idea of what will be on the midterm.
Projects cover only specific topics, so don't be tricked into thinking that these topics are the most significant. Almost every major topic is going to be tested.",0.0,235.0,449,,Midterm Topic List - Question on Priority,[midterm]
5ad7d45d0d63974e20c39180,"If there is anyone in the Miami area or close by (Ft. Lauderdale, Weston, Davie, Sunrise, Miami, etc.) interested in getting together to study, please let me know.",jc6w44hrp9v2ki,"[{u'text': u'Good idea, I'm in Miami, too. West Kendall. I'm in slack (@hgcode). 

-H', u'responses': []}]",,1.0,134.0,451,,"Study group - Miami, FL area",[group_study]
5ad7d45d0d63974e20c39181,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.


HILL CLIMBING

You are building an AI agent that can pass as an art critic. Your agent analyzes images of what it sees and critiques them. As a starting point, you decide to find the pixel with the highest value in an image. A pixel's value is defined as the sum of squares of its RGB components. Each component is a value in the range [0, 255].

1. You try hill climbing. Your agent starts at the top left of the image and goes through it pixel by pixel, left to right, top to down, flattening the image into a 1D array. It sees the following RGB values (starting at [22, 98, 75]). Using the column on the left, check which pixel is returned by hill climbing if it encounters these values?



2. Will this approach help you find the brightest pixel in the image? If not, how would you proceed to achieve that?


Solution: @544. Also see Saalis' answer below.",jc6w44hrp9v2ki,"[{u'text': u'Not quite sure I completely understand the question, but here are my thoughts:
1. Hill climbing will return the row (230,230,230). 
2. This linear scan algorithm will find the brightest pixel in the image, but with high computation complexity O(n2). For large n, I would consider other global search method such as simulated annealing. In my field, we actually use a brutal force method but took advantage of the smoothness of an image. It goes like this, scan every 2m pixels (m depends on the size of the picture, say m = 4), find the brightest pixel, form a smaller region around that brightest pixel and search every 2m-1, and so on till search 1 pixel. It forms an oct-tree type of mesh so complexity is much less. It fails when the picture is not smooth. Haven't seen this algorithm in AI text book yet, guess in AI field the search space is seldom smooth. ', u'responses': [u'I think hill climbing will get stuck before 140,70,210 (as sum of squared pixel values of 150 80 200 are greater)and will never reach 230 230 230.... We will need a random restart or annealing to overcome this.', u'That's right, if hill climbing looks one step around, the return value is 140,70,210. ', u'@Saalis is right! So what would this algorithm return and how would you answer 2.? ']}, {u'text': u' RGBSUM SquaresDelta22987515713 2210090185842871651008421281269710067902258913081206018752969303801508020068900159311407021068600-300230230230158700901009520014570050-8865015319721410801437964', u'responses': []}]",,1.0,254.0,452,,Challenge Question 7 - Optimization Algorithms,"[lesson3, challengeqtns]"
5ad7d45d0d63974e20c39182,I have submitted assignment 2 with submit script but forgot to complete it on t-square. Just realized after passing 7AM EST. Does this mean I will not get any points for this assignment?  Thank you for your help.,jc6w44hrp9v2ki,"[{u'text': u'could you give me steps to upload on T - Square ?', u'responses': [u'Kind of late now, but go to T-Square.  Select the class tab, select the assignments page, select assignment 2, then you will be able to add a document/file, upload it and submit', u'Yes, I can not upload now. However how does it impact my grades if do not upload files on T-square? I had already submitted them on bonnie for grading.', u'Word has been that it's a backup, that if everything is OK you probably won't have an issue.   That was said in the context of the first assignment, though, so I don't know if it's any different moving forward.', u'Ok, hopefully my bonnie submission doesn't have an issue.. I forgot to submit on t-square too..']}]",,0.0,204.0,454,I am pretty sure you are okay. They announced this at the last minute as well as it is meant as a backup so unless Bonnie crashes and your stuff isn't retrievable then you should be fine.,Assignment 2 submission,[a2]
5ad7d45d0d63974e20c39183,"Okay, since we are doing probability I'd like to throw out my two favorite probability puzzles out as my own personal challenge question.

One, commonly known as the Monty Hall paradox. Basically the question is as follows.

You have three doors and behind one door is a large prize and the other doors contain junk. You are asked to choose a door.
Let's say you choose door #1.
Then it is revealed that there is junk behind door #2. 
Now you have the choice, stick with door #1 or switch to door #3. What should you do?

My other favorite is the boy, girl paradox.
Mrs. Smith has two children. One of the children is a boy. What is the probability that the other one is a boy?

As you can guess these aren't the intuitive answer and that is my only hint. Have fun and don't cheat by looking on the internet!",jc6w44hrp9v2ki,"[{u'text': u'Coding a simulation to answer the Monty Hall problem (with help from my uncle) was my very first taste-or and intro-to coding!! Been coding since!

Thanks for the share, Brett!', u'responses': [u'I couldn't believe the answer when I first learned about that problem and had to code my own simulator to see with my own code that same result. Now the answer seems so obvious!', u'So what about the boy girl paradox? ', u'Also, if you read the history of the Monty Hall problem, there were professors, mathematicians and statisticians saying that the article publisher was wrong. Marilyn Vos Savant, the publisher, had to post a proof before they agreed with her.', u'I recall reading this nasty letter from this military statistician just brazenly attacking her. I wonder what it was like for the stats community during that month..', u'For the boy-girl paradox, I'm going to guess the answer is 50%?

I must say though, I almost always get these wrong... Haha.', u'Unless they're twins?!!??!! Haha! Looking forward to the answer. I will hold off on googling the answer for a few days.']}, {u'text': u'I think the boy/girl problem is underspecified by OP. Since the two probabilities are independent as written, I can't see any reason why it wouldn't be 50%, unless you factor in the very small rate of identical twins/triplets/etc, which would bump it up a little over 50%. Unless I'm missing something? I googled it and found these two examples of its formulation, which seem more interesting to me:  Mr. Jones has two children. The older child is a girl. What is the probability that both children are girls?
 Ms. Smith has two children. At least one of them is a boy. What is the probability that both children are boys?

Note that the phrasing of the questions matters a lot here, and subtly changing the wording changes the probabilities you find. Seems like part of the skill here is paying attention to the assumptions you're making based on the wording.', u'responses': [u'The second problem is the same as my first problem.
By saying one is a boy I haven't told you which position, or whether he is older or not. 
So, my combinations is:
boy, boy
boy, girl
girl, boy 
girl girl
By saying one is a boy all I have eliminated is the last one which leaves me with:
boy, boy
boy, girl
girl, boy
So, the chance the other one is a boy is only 33%.  This is the same as your SECOND question above. Your first question is 50/50.

So again, if I had specified the oldest or younges was a boy then it would be 50/50 but since I didn't specify then it is only 33%.
If this seems hard to believe think of it the same with coins and I tell you I flipped a coin twice and that one of the coin tosses was heads.  What is the probability the other is heads. 
']}]",,1.0,192.0,455,,My favorite probability puzzles,"[lesson5, challengeqtns]"
5ad7d45d0d63974e20c39184,"I know we spend most hours of this course on the programming assignments, but going through the text book today, I found a lot of interesting puzzles that can be solved using the concepts learned already.

Two of them are listed below:
======= On Search Topics / Constraint Satisfaction ======

1. The Missionary Problem:

 Three missionaries and three cannibals must cross a river using a boat which can carry at most two people, under the constraint that, for both banks, if there are missionaries present on the bank, they cannot be outnumbered by cannibals (if they were, the cannibals would eat the missionaries). The boat cannot cross the river by itself with no people on board. Device a sequence of actions to achieve the goal

I can easily solve this using Breadth-First search. Was wondering if we can define some heuristics for this problem, and use some of the local search problems like Hill-Climbing? Thinking of using the number of men on the first side of the river, f, as the heuristic

2. The Zebra Puzzle (Exercise 6.7): On Constraint Satisfaction Problem

In five houses, each with a different color, live fivepersons of different nationalities, each of whom prefers a different brand of candy, a differentdrink, and a different pet. Given the following facts, the questions to answer are “Where doesthe zebra live, and in which house do they drink water?”

The Englishman lives in the red house.The Spaniard owns the dog.The Norwegian lives in the first house on the left.The green house is immediately to the right of the ivory house.The man who eats Hershey bars lives in the house next to the man with the fox.Kit Kats are eaten in the yellow house.The Norwegian lives next to the blue house.The Smarties eater owns snails.The Snickers eater drinks orange juice.The Ukrainian drinks tea.The Japanese eats Milky Ways.Kit Kats are eaten in a house next to the house where the horse is kept.Coffee is drunk in the green house.Milk is drunk in the middle house.Discuss different representations of this problem as a CSP. Why would one prefer one representationover another?

-- I'm still reading on Constraint satisfaction Problems, so I'm yet to understand how to tackle. But would like to hear how others would tackle it.




",jc6w44hrp9v2ki,[],,0.0,178.0,457,,Interesting Exercises from the Text Book,[challengeqtns]
5ad7d45e0d63974e20c39185,"This week you should watch Lesson 5, Probability, and read Chapter 13 in AIMA (Russell & Norvig).

Please sign up for Gradescope if you haven’t already! Please check out @287. Students who do not sign up might not be able to hand in their midterm. Please inform your friends/study partners if they haven’t signed up already! 

Assignment 3:  Bayes Nets Sampling
Due: February 25 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 3 will soon be released, and the link to the repo and description will be posted on Piazza.
 Here are the OH calendar, the syllabus and the schedule.   
",jc6w44hrp9v2ki,"[{u'text': u'Heads up: There are 46 Bayes Nets videos, and they're on next week's list. One week sure doesn't sound like enough time to get through the videos, reading material, and assignment...

I'm already having a hard enough time completing the assignments when the content is scheduled before the assignment is released. I'll be starting the Bayes Nets content this week, not next. I'd suggest adjusting the schedule of lessons in the future, unless Assignment 3 is super easy. :) ', u'responses': [u'Lesson 5 is pretty short, mostly quizzes on probability. I'm planning on starting next week's lectures early too. I have to agree, this class is tough, but we can try our best!', u'Lesson 6 is no joke.

If you get out paper and pencil and take all the quizzes as you watch, it might take hours to do half (through lesson 23), which I just did.

""... and I really hope you understand - in depth - how Bayes networks work.""Sorry to let you down, Dr Thrun!', u'So, this class is graded pretty much like all the classes I have taken thus far. Typically a curve where half get As and then a another 33% B's and down from there. However, because it is VERY hard to get a good grade on assignments and I assume the exam, people end up spending way extra hours trying to get the higher grade which brings up the average. This is my 8th class and hands down I have probably spent twice the number of hours than I have in any other class. I have all A's up to this point too. I went in knowing this class was going to be difficult and believe at moment I am on my road to an A here as well but I suspect it will continue to be a ton of work and at some point due to personal situations I might not do as well. However, it is what it is and it is one reason why a Masters at Georgia Tech is worth alot. The other class (Machine Learning) for my specialty is apparently equally hard. The generic specialty has Graduate Algorithms which is also supposed to be really hard. 
So, my goal is to get through this class hopefully getting that A but at least getting a B then finish up my degree with something not as hard. I do wish they would make the class easier but it is so hard partially as we make it this hard. Meaning we all put in all these extra hours to pull out as many points as we can on the assignments. If we all did less work then the curve would be for a lesser grade and the distribution would still be exactly where it is. As long as people put in these hours to get it done, then you will have to do the same to stay in the right range.
With that all said, keep in mind HALF the class will get an A. And another third or more will get a B. So, you only have to be in the top 83% or so to get an A or B. This should be something realistic.
', u'Good points. I know the grade distribution will help a lot on the projects, and I'm perfectly fine with challenging projects. I expected nothing less with this course!

My main point is that if you follow the schedule, you'll be in a really tight spot with assignment 3. It's not a huge deal to work ahead as needed. I just think future students would welcome the heads up and extra time to digest the content before jumping in to the assignment.']}]",,0.0,257.0,459,,Week 6 Announcement,"[announcements, gradescope]"
5ad7d45e0d63974e20c39186,"Hi everyone.

Assigment 3 is now released and active on Bonnie. The git repo is here.
Please read the readme carefully.

The assignment is due on Bonnie and T-Square by February 25th 2018, 11:59pm UTC-12 (Anywhere on earth). The submission on T-Square is a backup just in case, and the submission to Bonnie will be officially used for grading.

Important: There is a TOTAL submission limit of 5 on Bonnie for assignment 3. 

This means you can submit to Bonnie a maximum of 5 times during the duration of the assignment. Please use your submissions carefully and do not submit until you have thoroughly tested your code locally.

If you're at 4 submissions, use your fifth/last submission wisely. We are not responsible for a final submission that gets a lower score than a previous submission. We will only use your LAST submission before the deadline for grading.

There will be a separate post soon about a Youtube live event going over Assignment 3.

Good luck!

",jc6w44hrp9v2ki,"[{u'text': u'May I ask what's the reason behind this total submission limit for this assignment? is it designed as part of the challenge? Is this assignment that special?', u'responses': [u'During office hours, I think a TA mentioned that it as because on this assignment, if you kept submitting you could deduce the correct answers without programming a working solution.']}, {u'text': u'There goes my brute forcing Bonnie approach to testing...yikes.', u'responses': []}, {u'text': u'Just glimpsing at assignment at moment so have read in depth but did notice that the PDF doesn't match the read me in that the PDF mentions 1a to 1c and 2a to 2e but the Readme also includes a 2f. Also, the PDF says it is due in October 2017. Also, the PDF isn't referenced in the readme. Is the PDF not updated yet for this class?', u'responses': [u'I apologize about the PDF. All the relevant and updated information needed for the assignment is in the Readme.', u'NO worries, just wanted to make sure. So, don't look at the PDF.', u'I would, it has some good resources for the sampling phase. You'll need web archive for one of the papers at least, though', u'running inference on P(T=true) should return 0.19999994 (i.e. almost 20%) , is this information in Readme correct??? A lot of people are getting close to 24%....']}, {u'text': u'
You may get an error in PyCharm when submitting this assignment.  Just add a parameter ""assignment_3"" (without the quotes) using the Edit Configurations dialog... see below.  After that the submission should work.

', u'responses': [u'I hope you aren't already submitting!!', u'
I did... but if it's any consolation I am repeating this class.  :)']}]",,0.0,335.0,463,,Assignment 3 Released,[a3]
5ad7d45e0d63974e20c39187,"This is the discussion post for Assignment 3 Part 1: Bayesian Network.

",jc6w44hrp9v2ki,"[{u'text': u'Am facing this issue while doing a dry run with probability_tests.py- ""as is"". I am using pycharm, python 2.7. I would expect to see ""NotImplementedError"".  What am I missing?


C:\Users\COMP\PycharmProjects\untitled\venv\Scripts\python.exe C:/Users/COMP/Desktop/user01/git_root/cs6601-a03/probability_tests.pyTraceback (most recent call last): File ""C:/Users/COMP/Desktop/user01/git_root/cs6601-a03/probability_tests.py"", line 2, in <module> from probability_solution import * File ""C:\Users\COMP\Desktop\user01\git_root\cs6601-a03\probability_solution.py"", line 8, in <module> inferenceExample() File ""pbnt/combined\exampleinference.py"", line 66, in inferenceExample Q = engine.marginal(sprinkler)[0] File ""pbnt/combined\Inference.py"", line 262, in marginal self.global_propagation() File ""pbnt/combined\Inference.py"", line 292, in global_propagation self.collect_evidence(0, startClique, 0, True) File ""pbnt/combined\Inference.py"", line 302, in collect_evidence self.collect_evidence(currentClique, neighbor, sep, 0) File ""pbnt/combined\Inference.py"", line 302, in collect_evidence self.collect_evidence(currentClique, neighbor, sep, 0) File ""pbnt/combined\Inference.py"", line 306, in collect_evidence self.pass_message(currentClique, prevClique, sepset) File ""pbnt/combined\Inference.py"", line 320, in pass_message oldSepsetPotential = self.project(fromClique, sepset) File ""pbnt/combined\Inference.py"", line 329, in project sepset.potential = clique.potential.marginalize(sepset.potential) File ""pbnt/combined\Distribution.py"", line 69, in marginalize index = self.generate_index_node(seq, intersect) File ""pbnt/combined\Distribution.py"", line 98, in generate_index_node return self.generate_index(index, axes) File ""pbnt/combined\Distribution.py"", line 110, in generate_index tmp[axis] = indexValueError: shape mismatch: value array of shape (3,) could not be broadcast to indexing result of shape (2,)', u'responses': [u'Wrong version of numpy is the cause of this. Setting up a virtual environment to satisfy all the requirements is working well to get around it. Anaconda is pretty great for managing differing requirements.', u'Thanks', u'Thanks @Jim!  I had this and was able to swap out my version of numpy for the older one requested by the assignment:
% sudo pip uninstall numpy
% sudo pip install -I numpy==1.11
after which it ran cleanly.

(I only use python on this particular env for this class, so the global change was not a concern)', u'I am using PyCharm.  I ran the pip commands suggested above from the command line and got successfully uninstalled numpy 1.13 and successfully 1.11 nstalled messages, but still got the errors afterward.

I was able to fix it by going to PyCharm File --> Settings then going to Project: assignment_3 --> Project Interpreter and installing the specific version of numpy there.

Incidentally, the Project Interpreter was showing that I had numpy 1.14 installed even though the command line said it had uninstalled 1.13 and installed 1.11.
Maybe someone else can explain why the versions don't match, but in the end I can now run the exampleinference as suggested in the readme.', u'also can try pip install -user numpy==1.11', u'Thank you!!', u'^^ thank you as well', u'Thanks!', u'Thank you ~!!', u'This was not listed in the setup.md file.', u'thanks!']}, {u'text': u'I see the below assertion error when running 1C using the sample code provided in the assignment 3 readme. Both by unit tests for 1A and 1B pass without errors. Is the below indicative of a misconfiguration in steps 1A and 1B:

""AssertionError: Attempt to Multiply Potential with incompatible type: Discrete or Conditional""

F_A_node = bayes_net.get_node_by_name('faulty alarm')
engine = JunctionTreeEngine(bayes_net)
Q = engine.marginal(F_A_node)[0]
index = Q.generate_index([True],range(Q.nDims))
prob = Q[index]
', u'responses': [u'resolved this issue after going back and changing parent and child links in 1a. It appears it needs to be defined correctly for 1c to work.']}, {u'text': u'Anyone know how to fix this error?
----------------------------------------------------------------------Traceback (most recent call last): File ""C:/Users/Dawn/Desktop/AI_course/assignment_3/probability_tests.py"", line 23, in test_probability_setup power_plant = set_probability(make_power_plant_net()) File ""probability_solution.py"", line 68, in set_probability F_A_dist = DiscreteDistribution(F_A_node) File ""pbnt/combined\Distribution.py"", line 319, in __init__ self.table = zeros([node.size()], dtype=float32)AttributeError: 'NoneType' object has no attribute 'size'', u'responses': [u'node is originally defined as node = []

Did you append the nodes you created?', u'I just figured out that it was a silly,silly mistake of flipping the 'au' in my spelling of faulty... thanks for responding! ', u'Don't talk about guage :-)']}, {u'text': u'Can we get some information on what these three parameters are in 1c: alarm_rings, gauge_hot, temp_hot? There isn't any documentation on them.', u'responses': [u'Those parameters are booleans True or False for the variable in question. So if alarm_rings is True, get_alarm_prob should return the probability that alarm is true', u'Thanks Mansoo!', u'Whoa, thanks, I totally missed this! I thought they were the string names of the nodes and added default values to them.', u'Well wait a minute Sasha, that answer doesn't make much sense Mansoo, as how would you need to return a probability that alarm rings when you're given a Boolean saying that alarm definitely rings or does not ring? Or a probability that gauge is hot when you're given a Boolean that says whether gauge is hot? Or a probability that temperature is hot when you're given a Boolean that says whether temperature is hot? The probability would be 0 or 1 according to the value of the Boolean, False or True respectively.', u'It is telling you which probability you want to return.  If alarm_rings is True, you return the probability that it is true.  If it s false, you return the probability that it is false.  Essentially the parameter controls which probability you return.', u'That's a possible interpretation of what Mansoo said, indeed, although as ever, rather under-specified :-)

Incidentally, of course Bonnie doesn't – or didn't, there's a chance that the goalposts may be being moved behind the scenes, without a public discussion in view of the fact that it could be affecting the submission limit – test that parameter']}, {u'text': u'Can someone explain to me if this requirement is correct from 1b?

The alarm responds correctly to the gauge 55% of the time when the alarm is faulty, and it responds correctly to the gauge 90% of the time when the alarm is not faulty. For instance, when it is faulty, the alarm sounds 55% of the time that the gauge is ""hot"" and remains silent 55% of the time that the gauge is ""normal.""

Why is 55% for both gauge faulty and normal? it shouldn't be 55% and 45%?
', u'responses': [u'Yes. It’s correct. Writing out truth tables for all probabilities can help visualize it. ', u'Normal in this case is not the opposite of faulty, it’s the opposite of hot. ', u'Just curious if for this parameter is one of the probabilities meant to be calculated? Since this would be a 3 variable relationship.', u'not sure that my understanding is correct, but I think yes, we need to calculate but it's just inversion, it's 3 variables relationship -  for 2 cases out of 4 we have numbers and the example gives a hint how to get values for the rest 2.', u'Alex, are you referring to the examples in the lectures?']}, {u'text': u'out of curiosity: are any formal approaches in designing a Bayesian network, for ex like it with classes/objects design or it is kinda 'art'? I mean a way to move from textual description to actual model.

Thanks
Alex', u'responses': [u'Causality or correlations (even if not particularly strong or proven) are easier to translate into a model, meaning , easier for our protein-based CPUs to reason about. As Bayes rule gives you the freedom to switch variables around and get a ""response"", whatever you can more easily get evidence/sensing data from is a better candidate to craft the network.

What is easier to gather data around, that weather affects traffic (stuff falling from the sky, yes or no? direct impact on visibility and road condition) or that traffic changes weather (dense enough traffic with hight heat and CO2 emissions affecting micro-weather on top of a busy highway intersection with little to nothing air circulation? the model might be difficult to translate to a tropical forest...)']}, {u'text': u'For part 1 does Bonnie test that the actual probabilities and network structure is correct or does it perform the same tests as the unit tests, essentially checking the dimensions?Bonnie tells me that my structure and probabilities are correct and that my marginal gauge is correct but not my marginal alarm. I’m calculating the marginal alarm exactly the same way as the marginal gauge, and if the inputs are all correct, per the above Bonnie feedback, I’m not sure how to reconcile these errors. Edit: when I run the code with enumeration engine rather than junction tree I get the correct answer. Is this acceptable?', u'responses': []}, {u'text': u'Has Anybody tried to run sanity check for the inference? 
P(T=true) should return 0.19999994 (i.e. almost 20%), I'm receiving ~24%, I double checked my code but I don't see a bug, has Anybody received something similar?', u'responses': [u'I am also getting 0.244318.... can anyone confirm this?', u'Do note that ""get_temperature_prob"" is conditional probability and naturally will not be the same as P(T=true). To test P(T=true) you should run your own test seperately. ', u'I get .2 exactly.

Edit: Oh, when I run P(T=true) I get .2.

When I run P(T=true|FA=false,FG=false,A=true) I get 0.244318 too', u'yeah, i figured that out', u'thanks', u'Should we be getting exactly 0.19999994 ? i'm getting 0.19999997', u'Somehow when I run the conditional I get 0.050000001, could something be wrong with my network? Gauge itself shouldn’t be part of the evidence right?', u'I get .2 exactly', u'So, does getting a .2 mean we're insane?', u'Thank you all for providing clarity on this! I assumed the README was helping us test one of the functions for 1c, so I spent way too long trying to figure out what I was doing wrong. On the bright side, I calculated get_alarm_prob by hand, which was a tedious but instructive exercise.

And to Austin, Gauge is not part of the evidence in this case. In the terminology of the book, Gauge would be a hidden variable.', u'Thanks Donovan! I think I am calculating my unknown probabilities incorrectly and that is leading to the seemingly odd value.', u'Austin, did you figure out how to complete the probability tables from part 1b?', u'I also get 0.2 exactly which makes logical sense to me as P(T=True) is something we were given and coded directly. Interestingly assertEqual does not pass, returning the amusing error message ""AssertionError: 0.2 != 0.2"", unless 0.2 is converted to numpy's float32.', u'Daniel, no I haven't been able to figure them out yet. I am not sure what resource to use to find out how to do it. I have watched videos and read book, but I still seem to be stuck.
', u'I am getting 0.0593036 for P(T=true|FA=false,FG=false,A=true) . Any idea what have been wrong?', u'Finally fixed the bugs and got the score.  @Kai Xin Thia comment was most helpful. I was banging my head why conditional probability is not .2.
', u'I am also getting similar answer for P(T=true|FA=false,FG=false,A=true) = 0.050000008  but getting P(T=True) = 0.2.  I am trying to do this by hand and having trouble even getting the same answer as my network.  Sudharshan, what were some of the bugs you needed to fix?']}, {u'text': u'In 1.c, get_{value}_prob functions, what is the second parameter for?

Should I use the second parameter to return of the probability when {value} is T/F?

The function description only seems to be required to return when {value} is T', u'responses': [u'Those parameters are booleans True or False for the variable in question. So if alarm_rings is True, get_alarm_prob should return the probability that alarm is true.']}, {u'text': u'Having trouble setting a unconditional probability. Anyone know why this is happening?

---------------------------------------------------
Traceback (most recent call last):  File ""probability_tests.py"", line 24, in test_probability_setup    power_plant = set_probability(make_power_plant_net())  File ""/vagrant/probability_solution.py"", line 77, in set_probability    f_a_distro[f_a_d_index] = [.85, .15]  File ""pbnt/combined/Distribution.py"", line 153, in __setitem__    exec(""self.table[""+index+""]="" + repr(value))  File ""<string>"", line 1, in <module>ValueError: cannot copy sequence with size 2 to array axis with dimension 0', u'responses': [u'Guys from slack where able to help me. I was initializing the BayesNode second parameter based on inputs to the node, not the possible values for the node.', u'check your f_a_node in first question to see did you assign 2 values to this node.']}, {u'text': u'I'm trying to test get_temperature_probability locally as I lost points for it when I ran on Bonnie (passed everything else in part 1) but I keep getting an error:

ErrorTraceback (most recent call last): File ""probability_tests.py"", line 77, in test_temp_prob print get_temperature_prob(power_plant, True) File ""probability_solution.py"", line 124, in get_temperature_prob engine = JunctionTreeEngine(bayes_net) File ""pbnt/combined/Inference.py"", line 218, in __init__ self.joinTree = self.build_join_tree(triangulatedGraph) File ""pbnt/combined/Inference.py"", line 363, in build_join_tree tree.init_clique_potentials(self.bnet.nodes) File ""pbnt/combined/Graph.py"", line 246, in init_clique_potentials clique.init_potential(v) File ""pbnt/combined/Node.py"", line 181, in init_potential self.potential *= node.distAttributeError: BayesNode instance has no attribute 'dist'

However, since everything else passed on Bonnie, I have a feeling that it is something wrong with my local setup and not the set up of the network or anything like that.  I'm running from PyCharm if it makes a difference.  Has anyone else seen this error and fixed it?', u'responses': [u'In my case, the error message meant the node is None or null. Try to check initialization of the net again.', u'Any luck here? I'm running into the same thing and am a little stumped.', u'Not sure if this is resolved, but I saw something similar when I had a comma instead of a period for something like ""A.dist.table""
in ""team_table = A.dist.table"" from the Readme.']}, {u'text': u'I am not able to follow what needs to be done as a part of the assiignment . For other assignment I got the function that we need to implemented with the input parameter and output defined. But for this assignment I am not which function or routine I need to implement.', u'responses': [u'I think I got it now. New to follow the test function to check the function that needs to be implemented']}, {u'text': u'
The alarm responds correctly to the gauge 55% of the time when the alarm is faulty, and it responds correctly to the gauge 90% of the time when the alarm is not faulty. For instance, when it is faulty, the alarm sounds 55% of the time that the gauge is ""hot"" and remains silent 55% of the time that the gauge is ""normal.""

Just confirming from the above - have people interpreted this as P(A | !G, !FA ) = 0? or P(A | !G, !FA) = 0.45 ?', u'responses': [u'I think it's always the opposite value and never zero (unless the other is 100%). So P(A=False | !G, !FA) = 0.90 but  P(A=True | !G, !FA) = 0.10 and then  P(A=False | G, !FA) = 0.10 but  P(A=True | G, !FA) = 0.90. The 0.55/0.45 cases would then relate similarly to the faulty gauge being true.
']}, {u'text': u'Is there a simple way to know if our bayesnet is working besides turning it to bonnie?  Like for specific values such as P(T=True | A=True, FG=True, FA=True ) = 0.818533 being true? I get P(T=True | A=True, FG=False, FA=False) = 0.244318 as others mentioned but the probabilities seem strange. Wouldn't there be higher probability of a high temperature if the alarm and gauge AREN'T faulty? I guess we should be doing hand calculations (hopefully correctly)?', u'responses': [u'Hand calculations is how I verified what was submitted in a matter of 30 minutes or so, but I only confirmed the three requested probabilities in the assignment.', u'Any hints on performing hand calculations.  I have been using enumeration or lecture 26 method but it took me some time to figure get_temp_probs. Thanks', u'You can treat each probability as independent and simply multiply down the line in each scenario.']}, {u'text': u'In setting up my probabilities does
P(A=False | !G, !FA) mean
(1) The probability that the Alarm is reacting INCORRECTLY given that the gauge reads normal and the alarm is not faulty
OR
(2) The probability that the Alarm is NOT-RINGING given that the gauge reads normal and the alarm is not faulty.

i.e. Does A_Nodes value indicate correctness or status?

I'm leaning toward the first, but i'm confused', u'responses': [u'P(A=False | !G, !FA) is option (2)']}, {u'text': u'In the README of this assignment part 1a:
A_node.add_parent(T_node)
T_node.add_child(A_node)
If my  own implementation do not have a direct connection between T and A does it mean I'm wrong?
Is this two line of code just trying to tell us how to use add_parent () and add_child() ? or is this supposed to be part of the correct Bayesian network structure?




', u'responses': [u'You use this to setup up your nodes. You need to add all the node relationships with this code before you can set their probabilities. I think it's best to write out the Bayesian tree first so you know which are parents and children and then you set their relationship with that code:
A_node.add_parent(T_node)  <---- T is a parent of A so T influences A
T_node.add_child(A_node)   <---- T has a child called A and similarly influences A as before
It's something like setting up a two way street. That's why it's considered two ""links"" when testing. Similarity, if A had another parent (like G), there would be 4 links in total between A and it's parents T,G.']}, {u'text': u'Should we consider being faulty as True or False? 

Right now, for FA and FG, I'm considering True to mean that it is faulty and False to mean that is accurate (not faulty). ', u'responses': [u'True means Faulty.


Use the following Boolean variables in your implementation:
A = alarm soundsFA = alarm is faultyG = gauge reading (high = True, normal = False)FG = gauge is faultyT = actual temperature (high = True, normal = False)
']}, {u'text': u'Is anyone know how to test 1c?', u'responses': [u'I tested it by calculating the answers by hand and then comparing my hand-calculated answers to what my code returned when I called those functions. There may be a better way, but this is one possible way to verify you're getting the right answer. ', u'I programmatically calculated the answers manually using the other components.  Start with the nodes that had discrete probabilities and verify that their probabilities were returned correctly, then build up from there to test probabilities with evidence (which I had to write more functions for).']}, {u'text': u'Calculating P(G) by hand:

I am trying to use the following to calculate the probability of the Gauge giving a hight temp. Here is what I am doing: 

P(G) = P(G|+T,+Fg)P(+T)P(+Fg)  +   P(G|+T,-Fg)P(+T)P(-Fg)  +  P(G|-T,+Fg)P(-T)P(+Fg)  +  P(G|-T,-Fg)P(-T)P(-Fg)

For P(Fg) I am using what I have calculated by hand and what I get with my code--fortunately those match.

Am I missing something?

Thanks', u'responses': [u'Your notation is accurate when I compare them to my hand calculations. This holds true if your notation means the following with the appropriate negations in meaning:

G = gauge indicates a hot temp
+T = temperature is hot
+Fg = gauge is faulty']}, {u'text': u'For part 1.c,Do I need to return float or tuple?Thanks,', u'responses': [u'Return float for 1c.']}, {u'text': u'Is it possible to pass Bonnie's 1a and 1b tests with the wrong network or probability distributions?', u'responses': []}, {u'text': u'The alarm responds correctly to the gauge 55% of the time when the alarm is faulty, and it responds correctly to the gauge 90% of the time when the alarm is not faulty. For instance, when it is faulty, the alarm sounds 55% of the time that the gauge is ""hot"" and remains silent 55% of the time that the gauge is ""normal.""

P(A=False | !G, !FA) = 0.90
P(A=True | !G, !FA) = 0.10

The issue I am having is that the above queries using my network results in 1.0 and 0.0 instead of 0.90 and 0.10.  In this case, it should return the values set as part of my setup_probs.  My dist table seem to be correct and debugging the pbnt code shows the correct values but in the incorrect index (pbnt's internal).  Rest of my network has correct values.  I thought that this value might be influenced by other nodes so hand calculated it and the got the expected values.  any ideas on what might be going wrong?', u'responses': [u'I believe your stated probabilities are correct.

What has happened to several others was mis-named/mis-identified nodes (e.g. copy/paste errors where they assigned evidence to the wrong node and/or tested the wrong nodes (looking up the wrong node name)).

That's the first thing I'd check.  The next would be that you're setting up your evidence correctly to do that test.']}, {u'text': u'I'm getting an error on my first run of bonnie.  Everything passes locally so I don't understand why the power_plant network variable would not exist as it returns from the function just fine locally..  .  I suppose that I am returning the network the wrong way or something for bonnie... but I cannot seem to understand it since it returns fine with local tests and probabilities are even returned correctly in my prob tests.

1c failed due to error: EXCEPTION IN (run.py, LINE 283 \""prob = pn.get_alarm_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment1c failed due to error: EXCEPTION IN (run.py, LINE 300 \""prob = pn.get_gauge_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment1c failed due to error: EXCEPTION IN (run.py, LINE 318 \""prob = pn.get_temperature_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment"",', u'responses': [u'Without seeing their code in run.py, I can't explain how their variable could be undefined.

Have you written tests that instantiate the power plant network and call your probability functions to verify they work?  The base unit tests don't hit this (IIRC)', u'Correct, I have created more tests, created the network, returned my probabilities, etc all locally.  The only thing I can think of is that there's an import (I don't have any extras actually) or some code probably at the top that I put in that pyCharm and local python is ok with but bonnie is not.  Having burned 2 submits with nulls being returned is not pleasant.  Thank you for any thoughts!!  My full bonnie output:

2b). Test that the posterior is calculated correctly. (5 points):                                                                
Unable to run test.  Please check your syntax.
(2c). Test for Gibbs convergence (5 points):                                                                                      
Unable to run test.  Please check your syntax.
(2c). Test that Gibbs is implemented correctly. (10 points):                                                                      
Unable to run test.  Please check your syntax.
(2d). Test for MH convergence. (5 points):                                                                                        
Unable to run test.  Please check your syntax.
(2d). Test that MH is implemented correctly. (10 points):                                                                         
Unable to run test.  Please check your syntax.
(1b). Test for the probability distribution of the power plant Bayesian network. (15 points):                                     
Unable to run test.  Please check your syntax.
(1a). Test for the structure of the power plant Bayesian network. (10 points):                                                    
Unable to run test.  Please check your syntax.
Test the student printed their name (a non-empty string):                                                                         
Unable to run test.  Please check your syntax.
(2e). Testing compare_sampling. (20 points):                                                                                      
Unable to run test.  Please check your syntax.
(2a). Test that the sports network is set up correctly. (10 points):                                                              
Unable to run test.  Please check your syntax.
(1c). Test for the inference task for various power plant situations: marginal alarm, gauge, and temperature. (10 points):        
Type of returned values is correct{  ""tests"": [    {      ""output"": {        ""points_available"": 5,        ""points_awarded"": null      },      ""description"": ""(2b). Test that the posterior is calculated correctly. (5 points)""    },    {      ""output"": {        ""points_available"": 5,        ""points_awarded"": null      },      ""description"": ""(2c). Test for Gibbs convergence (5 points)""    },    {      ""output"": {        ""points_available"": 10,        ""points_awarded"": null      },      ""description"": ""(2c). Test that Gibbs is implemented correctly. (10 points)""    },    {      ""output"": {        ""points_available"": 5,        ""points_awarded"": null      },      ""description"": ""(2d). Test for MH convergence. (5 points)""    },    {      ""output"": {        ""points_available"": 10,        ""points_awarded"": null      },      ""description"": ""(2d). Test that MH is implemented correctly. (10 points)""    },    {      ""output"": {        ""points_available"": 15,        ""points_awarded"": null      },      ""description"": ""(1b). Test for the probability distribution of the power plant Bayesian network. (15 points)""    },    {      ""output"": {        ""points_available"": 10,        ""points_awarded"": null      },      ""description"": ""(1a). Test for the structure of the power plant Bayesian network. (10 points)""    },    {      ""output"": {        ""points_available"": 1,        ""points_awarded"": null      },      ""description"": ""Test the student printed their name (a non-empty string)""    },    {      ""output"": {        ""points_available"": 19,        ""points_awarded"": null      },      ""description"": ""(2e). Testing compare_sampling. (20 points)""    },    {      ""output"": {        ""points_available"": 10,        ""points_awarded"": null      },      ""description"": ""(2a). Test that the sports network is set up correctly. (10 points)""    },    {      ""output"": {        ""points_available"": 10,        ""message"": ""1c failed due to error: EXCEPTION IN (run.py, LINE 283 \""prob = pn.get_alarm_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment1c failed due to error: EXCEPTION IN (run.py, LINE 300 \""prob = pn.get_gauge_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment1c failed due to error: EXCEPTION IN (run.py, LINE 318 \""prob = pn.get_temperature_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment"",        ""return_type_check"": true,        ""points_awarded"": 0      },      ""description"": ""(1c). Test for the inference task for various power plant situations: marginal alarm, gauge, and temperature. (10 points)""    }  ]} ', u'Hmm... I would start by removing any code you have that is outside of the functions that they provided for you to fill in.  I'm guessing that there is some collision going on that we can't see.   You might want to post a private message to the TAs to see if they can help identify the problem.', u'Thank you!']}, {u'text': u'Conditional probablity expects more than a few arguments like P(A = false | F_A = true, T = False)) so how did you all pass the 3 arguments, the function defination is accepting only one argument
get_temperature_prob(bayes_net,temp_hot)
Did you guys pass temp_hot as a tuple or list. What is bonnie going to pass anyone knows?
', u'responses': [u'temp_hot should be a boolean (True or False).  You're trying to determine the probability that the temperature will be whatever that variable is set to (e.g. if it's True, you want P(T=true) if it's False you want P(T=false)']}]",,7.0,332.0,464,,Assignment 3 Part 1 Discussion: Bayesian Network,[a3]
5ad7d45e0d63974e20c39188,"This is the discussion post for Assignment 3 Part 2: Sampling

",jc6w44hrp9v2ki,"[{u'text': u'I probably understand something wrongly, but I notice Gibbs_sampler() and MH_sampler() take no evidence as input. So there is a question:
Are we suppose to implement both function such that they know the evidence that A beats B and A draws with C?

If yes: then the sampler only work for this specific case, which doesn't sound great.

If no: we build sampler that sample base on prior. Then we need to handle samples that does not agree with the evidence in compare_sampling? Does these inconsistent samples contribute to their count in compare_sampling?
', u'responses': [u'My understanding is that both gibbs_sampler() and MH_sampler() are just tooling functions, so they whatever takes input and returns on iteration of sampling. If we need to calculate prob using the evidence that A beats B and A draws with C, then the main part of code (not the 2 tooling function) should feed the 2 sampler functions with related initial_state.

With this, I think we have to implement the sampler function that could sample for any state, e.g. we have to sample A, based on B, C, AB, BC, CA, so we still need to calculate the conditional prob P(A|B,C,AB,BC,CA) by ourselves, which is pretty mathematic...', u'You can generate samples in 2 ways:

1. Only generate samples with the evidence fixed. This means all samples generated will have AvB and CvA fixed.
2. Generate samples without any evidence fixed. This means samples will include ones that do not have AvB and CvA fixed.

In either case, you want to find the distribution of BvC (this part is handled in compare_sampling). Would using method 1 or 2 lead to different results for the distribution?

As for calculating the conditional probability like P(A|B,C,AB,BC,CA), a markov blanket may help there.', u'Hmmm, I think I will probably go with the first one, since it will help exclude lots of uesless samples in compare_sampling step!

Thanks!', u'Hi Mansoo,

Correct me if I have a bad understanding on this one. If you use MH and sample with evidence fixed,your samples will be drawn from the joint distribution. MH will then reject those not consistent with the evidence. In effect, MH is acting as a Monte Carlo rejection sampler on P(query|evidence). Is this really MCMC since we're not relying at all on the Markov Chain? ', u'I was wondering If we have status of A,B,C's skill levels from the parameter, wouldn't it be already evidence because the skill levels are fixed?
I'm not sure why we need to think about cases where no evidences are fixed.

EDIT: never mind. I figured it out']}, {u'text': u'I was just looking over the test code provided and stumbled across this for part 2b

abs(posterior[0]-0.25)<0.01 and abs(posterior[1]-0.42)<0.01 and abs(posterior[2]-0.31)<0.01

So it looks like the test is expecting posterior = [0.25, 0.42, 0.31] The problem is 0.25+0.42+0.31 = 0.98 < 1.00, so the expected posterior is not a valid probability distribution. It looks like something's not quite right here.
', u'responses': [u'It is taking the truncated values of the posterior and then verifying against that. So before truncation, the values should add up to 100.', u'No it's not, it's simply not very careful coding, it shouldn't affect the assertion though as the tolerance is quite large']}, {u'text': u'For MH sampling, any suggestion on the proposal distribution? Since it's discrete, the provided Cheat Sheet pdf does not really help here. After reading some other research papers, I decided to use prob [0.25, 0.5, 0.25] for left and right side of each state, then found the converged prob is not correct (Guess the proposal distribution is not symmetric, so I cannot simply use p(new)/p(old) for acceptance probability).

Any suggestions or any other article I can read to find better idea?', u'responses': [u'I'd recommend using uniform for the proposal distribution.', u'Great! I will give it a try', u'+1']}, {u'text': u'Another question is regarding the question 2e. When talking about N (say N=10) successive iterations, and to get delta <= 0.001, are we talking about (Assume after M sampling) which one of the following:
A. Prob from sampling 0:(M-10), vs. prob from sampling 0:M
B. Prob from sampling 0:(M-10), vs. prob from sampling (M-10):M
C. Prob from sampling (M-20):(M-10), vs. prob from sampling (M-10):M

My feeling is we should look at option A, since 10 sampling is definitely not enough get a reliable probability distribution.

My problem here is that, I used option A, but when choosing N=10, my code would converge into a very different prob distribution (actually not converging, just N is not big enough to add not useful samples for AvB=0 and CvA=2)', u'responses': [u'You can try different N if you want in your compare_sampling.

When comparing distributions, I'd recommend comparing the distribution for samples 0:m vs. distributions for samples 0:m+1 (so like option A above). There are different ways to check for convergence. You can check after each iteration, N times in a row. Or you can check at m, then at m+N.

At the end, the goal is to get a distribution from sampling that is close to the calculated value in 2b. Different methods of checking for convergence may have tighter or looser convergences. However you check for convergence, make sure you use the same convergence check method for Gibbs and MH.

Also, a somewhat large initial ""break in"" period may be helpful. For example, you can generate some X number of samples before you start checking for convergence.

', u'If we have a large break in period so that we end up with good values, and then a fairly lax delta (0.001) over N consecutive iterations, how should we compare the speed of convergence?

I'd expect MH and Gibbs to consume the same number of samples in that case (break in iterations + N). Do rejected samples not ""count"" towards MH number of iterations?


EDIT - nevermind - after thinking it through a bit I found a combination of parameters that makes sense. :)']}, {u'text': u'Incidentally, is the wording of 2e as intended?
For instance, if Metropolis-Hastings takes twice as many iterations to converge as Gibbs sampling, you'd say that it converged faster by a factor of 2. Fill in sampling_question() to answer both parts.It seems to me that there's a mistake there; an algorithm that takes twice as many iterations to converge converges slower by a factor of 2. So, the question is, could you clarify, should the algorithm name that we return be the faster algorithm? Then I think it's clear that the value of the factor that we return should be $$> 1$$, so that it represents how much faster the faster algorithm is, right?

As it seems I've managed 100% with that interpretation, although someone said they got 100% without implementing some functions, so it seems worth checking', u'responses': [u'Your interpretation is correct - if the algorithm takes twice as many iterations, it is converging slower by a factor of 2. The sampling_question should return the faster one and by what factor it was faster by. The description should say ""For instance, if Metropolis-Hastings takes twice as many iterations to converge as Gibbs sampling, you'd say that Gibbs converged faster by a factor of 2"". I'm updating the readme with this change.']}, {u'text': u'What is expected to return for ""MH_rejection_count"" in 2e?

Is that the number of rejections in MH sampling? MH_sampling function only returns a new iteration (a tuple with states), so how can we get rejections numbers? Does that mean we need to modify the return clause of MH_function to also include rejections?', u'responses': [u'It might be on you to call the MH function in a loop and reject samples that it returns inside `compare_sampling`, but I hope a TA answers this since I would like to know as well', u'I confirm that Bonnie is not, or was not, testing the MH_rejection_count value; as you say, it would need 1) modifying the return value of the MH_sampler() function, that could itself risk making Bonnie unhappy, 2) setting some global – or function attribute – variable, or 3) testing for accept/reject in the calling function rather than in the MH_sampler() function itself.

The chances are that including that value as a return from compare_sampling() is either legacy from a time when rejection sampling was being tested, or a hangover from stub code that wasn't ever changed in the final release.', u'So then should the return statement be amended to:

    return Gibbs_convergence, MH_convergence, Gibbs_count, MH_count

or left alone? I don't want to waste a submission on a small mistake like that.

Thanks,Jim', u'Don't change the return types, obviously, unless you are willing to risk upsetting Bonnie', u'Obviously rejection sampling is required for MH. What about Gibbs sampling? Use rejection sampling or likelyhood weighting? As we are supposed to compare the two sampling methods, I assume rejection sampling must be used for Gibbs sampling as well. Any one has different opinion on this?

Also what is in the MH_count, the total count or the count excluding the number of rejection?', u'I also think so. I didn't hardcode an evidence in my MH and Gibbs samplers so I think that it's required to use rejection for both samplers(take only samples where  ""A won against B and tied C"") and count steps after rejection(not rejected), but in case of MH it looks like first I should reject everything what is not ""A won against B and tied C"" and if a sample is not rejected  then check whether the sample was rejected by MH sampler and if so count it as rejected. Does it make sense????', u'That's right. I can confirm that Bonnie expects comparison of iteration excluding rejection count. I end up following MarkBenjamin's advice (below), which is to use a boolean fix_avb_cva_evidence to handle evidence in the Gibbs sampler. It is faster than the implementation with rejection. For MH, rejection has to be used. Both converges to the posterior probability in 2b. ', u'"" if a sample is not rejected then check whether the sample was rejected by MH sampler and if so count it as rejected"" - this statement is defenitly  incorrect']}, {u'text': u'For my posterior I think my answer is close, but it doesn't pass the unit tests because my probability for index 2(tie) is 0.01375 away from the expected instead of 0.01.

Is there anything I can do to fix this that I may be missing?  Does this mean I did my game network wrong somehow?  The other two probabilities are within the limit so not sure what is wrong.', u'responses': [u'
I wrestled with a similar situation for far longer than I'd like to admit.  My issue was in the distribution setup. I had a typo passing the wrong node name to a function (cut/paste that didn't get changed).  I'd been over my setup several times, and finally decided to take one more, very close look and found the off by one letter typo.   

If you've not discovered it, might be worth another look. ', u'For me, it was a similar issue to Scott's. The order of your nodes matters when setting up the distribution tables.', u'Yup, ended up being something dumb, one of my distributions added up to 1.1 instead of 1.0 due to a typo (which since I had copied and pasted it caused issues in 4 different places).  Typos are killer!']}, {u'text': u'In Part 2c it says:""If an initial value is not given, default to a state chosen uniformly at random from the possible states."" 

Does this mean that if the initial state is empty the team values should be chosen based on the initial probability distribution for skill and the match values should be chosen based on the probability of those team values, or is it meant to be just a random selection of values in the range [0, 3] for skill and [0,2] for match outcomes?
', u'responses': [u'You can choose randomly both for the skills and for the match outcomes for the initial state if one isn't given.', u'Before I burn 1/5 Bonnie submissions, can we get an explicit yes or no:
1) Does ""initial state isn't given"" mean the value of initial_state will be None?
2) If not None, will it be an empty list or a partially filled in list with some values being None?

I'm newish to Python, so the subtleties of ""isn't given"" seems woefully under specified, seems like a default value in the provided code would make this super clear...', u'You can test for both None and empty list in python with one check because they both evaluate to False.

if initial_state:
']}, {u'text': u'A few more questions about the Gibbs_sampler() function, that I am having trouble understanding from the assignment description:

In the paper on Gibbs sampling it suggests that you can specify certain variables as fixed, but the function provided doesn't seem to have a mechanism to specify any of the state id's as fixed. Is there some assumption about fixed variables that we are supposed to know in advance and hard code in there, or are all the state id's meant to be resampled, or am I missing some other assumption in the documentation?

Are we always meant to make the assumption that A beats B and A draws with C like is given in the calculate posterior section in 2b or is their some different assumption for the sampling sections?

The Sampling section also says: ""Each team has a fixed but unknown skill level, represented as an integer from 0 to 3."" At what point are these fixed, and are they meant to be resampled or fixed in Gibbs sampling?', u'responses': [u'If you wish to hard fix the evidence variables within your Gibbs_sampler() function, you may do so.

As for each team's skill level, it may change when you generate new samples.']}, {u'text': u'So, I have a question. In part 2c/d are we supposed to provide: 
1) Generic Gibbs/MH samplers?
2) Samplers for the specific case where AvB, CvA evidence is provided?

I ask because the sampling function signatures do not take evidence as an argument, so we either have to hard code that in, or not. For example, it might be for 2e, evidence is AvB = 2. However, the 2c sampler could easily choose to update AvB to 0 or 1', u'responses': [u'For 2c/2d, you can do either 1) or 2), as long as the BvC distribution (given A beats B and A draws with C) is properly calculated in 2e.', u'I confirm that Bonnie allows you to add a default parameter such as fix_evidence=None then accept a dictionary of indices in the state vector, to the values at those indices, or just a boolean fix_avb_cva_evidence=False with special cases in the function for handling fix_evidence is not None or fix_avb_cva_evidence == True', u'Bonnie gives me feedback that “Gibbs should return a uniform distribution when no initial state is provided”, so does this mean we shouldn’t hard code the evidence in to Gibbs but allow a parameter to turn it on for 2e?', u'Hi Mansoo,

For 2c/2d, can you clarify if no list is given, should we return [x1,x2,x3,e4,x5,e6] or [x1,x2,x3,x4,x5,x6] where xi is a random value drawn uniformly from Xi and ei is the evidence for Xi?']}, {u'text': u'For the convergence in 2e, can we use any method to determine convergence or do we need to use N=10, delta = 0.001?', u'responses': [u'You can change N and delta if you want.']}, {u'text': u'Do I have the following right?

The gibbs_sampler accepts an initial_state list with six elements with the first three elements being the skills of the teams. That means that if we want to calculate the a game result (for example, AvB), we can do so directly from the skills table. We don't need to use the indirect evidence from the results of the BvC and CvA matches. In other words, the following simplification holds:P(AvB | A,B,C,BvC,CvA) = P(AvB | A,B)
That is, if A and B's skill levels are known, the match results BvC and CvA are irrelevant because those results don't influence AvB through any mechanism other than the skill levels, which are already fixed, known inputs.

The reason I feel the need to ask this is that the readme in 2b says ""In the next two sections, we'll be arriving at the same values by using sampling in the next section."" But 2b (EnumerationEngine) asks a very different question than 2c (Gibbs). 2b does not give us information about the skill levels of A,B, and C. Instead, it gives us the results of two matches that shifts the likely probabilities of A, B, and C's skill levels each in different ways. The following two are not equal:
P(BvC | AvB,AvC) <> P(BvC | A,B,C,AvB,AvC)

The only way I can see for Gibbs to converge to the 2b results is if we write the Gibbs function to ignore the team skill levels. What am I missing?', u'responses': [u'2c and 2d are only single iteration calls; you don't need to worry about convergence. 

In 2e, we are asked to compare Gibbs with MH (this is where you will call your 2c/2d models with iterations), under the same condition as 2b: ""Given the same outcomes as in 2b, A beats B and A draws with C"". ']}, {u'text': u'I seem to be having a mental block for parts 2b.  I'm using the EnumerationEngine as the Readme.md file suggests, and modeling it after the JunctionTreeEngine, but my results are slightly off and I can't seem to pin point the problem.  I'm getting [0.25821713, 0.37421316, 0.36756971 ] for the posterior result when the evidence is A wins agains B and A Ties with C.  My Bays Network structure and distribution seems to be correct as it passes the unit tests for those parts.  Any helps would be appreciated.', u'responses': [u'My problem was that I was using the incorrect set of nodes in the creation of a Conditional Distribution.', u'Hi David,

Facing similar situation. What exactly was your issue ', u'When I was creating the ConditionalDiscreteDistribution I used a node more than once.  For example I passed [node_a,node_a and node_cva] for the nodes parameter when I should have had [node_c, _node_a, node_cva].']}, {u'text': u'2c. I'm stuck with calculation of probability  to perform sampling P(A| B,C, AB, BC, CA) .

The way how I'm trying to do it:
using Markov blanket
P(A| B,C, AB, BC, CA)  = P(A|B, C, AB, CA)

if I interpreted it correctly, using (14.12) from the book
 P(A|B,C, AB, CA) = aP(A)*P(AB|A,B)*P(CA|A,C)

Is it correct way in general to calculate it? If so them any hints what to do with 'a' coefficient and how to deal with the fact that we have distribution of P(A)?

Thanks
Alex', u'responses': [u'Alex, I'm at exactly the same point you are. The dependence on P(A) should be fine (I think) because we need to end up with a distribution for P(A | B,C,AB,BC,CA). The 'a' coefficient in the formula from the book simply implies that the distribution will need to be normalized, if I've interpreted earlier parts of the book correctly.

The part of this im not sure about currently is the dependence on particular values of ""A"" in P(AvB | A,B) and P(AvC | A, C). Unless these are also meant to represent distributions P(AvB=avb | B=b, A)...etc. Would appreciate if a TA chimed in, but that's what im going to try next.', u'about P(AB|A,B) - I'm thinking to use A, B values from the input tuple and then lookup P from the AB distribution table, but I still don't see how to connect things and calculate the result: P(AB|A,B) its distribution between 3 values, P(A) it's distribution between 4 values', u'If my understanding is correct. 

Do this for all a values:
P(A|B,C, AB, CA)
= P(A=a, B,C, AB, CA) / sum_A P(A, B,C, AB, CA) [enumerate]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / sum_A P(A)P(B)P(C)P(AB|A,B)P(CA|A,C) [factor out]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / P(B)P(C) sum_A P(A)P(AB|A,B)P(CA|A,C) [move factors independent of A out]
= P(A=a)P(AB|A=a,B)P(CA|A=a,C) /  sum_A P(A)P(AB|A,B)P(CA|A,C) [ cancel like terms]

You should result in a probabilities for each value of a, which should sum up to 1.



Sample from this distribution to get new a.', u'Tasuku's reply above is good.

When you divide by ""sum_A P(A)P(AB|A,B)P(CA|A,C)"", that is same as multiplying by the alpha (normalization constant).', u'thanks', u'$$P(A|B,C, AB, CA)$$
$$= \frac{P(A=a, B,C, AB, CA)}{ \sum_{a_i=\{0,1,2,3\}} P(A=a_i, B,C, AB, CA)}$$ [enumerate]
$$= \frac{P(A=a)P(B)P(C)P(AB|A=a,B)P(CA|A=a,C)}{ \sum_{a_i} P(A=a_i)P(B)P(C)P(AB|A=a_i,B)P(CA|A=a_i,C) }$$ [factor out]
$$= \frac{P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C)}{ P(B)P(C) \sum_{a_i} P(A=a_i)P(AB|A=a_i,B)P(CA|A=a_i,C) }$$ [move factors independent of A out]
$$= \frac{P(A=a)P(AB|A=a,B)P(CA|A=a,C)}{ \sum_{a_i} P(A=a_i)P(AB|A=a_i,B)P(CA|A=a_i,C) }$$ [ cancel like terms]

Is this more readable?', u'Wouldn't it have to A=ai for every A term? Something like P(AB|A=ai,B)?', u'I got this: = P(A=a)P(AB|A=a,B)P(CA|A=a,C) normalized and that works for A,B and C.
However,
How do I get P(BC=a) in = P(BC=a)P(AB|A,B)P(CA|A,C)? As we have no table for that? Again, how do you find P(BC=a)?
', u'I have a similar question as Brett's, P(AB| A=a, B=b_initial) yields a vector of probabilities for the match results. Do we select from that distribution using the initial state of AB?', u'@Jianchao Yang - Your answer helped me. Thank you!', u'@Jonathan I have the same question. P(AB| A=a, B=b_initial) is a vector. How do we get a single number out of it for calculating the denominator ?', u'Ok, I understand it now. P(AB| A=a, B=b_initial) is the probability that AB is the value in the sample given A=a and B= b_initial. So we just find it by using the 3 indices over the dist table.', u'@Simha Reddy Can you elaborate on what you mean? I'm stuck at the same point. What do you mean AB is the value in the sample given A=a and B=b_initial? Does this mean that if the initial state of AB is 0, and you have A=0 and B=1, for example, you would grab the probability in the AB dist table where A=0 and B=1 for index=0 (i.e. the first of the three probabilities in the vector)?', u'@Nathan Susanj Yep. That is exactly it. To make it more explicit,  P(AB| A=a, B=b_initial)  =  P(AB=ab_initial| A=a, B=b_initial) ']}, {u'text': u'I am not fully understanding what the algorithm means in the MH sampling paper. 

I have read the paper several times and am not sure what the symbols mean, or how they translate to generating a sample. Given the equation below, what is q? and what distribution corresponds to q(x(i) | x(i-1)) ?
Propose: xcand ∼ q(x(i)|x(i−1))
Is there any explanation or reference for this elsewhere to better understand the MH sampling process?After generating samples how is the acceptance criteria alpha defined?
$$α(xcand|x(i−1))=min1,q(x(i−1)|xcand)π(xcand)q(xcand|x(i−1))π(x(i−1))$$
Here it seems like alpha is min(1, some_probability) but the symbols in the calculation are not familiar to me given our reading and lectures. Can one of the TA's provide some additional pseudocode for reference or clarity on the MH procedure?Thanks.', u'responses': [u'I'm also having a hard time understanding this.', u'The paper mentions that proposals may be drawn from a symmetric distribution, including Uniform or Gaussian or an asymmetric distribution. My current understanding is that xcand should re-sample all variables uniformly at random giving a symmetric distribution.

Is this correct?

Then we set the acceptance value alpha to the probability P(BvC | A, B, C, AvB, CvA)(i) / P(BvC | A, B, C, AvB, CvA)(i-1) select a random value u between 0 and 1 and if u < alpha we accept.Is this the correct way of thinking about acceptance?', u'about sampling a new state I also have the same understanding, by the way we should generate full new state not just one variable is it correct?

but I'm not sure about acceptance probability, why do you think that we should calculate P(BvC | A, B, C, AvB, CvA)? but not P(BvC, A, B, C, AvB, CvA) for example? Probably I'm wrong but taking into account our network P(BvC | A, B, C, AvB, CvA) = P(BvC|B,C) in that case we do not take into account whole state.', u'You might be right. This is where I'm still confused on this problem. I'm going to give it another go with this understanding. Thanks for the feedback.

Are you getting MH to converge given the full joint probability?', u'haven't tried yet', u'I thought this was it, but I think I just got a lucky random draw. I am still converging to the uniform distribution with this method. I still think I'm missing something with the acceptance criteria.', u'nice, qq: do you perform only one iteration or you keep sampling until you find an acceptable sample?', u'it looks like it's good enough to return just a result of one iteration', u'I just selected random samples and tested acceptance in the convergence test.']}, {u'text': u'I got points on Bonnie for my MH_sampler being implemented correctly, but I didn't get the 5 points for it converging to the right distribution within 50000 iterations.  Does this mean that I'm not rejecting as often as I should be?  I'm converging to a relatively uniform distribution apparently ([.32, .32, .35]) so this is my guess but in that case I'm not sure exactly what I'm doing wrong.  Anyone else have this issue?', u'responses': [u'Yes. I am also converging to the uniform distribution for MH. It makes me think I am not understanding how to calculate the Acceptance probability correctly. I wish I understood better what the sampling criteria, acceptance criteria and parameter u mean in context.', u'I had this same issue - you're in luck. Just implement the MH_sampler method so that it returns the new candidate AFTER you've performed the acceptance testing.

In my original implementation I just returned the candidate from MH_sampler and did all the acceptance/rejecting in the compare_sampling method. It converged properly. So overall it was right, but like for the Gibbs case, bonnie needs the results of MH_sampler to be the accepted candidate.', u'How do you get the rejection count if you do it this way? I thought the TA's said we should implement generic samplers, is this not the case?', u'I did it that way and am still converging to the uniform :/From above it seems like returning the rejection count is unnecessary in sampling, so I didn’t and I didn’t lose any points on that section, so I’m not worried about that aspect of it.  I am hard coding the evidence, but again from above it seems like that should be acceptable.  It has to be the way I’m computing the acceptance condition...', u'You don't need rejection_count, I believe it's legacy code. I set mine to 0 and it passed bonnie with no problems. ', u'I have the same issue. There are a couple of questions that i have : 
1) For each iteration, do we need to propose a new value for all the variables other than the evidence?
2) Correct if i am wrong, the accept criteria for AvB is :
     calculate alpha = min(1 , new P(AvB|A,B)/old P(AvB|A,B)) 
     then compare it with a random number u which is between 0 and 1
I feel like i must have done something wrong in the accept criteria to get a uniform distribution for MH. 

', u'That is the way I understood it. I have not sent mine to bonnie yet however. Below is my dumbed down version of http://www.mit.edu/~ilkery/papers/MetropolisHastingsSampling.pdf algorithm without multiple iterations
candidate = listOfRandomStates #Except evidence
alpha = calculateAlpha #New/Old
If(alpha > 1) return candidate
else
   If(randomNumberBetween0and1 < alpha) return candidate
   else return origonalState
', u'Jake, if you exclude evidences from listOfRandomStates, how would you count reject in the convergence method? I thought I need to reject based on AvB=0 and CvA=2 from the convergence method

EDIT: It should exclude evidences from the new state.', u'I'm still converging to the uniform.  I used the method that Jim mentioned above for my acceptance probability:

P(BvC | A, B, C, AvB, CvA)(i) / P(BvC | A, B, C, AvB, CvA)(i-1) 

Is this potentially incorrect?  I'm really not sure what to use for this part and it seems to be my only issue still.', u'Carey,

I don't think that method considers the likelihood of your entire state.

I think you need to consider the whole state.

Check out equation 14.2 from the book.

P(A,B,C,AvB,BvC,CvA) = P(A)*P(B)*P(C)*P(AvB | A, B)*P(BvC | B, C)*P(CvA | C, A)', u'I am also converging uniform distribution with MH. Did you guys find any solutions to make it converge the similar distribution to 2b?', u'Thanks Anthony. That helped my MH a bunch!', u'Following the below steps (same everyone did above) i am still converging to unifom (.33, .33, .033)

1. random sample X ( uniform random for all 6 variables)
2. Acceptance A = min (1, P(X) / P(X_1)
3. return state if accepted

accept sample if AvB = 0 and CvA =2

What i am missing above?  What helped you all?', u'@Sudharshan

I'm not sure if you have figured this out yet. Here are some pointers.

I would make sure that you are solving for the correct probability with P(X).

I read on here that those who implemented a generic solution with all 6 variables instead of the 4 that are not evidence rejected all states where AvB != 0  and CvA != 2 at the beginning of the function.

Also, acceptance requires a scenario for both results of the min evaluation, whether it is 1 or alpha. The comparison to the random value between 0 and 1 is needed in the case where alpha is less than 1.', u'General question on MH. Are you supposed to do the acceptance test on the entire proposed candidate state or separate acceptance tests on each random variable in the proposed candidate state? I'm assuming the entire candidate state, but some of the comments above made me question that.', u'I'm not converging to uniform, but it's still slightly different from the expected distribution. This is what I got on Bonnie -


{
""output"": {
""points_available"": 5,
""message"": ""Incorrect distribution generated after 500000 runs. Should have reached something near [0.259, 0.428, 0.313] instead of ['0.19', '0.50', '0.31'].\n"",
""return_type_check"": true,
""points_awarded"": 0
}
""description"": ""(2d). Test for MH convergence. (5 points)""
}

In my implementation, I'm generating a random value for all variables except the evidence variables for the new state. I'm then calculating the acceptance ratio by P(new)/P(old), generating mu between 0 and 1 and returning the new state if mu <= acceptance, else the old state. I don't know where I'm going wrong to cause the variation in the answer. 
Was there any change in the algorithm that helped you out?

']}, {u'text': u'I did it that way and am still converging to the uniform :/From above it seems like returning the rejection count is unnecessary in sampling, so I didn’t and I didn’t lose any points on that section, so I’m not worried about that aspect of it.  I am hard coding the evidence, but again from above it seems like that should be acceptable.  It has to be the way I’m computing the acceptance condition...', u'responses': [u'Meant to comment this above but the piazza mobile app is a bit unintuitive, please ignore.']}, {u'text': u'Has anyone else received the following error when submitting to Bonnie:

""MH_sampling failed due to error: EXCEPTION IN (run.py, LINE 728 \""sample = pn.MH_sampler(game_net, list(initial_state)) # returns a tuple\""): only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices""
I got this for all of the tests for MH. When I did this submission, I forgot to generate a state for the MH sampler if None was passed in. However, I'm not sure if this error is due to my mishandling of the initial_state = None case, or if I have some indexing error that does not show up when I test it locally.', u'responses': [u'Yes, that looks like a numpy version mismatch, have you run the program with the provided vagrant vm? That should give the same/similar error as Bonnie if it is. ', u'Yeah, I am running on the vagrant VM. I still can't figure out what caused that error on Bonnie because I can't reproduce it on the VM. I am afraid to run it on Bonnie again after fixing the initial_state error in case there really is something wrong with it and I just can't find it...', u'Avery did you figure this out?', u'Nope - I'm still unable to locate the issue', u'That error seems to indicate that you are indexing into an array with an incompatible variable type. Debug your code and make sure any variable you are indexing an array with is an integer and not a float or some other incompatible type.', u'So after fixing the error where I did not create a random state when initial_state was not passed in, I did an infinite loop on the vagrant VM for hours where I generate a random state and run my MH method on it until it converges. During that time, I never got an indexing error of any sort. Finally, I was convinced that the error must have been related to my mishandling of the initial_state, so I submitted again. Not only did I still get the indexing error, I also got the exact same 

When provided no initial state, MH should generate a state from uniform distribution

error as before. I do the exact same thing as I did in my Gibbs method to check this:

if initial_state is None:	return a state chosen uniformly at random

Since this worked in Gibbs, I have no idea why it would still cause me to get the same error in MH. As for the indexing error, I still suspect that it is caused by my code failing at this point. The test script returns the above error at line 657, and the other errors relating to my indexing both occur after it (lines 728 and 813). 

Does the test script test cases where initial state is provided as something other than None, but it is not a valid sample? I have no idea why it still failed with that error message...', u'Our code should be able to manage the case the initial_state being [] or None. Hence a check at the starting and initialising the initial_state is a must', u'The error is due to list(initial_state) in the command and initial_state being empty list. You can check this by trying to run in the console', u'


Now I'm really confused... No matter what I did, I could not reproduce this error. So I opened up the vagrant VM (the exact one linked from the assignment description) and it has the wrong numpy version. It is still different than the version on my Mac, so the VM is definitely working. Does anyone know what's up with this?']}, {u'text': u'I'm feeling rather unsure of how to go about setting up the probabilities distributions for the match outcome nodes, based on the README. Anyone else struggle with this?', u'responses': [u'it took me a lot of time to get the idea - we need to cover all possible combinations for 2 teams(in terms of skills) and using skill difference set probabilities for each match result', u'what you are setting up is the various conditional probabilities of all the combinations of skiils of the three teams. That is total 12 distributions. The probability value is to be arrived at based on the difference of between skills of the two teams. ', u'Where are you stuck? It took me some head scratching and sketching it out on paper compared to the boolean version. A key thing that I was stuck on was figuring out to go from [false, true] to [0, 1, 2, 3] when adding the actual values. I would not describe the pbnt API as intuitive, and the documentation is not very clear, but reading the code helped. 

Also @srirangam, I did it with 16 distributions, since there are 2 teams per game, each with 4 possible skill levels, so 4 ^ 2 = 16 possible games played. How did you get 12?', u'I figured it out after cogitating for awhile. It was the transition from boolean to non-boolean variables that was throwing me, too.']}, {u'text': u'From part 2.e
""We'll say that the sampler has converged when, for ""N"" successive iterations, the difference in expected outcome for the 3rd match differs from the previous estimated outcome by less than ""delta"".""
Is the 3rd match BvC (I would assume since that is what we had been looking for earlier), or is it 3rd in the list CvA?', u'responses': [u'It is the BvC match.', u'The posterior we are calculating is the probability of [win, loss,tie] in the next B Vs C match']}, {u'text': u'I'd figured I'd ask this same question in a new thread. I'm working on Gibbs.
I got this: = P(A=a)P(AB|A=a,B)P(CA|A=a,C) normalized and that works for A,B and C.
However,
How do I get P(BC=a) in = P(BC=a)P(AB|A,B)P(CA|A,C)? As we have no table for that? Again, how do you find P(BC=a)?

Okay think I got it, answering my own question it is just the look up of B and C on the table, meaning P(BC)=P(BC|B,C)

', u'responses': [u'Since the probabilities for the three skill nodes and three result nodes are same, we can use the same probability dist.table.']}, {u'text': u'Hi, just starting with Part 2 of the assignment. Needed some clarification with respect to part 2d - MH_sampler. From the cheat sheet provided I understand that a candidate sample is accepted or rejected based on the acceptance probability. What should the MH_sampler function return in such a case? Should it be None, or the initial state or the rejected candidate or something else? Also, should the sampler function even compute the acceptance probability or should it only be generating the candidate sample.

Thanks!', u'responses': [u'The sampler function should calculate the acceptance probability. If the candidate is rejected, it should return the initial state.', u'If it is rejected and returns the initial state, should this also be added to the list of valid samples in the compare sampling method or counted as a rejection and discarded?', u'Good point, Jim.  One thing to look out for along this line of reasoning is the degenerate case where the new randomly generated value is the same as the prior state.', u'Thank you Mansoo for this answer. This really helped me understand what MH is doing, and I finally tracked down the problem with my sampler.', u'It should be added to the list of valid samples. What is rejected is a candidate. You need to count it under rejection too. You will consider for the proposal provided the values tally with the two fixed evidences(as far as this assignment goes)']}, {u'text': u'I am calculating AvB_node_distribution.   from data given I can get  AvB_node_distribution[0,1,:]=[.2,.6,.2]. However how should I calculate AvB_node_distribution[1,0,:] ?', u'responses': [u'Just swap the winner values, so [.6, .2, .2].', u'Please comment on my understanding -
If AvB_node_distribution[0,1,:]=[.2,.6,.2] then AvB_node_distribution[1,0,:] should be [.6,.2.,.2] because this time A has   higher skill by 1 so A's chance of winning is same as B had when its skill was higher by 1', u'Correct.']}, {u'text': u'I'm confused about implementing the MH acceptance function. If the posterior of every candidate returns an array of [win, loss, tie] probabilities, how exactly to you translate that to a value you can divide by the previous posterior and compare to alpha, for the purposes of rejection? Are we testing each match probability for acceptance individually?', u'responses': [u'I'm not sure if you figured this out yet but each call of the sampling function returns a state of [A, B, C, AvB, BvC, CvA]. From this new accepted state, the values of BvC are observed to formulate estimates of the inference probabilities.']}, {u'text': u'(2b). Test that the posterior is calculated correctly. (5 points):                                                                
Type of returned values is wrong. Please re-check the notebook to check for desired return type.
I got this error for 2b, but it also shows I was awarded the full points. Should I be worried?
', u'responses': [u'+1. I changed the return type to desired and got lesser points. Whats going on?', u'If you received the points, that means you are fine.', u'Note that the function requires `list` as return type, while the slicing array from the engine is a numpy array.
Bonnie may be strict on this data type check.']}, {u'text': u'Trying to understand Metropolis–Hastings from this link:

https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm

Could someone explain what g(x|x') represent in our assignment case?

', u'responses': [u'It represents the generative function that generates candidate successors. However, pick a symmetrical function, then all such terms cancel. That is called the Metropolis algorithm I think.

There's a paper linked from either the readme or the pdf in the repo, described as a Metropolis Hastings cheat sheet as I recall, that may be helpful', u'I think in the wikipedia information posted above, g(x|x') is referring to the proposal distribution. In the paper linked in the assignment readme, the notation for the proposal distribution is q(xi-1|xcand).', u'This video helped me understand the algorithm better. It is a little long (~30 min), but better explains some of the nuance of the implementation than the paper (at least for me): https://www.youtube.com/watch?v=h1NOS_wxgGg']}, {u'text': u'I have added 
from __future__ import division at the top of my solution file. Just want to make sure that this is okay.', u'responses': [u'That's fine.']}, {u'text': u'I wasn't sure completely sure about my answer to the last question but Bonnie gave me 100%. So, that means I am good, right?', u'responses': [u'Okay I know the TAs don't work on weekends but this was posted on Thursday?', u'Brett, based on @551 I think you are good. I just added up 'points awarded' and made sure it was 100. I got an 'incorrect type' message for one sub-section but since I got the points I'm going to ignore it. Congrats on being done!', u'Thanks Sandy']}, {u'text': u'are we allowed to use numpy.random_integers() instead of random.randint()? I believe that random.randint() is not uniform', u'responses': [u'.', u'hmm, nvm, I believe the suggestion from the git repo was referencing to numpy.random.randint() not the regular random.randint()', u'Edited']}, {u'text': u'Estimating p(BvC | AvB=0, CvA=2)

I understand that in 2e, we try to arrive at the same distribution for p(BvC | AvB=0, CvA=2) that we arrived at in 2b, but this time using Sampling.

So my understanding is that for each round the loop, draw a sample then, compute  p(BvC | AvB=0, CvA=2)  and repeat until it converges.

My question is: for each sample value drawn, do we read off  p(BvC | AvB=0, CvA=2)  from the distribution tables already built into the network or we have to derive a formula for calculating p(BvC | AvB=0, CvA=2) then plug in the numbers/values from the sample?

Second question: For this function compare_sampling(bayes_net, initial_state, delta), do we assume the initial_state will always have AvB=0, CvA=2 or do we have to somehow manage this within our Gibbs/MH functions?', u'responses': [u'I got stuck on this for a while similarly too. You are overthinking it like me.  Easier to think of it this way P(BvC) = P(BvC | P(B), P(C))', u'Thanks Brett,

Did you break P(BvC | B, C) into:

p(BvC = 0) = p(B) * P(C) * P(BvC=0 | p(B), p(C))
p(BvC = 1) = p(B) * P(C) * P(BvC=1 | p(B), p(C))
p(BvC = 2) = p(B) * P(C) * P(BvC=2 | p(B), p(C))

Then normalized each? This part still confuses me
', u'P(BvC)=some number is the probability that P(BvC) is that given the values for B and C. It is actually the simplest to calculate.
', u'Can you answer this? What is the probability of P(BvC=0) given that B is 0 and C is 2?']}, {u'text': u'Should I know what I am doing for Gibbs and MH? I am kind of lost as far as how to create a sampling code.', u'responses': [u'I spent about 10 hours on Gibbs and about 3 on MH as it isn't simple to understand the math. So, have fun as all you got is the reading material and what is in here.', u'Thanks. Just wanted to make sure I should have no idea as the first part held your hand mostly and it was pretty obvious what to do.', u'Nope unfortunately, it is alot of thinking and reworking. There are a few post above that will help you alot.  Here is the one that helped me a ton for Gibbs:

Tasuku Miura
 4 days ago 
If my understanding is correct.
 
Do this for all a values:
P(A|B,C, AB, CA)
= P(A=a, B,C, AB, CA) / sum_A P(A, B,C, AB, CA) [enumerate]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / sum_A P(A)P(B)P(C)P(AB|A,B)P(CA|A,C) [factor out]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / P(B)P(C) sum_A P(A)P(AB|A,B)P(CA|A,C) [move factors independent of A out]
= P(A=a)P(AB|A=a,B)P(CA|A=a,C) /  sum_A P(A)P(AB|A,B)P(CA|A,C) [ cancel like terms]
 
You should result in a probabilities for each value of a, which should sum up to 1.

', u'Note above, the last line is the key. 
= P(A=a)P(AB|A=a,B)P(CA|A=a,C) /  sum_A P(A)P(AB|A,B)P(CA|A,C)
And the bottom part can be factored away by normalizing.', u'Ah, that's how we calculate a new Gibbs state to compare with our initial_state? For the new state [P(A), P(B), P(C), P(AvB), P(BvC), P(CvA)], we use that calculation method to get each of the new probability values in it? ']}, {u'text': u'How to read result returned from Bonnie?

In my terminal that I run ""python submit.py assignment_3"", I see:
(2c). Test for Gibbs convergence (5 points):Type of returned values is correct(2c). Test that Gibbs is implemented correctly. (10 points):Type of returned values is correct(2d). Test for MH convergence. (5 points):Type of returned values is correct(2d). Test that MH is implemented correctly. (10 points):Type of returned values is correct

However in the json file, I see:

{ ""output"": { ""points_available"": 5, ""message"": ""Gibbs_sampling failed due to error: EXCEPTION IN (run.py, LINE 593 \""sample = pn.Gibbs_sampler(game_net, list(initial_state)) # returns a tuple\""): 'NoneType' object has no attribute '__getitem__'"", ""return_type_check"": true, ""points_awarded"": 0 }, ""description"": ""(2c). Test for Gibbs convergence (5 points)"" },

So json file says 0 points awarded?', u'responses': [u'I wish we could test more than 5 times. Sounds like your code didn't return a solution if initial_state = [] maybe?', u'Hmm, you are right. I only dealt with None input, but not []. Will test it now. Thanks!!!', u'I only took None as well and got a 5/5 so don't think that is it.']}, {u'text': u'Hint on p(BvC | AvB = 0, CvA = 2)

I'm scratching my head how to compute this value.

I'm thinking of reducing this to just p(BvC=i | B, C) =  p(B) * P(C) * P(BvC=i | p(B), p(C))
for i = 0, 1,2 

However, this doesn't seem to use the conditions given, i.e AvB = 0, CvA = 2

I'm alternatively interpreting it as p(BvC=i | AvB = 0, CvA = 2)  = p(AvB = 0) * p(CvA=2) * p(BvC=i) for i =0,1, 2
for that particular sample.

Any hint about getting this distribution? This is the only part I'm yet yo figure out', u'responses': [u'P(BvC) is just P((BvC)|B,C)', u'Are you sure about that Brett? Why wouldn't you include the probabilities of B and C in the equation as well since they are part of the Markov blanket for BvC?

I was doing the same as James:

P(BvC=0) = P(B) * P(C) * P(BvC = 0 | B, C)
P(BvC=1) = P(B) * P(C) * P(BvC = 1 | B, C)
P(BvC=2) = P(B) * P(C) * P(BvC = 2 | B, C)

and then normalizing? Does that reduce to the same thing as P(BvC | B, C)?', u'While I haven't submitted to Bonnie, I also think P(BvC) is just P((BvC)|B,C)', u'I haven't submitted yet but my solution is converging on the basis of using P(BvC | state) = P(BvC | B, C)

I believe the definition of a Markov Blanket is the node's parents, its children, and its children's parents. From that interpretation, B and C are not part of BvC's blanket...']}, {u'text': u'In the unit tests, my unit test 3 is passing, but unit test 4 is returning ""incorrect posterior calculated"". Since test 3 is passing, I'm assuming that my distribution tables are correct. If that is the case, I don't understand how test 4 would fail since we only need to specify the evidence and all the calculation is done in the engine. I'm sure the evidence I've specified is correct. Could I be missing something else?', u'responses': [u'Nevermind. I realized I was using JunctionTreeEngine instead of EnumerationEngine. ']}, {u'text': u'I cannot figure out what is going wrong with my Bonnie submissions for the Gibbs_sampling tests. Everything works fine locally, but I get the following errors on Bonnie:

    {
      ""output"": {
        ""points_available"": 5,
        ""message"": ""Gibbs_sampling failed due to error: EXCEPTION IN (run.py, LINE 593 \""sample = pn.Gibbs_sampler(game_net, list(initial_state)) # returns a tuple\""): The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"",
        ""return_type_check"": true,
        ""points_awarded"": 0
      },
      ""description"": ""(2c). Test for Gibbs convergence (5 points)""
    },
    {
      ""output"": {
        ""points_available"": 10,
        ""message"": ""When provided no initial state, Gibbs should generate a state from uniform distribution. \nGibbs_sampling failed due to error: EXCEPTION IN (run.py, LINE 518 \""test_sample = pn.Gibbs_sampler(game_net, list(initial_state))\""): The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"",
        ""return_type_check"": true,
        ""points_awarded"": 0
      },
      ""description"": ""(2c). Test that Gibbs is implemented correctly. (10 points)""
    },

I can't narrow down what line this error is being thrown on since run.py seems to catch the error and print the unhelpful ""EXCEPTION IN (run.py, LINE 518 \""test_sample = pn.Gibbs_sampler(game_net, list(initial_state))"".

I have removed any conditionals with just an array as the condition in case a numpy array is being passed in. Does anyone know what else can cause this error? I only have 2 submissions left and I'm scared to try anything else without a high degree of certainty that it will work.', u'responses': [u'From the message in the second test, it looks like when bonnie feeds an input where the initial_state variable is None or [], you aren't handling it correctly by providing a uniform random distribution as a sample. I implemented a check for both of these possibilities for Gibbs and MH.

Essentially, you need to provide randomly generated values for A, B, C, AvB, BvC, and CvA and return them as a sample when given an initial_state value of None or []. Uniform just means equally likely to be any of the values that could be chosen. 

This requirement comes from the last paragraph of 2c and 2d in the Readme.']}, {u'text': u'Hi All, I have some confusion regarding parts 2c to 2e
For 2c (Gibbs Sampler):
My understanding is that if initial_state is [] or None (empty), then we randomly assign values to each of the 6 nodes. If the initial state is not empty, then we randomly choose one variable, and update the value. So here are my questions regarding Gibbs:

1) Does the initial_state ever come in partially filled? i.e. ([None, None, None, 0, None, 2]). And if yes, does that mean we randomly assign values to the remaining nodes and return that as a candidate and then still randomly update one of those nodes with a random value? Or, is the 0 and 2 considered ""evidence"", and they should remain fixed?

2) What is the purpose of calculating the probability? Inside Gibbs_sampler(), my understanding is that we're creating a new candidate state, so why do we need to calculate the probability? Is this only done when calculating convergence in the samples? P(A|B,C, AB, CA)
= P(A=a, B,C, AB, CA) / sum_A P(A, B,C, AB, CA) [enumerate]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / sum_A P(A)P(B)P(C)P(AB|A,B)P(CA|A,C) [factor out]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / P(B)P(C) sum_A P(A)P(AB|A,B)P(CA|A,C) [move factors independent of A out]
= P(A=a)P(AB|A=a,B)P(CA|A=a,C) /  sum_A P(A)P(AB|A,B)P(CA|A,C) [ cancel like terms]

For 2d (Metropolis-Hastings):From my understanding the main difference between MH and Gibbs, is that in MH, we can have multiple variables change, and that we're probabilistically determining if the candidate should be accepted.

1) Can someone explain how we determine which variable(s) to change? Do we just go through each variable and randomly adjust it? Once we get the candidate state, we calculate the alpha and accept/reject it accordingly?

For 2e Sampling1) For part 2e it says ""A beats B and A draws with C, you should now estimate the likelihood of different outcomes for the third match by running Gibbs sampling until it converges to a stationary distribution"". Are we supposed to call our Gibbs_sampler method with the initial state [None, None, None, 0, None, 2] to reflect the evidence?
', u'responses': [u'Gibbs:
1) I did not handle partially filled initial_states, only a complete state or a totally empty state. Everything passes for me on Bonnie so I think you can safely ignore that edge case. 
2) In Gibbs you are randomly selecting one variable of the 4 that could change (A, B, C, BvC) and then calculating a value for it based on the other initial state variables. You aren't calculating the full probability that the new state will occur. 
MH:
1) Your candidate sample may change any or all of the 4 variables that are not evidence, these variables are determined randomly. Once you have that new sample, as you state above, you calculate alpha and determine if it should be accepted. 
2e:
1) Yes, you will call your Gibbs method with an initial state. Given the problem statement you can assume AvB = 0 and CvA = 2. People implemented Gibbs differently in terms of handling evidence, so the way you process the initial state in Gibbs will be implementation specific.', u'Am I correct in thinking ""calculating a value for it based on the other initial state variables"" is really just as simple as multiplying the match and skill table values based on the current state after choosing one index to change in the initial state (or multiple for MH)?', u'Thanks Sandy!
That was very helpful. 

Just for clarification, how we handle the evidence is up to us, but for part 2e) The first time we call Gibbs, we are passing a partial state [None, None, None, 0, None, 2]. But for future iterations, are are we still passing only the partial state as evidence? Or are we passing in the state that was generated the last time? 
', u'Minh - the process for finding the probability of the randomly chosen variable will depend on whether it is a skill level variable or a match outcome variable. One is a bit easier than the other... see above posts for more discussion on that. 
Gibbs is a form of MH, these excerpts come from the Yildirim MH paper to provide some comparison ""Are Gibbs sampling and MH sampling related? Yes. In fact, Gibbs sampling is a special case of MH sampling where proposal distributions are the posterior conditionals. Recall that all proposals are accepted in Gibbs sampling, which implies that the acceptance probability is always 1."" and then ""Finally, there are cases in which Gibbs sampling will be very inefficient. That is, the “mixing” of the Gibbs sampling chain might be very slow, meaning that the algorithm may spend a long time exploring a local region with high density, and thus take very long to explore all regions with significant probability mass"". The uniform randomness of MH allows the sample to move around a bit more.

William - at the risk of saying too much in answering your question I suggest rewatching Lesson 6.43 ""Gibbs Sampling"". That will answer your question.', u'Thanks.', u'""Your candidate sample may change any or all of the 4 variables that are not evidence, ""
For Gibbs, I randomly select one variable out of 6 (6, not 4 right?) to update and then calculate its probability distribution given the state of all 6 variables and from that distribution I pick a new value to return a new state.

Would it be that form HM, first I have to randomly choose how many variables to update and then randomly pick those variables?
Like, 1) Pick how many to update randomly, example, 3, then 2) Pick n (in this example 3) variables to update from all 6?', u'People handled evidence in Gibbs differently, but in general you wouldn't want to change AvB and CvA because those are fixed by the problem statement. For MH, I just randomly updated each of the non-fixed variables. I didn't worry about how many actually changed, just assume up to 4 (in this problem) can change with each iteration.']}, {u'text': u'Is there a reason that Gibbs doesn't require a alpha or acceptance comparison like MH? For Gibbs, it seems like I'm just calculating the probability distribution of all the possible states of a random index in the initial state and then making my new state based on a random sampling of the possible values for the index (0,1,2 for match as well as 3 for skill) based on the probability distribution of those different states. For MH, I'm calculating just the new probably of the new completely random state (other than evidence) and then using the acceptance ratio of the probabilities compared to a uniform random value from 0 to 1 to determine whether I accept it.

Couldn't I just pick the state (initial or new) at random if the acceptance ratio is below 1 and always accept the new state if it is above 1? It seems like using 0 to 1 is just to make up for the lack of a simple random selection function.

', u'responses': [u'MH uses random samples with the ""information"" from the ratio of probabilities to drive the convergence. For Gibbs, the sample generating step already accounts for the information since it uses the calculated distribution of the chosen variable to make new samples, so does not need an acceptance step. I think there is a section in a textbook that goes into detail about why Gibbs works.']}, {u'text': u'I'm getting 8/10 points on 2c, testing the Gibbs sampler. Has anyone else gotten this? Did you manage to fix it/ see what would be removing 2 points? Other than that I'm getting full marks, so it's not a major concern.', u'responses': [u'Any info in the message on this section from Bonnie?', u'No, it's the first place I checked. Nothing indicating why it's a 2 point loss. I'm wondering if it just converged slower than expected?', u'If you received full points on the compare_function portion, then it's within the Gibbs_function itself. 

My first thought would be if you're not correctly selecting the new state of the randomly chosen variable with the updated probabilities. In theory, bonnie could check the probability distribution on the same state over and over and see if your function returns a similar distribution within a range. If you're outside the range, you may lose points.']}, {u'text': u'Anyone has faced issue in Gibbs Sampler that probability converges to 0.2,0.6,0.2 rather than the required answer. Following the paper my algorithm looks good ,but might be I have done some thing wrong in my implementation. If anyone can please provide any pointers for debugging.
Thank you', u'responses': [u'Not sure if I can be of help with the information provided but here is my input. While building Gibbs I paid close attention to Figure 14.16 in the book. I made sure to understand the normalization of N.
During this process I debugged by:
- Doing calculations by hand and comparing it to the output.
- Stepping through the code. Found a few bugs dealing with indexing out of bounds. 
Once Gibbs was working:
- How are you calculating your convergence?
- Try increasing your burn in period. This value was key for my implementation. ', u'Agree that you need to step through your code, if you are comfortable with the algorithm then you likely have a bug. I had a similar result for MH and realized I had a repeated index value (something like [BvCCount[0], BvCCount[1], BvCCount[0]] instead of [BvCCount[0], BvCCount[1], BvCCount[2]] ) that was resulting in two equal decimal values in a distribution. I also had a bug where I had the order wrong for A, B, or C when using skill as index. I ended up using a bunch of scratch paper and a calculator to find those bugs, they weren't obvious. Good luck!', u'Thanks Edgar and Sandy
I was able to find bug my bug doing hand calculations and going step by step. I had a implementation issue where I choose index instead of actual value at one place.', u'Is there a simple way to know if you're doing the hand calculations correctly? Did you use the inference to check your calculations?']}, {u'text': u'Which algorithm converges more quickly? By approximately what factor? For instance, if Metropolis-Hastings takes twice as many iterations to converge as Gibbs sampling, you'd say that Gibbs converged faster by a factor of 2. Fill in sampling_question() to answer both parts.

Should we hardcode values based on local testing, or , we should create bayes_net and call compare_sampling and calculate the value at runtime?', u'responses': [u'It sounds like we just choose one method from the options [0, 1] and then put the factor of how many more iterations it takes the other method. I think choice = 2 is just an impossibly wrong answer the same way factor = 0 is.', u'For that sampling_question(), just hardcode the values for choice and factor. The default values choice=2 and factor=0 are meant to be wrong as mentioned by Minh.']}, {u'text': u'Regarding expected value, what are we defining that as? The assignment says: 

the difference in <strong>expected outcome</strong> for the 3rd match differs from the previous <strong>estimated outcome</strong> by less than ""delta"".
I've been calculating the expected value using:
P(B wins) * 0 + P(C wins) * 1 + P(tie) * 2 = expected value for 3rd game

The numerical values for the categories (B winning, C winning, tie) seem arbitrary though. Any clarity on what the definition of ""expected"" value is would be great. 
', u'responses': [u'
', u'You could try that. Or you can check if each of the 3 probabilites (win,loss,tie) are within delta of the previous probabilities. ', u'Also, could try euclidean  distance ', u'I ended up going with Euclidian distance function and it works better (and more evenly) I think ', u'Also, check Erik's response on https://piazza.com/class/jc6w44hrp9v2ki?cid=548', u'An interesting idea using Euclidean distance. Would you have x and y coordinates or just assume that the expected value is just a radial distance from the calculated probabilities like so?

$$ E[R]={\sqrt{X1^{2}+X2^{2}}}$$']}, {u'text': u'Quick question:
Is the expectation that after a large number of runs, both the Gibbs and MH distributions will converge to the posterior distribution we calculated in 2b?
OR
Is it supposed to converge to the appropriate Team 1 vs Team 2 distribution based on the skill level of the teams in the initial state. 

', u'responses': [u'+1 for this question. I'm leaning toward the whole point of the exercise being to match the posterior distribution produced by the inference engine to develop our intuition of how it works', u'Yes, after a reasonable number of runs, both MH and Gibbs should come close to the 2b results. They are not likely to be exact as the algorithms are approximations. Also, as the write up mentions some burn-in may or may not be required.']}, {u'text': u'when getting the probability of AB for example, I do the following as provided in the readme to get the distribution table
AvB_match_table = AvB.dist.table
but once I have it, how do I determine which probability I should be selecting from the table?
if I have the outcome of AvB = 1 then I know I need to draw from column 1 in the table, but what about the row?... is this determined by multiplying out the two different possible row values? (given by A and B separately)

So if A_skill = 1 and B_skill = 2, then I assume I would need to do something like this:
AvB_probability = AvB_match_table[1,1] * AvB_match_table[2,1]

does this seem right?', u'responses': [u'As I am not sure about how directly one can answer with code snippets, I am going to use another example
from the README.md.

A_distribution = ConditionalDiscreteDistribution(nodes=[G_node, T_node, A_node], table=dist)

This creates a 3 dim array which can be accessed as:
p = A_distribution[G_state][T_state][A_state]

Also, I found this link useful: https://github.com/slychika/pbnt (although, all relevant info is already in the a03 README.md)
']}, {u'text': u'In Gibbs sampling, once you get a distribution of the probabilities for all values of, say A=a, what does sampling a new value for A mean? Do i randomly select a new value for A? If that's the case, the probability calculation doesn't make sense. So is it based on likelihood weighting?', u'responses': [u'Once you have calculated the probability distribution for p(A) based on the , select randomly from the calculated distribution.

Basically one is sampling the variable ""from the conditional distribution with the remaining variables fixed to their current values"" Ref: http://www.mit.edu/~ilkery/papers/GibbsSampling.pdf


', u'I mean, I understand that I COULD just select a random state and use that... the disconnect for me is why do we need to figure out the probabilities at all if it's a state and not a probability that we need to return?', u'Seems to have to do with that it's not an entirely random state. You choose the new state in Gibbs based on the posterior probability.

I.e. ""Gibbs sampling is a special case of MH sampling where proposal distributions are the posterior conditionals. Recall that all proposals are accepted in Gibbs sampling, which implies that the acceptance probability is always 1.""

That's where the magic is. At least to me.']}, {u'text': u'for both Gibbs and MH, I'm a bit confused about the return values... within the function my understanding is that we generate a probability distribution for the randomly chosen variable and then we randomly select a value from that distribution, but where does the randomly selected value go at this point?  the initial input value is a list of 6 value for A,B,C, AvB, BvC, and CvA so it looks like [1,2,1,0,2,0] for example... these are indexes not probabilities... so I'm expecting that the returned tuple of 6 should also look like that... so how do I turn the randomly sampled probability distribution value into an index?

I think I'm just really confused about what these functions are expecting for return values... it doesn't make sense to me', u'responses': [u'They are both expecting a new state tuple.

For Gibbs, what you said -""we generate a probability distribution for the randomly chosen variable and then we randomly select a value from that distribution"" is almost correct- just one change- then we randomly select a value using  that distribution, not from that distribution.', u'so I'd want to select a new index state value using the probability distribution... that seems to make sense, but I'm not clear on the how...

once I have the distribution, how do I use it to select a value?', u'I have a list of probabilities that all add up to 1, but how do I translate that to a new state value?  if I randomly select from the probabilities, I have a single probability value that seems to me to be meaningless... what does that randomly selected probability value mean? or rather, how do I translate it to an index value to generate a new state?  I'm somehow lost on this last part and I haven't quite found the disconnect...', u'Considering that the probability distribution that you have calculated is the list of probabilities for all possible values of a variable, we are trying to sample using this distribution.

For a quick refresher, check the first couple of minutes of this video. 
https://www.youtube.com/watch?v=ol0l6aTfb_g
This example is for a distribution over two states. Just extend it to as many states as relevant - 4 for skill levels, etc.', u'Here's something usable...

From the README.md...
Hint 2: you'll also want to use the random package (e.g. random.randint()) for the probabilistic choices that sampling makes.
https://docs.scipy.org/doc/numpy/reference/routines.random.html
', u'my reply above was meant to be down here... I understand that I can just randomly selected an integer from the possible skill values and return that as the new state, what I'm not getting is what is the point of calculating the probabilities?  what purpose do they serve in selecting the new state value?  the videos and readings aren't very clear on that part', u'Yeah, I have a lot of questions too but no one seems to be able to answer them. Basically ""sink or swim"". Don't miss the office hours at 5 pm with Theodore on Saturdays.', u'The Gibbs and MH sampler returns a new sample, not a list of probabilities. The point of calculating the probabilities is to make new samples that fits the Gibbs/MH algorithm. If you just completely randomly change a variable and return it as a new sample, it is not consistent, and the resulting distribution for a variable is not the correct one.', u'And the new sample ""fits"" Gibbs because the sample choice for the randomly selected variable is dependent on the probability of that choice for the variable?', u'I understand I'm not returning probabilities, but actual states.  That's always made sense, what I am missing is I can't seem to figure out how the variable sampling is actually done... the lecture and papers don't seem to explain it very well, or I'm completely missing something...', u'specifically, my breakdown in understanding is with this part from a post above:

P(A|B,C, AB, CA)
= P(A=a, B,C, AB, CA) / sum_A P(A, B,C, AB, CA) [enumerate]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / sum_A P(A)P(B)P(C)P(AB|A,B)P(CA|A,C) [factor out]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / P(B)P(C) sum_A P(A)P(AB|A,B)P(CA|A,C) [move factors independent of A out]
= P(A=a)P(AB|A=a,B)P(CA|A=a,C) /  sum_A P(A)P(AB|A,B)P(CA|A,C) [ cancel like terms]
You should result in a probabilities for each value of a, which should sum up to 1.
Sample from this distribution to get new a.

once I have the probabilities for each value of a, do I just select the new value of a as the one with the highest probability from the distribution I generated?  or is there some other method that I'm missing... everything I read just says ""sample it""... but what does that actually mean? that's what I'm not clear on', u'I think I found the way to do this, something like the following:
numpy.random.choice(numpy.arange(1, 7), p=[0.1, 0.05, 0.05, 0.2, 0.4, 0.2])']}, {u'text': u'I can't wrap my head around convergence. I'm trying to see if for for all 10 consecutive calls to Gibbs, the difference in probabilities is less than the delta. But I seem to be stuck in an infinite loop. Any ideas about how to implement convergence would be great.', u'responses': [u'Check across iterations within the same run']}, {u'text': u'I keep getting the following errors when submit. I provided a uniform distribution if initial state is absent. And the sampling was able to converge locally.

""When provided no initial state, Gibbs should generate a state from uniform distribution. \nGibbs_sampling failed due to error: EXCEPTION IN (run.py, LINE 518 \""test_sample = pn.Gibbs_sampler(game_net, list(initial_state))\""): probabilities do not sum to 1""

""Gibbs_sampling failed due to error: EXCEPTION IN (run.py, LINE 593 \""sample = pn.Gibbs_sampler(game_net, list(initial_state)) # returns a tuple\""): probabilities do not sum to 1""
', u'responses': [u'Just to be sure, are you returning a uniform distribution, or a state with all variables selected according to uniform distribution? ', u'Is a random selection for each variable considered uniform distribution in this case? like 
[randint(0, 3), randint(0, 3), randint(0, 3), randint(0, 2), randint(0, 2), randint(0, 2)]
', u'Are you handling the InitialState==None, []?
', u'Right. If initial_state == None or []: return the above state
', u'And, just making sure, you are returning a tuple. 

""Looking up different lists with the same contents would produce different results, even though comparing lists with the same contents would indicate them as equivalent"". This could potentially lead to an issue like this.', u'The tuple is just for the grading program then?', u'Both samplers return tuples. Is it possible to check the logic at run.py: LINE 518? Right now, it's a blackbox and the limit on the number of submissions doesn't allow me to do additional debugging.', u'One suggestion is to be sure that you are applying the normalizer when calculating the probabilities, in Gibbs', u'For each sampler, the returned tuple should not be normalized, right. It is a tuple of sample variable values of length 6, like (1, 3, 2, 1, 0, 2)', u'It turns out I was still using numpy 1.8. The error stems from numpy.random.choice of numpy 1.11 or above.

Vagrant should have the same numpy version as bonnie I suppose. How come it is also 1.8 as I checked?
']}, {u'text': u'How do we use the new sampled state returned from Gibbs Sampler? Do we just observe the value of BvC returned from Gibbs Sampler each time and update a distribution?

Edit: Yeah I think this is the way. My gibbs sampler is giving a uniform distribution for BvC lol', u'responses': [u'From what I understood, ""Gibbs sampling is a special case of MH sampling where proposal distributions are the posterior conditionals. Recall that all proposals are accepted in Gibbs sampling, which implies that the acceptance probability is always 1."" Thus if your Gibbs sampling is correctly setup as stated in this quote, you always have a better approximation of the correct probability distribution and thus every time you sample that ONE random variable per the Gibbs method, you get closer to the solution. 

With MH on the other hand, you randomly select variables from for the entire state (besides evidence) and use the resulting acceptance ratio to decide whether the new state is a closer approximation and accept it or further and reject it.', u'Uniform distribution for BvC? On the initial iteration or after a ""sufficiently large"" number of iterations? Your Gibbs Sampler should be returning the same value as your calculate_posterior function after sampling sufficiently.', u'how do you arrive at a new state given the probability distribution?  I have gotten to the point in Gibbs where I have a probability distribution equal to a total of 1, but I can't figure out how we actually generate a new state from that...', u'Well, all I know is that your Gibbs output has to equal (approximate) your calculate_posterior function if you give it the same initial values after repeating the Gibbs sampling a number of times.

As I take it, if you calculated the probability distribution for your randomly selected variable (i.e. what would be the probability of state 0,1, 2, 3 be like for that variable?), you then need to decide on what to take as a sample for that variable you selected. So if the variable has states [0, 1, 2] and you calculated their probability to be [0.1, 0.8, 0.1], you could guess that more often than not, the correct state is 1. But we're not just guessing like that because we could be wrong. Instead we're sampling so you should decide randomly BASED on that probability. After enough iterations of Gibbs, you should arrive at the most likely state variables for the given conditions.', u'Yeah after 500,000 iterations I get [0.33, 0.33, 0.33].', u'I just count up how many times the different values of BvC occurs to make the distribution', u'Do your calculate_posterior function again. I don't believe given that AvB = 0 and CvA = 2, that it is a uniform distribution for BvC. Obviously, B is a worse team than A and if C tied A, C must be close to the same skill level as A. Thus your posterior distribution for BvC should reflect that B is PROBABLY going to lose to C in [P(Bwin), P(Cwin), P(Tie)]. And if you have it set up correctly and are reasonably lucky, you shouldn't need more than a few thousand iterations (or less).', u'Yea that function is working as intended. Maybe i messed up some of the conditional probability in gibbs sampler', u'What happened was that I was passing the probability distribution without telling numpy which argument it was supposed to represent... So it was uniform no matter what', u'Ah. I see in someone else's post that they give the answer. So the answer SHOULD be [0.259, 0.428, 0.313]. Do you get that now?', u'[0.260236, 0.431242, 0.308524] close enough?', u'Yeah, that's it. Looks like it's working. My Bayesian belief that I understand what the Hell I'm doing went up a little.', u'@Minh, what do you mean we decide randomly based on the probability?  if it's random, how is it based on any probability?

specifically, my breakdown in understanding is with this part from a post above:
 
P(A|B,C, AB, CA)
= P(A=a, B,C, AB, CA) / <strong>sum_A</strong> P(A, B,C, AB, CA) [enumerate]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / <strong>sum_A</strong> P(A)P(B)P(C)P(AB|A,B)P(CA|A,C) [factor out]
= P(A=a)P(B)P(C)P(AB|A,B)P(CA|A,C) / P(B)P(C) <strong>sum_A</strong> P(A)P(AB|A,B)P(CA|A,C) [move factors independent of A out]
= P(A=a)P(AB|A=a,B)P(CA|A=a,C) /  <strong>sum_A</strong> P(A)P(AB|A,B)P(CA|A,C) [ cancel like terms]
You should result in a probabilities for each value of a, which should sum up to 1.
Sample from this distribution to get new a.
 
once I have the probabilities for each value of a, do I just select the new value of a as the one with the highest probability from the distribution I generated?  or is there some other method that I'm missing... everything I read just says ""sample it""... but what does that actually mean? that's what I'm not clear on', u' 
I think I found the way to do this, something like the following:
numpy.random.choice(numpy.arange(1, 7), p=[0.1, 0.05, 0.05, 0.2, 0.4, 0.2])
', u'Yep. That's how I do it. I've heard there are other methods with uniform(0,1) random sampling similar to MH or Euclidean distance but I have too little experience to understand the differences. Truth be told, I can't figure out why using random.choice works for Gibbs but doesn't work for MH. Something to do with how when using the weighting of the probability compare to a uniform(0,1) value favors the acceptance of higher assertion ratios but not exclusively whereas in Gibbs you assume you will always accept the new state.', u'awesome, I now have gibbs and mh at least running... unfortunately, I'm not getting the values to converge to the expected posterior...any tips on how the convergence is supposed to be done?  I don't quite get how we go from the step of only running the sampler once to running it until convergence...']}, {u'text': u'This is what I got on Bonnie for MH convergence-
 

{
""output"": {
""points_available"": 5,
""message"": ""Incorrect distribution generated after 500000 runs. Should have reached something near [0.259, 0.428, 0.313] instead of ['0.19', '0.50', '0.31'].\n"",
""return_type_check"": true,
""points_awarded"": 0
}
""description"": ""(2d). Test for MH convergence. (5 points)""
}

In my implementation, I'm generating a random value for all variables except the evidence variables for the new state. I'm then calculating the acceptance ratio by min(1, P(new)/P(old)), generating mu between 0 and 1 and returning the new state if mu <= acceptance, else the old state. I don't know where I'm going wrong to cause the variation in the answer. 
Am I missing something?
', u'responses': [u'Hmm. Your method appears valid from what I've read. The value you're returning looks like the same as if you only did one or a few iterations. Did you try looking at how your answer converges towards the correct solution by printing out each accepted iteration of MH?', u'Yes, there was a small index error in my P calculation. It is working fine now :)', u'I had this error when my evidence wasn't hard coded.']}, {u'text': u'I don't fully understand the probabilities in MH in the book and the PDFs and want to check my understanding. 

π(x) is the probability that x would have been chosen, given the evidence involved. So if the evidence is [1, 1, , , , ] and x is [1, 1, 0, 0, 0, 0], we'd calculate the probability of getting x given the evidence. Is that right?

q(x'|x) and q(x|x') make much less sense to me for this application, since there isn't really a relationship between x and x' if we're sampling them from a uniform proposal distribution. Is the idea that since x and x' are equally likely, the probabilities cancel in the acceptance criteria and we are left with just the ratio of π's?

That doesn't seem right to me because some x's are more likely than others, but I'm stumped as to how to calculate the q's otherwise. Should we be calculating the probability of getting a particular value for BvC given the rest of the state? Any pointers here would be great because I'm going in circles a bit.', u'responses': [u'This video helped to understand MH: https://www.youtube.com/watch?v=h1NOS_wxgGg
Yes, the q terms can be avoided (cancels out) if you use a symmetric proposal function, e.g. uniform distribution']}, {u'text': u'for Gibbs_sampler my solution fails for EXCEPTION IN (run.py, LINE 518 \""test_sample = pn.Gibbs_sampler(game_net, list(initial_state))\""): [Errno 27] File too large"",
anyone know how do I fix?', u'responses': []}, {u'text': u'I got past my hurdles on gibbs, now I'm trying my darndest to wrap my head around MH...

my understanding of the process is as follows:
start with an initial state of all values
generate a candidate state (is this completely random or is it based on something?  I've seen mention of using a distribution to determine steps but honestly haven't really understood this... and wouldn't a random choice end up working anyway since we still have the alpha check?)

now compare initial and candidate states to generate an alpha... this alpha equation is where I really get hung up... is alpha just the following or am I missing something here?
alpha = [a_cand_prob * b_cand_prob * ...]/[a_prob * b_prob * ...]
', u'responses': [u'I generated a completely random sample for (A, B, C, BvC) on each iteration (AvB and CvA fixed, since they are given). This is important because it allows you skip calculating the q term in the alpha calculation.

For the alpha value, I only looked at P(BvC) for the candidate and previous iteration. Alpha is the minimum of the P(BvC - current) / P(BvC - previous) and 1.0. That seemed to work.

I found this video quite helpful: https://www.youtube.com/watch?v=h1NOS_wxgGg&t=1148s', u'for gibbs and MH, should the convergence checks be performed inside the sampler or outside?

would the check for alpha not be considered a convergence check?

I'm having a hard time getting either algorithm to converge to the expected posterior', u'That video is a good start. Try getting Gibbs working first. At least for me, it was more intuitive. Ignore the convergence and delta stuff for now. Just run it for a 1000 (or 10000) iterations like a burn and see what your final sample is. Remember to use your sample output as your new input for the each Gibbs sampling step. It should be obviously approaching [0.259, 0.428, 0.313] but not quite there. That means you're on the right track and can continue to finish the convergence (Gibbs first) with a while loop and the additional stopping conditions you ignored. MH shouldn't be much more work I think.', u'ok, so I think I must be misunderstanding something about running Gibbs multiple times...

I run Gibbs, which generates a new sample, which is a tuple of values for (A,B,C, AvB,BvC,CvA)...
then I get the new posterior for BvC using the match table as show in the readme and compare it to my previous posterior (this is where the diff is checked?)
then I loop and run Gibbs on that newly generated tuple and continue looping and comparing until the diff is less than 0.1...

but it seems I am missing something... for the BvC posteriors should I be combining them somehow? is that how you converge at a specific value?', u'At least for me, I had to turn the new sample back into a list to run it through the Gibbs sampling function again. I seem to understand it's because there may be an error if you're comparing lists rather than tuples. Again, it's over my head but that's what they say so I believe them.

Not sure what you are doing with the match table but realize that your output from Gibbs sampling IS your new posterior. You don't need to do anything. Just feed it back into itself. Like I said, ignore the delta check for now if you aren't approaching the known solution from calculate_posterior just based on brute force of 1000 runs.', u'I think that part is working fine (no errors anyway)...

but for the convergence do you calculate an average over all the posteriors generated?', u'Well, I guess it depends on how you do it. But I take the state output from a single iteration of Gibbs sampling and take the expected value for BvC (win, lose, tie). Then I just normalize my convergence output of all those expected states to 1 to get the posterior approximation.', u'Minh, I really appreciate the help.  I've posted an expanded explanation of what I'm not understanding in @580 if anyone gets a chance to weigh in']}, {u'text': u'For MH, when we're calculating alpha, so π(x_cand)/π(x(i-1)), which way are we computing π?

like this? π(x) = P(BvC=x[BvC] | x[B], x[C]) In other words, the probability we get the value we randomly generated for BvC given B and C, because the skill levels of B and C are already present in x and are the only thing that affects the outcomes of BvC. This seems to be how other people are interpreting MH, but doesn't intuitively make sense to me because then the evidence isn't ever used: we're sampling from the uniform distribution so the evidence isn't weighed there, and then it's not incorporated into π, and therefore alpha, either. 

So maybe it's like this?
P(x|e) = P(BvC, A, B, C | AvB, CvA) or in other words, the probability that we'd get this combination of BvC, A, B, and C given the evidence for AvB and CvA. 
so this would boil down to P(BvC|e) * P(A|e) * P(B|e) * P(C|e)
is that the right approach?', u'responses': [u'If you want a quick (and correct) answer to this it seems better to post a new thread unfortunately.

Saying that, I think your later idea is closer to the truth, I believe.', u'Ok, I'll post it in a new thread']}, {u'text': u'I got exception error.
 ""output"": { ""points_available"": 19, ""message"": ""Sampling comparison failed to execute due to error: \nEXCEPTION IN (run.py, LINE 863 \""sampling_choice, factor = pn.sampling_question()\""): list index out of range\n"", ""return_type_check"": true, ""points_awarded"": 17 }, ""description"": ""(2e). Testing compare_sampling. (20 points)"" Does anyone know what caused of this exception error?I returned lists of floats for Gibbs_convergence and MH convergence.', u'responses': [u'This error is due to invalid index. Choice corresponds to the index of the list, which should be 0 or 1. Seems like you're setting it to something >= 2.', u'But I did not use any choice in my codes. :(', u'You have to edit the sampling_question() function to change the hard-coded choice (which is 2 and of course won't work)... ', u'Thank you', u'Can the factor be float?', u'I presume it could.  I just checked mine again.. it was just an integer.  I'm not sure how much they are validating that response other than making sure you have one.', u'I didn't have any problem submitting with a float. I think that question is kind of a gimmie though. I wish they had put it at like 1 point so I wouldn't have wasted so much time trying to get it perfect. Then again, it's easy points.', u'thank you']}, {u'text': u'any suggestions on what to look for if my gibbs sampler isn't converging to the expected posterior?  my resulting posteriors are different with each run of gibbs I do... sometimes the values are close to what the expected posterior is, but other times it is way off...', u'responses': [u'Try tuning the hyperparameters, like lowering delta and raising N and the burn-in count.', u'See @582...    There always seems to be some variance in each run.', u'Do you know what is allowed variance? I have only one submit left and got 98. I fixed the two point issue.', u'thanks guys, I'll try those out and keep looking', u'Wooseog, I don't know what the variance is, but I presume it is pretty large.  The issue you have with 5th submission is that if you've broken something else you could lose points with no way to recover.   I'd be very sure that I'm feeling lucky and really want those two points before I did another submission.']}, {u'text': u'I posted a separate thread for this, but it's driving me up a wall and I'm hoping to get some more feedback if I post here...

more detail can be found in @587

I submitted to bonnie and it says my distributions for the game network are wrong...  it's showing the the distributions for A,B, and C and AvB, BvC, CvA are swapped somehow...  I assigned everything as outlined in the assignment and when I manually check the distribution tables they are correct...', u'responses': []}]",,18.0,331.0,465,,Assignment 3 Part 2 Discussion: Sampling,[a3]
5ad7d45e0d63974e20c39189,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.


SIMULATED ANNEALING
 
1) You are performing Simulated Annealing on a search space. Given that you are at a specific state with a value given by E, and you find a new state given by E', what is the probability of the new value being accepted as per the values given below?
 

Current State, E
(Evaluation)

Potential New State, E'
(Evaluation)
TemperatureProbability of Accepting1006050_________________20012050_________________10025150_________________20021030_________________100150300_________________20040300_________________
 
2) When performing Simulated Annealing, should you start with a temperature of infinity or some finite value? What factors would influence your decision?
 
3) In the ideal case, Simulated Annealing runs in a continuous fashion, with Temperature taking infinitely small steps; however, if you were to ""cheat"" by taking discrete steps, what issues might you run into? How would you know if your answer was right?




Solution: @545",jc6w44hrp9v2ki,"[{u'text': u'
2) I think Temp should be large enough to jump off the small peaks but not bypass the global maxima..... A prior knowledge of limits of maximum and minimum values possible would help....

3) If the Annealing steps are discrete, we might miss some maxima values which could be global maxima. Once missed, there is no way to know if the answer is right, unless a fresh search is started or random restart is performed.

', u'responses': [u'I believe there is a sign error']}, {u'text': u'1. Same answers as Saalis except for the last three. For 4 and 5 I think the probabilities will be 1 because delta E is greater than zero. Don't we always accept E' in those cases? For 6 there is a small typo where the answer is to e^-8/15

2. Starting with T = inf is pointless b/c lim of e^(delta E/T) -> 0 as T -> inf. You want to have some minimum absolute transition probability though. Based on the problem domain, you would know the maximum delta E and thus you could solve for a maximum starting temperature given max delta E and min transition probability.

3. In addition, you could also increase the granularity of your discrete steps as T -> 0 in order to narrow in on the very peak.', u'responses': [u'1: yes, when the move is an improvement, we always take it.', u'3. As an alternative, set a minimum temperature, set different rate regimes for different phases of learning, etcetera.

See Free Lunch, No & Free Lunch, Really No']}, {u'text': u'1) Calculate probability of accepting

Current State, E
(Evaluation)

Potential New State, E'
(Evaluation)
TemperatureProbability of Accepting1006050$$e^{-4/5} = 0.45$$20012050$$e^{-8/5} = 0.20$$10025150$$e^{-1/2} = 0.61$$200210301.01001503001.020040300$$e^{-8/15} = 0.59$$

2) Starting with an infinite value for T seems like a bad choice and not well suited to individual problems. I have read before that one simple choice is using the max($$\Delta E$$) for the problem space, but many other more accurate but complex schemes exist for choosing an initial value for T.

3) If you were to take discrete steps, I think you may run into accuracy issues and potentially miss the global maximum.', u'responses': []}]",,1.0,259.0,466,,Challenge Question 8 - Optimization Algorithms,"[lesson3, challengeqtns]"
5ad7d45f0d63974e20c3918a,"Time: Wednesday (2/14) at 2 PM Eastern Time

We'll be going over Assignment 3

Link: youtube

",jc6w44hrp9v2ki,"[{u'text': u'Will this session be recorded available also?', u'responses': [u'Yes, you can access it after the session is over at the same link.', u'Thanks ']}]",,0.0,283.0,467,,Youtube Live Event Assignment 3,[a3]
5ad7d45f0d63974e20c3918b,"I confess I am pretty daunted by the mathematics in AIMA chapter 14 and the supplemental papers on assignment 3.  I understood the video lectures and did well on its probability quizzes, but there's a pretty big step up in complexity in the accompanying written material.

An example is in the Metropolis Hastings paper, which in section 2 twice describes the example as ""simple"" but is very challenging to me.

Can we be successful in the assignment (and subsequent work) with limited understanding of these formulas?",jc6w44hrp9v2ki,"[{u'text': u'I just found out this morning that most of chapter 14 is missing from my international version of the book. I think this is really going to hamper my understanding of the formulas. :) That’s what I get for trying to save a buck. I’ll have to learn about Bayes networks elsewhere.', u'responses': [u'Ouch!  That is good to know.  I bit the bullet and bought the U.S. version but can recall most everyone saying that nothing was missing from the international version save the last 2 chapters.  Sounds like that was not the case.']}, {u'text': u'+1', u'responses': []}]",,0.0,223.0,468,"Is it possible the notation is tripping you up? When I was first familiarizing myself with the mathematical notation I found it helpful to rewrite the equations without notation and in plain English.

[original poster] Yes, that is likely, although probably not my only hindrance :)   I'll give it a try, thanks!",Math!,[a3]
5ad7d45f0d63974e20c3918c,"Anyone else having issues logging in to Buzzport or Udacity?

I'm getting AuthenticationException",jc6w44hrp9v2ki,"[{u'text': u'It's fixed now. I didn't do anything but wait 15 minutes.', u'responses': []}]",,0.0,137.0,469,"I had some issues, so went to http://passport.gatech.edu and once logged in there, could go to buzzport",Buzzport Login,[other]
5ad7d45f0d63974e20c3918d,"Hi Everyone 

In the lesson 6 slide 12(Explaining away quiz) Bayes rule is used to calculate P(R|H,S)
Could Somebody please explain this formula:

P(R|H,S) = P(H|R,S) * P(R|S) / P(H|S).

If I try to apply Bayes theorem shouldn't it be something like P(R|H,S) = P(H,S | R) * P(R) / P(H|S)?


Thanks
Alex",jc6w44hrp9v2ki,"[{u'text': u'I was confused about this at first too. Equation 13.3 in the textbook (page 496 in my version), deals with this explicitly:

... We will also have occasion to use a more general version [of Bayes rule] on some background evidence e.

P(Y | X, e) = ( P(X | Y, e) * P(Y | e) ) / P(X | e)

You'll find that the above corresponds exactly to the expansion of P(R | H, S) in the video where Y corresponds to R, X to H and S to e. It's just a more general version of Bayes rule that accounts for multiple variables instead of just two.', u'responses': [u'thanks']}]",,0.0,87.0,472,"If you rearrange ""P(R|H,S) = P(H,S | R) * P(R) / P(H|S)""
Proof:
Assume P(R|H,S) = P(H,S | R) * P(R) / P(H|S) is true,
P(H|S)*P(R|H,S) = P(H,S | R) * P(R) even when both sides are not with a trivial solution,
However,the left is P(R,H|S) while the right is P(H,S,R) and there is no guarantee that they are equal.
Thus,it was proven by contradiction.

I suggest you make P(R|H,S) = P(H|R,S) * P(R|S) / P(H|S) a multiplication on both sides to examine the correctness of your calculation.

Edit:also,P(R|H,S)* P(H|S) *P(S)= P(H|R,S) * P(R|S)*P(S).I hope this helps",Explaining away quiz,[lesson6]
5ad7d45f0d63974e20c3918e,I see assignment 1 in gradebook and don't see any score. So just making sure it is not released.,jc6w44hrp9v2ki,"[{u'text': u'I don't have a score yet either. Perhaps they are still dealing with the plagiarism cases.', u'responses': [u'We had T-Square issues after grading was done, but it's all been sorted out now.
Thanks for your patience, and apologies for the delay!']}, {u'text': u'Are the Assignment 1 scores still not released yet?', u'responses': [u'We had T-Square issues after grading was done, but it's all been sorted out now.
Thanks for your patience, and apologies for the delay!']}]","It hasn't been released yet. The TA in-charge had something come up, but is working on it now. Should be out by the end of the week. Apologies for the delay.",0.0,206.0,473,,Is Assignment 1 score released?,[a1]
5ad7d45f0d63974e20c3918f,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.
 

GENETIC ALGORITHMS
 
Consider a genetic algorithm in which individuals are represented using a 5-bit string of the form b1b2b3b4b5. An example of an individual is 00101, for which b1 = 0, b2 = 0, b3 = 1, b4 = 0, b5 = 1. The fitness function is defined over these individuals as follows:
 
f(b1b2b3b4b5) = b1 + b2 + b3 + b4 + b5 + AND(b1, b2, b3, b4, b5)
 
where
 
AND(b1, b2, b3, b4, b5) = 1, if b1 = b2 = b3 = b4 = b5 = 1
AND(b1, b2, b3, b4, b5) = 0, otherwise.
 
1) Given the following population, complete the following table to show the fitness levels and probabilities of selecting each of the following individuals.
 
IndividualFitness (f)Probability of Selection0010011000010011001000100
 
2) Now, for the individuals above, perform a single 1-point-crossover and a single mutation to come up with the child with the highest possible fitness. The point for crossover is the point between b3 and b4.
 





Solution: @546",jc6w44hrp9v2ki,"[{u'text': u'IndividualFitness (f)Probability of Selection0010010.1251100020.250100120.251001020.250010010.125

Let's set $$P(Mutation) = 0.25$$

>>> [random.random() for _ in range(6)]
[0.881114458530351, 0.02756158361166927, 0.21030806164068794, 0.6787757627334948, 0.08141647999217938, 0.009510629606315213]
random value 0.88: parent 1 00100
random value 0.03: parent 2 00100

child 1 00100, child 2 00100

mutation

child 1
random value 0.21, mutation
random value 0.68,  mutate 4th bit, 00110

child 2
random value 0.08, mutation
random value 0.01, mutate 1st bit, 10100

both child strings equal fitness level 2', u'responses': [u'Hey Mark, 
the first one is correct! However you can come up with a stronger descendant in no. 2.', u'You could, providing you could decide your own random numbers :-)

Obviously for instance a cross between 11000 & 01001 would have one of its children as 11001, a mutation in the 3rd or 4th bit would be 11101 or 11011 respectively, either would be of fitness level 4. Was that what you were trying to ask?', u'Yes, that's what we're going for.', u'Well done!']}, {u'text': u'So under this fitness function, the strongest would be [1,1,1,1,1] correct?
Given enough time should the algorithm find this solution?', u'responses': [u'Providing there were 2 children in the first generation similar to 11101 & 11011, then a cross between them, even without mutation, would have as one of its offspring 11111.

There is some handling of Genetic Algorithms in CS7641 Machine Learning, basically you notice that it tends to move more gradually, more organically, in the direction of the optimal answer, rather than purposefully']}, {u'text': u'1) Calculate Fitness and Probability of Selection for each individual.

IndividualFitness (f)Probability of Selection0010010.1251100020.250100120.251001020.25001001
0.125


2) Perform Crossover and Mutation
Choose 5 pairs with probability of selection proportional to each individual fitness score.Perform Crossover at the crossover point in between b3 and b4 represented by "".""With a probably of mutation of 1.0 randomly select a digit to mutate and randomly select a value in range(0, 1)Mutation digit marked in Bold
SelectionCrossoverMutation010.010101001000100.10100.101000010000001.00001.000011000110100.10010.010101001011100.10100.101000010000110.00

Calculate fitness and probability of children.
ChildrenFitness (f)Probability of Selection0100010.1251000010.1250011020.250101130.3751000010.125', u'responses': []}]",,2.0,240.0,474,,Challenge Question 9 - Optimization Algorithms,"[lesson3, challengeqtns]"
5ad7d45f0d63974e20c39190,"question says ""3 total matches are played. "" among A, B and C. What does it mean. Should I take it like A played one game with B, B played one game with C and C played one game with A ?",jc6w44hrp9v2ki,[],,0.0,153.0,476,"I think I did not read question right. there are 3 games AvB, BvC and CvA only.",question on game play Part 2,[a3]
5ad7d4600d63974e20c39191,"For Lesson 6 slide 8,
Can someone explain how the instructor went from:P(+2 | +1) 
to:
P(+2 | +1, C) * P(C | +1) + P(+2 | +1, !C) * P(!C | +1)



Thanks!
",jc6w44hrp9v2ki,[],,0.0,131.0,477,"P(+2 | +1) *P(+1)=(P(+2 | +1, C) * P(C | +1) + P(+2 | +1, !C) * P(!C | +1)) *P(+1)

Note: the naming fashion is: +2 means t2=+, opposite to t2=-
If you rearrange the above terms with Bayes Theorem,P(+2) = P(+2) is what you will get.

----

That expansion is the ""Total Probability"" for getting T2=+ (given that T1 is +).  It's summing all the ways you can get the ++ situation (if you KNOW you got one positive already), and there are two:
1. You can get a second positive test when you actually DO have cancer
2. You can get a second positive test when you actually DON'T have cancer.
But they're not equally likely -- they're weighted by their likelihoods, which is the second term in the expansion -- the likelihood of cancer or not (again, given that we DID get a positive first test, which the situation stipulates).

The next step drawn (reducing P(t2=+ | t1=+ , C) to P(t2=+ | C)  ) is the tricksy one, where t2 has lost its dependence on t1.  Because we're now assuming that cancer is certain (in the first term), t2 is no longer dependent on t1, but is solely dependent on the presence of cancer.

",Explain Cognitive Independence 2,[lesson6]
5ad7d4600d63974e20c39192,"I am having trouble trying to understand how landmarks and triangle inequality works on ALT search. Does any of you have a good support material on this subject?

Thanks!",jc6w44hrp9v2ki,[],,0.0,130.0,480,,ALT search,[a2]
5ad7d4600d63974e20c39193,"I am trying to understand unit tests. I see following for faulty gauage:
 test_prob1 = F_G_dist[0][1] test_prob2 = F_G_dist[1][0] self.assertEqual(int(test_prob1*100), 5, msg='Incorrect faulty gauge distribution') self.assertEqual(int(test_prob2*100), 20, msg='Incorrect faulty gauge distribution')

what do [0][1]. and [1][0] stand for here ?",jc6w44hrp9v2ki,[],,0.0,171.0,481,"Those are the indices into the table of the probability distribution for the F_G_node, that normally at that stage you should have set in your set_probability() function, see https://github.gatech.edu/omscs6601/assignment_3#1b-setting-the-probabilities",meaning of two[][] in distribution,[a3]
5ad7d4600d63974e20c39194,"The course designer could have easily left out lesson 5 and said ""you're expected to have a firm grasp of probability"".  For those of us who haven't touched probability in several years this was a GREAT refresher.  The examples are excellent and the quizzes help a lot.",jc6w44hrp9v2ki,[],,0.0,156.0,482,,Thanks for Lesson 5,[lesson5]
5ad7d4600d63974e20c39195,"So to learn some about Gibbs etc I am experimenting with the simple rain network but getting a result that I don't understand (or I'm setting up the Bayes network wrong). Here is the network -

The probability of cloudy P(C) = 0.5

But if I ask for the probability of cloudy via the network I get 0.58..

jt_engine = JunctionTreeEngine(bayes_net)
Q = jt_engine.marginal(cloudy)[0]
index = Q.generate_index([True],range(Q.nDims))
prob = Q[index]

However, if I disconnect the 'wet grass' node from the network I get the expected result P(C) = 0.5. The P(C) should be a constant (=0.5) regardless of the existence of the wet grass node - right?

Thanks
",jc6w44hrp9v2ki,"[{u'text': u'So I just got the idea to try EnumerationEngine instead of JunctionTreeEngine. Using EnumerationEngine the expected result (=0.5) is returned when the 'wet grass' node is included.
So now two questions instead of one .. a) why is the JunctionTree result wrong and b) what is the difference between EnumerationEngine and JunctionTreeEngine? Which should we use? (although for 2c and 2d I get we should use neither)
Thanks

', u'responses': []}, {u'text': u':-)

P(you are right) = 0.90.

However P(you are right | can read all code) = 0.5 or thereabouts I think.

Here is the code I used. I am having a hard time figuring out what might be wrong with it. It builds the network with and without the wet grass node and then calcs the marginal probability using both Junction Tree and Enumeration engines. Here is the result -

prob: 0.5 , engine: <Inference.JunctionTreeEngine instance at 0x10a46ebd8>prob: 0.5 , engine: <Inference.EnumerationEngine instance at 0x10a46ebd8>prob: 0.589356 , engine: <Inference.JunctionTreeEngine instance at 0x10a46ecb0>prob: 0.5 , engine: <Inference.EnumerationEngine instance at 0x10a46ecb0>
all the code-
from Inference import *def rain_network(include_wetgrass):    cNode = BayesNode(1, 2, name=""cloudy"")    sNode = BayesNode(2, 2, name=""sprinkler"")    cNode.add_child(sNode)    sNode.add_parent(cNode)    rNode = BayesNode(3, 2, name=""rain"")    cNode.add_child(rNode)    rNode.add_parent(cNode)    if include_wetgrass:        wNode = BayesNode(4, 2, name=""wetgrass"")        sNode.add_child(wNode)        rNode.add_child(wNode)        wNode.add_parent(sNode)        wNode.add_parent(rNode)    nodes = []    # cloudy distribution    cDistribution = DiscreteDistribution(cNode)    index = cDistribution.generate_index([], [])    cDistribution[index] = 0.5    cNode.set_dist(cDistribution)    nodes.append(cNode)    # sprinkler    dist = zeros([cNode.size(), sNode.size()], dtype=float32)    dist[0,] = 0.5    dist[1,] = [0.9, 0.1]    sDistribution = ConditionalDiscreteDistribution(nodes=[cNode, sNode], table=dist)    sNode.set_dist(sDistribution)    nodes.append(sNode)    # rain    dist = zeros([cNode.size(), rNode.size()], dtype=float32)    dist[0,] = [0.8, 0.2]    dist[1,] = [0.2, 0.8]    rDistribution = ConditionalDiscreteDistribution(nodes=[cNode, rNode], table=dist)    rNode.set_dist(rDistribution)    nodes.append(rNode)    # wetgrass    if include_wetgrass:        dist = zeros([sNode.size(), rNode.size(), wNode.size()], dtype=float32)        dist[0, 0,] = [0.99, 0.01]        dist[1, 0,] = [0.1, 0.9]        dist[0, 1,] = [0.1, 0.9]        dist[1, 1,] = [0.01, 0.99]        wgDistribution = ConditionalDiscreteDistribution(nodes=[sNode, rNode, wNode], table=dist)        wNode.set_dist(wgDistribution)        nodes.append(wNode)    # create bayes net    bnet = BayesNet(nodes)    return bnetdef infer(bayes_net, engine):    #Compute the marginal probability of cloudy    cloudy = bayes_net.get_node_by_name('cloudy')    Q = engine.marginal(cloudy)[0]    index = Q.generate_index([True], range(Q.nDims))    prob = Q[index]    print 'prob:', prob, ', engine:', enginenet = rain_network(False)infer(net, JunctionTreeEngine(net))infer(net, EnumerationEngine(net))net = rain_network(True)infer(net, JunctionTreeEngine(net))infer(net, EnumerationEngine(net))', u'responses': []}]",,2.0,195.0,483,"$$P(\mathtt{bug~in~David's~code})=0.99$$
$$P(\mathtt{bug~in~pbnt})=0.009$$
$$P(\mathtt{bug~in~numpy})=0.0007$$
$$P(\mathtt{bug~in~Python})=0.0003$$",Rain Network Question,[a3]
5ad7d4600d63974e20c39196,"Probability is definitely not my strongest skill, but WHY, WHY does this answer/formula makes sense??? 

UPDATE: I spent some time breaking my head over this, and turns out the answer is in the next video. There is a formula

",jc6w44hrp9v2ki,"[{u'text': u'Well, without having to rely on Bayes rule, and accepting the ""joint probabilities"" as true, the reasoning I believe would be the following

P ( C | + ) = ""Have cancer WHEN test is positive"" or in other words ""It's the proportion of cancer among having a positive test""

that is very close to

P ( +, C ) = ""Have cancer AND test is positive""

they are very close but not the same right?
Close but not the same, why are they different?

P ( +, C ) = P ( C | + ) * P ( + )

so if you want P ( C | + ) 

P ( C | + ) = P ( +, C) / P ( + )

and P ( + ) = P ( + , C ) + P ( +, ! C ) which you have above as the formula.

Hopefully I didn't confuse you more, certainly I also got confused when explaining.

I found this post useful:

https://stats.stackexchange.com/questions/214275/intuitive-difference-between-joint-probability-and-conditional-probability-in-th/


', u'responses': [u'thanks, great explanation']}, {u'text': u'When you take a step back from it and look at the overall numbers, it may make more sense.  

Say you have 1000 people take the test.   Of the 1000 people who take the test, 10 people will actually have cancer and 990 people will not have cancer.

Of the 10 people who have cancer, 9 of them will get a positive result.

Of the 990 people who do not have cancer, 198 of them (0.2 * 990) will get a positive result.

So there will be a total of 207 people (9 + 198) who have a positive result.   Of those, 9 will actually have cancer.  so 9/207 (4.348%) is the percentage of people who have a positive result who actually have cancer.

The reason the number is so small is because of the large number of people who don't have cancer that drives the number of false positive results higher (it is a fairly high percentage -- 20% of the tests result in a false positive).  One would hope that an actual test would have a lower false positive result.', u'responses': [u'thanks for a great breakdown!!! its really helped']}, {u'text': u'Shouldn't the P(+,C) = (total probability of +)*P(C) in which case the total probability of + = P(+|C)*P(C)+P(+|!C)*P(C) ?', u'responses': [u'your second one should be P(+|!C) * P(!C) -- the probability of a positive result when someone doesn't have cancer times the probability that the person doesn't have cancer.']}]",,0.0,169.0,484,,Cancer Example,"[a3, lesson5]"
5ad7d4600d63974e20c39197,"I didn't understand how this expansion happened:
https://youtu.be/EZpzEZPy0Wk?t=17s

Sebastian has...
P ( R | H, S ) = ?

And Bayes Rule states:
P ( A | B ) = P (B | A) * P(A) / P(B)

therefore, shouldn't ""B"" = ""H,S"" ?

I would have expanded the formula this way:

P ( R | H, S) = P ( H, S | R) * P(R) / P(H,S)

Why was Sebastian able to expand it to 

P ( R | H, S) = P ( H | R, S) * P( R | S ) / P( H | S )",jc6w44hrp9v2ki,"[{u'text': u'@472', u'responses': [u'Trouble is, it's not very clearly answered there', u'Then why start a new thread with the same question? This gives us two disjointed discussions on the same topic.', u'I didn't; moving the unclear answer here, for the sake of completeness', u'Thanks', u'In fairness, Nathan's answer in the followup is clear, it's the student answer that I think wasn't very clear there', u'Mmmm, this is really weird. I can see that post if I click on it, yet I don't see it on the left side. I don't have any filters and the post 469 and then it jumps to the 472.
If I search for ""Explaining away"", I only see my post, 472 doesn't show up. 
If I filter by ""lesson6"" posts, I only see two posts and 472 is also not showing up.
What could be going on?', u'Ahh, I see below that someone marked the other one as duplicated, I guess that's why....', u'When Mark labelled it as a duplicate, it merged that post into this one; thus, removing it from the list on the left. However, it still exists in the system, on the back-end, as a separate post. You just can't get to it directly via the list on the left anymore.']}, {u'text': u'Explaining away quiz
Hi Everyone 

In the lesson 6 slide 12(Explaining away quiz) Bayes rule is used to calculate P(R|H,S)
Could Somebody please explain this formula:

P(R|H,S) = P(H|R,S) * P(R|S) / P(H|S).

If I try to apply Bayes theorem shouldn't it be something like P(R|H,S) = P(H,S | R) * P(R) / P(H|S)?


Thanks
Alex', u'responses': [u'', u'If you rearrange ""P(R|H,S) = P(H,S | R) * P(R) / P(H|S)""
Proof:
Assume P(R|H,S) = P(H,S | R) * P(R) / P(H|S) is true,
P(H|S)*P(R|H,S) = P(H,S | R) * P(R) even when both sides are not with a trivial solution,
However,the left is P(R,H|S) while the right is P(H,S,R) and there is no guarantee that they are equal.
Thus,it was proven by contradiction.

I suggest you make P(R|H,S) = P(H|R,S) * P(R|S) / P(H|S) a multiplication on both sides to examine the correctness of your calculation.

Edit:also,P(R|H,S)* P(H|S) *P(S)= P(H|R,S) * P(R|S)*P(S).I hope this helps', u'I was confused about this at first too. Equation 13.3 in the textbook (page 496 in my version), deals with this explicitly:

... We will also have occasion to use a more general version [of Bayes rule] on some background evidence e.

P(Y | X, e) = ( P(X | Y, e) * P(Y | e) ) / P(X | e)

You'll find that the above corresponds exactly to the expansion of P(R | H, S) in the video where Y corresponds to R, X to H and S to e. It's just a more general version of Bayes rule that accounts for multiple variables instead of just two.', u'thanks']}]",,0.0,152.0,485,"Standard / 'Simple' Bayes Rule is
$$P(Q|R) = \frac{P(R|Q)P(Q)}{P(R)}$$

Then condition it all on $$P(S)$$ gives

$$P(Q|R,S) = \frac{P(R|Q,S)P(Q|S)}{P(R|S)}$$

or with the R,H,S variables

$$P(R|H) = \frac{P(H|R)P(R)}{P(H)}$$

then condition it all on $$P(S)$$ gives

$$P(R|H,S) = \frac{P(H|R,S)P(R|S)}{P(H|S)}$$",&#34;Explaining Away&#34;,[lesson6]
5ad7d4610d63974e20c39198,"Hi class,

Since we probably have a lot of people here with machine learning experience, I thought I would get some opinions about this.

I have an opportunity to get training on a cloud machine learning platform through work, and the choice of which one is somewhat up to me. What opinions do people have about Azure vs Google Cloud vs AWS? My criteria are: 
relevance to working environment: which platforms are more companies adopting/which are easier for companies to adoptaccess to training resources: I'd be finding and doing the training on my own, so the easier and more streamlined it is, the betterare there other criteria I should consider?

Maybe the answer is that any would be a fine option for me, but since I don't have experience in any of them, I thought I'd see what others think. Thanks!",jc6w44hrp9v2ki,"[{u'text': u'These are based on observations/feedback and some experience.

1. I have met engineers that have had experience with Azure and expressed significant disdain.
2. AWS tutorials are great, and well developed for step by step guidance. I use AWS services for GPU training. There are alot of AMIs out there with necessary software already built out.
3. I have not used Google Cloud, but I am assuming tensorflow integration has to be pretty good. Seems like in terms of tutorials, they are lagging AWS.

I would have a bias to select AWS or Google Cloud over Azure...

Am keen to hear others thoughts as well!

', u'responses': []}, {u'text': u'I have worked a fair amount with Azure and AWS, though only a bit of it was actual machine learning.  Most of it was with data ingestion, storage, transformation, and presentation.  Overall I absolutely hated Azure and like AWS quite a bit.  A number of different Azure components that I used were not ready for production use.  Azure tech support was abysmal.  The vast majority of tutorials out there are geared towards AWS, so I frequently felt like I was the only person out there that was using certain Azure components.  AWS definitely isn't perfect, but the volume of information out there about AWS alone makes it a solid choice of a platform.

I haven't used Google Cloud personally, but I have a friend that works at Google and uses it regularly.  He raves about its ML abilities, but he could be biased.

You didn't mention any details about what you're doing, but you may need to consider more than just the ML tools.  If you need other parts of the pipeline, there are significant differences.
', u'responses': [u'Thanks for your thoughts. I'm a consultant and the type of work needed can vary. Most of my work has fallen in on an already established data ingestion and storage process. My work has mostly entailed data transformation and visualization. I don't currently have a use case for cloud ML, but was thinking it would be a good skill to acquire.']}]",,0.0,141.0,487,,Thoughts about cloud machine learning platforms,[other]
5ad7d4610d63974e20c39199,"I have numpy version 1.11. I am getting the following error for the probabilities, using the examples provided. Could be something silly but can't find it, any hints?
dist[0,:] = [0.2, 0.8] 
ValueError: cannot copy sequence with size 2 to array axis with dimension 1",jc6w44hrp9v2ki,"[{u'text': u'Hi William, thanks for trying to help. I understand what the message means, but it happrens also if I am following the example (with appropriate name changes):

A_distribution = DiscreteDistribution(A_node)
index = A_distribution.generate_index([],[])
A_distribution[index] = [0.3,0.7]
A_node.set_dist(A_distribution)', u'responses': [u'When you declared A_node did you set the number of values to 2?', u'I believe so, but maybe it could be something related to that. I will have to check later, I don't have the code with me. Thanks for the tip.']}]",,1.0,172.0,488,This means that the number of columns in dist is 1 when it should be 2. You must have created dist with incorrect sizes.,python error,[a3]
5ad7d4610d63974e20c3919a,"I was reviewing genetic algorithms (reading the plot of Twins on wikipedia), and it looks like a sequel starring Eddie Murphy (as the long lost third brother), with Schwarzenegger and DeVito, is in the works - filming starts 2018!",jc6w44hrp9v2ki,"[{u'text': u'LOL. I looked this up to confirm. Pretty excited for ""Triplets""!', u'responses': []}]",,0.0,126.0,489,,genetic algorithms using neural-net processors (off-topic!),[lesson3]
5ad7d4610d63974e20c3919b,"In the Causal Direction video segment (31) of Bayes Nets, the instructor generalizes Causal Direction as ""when the networks flow from causes to effects"". However, the network that was drawn seems to have the arrows going from effect (Alarm being sound) to cause (Burglar and Earthquake).

Am I miss interpreting the graph or was his statement incorrect?",jc6w44hrp9v2ki,[],"I think the network shown in that video segment 31 is an example of what NOT to do, as in the network shown is not connecting nodes in the causal direction. If you look at an earlier segment (video 26 for example), it has the network drawn in the causal direction.",0.0,143.0,490,,Clarification on Causal Direction,[lesson6]
5ad7d4610d63974e20c3919c,"Hi,
If my script somehow contains a bug or whatever such that bonnie throws an error, will this submission be counted toward the 5 submission limit??
I guess the answer is probably no. I still want to confirm!
Thank you!",jc6w44hrp9v2ki,[],,0.0,189.0,491,If you log into Bonnie it will show you how many of the 5 you've used. ,Is Failed Submission Counted Toward 5 Submission Limit?,[a3]
5ad7d4610d63974e20c3919d,"HI,
As per the comments in the code for Gibbs sampler function :

initial_state is a list of length 6 where: index 0-2: represent skills of teams A,B,C (values lie in [0,3] inclusive)index 3-5: represent results of matches AvB, BvC, CvA (values lie in [0,2] inclusive)
Does this mean the it looks like this :

initial_value =
[
    [ p(A) ] , [ p(B) ] , [p(C)] , [ p(avb) ] , [ p(bvc) ] , [ p(cva) ]
]
",jc6w44hrp9v2ki,[],,0.0,182.0,494,"1 That's a list of 6 lists of length 1; although technically it is a list of length 6, clearly it would have been described more specifically
2 Even then, initial state is not a vector of probabilities, it is a state vector, your probabilities would be $$0 \le P \le 1$$, not ""values in [0,3]"" or ""values in [0,2]""

the idea is that the initial state is for instance [3, 3, 2, 2, 1, 2]",initial_state,[a3]
5ad7d4620d63974e20c3919e,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.

Aaaand we are on to Constraint Satisfaction Problems!

SUDOKU 
Here is a simple Sudoku. In this puzzle, we have 3 constraints:
(i) Every row has to contain all digits (from 1 to 4).
(ii) Every column has to  contain all digits.
(iii) Every box of four (there are four of these) has to contain all digits.



1. Design a constraint graph for this problem.

2. Which algorithms might best solve this problem?




Solution: See Mark's answer below. It can be solved with a simple backtracking search with minimum remaining value and least constraining value.",jc6w44hrp9v2ki,"[{u'text': u'1 constraint hypergraph
the rectangles at the top represent row constraints, the middle row of rectangles represent column constraints, the lower row represent quadrant constraints; the constraints being $$Alldiff$$; the graph is generic, you could (?) substitute 3 for 1A, 2 for 3A, 1 for 2D, 4 for 4D

2 AC-3 would seem eminently capable of solving;
Firstly for 2A we remove 2 & 3 from its domain resulting from the row constraint, & 1 from the column constraint, making it 4;
then 4A is 1 as a result of the row constraint removing 2, 3, & 4;
then for 2B we remove 3 & 4 as a result of the quadrant constraint, then 1 as a result of the column constraint, making it 2;
then for 1B we remove 2, 3, & 4 as a result of the quadrant constraint, making it 1;
then for 4B we remove 1 & 2 as a result of either the quadrant or the row constraint, 4 as a result of the column constraint, making it 3;
then for 3B we remove 1, 2, & 3 as a result of the quadrant constraint making it 4;
then for 2C it's 1, 2 & 4 as a result of the column constraint, making it 3;
for 4C it's 1, 3, & 4 as a result of the column constraint, making it 2;
for 1C it's 2 & 3 for the row, 1 & 3 for the column or the quadrant, making it 4;
for 3C it's 2, 3, & 4 for the row, making it 1;
for 1D it's 1, 3 & 4 for the quadrant or the column, making it 2;
for 3D it's 1, 2 & 4 for the quadrant, the row, or the column, making it 3

More generally we may consider PC-2 for more advanced sudoku questions', u'responses': [u'Correct!']}]",,0.0,215.0,497,,Challenge Question 10 - CSP,"[lesson4, challengeqtns]"
5ad7d4620d63974e20c3919f,"Thank you for providing us with a fun project that reinforces Bayes nets extremely well!

I just had one question on part 1c, what do the arguments alarm_rings, gauge_hot, and temp_hot represent in the get_..._prob(bayes_net, ??? ) functions? I didn't see this in the Readme nor was it in the source code.

A great tip for next semester would be to specify what this value represents and what type it is ex: int, long, bool..etc. in the Readme.

Thank you!",jc6w44hrp9v2ki,"[{u'text': u'I think it helps make it more clear to rephrase it as ""Get the probability that the alarm is ringing."" or conversely ""Get the probability that the alarm is not ringing.""  This is different than ""Get the probability that the alarm is ringing given alarm_rings=True"" which can be easy to confuse given the description.', u'responses': []}]",,0.0,164.0,498,"IIRC, bayes_net is returned after calling set_probability(make_power_plant_net()).  The rest are booleans.  Booleans regard whether that evidence is known a True or False

For example you could do something like the following to ""Calculate the marginal probability of the alarm ringing (T/F) in the power plant system.""

power_plant = make_power_plant()bayes_net = set_probability(power_plant)alarm_rings = Truealarm_prob = get_alarm_prob(bayes_net, alarm_rings)
",Function arguments in Part 1c,[a3]
5ad7d4620d63974e20c391a0,"Just checking things after cloning assignment 3.  I'm getting python error out the gate just running probability_test.py.  Something to do with attempted relative import in a non-package.  There is a . (dot) import in the PIL directory structure that is causing this.  I'm not sure how to correct this as this is not a file supplied by the assignment.  I suppose I could deinstall PILLOW from my Python configuration and see what happens.   Not sure what to do.  This kind of error did not occur with the other two assignments.  I'm running on SuSe Linux executing from the command line.  Not a python ""package"" expert.   Any help is appreciated.  Thanks

Update:  Adding an empty file named __init__.py in the same directory as probability_tests.py and probabilty_solution.py fixed the problem.

richard@linux-nab9:~/classes/Georgia_Tech/CS6601/Assignments/assignment_3> python probability_tests.pyTraceback (most recent call last):  File ""probability_tests.py"", line 2, in <module>    from probability_solution import *  File ""/home/richard/classes/Georgia_Tech/CS6601/Assignments/assignment_3/probability_solution.py"", line 18, in <module>    from Node import BayesNode  File ""pbnt/combined/Node.py"", line 37, in <module>    from Distribution import *  File ""pbnt/combined/Distribution.py"", line 38, in <module>    import Utilities  File ""pbnt/combined/Utilities.py"", line 38, in <module>    from __init__ import *  File ""/usr/lib64/python2.7/site-packages/PIL/__init__.py"", line 14, in <module>    from . import versionValueError: Attempted relative import in non-packagerichard@linux-nab9:~/classes/Georgia_Tech/CS6601/Assignments/assignment_3> ",jc6w44hrp9v2ki,[],,0.0,157.0,500,"You'll need to provide the proper Python environment; hopefully you've seen or heard of Anaconda before, that is one of the more full-featured virtual environment & Python package managers",Assignment 3: Python error running probability_tests.py - Attempted relative import in non-package,[a3]
5ad7d4620d63974e20c391a1,"This week you should watch Lesson 6, Bayes Nets, and read Chapter 14 in AIMA (Russell & Norvig).

Please remember to sign up to Gradescope if you haven’t already! Please check @287.

Please have a look at PARQR! It’s extremely useful in our experience and can potentially save you a lot of time. Check @432 for details.

Assignment 3:  Bayes Nets Sampling
Due: February 25 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 3 is out! Please check @463 for details. YouTube Live Office Hours have been held; please check @467.

As always, here are the OH calendar, the syllabus and the schedule.  

",jc6w44hrp9v2ki,[],,0.0,254.0,501,,Week 7 Announcement,[announcements]
5ad7d4620d63974e20c391a2,"Hi,

Any hint on deriving the probabilities corresponding to each team level?

I'm tempted to calculate the Expected skill levels from the  prior distribution of skill levels for each team.
",jc6w44hrp9v2ki,"[{u'text': u'Never mind, figured out what I was looking for', u'responses': []}]",Marking as resolved,0.0,175.0,502,,Hint on skill levels,[a3]
5ad7d4620d63974e20c391a3,"OH at the calendar below:

https://calendar.google.com/calendar/embed?src=7f5agh74re4ldpkddoqa91ce4s%40group.calendar.google.com&ctz=America/New_York
 
Is it in EST or UTC?

Is there a way I can convert entire calendar to IST?",jc6w44hrp9v2ki,[],The calendar linked above is in EST. Not sure about how you can convert it.,0.0,120.0,504,"I see the time zone is the last parameter in the query string - ""ctz=America/New_York"".  If you change that to an appropriate value for your time zone, it should update the display times (I just tested by changing it to ""ctz=America/Phoenix"" and the times are displayed in Mountain Time.  Sorry - I don't know the appropriate value for IST.",TimeZone for Office Hours,[office_hours]
5ad7d4630d63974e20c391a4,"I am not clear what should go to [0] and what should go to [1]. For example.
>>When the temperature is hot, the gauge is faulty 80% of the time. 
P(G| T=1, F_G=1) should (0.2, 0.8) or (.8,.2)
similarly for 
>>Otherwise, the gauge is faulty 5% of the time
P(G| T=0, F_G=1) should be (.95, .05) or (.05,.95)

How to visualize this ?",jc6w44hrp9v2ki,[],,0.0,148.0,505,I think I got it just by re reading example.,confused about [0] and [1] values,[a3]
5ad7d4630d63974e20c391a5,"I am working on G_NODE with equation G_node = zeros([T_node.size(), F_G_node.size(), G_node.size()], dtype=float32) 
questions says ""When the temperature is hot, the gauge is faulty 80% of the time. Otherwise, the gauge is faulty 5% of the time""
I could set probability like this 
P(G|T=1, F_G=1) = 0.2,0.8
P(G|T=1, F_G=0) = .95 ,.05

However how to come up with values for when temperature is NOT hot scenarios
P(G|T=0, F_G=1) = ??
P(G|T=1, F_G=0) = ??
",jc6w44hrp9v2ki,"[{u'text': u'I guess if i could ask this question differently,
Consider F_G, T= ""Faulty"" and F = ""Not Faulty""
TF_GP(G is True Given T and F_G)tt0.20tf0.95ftAffB

How would we calculate A and B in these scenarios?
It understand the readme show the compliment probability, i.e P(G is True give NOT (T= t and F_G = t) )= 1 - 0.20 = 0.80, however this is not the same as A or B.

 
', u'responses': [u'For A: since F_G=True, the Gauge is accurate 20% of the time. So considering it is accurate 20% of the time, what should be the probability that Gauge reads ""Hot"" or True, when the actual Temperature is ""Normal"" or False?', u'Exactly, how would we go about calculating that from this table?', u'I am lost in translations. Here is what I deduce based on wordings:

When the temperature is hot, the gauge is faulty 80% of the time Otherwise, the gauge is faulty 5% of the time ==>

P(G|T=1, FG=1) = .8
P(G|T=0, FG=1) = .05


The temperature gauge reads the correct temperature with 95% probability when it is not faulty and 20% probability when it is faulty ==>
P(G|T=1, FG=0) = .95
P(G|T=1, FG=1) = .2

here I have two readings for 1,1 and 1,0 is missing. pl advice.
', u'I was finally able to get correct values and run it on Bonnie successfully. I would admit however language of this assignment part 1 was not as clear as it should have been. (or may be it is my poor English !!!).', u'What methodology did you use to complete G's joint probability?', u'Daniele - I will update on this in a while today. ', u'This is how I looked at it. Not sure this is correct approach but for me it works. Let me know if my interpretations look good to you. (I still get confused when I read the problem again )

The temperature gauge reads the correct temperature with 20% probability when it is faulty. >> T T .2 The temperature gauge reads the correct temperature with 95% probability when it is not faulty>> T F .95 When the temperature is hot, the gauge is faulty 80% of the time.  (it means .8 probability is there when temp was hot but detected as normal. So it is probability for F T state)>> F T .8 Inverse of The temperature gauge reads the correct temperature with 95% probability when it is not faulty>> F F .05', u'That's what I went with also, but I have not submitted to Bonnie yet to verify if this is correct.
']}, {u'text': u'', u'responses': [u'.']}]","""When the temperature is hot, the gauge is faulty 80% of the time. Otherwise, the gauge is faulty 5% of the time"" - this is referring to the relationship between T (temperature) and F_g (faulty gauge).

P(G|T=1, F_G=1) means ""probability of gauge given temperature is hot and gauge is faulty"".

If you want to get the correct probabilities for G (gauge), you may want to use another description from the readme:

""The temperature gauge reads the correct temperature with 95% probability when it is not faulty and 20% probability when it is faulty. For simplicity, say that the gauge's ""true"" value corresponds with its ""hot"" reading and ""false"" with its ""normal"" reading, so the gauge would have a 95% chance of returning ""true"" when the temperature is hot and it is not faulty.""",1.0,176.0,506,"Hi Vishwadeep,


You could try coming up with the conditional probability table associated with G. Then you could pick the values you are looking for directly from the table ",pointers on 3 variable relationship,[a3]
5ad7d4630d63974e20c391a6,"L6/Video 29:
Why is B not dependent on J and M???
It is just a case that given A, B is not dependent on J and M, but otherwise it will be.
The lecture suggests otherwise.
",jc6w44hrp9v2ki,[],,0.0,141.0,507,,Dependance,[a3]
5ad7d4640d63974e20c391a7,"If, like me, you were new to the monty hall problem and found really hard to believe and understand the answer, then, there's some relief as you are not alone. According to Wired, Paul Erdos wasn't really convinced either!

""Paul Erdős, one of the most prolific and foremost mathematicians involved in probability, when initially told of the Monty Hall problem also fell victim to not understanding why opening a door should make any difference. Even when given the mathematical explanation multiple times, he wasn’t really convinced. It took several days before he finally understood the correct solution.""
https://www.wired.com/2014/11/monty-hall-erdos-limited-minds/

Wikipedia has a great visualization of the problem:
https://en.wikipedia.org/wiki/Monty_Hall_problem#Simple_solutions

I'm teasing some friends and they are swearing that the chances become 50-50 after the third door is opened :)",jc6w44hrp9v2ki,"[{u'text': u'Here is another fun read from Marilyn vos Savant's column in Parade that popularized this problem. Especially entertaining are the numerous math PhDs with their condescending put-downs:

http://marilynvossavant.com/game-show-problem/', u'responses': [u'Reading those responses were quite depressing... That Don Edwards guy and his 2 responses were disgusting. Wow, just wow. +1 and +.66 for Ms. Savant and her answers though! Thanks for the share, Nick!']}, {u'text': u'A good way I've heard it explained is to imagine there are 9 goats and one car.

If Monty closed every door but the one you selected and also one other - would you switch?', u'responses': []}]",,0.0,163.0,515,,Monty Hall - Some relief,[lesson6]
5ad7d4640d63974e20c391a8,"In the README, we're given hints on how to set probabilities and conditional probabilities for variables that are either true or false.

However, how would I set a variable that can take more than two values?

E.g. if I wanted to set P(AvB=2 | A = 0, B = 3)  how would I set this? Or am I missing something?


Kr",jc6w44hrp9v2ki,[],,0.0,148.0,516,Figured out.,pbnt for a variable that can have more than 2 values,[a3]
5ad7d4640d63974e20c391a9,"I've been struck at part 2b for a while, and finally found that I've been using JunctionTreeEngine from part 1 instead of the required EnumerationEngine.

In part 2b, as A beats B (i.e. skill A>B) and A and C (i.e. skill A~=C), 
it's intuitive to see it's likely C will also beat B (also suggested from the test case given).

But using JunctionTreeEngine, I got C is more likely to tie with B than wining B. Does that means JunctionTreeEngine is wrong (or it approximates not accurately enough)?

From the source code of pbnt:
class JunctionTreeEngine(InferenceEngine):
    """""" This implementation of the Junction Tree inference algorithm comes from ""Belief Networks: A Procedural Guide"" By Cecil Huang an Adnan Darwiche (1996).  See also Kevin Murhpy's PhD Dissertation.  Roughly this algorithm decomposes the given bayes net to a moral graph, triangulates the moral graph, and collects it into cliques and joins the cliques into a join tree.  The marginal is then computed from the constructed join tree.
    """"""
    
class EnumerationEngine(InferenceEngine):
    """""" Enumeration Engine uses an unoptimized fully enumerate brute force method to compute the marginal of a query.  It also uses the standard constructor, init_evidence, and change_evidence methods.  In this engine, we use a hack.  We have to check and see if the variable is unobserved.  If it is not, then we know that the probability of that value is automatically 1.  We use this hack, because in order to do it properly, a table of likelihoods that incorporates the evidence would have to be constructed, this is very costly.
    """"""
",jc6w44hrp9v2ki,"[{u'text': u'Thanks for the student answer. We cannot assume A's skill level is higher than B's, but with such knowledge I believe it's reasonable to assume the likelihood of C beating B is also higher. I wonder how are those two engines different in given the fairly different answers?', u'responses': []}, {u'text': u'Oh. Thanks. I had to import EnumerationEngine myself. Guess that's why you have to read closely.', u'responses': []}]",,0.0,175.0,517,"I think you might be making a bad assumption.  We are not being told what the skill levels of the teams are; all we know is the outcome of the two of the games.  Even though A beats B, it can still have less skill than B (i.e. they got lucky).",JunctionTreeEngine vs EnumerationEngine,[a3]
5ad7d4640d63974e20c391aa,I can't find the link inside google calendar.,jc6w44hrp9v2ki,"[{u'text': u'Kshitish OH
', u'responses': [u'']}]","Hi Andres, 

Due to some personal emergency, Kshitish won't be able to take Office Hours today. His OH has been shifted to same time tomorrow. 

We sincerely apologize for the inconvenience and the delay in communication. ",0.0,142.0,519,,Kshitish OH Link,[a3]
5ad7d4640d63974e20c391ab,,jc6w44hrp9v2ki,[],,0.0,2.0,520,,Kshitish OH,[a3]
5ad7d4640d63974e20c391ac,"I'm going through the provided paper on Gibbs Sampling for Assignment 3. The numbers they use in section 2 don't look right to me, so I want to verify that I'm not missing something. 

They say the value of $$P(\neg c \mid r, s, w) = 0.6923$$, but since it's calculated from $$1 - P(c \mid r, s, w)$$, shouldn't it actually be equal to $$0.5556$$?",jc6w44hrp9v2ki,[],,0.0,168.0,521,I saw this too. They get it right in the next example. Not sure what happened.,Gibbs Sampling Paper Error,[a3]
5ad7d4640d63974e20c391ad,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


MENU CSP

You are designing a menu for a special event. There are several choices, each represented as a variable:
(A)ppetizer, (B)everage, main (C)ourse, and (D)essert.

The domains of the variables are as follows:
A: (v)eggies, (e)scargot
B: (w)ater, (s)oda, (m)ilk
C: (f)ish, (b)eef, (p)asta
D: (a)pple pie, (i)ce cream, (ch)eese.

Because all of your guests get the same menu, it must obey the following dietary constraints:
(i) Vegetarian friendly: The appetizer must be veggies or the main course must be fish or pasta (or both).
(ii) Total budget: If you serve the escargot you cannot afford any beverage other than water and you cannot afford any dessert other than cheese.
(iii) Calcium requirement: You must serve at least one of milk, ice cream or cheese.

1. Draw the constraint graph over the variables A,B,C and D.

2. We first assign A = 3
A -> [     e     ]
B -> [  w  s  m  ]
C -> [  f  b  p  ]
D -> [  a  i  ch ]
Fill in the domains of the remaining variables after forward checking. For the eliminated values, leave blank.
A -> [     e     ]
B -> [  _  _  _  ]
C -> [  _  _  _  ]
D -> [  _  _  _  ]

3. Now image that you have one more constraint (still A = e).
""(iv) Kid friendly: You must serve at least one of veggies, soda, pasta, or ice cream.""

Give a solution for this CSP or state None if no such state exists.



Solution: Check Mark's answer below.
",jc6w44hrp9v2ki,"[{u'text': u'1 constraint hypergraph:

2
A -> [   e   ]
B -> [   w   ]
C -> [  f p  ]
D -> [   ch  ]


3 constraint hypergraph

A -> [   e   ]
B -> [   w   ]
C -> [   p   ]
D -> [   ch  ]

So the answer is to serve escargots for the Appetizer, water for the Beverage, pasta for the main Course, cheese for the Dessert', u'responses': [u'Hi, 

I have a question, if you don't mind. Why the answer to Kid Friendly menu be:
A -> [   e   ]
B -> [   w   ]
C -> [   p   ]
D -> [   ch  ]
And not: 
A -> [   e   ]B -> [   w   ]C -> [  f p  ]D -> [   ch  ]
Here also, we are satisfying the constraint 'at least one of veggies, soda, pasta, or ice cream'. Do we necessarily need to remove fish from the main course to satisfy constraint (iv)? Am I missing something here?', u'Hi Ruhal,

That constraint, in conjunction with the constraints that have already limited the domains, constrains the main course to strictly pasta. So we may remove fish from the domain of the main course.', u'
Maybe a wee bit late to the party, but looking at the overall question with a bit different wording might help with the understanding why fish needs to be removed when the kid friendly constraint is added.  

The overall problem didn't explicitly state, but implies, that only one of each option for A, B, C, D can/will be selected by the menu planner.  With the initial set of constraints, the planner has two valid options, fish and pasta, which could be selected for the menu while still satisfying the constraints.   However, after adding the kid friendly constraint, if the planner were to select fish, the menu would violate the constraints, so fish needs to be removed from the list of main courses.   

Hope this helps and doesn't add any confusion. ', u'Agreed. If fish were served, then it would no longer be kid friendly, so pasta is the only remaining option that will be satisfactory. ', u'Thanks @E. Scott Daniels, I could not imply that and hence got confused.']}, {u'text': u'Thanks. I have the same answers and graph.

Do we have to write constraint out like
(i) Either A = [v] or C= [f] or C = [p]
(ii) B=[m] or D=[a]
(ii) IF A= [e] THEN  B=[w] AND D=[ch]

The first figure marked as 1 constraint hypergraph should be 3 constraint hypergraph or Do I have my terminology wrong?

Thanks
mian
', u'responses': [u'the 1 refers to the question number, not the number of constraints']}, {u'text': u'What does A=3 stand for in part 2? Do you mean A=e?', u'responses': []}]",,2.0,237.0,523,,Challenge Question 11 - CSP,"[lesson4, challengeqtns]"
5ad7d4650d63974e20c391ae,"How would you calculate the marginal probability of John calling?

Would it be:

(0.9 + 0.05) / 2 

?


",jc6w44hrp9v2ki,"[{u'text': u'Your solution assumes that the probability of Alarm is 50/50. To calculate the marginal probability of JohnCalls, you must calculate the marginal probability of Alarm, which in turn depends on Earthquake and Burglary. ', u'responses': []}]",,0.0,153.0,524,"Without giving away the whole solution, a hint would be to remember that the probability of John calling depends on the probability of the alarm going off; So your equation will need to take into account the probability of the alarm going off.  Recall that P(A|B) can be calculated as P(A|B) * P(B).",Calculating Marginal Probability,[a3]
5ad7d4650d63974e20c391af,"For when you've got time to go further

Today's packtpub free book is Bayesian Analysis with Python, looks quite intriguing, apparently it leverages 
https://github.com/pymc-devs/pymc3 that looks good, needing theano as a dependency",jc6w44hrp9v2ki,"[{u'text': u'The getting started Jupyter:
https://github.com/pymc-devs/pymc3/blob/master/docs/source/notebooks/getting_started.ipynb', u'responses': []}]",,0.0,170.0,525,,Bayes &amp; Python,"[python, a3, lesson6]"
5ad7d4650d63974e20c391b0,"This is a really dumb question, but how exactly do I run just one part of the probability_tests.py file? I would like to check to make sure the network is set up correctly. I can run the tests with >>python probability_tests.py, but that runs the whole file. How do you just run one of the tests?",jc6w44hrp9v2ki,"[{u'text': u'If you use the Pycharm, right click on the function, there is an option to run the selected test function only. Whatever you can do with Pycharm, you can run selected test in command by assigned the test name. Look up for the nosetest or unittest command in python.', u'responses': []}, {u'text': u'You can also annotate with 
@unittest.skip("""")', u'responses': []}, {u'text': u'You can run the specific test you want by specifying the test name as the first arg. Here's an example for running test_network_setup:python probability_tests.py ProbabilityTests.test_network_setup', u'responses': []}]",,0.0,160.0,528,"Comment out the tests (methods) you don't want to run.

Or call nosetests directly with the test specification, such as$ nosetests --nocapture -v probability_tests.py:ProbabilityTests.test_network_setup",How Do I Run Just Part of the Probability Tests?,[a3]
5ad7d4650d63974e20c391b1,"Hi, I am about to finish part 1 and curious if it worth to submit to Bonnie to make sure everything is completed correctly before I move on to part 2. How did you distribute your Bonnie runs and let me know pros and cons of your decision? ",jc6w44hrp9v2ki,"[{u'text': u'I haven't even submitted yet.  Just going to keep testing before I give it a shot.', u'responses': [u'what part are you working on now?', u'Writing the gibbs sampler.  Everything else passes the unit tests thus far.']}, {u'text': u'I submitted after finishing both parts and part 1 works fine. I think the test cases given should be enough for validating part 1.', u'responses': [u'thanks, i think i am going to complete everything and then submit. I feel like unit tests are not well covered at all', u'And in part 2e compare_sampling, you should get similar value from part 2b calculate_posterior, where C is likely to win than to tie than to lose. You can run 2e a few times to validate before submitting.']}, {u'text': u'In my opinion, it is NOT worth it. The Bonnie submission gives you a ton of information so you will be able to fix part 1 easily (like it'll tell you exactly what it was expecting, whereas for Gibbs and MH and it just tells you it didn't work). I would wait until you have part 2 working to your satisfaction. ', u'responses': [u'thank you for your good advice', u'+1. Thank you much, Lily!']}]",,0.0,175.0,529,,Distributing Bonnie runs?,[a3]
5ad7d4650d63974e20c391b2,"Seeking clarification of delta please.. In the assignment description it seems confusing. In my own tests I need to use a small enough delta to get good accurate convergence. In fact, the assignment recommends to 'tune' delta for accuracy which implies its under our control which makes sense.

However, delta is provided by Bonnie as a parameter for compare_sampling() which appears to contradict that it's under our control.

So maybe the question just boils down to - can we ignore the delta parameter supplied by Bonnie in compare_sampling()?",jc6w44hrp9v2ki,"[{u'text': u'You need to use the delta passed so bonnie can test your solution using different values of delta to make sure it is working as expected for each delta value. The point of us manipulating them in testing is to understand how those parameters effect the convergence quality and time. Doing so also provides us with an understanding to the final question of which method of convergence is better and by how much.', u'responses': []}]","Yes. If you wish to, you can use a specific delta that you choose instead of the parameter that was passed in.",0.0,160.0,532,,Clarification of Delta?,[a3]
5ad7d4660d63974e20c391b3,"Hi,
In my recent submissions I am getting an error related to two factor auth.
When I login to passport I got the following message
""You will soon be required to use two-factor authentication for this account. Please press the button below to set it up.""

Has anyone experience something similar?

What should I do?",jc6w44hrp9v2ki,"[{u'text': u'When will 2FA become the norm? I haven't seen anything in my email about it. I just don't feel about doing this weekend, I'd like first to get done with my homework and then do that.', u'responses': [u'They just sent an email with the deadline, it's some time in mid March. The 16th, I think.']}, {u'text': u'I have a new question. I downloaded Duo Mobile and have my 6-digit code now.
When I try to login on Vagrant VM, it asked for my username and password, what should i provide in password? should it be password + 6-digit? or just 6-digit? I tried both and all failed. what should i do now?
', u'responses': []}]",,1.0,159.0,534,"I was getting this yesterday too (even though I did not have 2FA). I think it's due to the impending changes from Georgia Tech forcing us to get 2FA on our accounts. I logged onto Passport and added authentication to my account, and then I followed the instructions here which allowed me to submit to Bonnie.",&#34;Username and password failed (Do you use two-factor?)&#34; Error,[a3]
5ad7d4660d63974e20c391b4,"This question is about the specific implementation required for the assignment. My understanding is that the Gibbs_sampler() method is a generic implementation in which any state can be chosen. But the definition of Gibbs sampling in Russell-Norvig is
 ""The Gibbs sampling algorithm for Bayesian networks starts with an arbitrary state (with the evidence variables fixed at their observed values) and generates a next state by randomly sampling a value for one of the nonevidence variables Xi.""

Should we keep fixed the evidence variables in the Gibbs_sampler() method?

thanks
Ivan",jc6w44hrp9v2ki,[],,0.0,174.0,536,"From several threads in @465, there seem to be 3 valid options:

1) Allowing evidence variable to be changed as part of Gibbs sampling.
2) Hard code your Gibbs sampling implementation to treat AvB and CvA as fixed values.
3) Some students have reported that changing the function definition to allow for an optional evidence parameter is passing Bonnie for a solution that is closest to the one in the book.",Gibbs algorithm: allow evidence variables to change?,[a3]
5ad7d4660d63974e20c391b5,"No matter what I do, I can't seem to correctly set up a BayesNet. The network I set up always has only one node, no matter how many nodes I pass to the BayesNet function in the nodes list. I'm pulling my hair out trying to see what I'm doing wrong. I copied everything from the pbnt readme directly and it still doesn't work. Any ideas?

# Testing pbntimport sysif('pbnt/combined' not in sys.path):    sys.path.append('pbnt/combined')from exampleinference import inferenceExamplefrom Node import BayesNodefrom Graph import BayesNetfrom numpy import zeros, float32import Distributionfrom Distribution import DiscreteDistribution, ConditionalDiscreteDistributionfrom Inference import JunctionTreeEnginecNode = BayesNode(0, 2, name=""cloudy"")sNode = BayesNode(0, 2, name=""sprinkler"")cNode.add_child(sNode)sNode.add_parent(cNode)nodes = [cNode, sNode]#cloudy distributioncDistribution = DiscreteDistribution(cNode)index = cDistribution.generate_index([],[])cDistribution[index] = 0.5cNode.set_dist(cDistribution)#sprinklerdist = zeros([cNode.size(),sNode.size()], dtype=float32)dist[0,] = 0.5dist[1,] = [0.9,0.1]sDistribution = ConditionalDiscreteDistribution(nodes=[cNode, sNode], table=dist)sNode.set_dist(sDistribution)bnet = BayesNet(nodes)print bnet.get_node_by_name('cloudy')print bnet.get_node_by_name('sprinkler')print bnet.nodesprint len(bnet.nodes)

The above outputs:

<Node.BayesNode instance at 0x00000000061E3E48>
None
set([<Node.BayesNode instance at 0x00000000061E3E48>])
1
The ""cloudy"" node is there, but sprinkler is missing. This happens no matter what I try. Can't even get past step one on the assignment because of this.",jc6w44hrp9v2ki,"[{u'text': u'I think you mean this? You're overwriting nodes I believe.
cNode = BayesNode(0, 2, name=""cloudy"")
sNode = BayesNode(1, 2, name=""sprinkler"")', u'responses': []}, {u'text': u'Thank you to everyone who answered. Should have caught that... working on little sleep (toddler was sick all week).', u'responses': [u'Nathan, I did the same exact thing when I started the assignment. Took me well over an hour of stepping through my code to figure out what was going on. And my kids have actually been sleeping lately so I can't claim lack of sleep on this one!']}]","cNode = BayesNode(0, 2, name=""cloudy"") 
sNode = BayesNode(0, 2, name=""sprinkler"")You're giving both nodes the same id of '0'. Try giving each node a unique id and let me know if that helps.",0.0,169.0,539,"The first argument in the BayesNode class is an id. The node id must be unique in the network, so give try giving different ids for each of the nodes.",Problems with Basic BayesNet Setup,[a3]
5ad7d4660d63974e20c391b6,"On exampleinference.py line 66, I replaced the Q = engine.marginal(sprinkler)[0] with Q = engine.marginal(cloudy)[0] to test how the marginal work. The result is: 
('The marginal probability of cloudy=false:', 0.36592335)

This really confused me. From ExampleModels.py, cloudy has no parents and it's distribution is [0.5,0.5]. Then shouldn't the marginal probability of couldy=false be  0.5?",jc6w44hrp9v2ki,"[{u'text': u'You are right, change to enumeration engine gave me 0.5 for cloudy=false, although I can't figure out why the two engine should be different.
Now I'm trying to figure out when I test the marginal in probability_solution.py why my P(T = true) = 0.0375978, which is far away from 0.2 (my T_Node has no parent and I set it's distribution to [0.8,0.2]).  
I tried both EnumerationEngine and JunctionTreeEngine, both give me the same result.', u'responses': []}]",,0.0,120.0,540,"It might be related to what I also saw. Try the enumeration engine to see if it makes a difference.
",why P(cloudy = False) != 0.5?,[a3]
5ad7d4660d63974e20c391b7,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


Futoshiki

Futoshiki, or More or Less, is a game from Japan. Its name means ""inequality"". For this question, we will attempt to solve a Futoshiki puzzle using the Constraint Satisfaction techniques learnt in the class. The puzzle is played on a 4 x 4 square grid. The objective is to place the numbers 1 to 4 in the squares while obeying certain constraints. Some of the numbers may be given to begin with. The constraints are as follows:(i). Each row and each column contains each of the digits exactly once.(ii). Inequality constraints are specified between some squares, indicating that the number in one square must be higher or lower than its neighbor.Keeping these in mind, we wish to solve the following Futoshiki:



1. After applying all constraints, what are the domains for A and B after one iteration of forward checking?


2. Solve the Futoshiki by filling in the blanks.






Solution: Check Mark's answer below.",jc6w44hrp9v2ki,"[{u'text': u'1 - A and B can be any number but not one. However, a good option would be A  = 2 and B  = 4 looking at inequalities and applying least constraining solution.
2 - 
 1243432132142132
', u'responses': [u'your column 2 has ""2 3 2 1""']}, {u'text': u'1 I think ""one iteration of forward checking"" may be a matter of interpretation; however, interpreting it as only allowing for one level of constraint propagation, then 1 is removed from the domain of A as a result of the row constraint, 4 as a result of the $$<$$ constraint beneath A, so the domain for A is $$\{2,3\}$$. Similarly for B, 1 as a result of the column constraint & 1 as a result of the immediate $$>$$ constraint, gives a domain of $$\{2,3,4\}$$. However, chaining constraints then we observe that B is greater than something that is greater than something else, while neither of those may be 1 as a result of the column constraint, so B is 4. When we observe that B is 4, then the value that A is less than, must be $$\le 3$$ as a result of the row constraint, so A is 2. That is, obviously, taking the interpretation of 'one iteration' quite far :-)', u'responses': [u'Good answer!', u'For part a would it be an acceptable answer to say that the domain for B is {3, 4}? If you at the beginning of the search you enforced arc consistency you’d have already reduced the domain down to those two and the 1 would have no impact. ']}]",,1.0,226.0,541,,Challenge Question 12 - CSP,"[lesson4, challengeqtns]"
5ad7d4660d63974e20c391b8,"Solution for Challenge Question 6 @389.

A. What heuristic would you choose for Puzzle 8? How did you arrive at it?
The two most obvious answers are the following:
Number of misplaced tiles (this is also called the Hamming distance)Manhattan distance (i.e., the number of columns + rows by which the tile is misplaced)
 
The number of misplaced tiles simply counts 1 for every tile that is not in its final position. In the best case, each of these tiles would need to be moved by at least one spot into their correct positions; therefore, it never overestimates, and is therefore admissible.
 
The Manhattan distance can count more than 1 for each tile that is misplaced. This would occur only when it is misplaced by more than just one row or one column. In such a case, while counting a value of 1 for that tile would still be admissible, we can do better!
 
 1 | 3 |                  1 | 2 | 3
-----------              -----------
 2 | 8 | 5                4 | 5 | 6
-----------              -----------
 7 | 4 | 6                7 | 8 |

  Current                   Final

HD: 6
MD: 0 + 2 + 1 + 2 + 1 + 1 + 0 + 1 = 8
Consider the above example. All tiles except for 1 and 7 are misplaced, giving a Hamming distance of 6.
 
However, we would need a bare minimum of two moves for tile 2 to move to its correct spot - RIGHT, and then UP. There is no combination of moves that can help us achieve it in less, since a tile can be displaced if and only if we make a move. Thus, it never overestimates. We can easily calculate this conservative estimate by checking the number of rows and columns by which a tile is displaced from its desired position - and thus, we can use Manhattan distance.
 
We can see from this example that the Manhattan distance will always give a value greater than or equal to the Hamming distance. It also never overestimates, which means it strictly dominates the Hamming distance, and is therefore a better heuristic. It is also important to note that the Manhattan distance can be computed extremely quickly, and is therefore not a bad choice of heuristic at all.
 
You can arrive at these Heuristics by relaxing the problem at hand. You can summarize the constraints on Puzzle 8 as follows:
You must move tiles into their correct positionsA tile can only be moved UP, LEFT, DOWN or RIGHT.A tile can only move into a blank space.If a tile is displaced from its position, it is counted as a move.If a tile moves to its adjacent position, it is counted as a move.
 
By removing rule 3, you can arrive at a problem which can be solved using the Manhattan distance heuristic.
By removing rules 2, 3 and 5, you arrive at a problem which can be solved using the Hamming distance.
 
For many problems where you wish to search through the space of potential solutions, if you need a heuristic to help your informed search, you can take a similar approach of relaxing the constraints on the problem and seeing if it can be solved quickly (since the Heuristic needs to be something you can compute quickly). We will look at one such approach below.
 
B. Give an admissible heuristic for the Rubik's Cube problem.
This is a slightly more difficult problem. However, we can still come up with some interesting heuristics to solve it. For simplicity, we will go with a 3x3 Rubik's cube here. It is important to note that in such a cube, the center square on each face never moves - there is no move that can displace it. Therefore, the color of the center square on each face is the desired color of that face.
 
One approach would be to remove all heuristics except the main rule of the Rubik's cube - that each side needs to have all squares of the same color. Then, we come up with a solution that basically equates to ""paint each face in the color of its center square."" This doesn't require any moves to solve the problem, and therefore gives us a heuristic that always returns zero. This never overestimates and is technically consistent, which means it is an admissible heuristic and is valid. However, this isn't very useful, so we should probably come up with something a little less trivial.
 
Another heuristic suggested in the class was ""one if incomplete, zero if complete"". Again, this never overestimates, since we need at least one move to solve an unsolved cube - therefore, it is admissible, but isn't very useful. It will return a 1 as long as our search runs, and returns 0 for a goal state, which was going to happen anyway.
 
How about if you extend the hamming distance example from the previous question, and take ""number of misplaced squares""? That should work, right?
 
Consider the following cube state:
 

 
Here, one turn to the right (which should count as one move) will solve the puzzle. However, the Hamming distance will count 12 squares (6 seen, 6 unseen) - giving us an overestimated value!
 
However, we can see here that one move always displaces 12 squares. How about if we just divide the Hamming distance by 12? Amazingly, that is an admissible heuristic! It's not something you can always count on though - in this case, the Hamming distance is only overestimating because it always overestimates by a fixed scalar amount. It's similar to taking something like 10*Euclidean distance as opposed to just Euclidean distance. Therefore, (number of displaced squares)/12 is a decent heuristic!
 
In his paper, Korf takes a slightly different approach - rather than using squares to create a Heuristic, he uses ""cubies"". A cubie is one of the 27 little cubes that constitute a Rubik's cube. On each edge, the corner cubies display 3 faces and the center cubies display 2. We don't need to account for the cubies that form face centers since they are always ""solved"".
 
Now, consider an optimal solution for a Rubik's cube. Any move you make will be because one or more cubies are displaced. Any move you make will displace 8 cubies (4 corner, 4 center). How about if we apply Manhattan distance here? He proposes summing up the Manhattan distances for the edge cubies and for the corner cubies, taking the max of the two, and dividing by 4 (since in any move you move four edge cubies and four corner cubies).
 
The rationale for taking the max is a bit more complex - since we have fewer corner cubies than edge cubies, the expected value of their Manhattan distance is also less - therefore, taking the value for center cubies whenever it is higher would actually create a heuristic that dominates! You can refer to the Korf paper to get into this in greater detail.",jc6w44hrp9v2ki,[],,0.0,151.0,542,,[Solution] Challenge Question 6 - Search,"[lesson2, challengeqtns]"
5ad7d4670d63974e20c391b9,"Solution for Challenge Question 4 @321

Here's Thad himself trying to work this out - https://youtu.be/O0-f1j5_X0A?t=3m25s
It's definitely something that will help you understand the various Search algorithms better and will prepare you for the midterm. It's okay if the numbers you computed do not exactly match the answers mentioned in the video: as long as you got the approach right, you should be fine!
 
In addition, one of the students from a previous semester did this amazing job of creating visualizations for the search algorithms: https://codepen.io/zackee12/full/LxKbjg
(Thank you so much, Zachary!)

 

In addition, we hope you noticed that DFS was quite easy to work out but took a really long path to find the goal. Did you also notice how A* tends to have a 'sense of direction' towards the goal unlike other searches which explore around without any approximation of the target? UCS and Bidirectional UCS end up finding the same path and in bidirectional UCS, it should not make a difference if you keep a common frontier or if you keep two separate frontiers. We also hope that this exercise made you see the difference in the stopping criteria of bidirectional UCS and bidirectional BFS.   
 
Hope this makes you search deeper on this topic! Remember Search forms the basis of AI. (Game playing is also a form of search - Adversarial Search!)",jc6w44hrp9v2ki,"[{u'text': u'Am I not understanding the DFS correctly? It looks like the visualization never finished.', u'responses': [u'Hey Anthony, this is just a screen cap, visit the link for the full simulation.']}]",,0.0,159.0,543,,[Solution] Challenge Question 4 - Search,"[a2, lesson2, challengeqtns]"
5ad7d4670d63974e20c391ba,"This is the solution for Challenge Question 7 @452.

1. The algorithm returns the 6th pixel, as shown below in green. This is a classic example of Hill Climbing being stuck in local maxima/minima.


2. Naturally, the algorithm won't return the brightest pixel of the image, but rather the first local maximum. In order to get the global maximum you have to implement a different algorithm like Random Restart, Simulated Annealing, Stochastic Beam Search etc. The randomness of these algorithms will guarantee an optimal solution.",jc6w44hrp9v2ki,"[{u'text': u'Regarding part 2, if we need the optimal solution, I wonder what's the advantage of all these algorithms compared to linear search... Thanks', u'responses': [u'Hey Tony, 
Search algorithms would work for this particular challenge question, but they would fair much worse for non-discretized problems. Imagine implementing search algorithms in a continuous space!
These optimization algorithms approximate a solution without actually having to explore the entire target space, which is often impossible. ']}]",,0.0,161.0,544,,[Solution] Challenge Question 7 - Optimization Algorithms,"[challengeqtns, lesson3]"
5ad7d4670d63974e20c391bb,"Solution to Challenge Question 8 - @466.

1) You are performing Simulated Annealing on a search space. Given that you are at a specific state with a value given by E, and you find a new state given by E', what is the probability of the new value being accepted as per the values given below?
 

Current State, E
(Evaluation)

Potential New State, E'
(Evaluation)
TemperatureProbability of Accepting10060500.449200120500.202100251500.6062002103011001503001200403000.587
 
Clearly, when you get an E value that is better, you accept it blindly; if T = 0, you set P to zero, rather than allowing for silly division-by-zero errors.
The question arises: does this even matter for Machine Learning? It does! We will see more about this when we get to the chapter on Neural Networks.
 
2) When performing Simulated Annealing, should you start with a temperature of infinity or some finite value? What factors would influence your decision?
3) In the ideal case, Simulated Annealing runs in a continuous fashion, with Temperature taking infinitesimally small steps; however, if you were to ""cheat"" by taking discrete steps, what issues might you run into? How would you know if your answer was right?
In an ideal case, you would be able to start at a temperature of infinity, reduce the temperature in infinitesimally small steps, and take very small steps when finding a new position - however, this is not practically possible. Restricting your temperature (starting at a large finite value), however, can result in not jumping around enough; having too small a delta can take too much time, and having a large delta can result in peaks being skipped altogether - all resulting in us finding only local optima! How do we get around this?
 
Without further info, you really can't. If you have an idea about the topology of your search space (i.e., where you can expect to find peaks, the relative heights of peaks and pits, etc.) you could probably come up with a good temperature to start at, and a suitable delta - the idea being that you need some domain knowledge before you can decide how to restrict your search.
 
In the past, this was very important - with limited processing power, we needed to take educated guesses on our search space so that we could cheat by restricting our search by adjusting our hyperparameters. This is becoming less of a problem now, since the amount of processing power we have at our disposal allows us to run searches easily from high temperatures, with small changes, meaning we can approximate an ideal run of simulated annealing.
 
If we do have to cheat, however, there is always a chance we will end up in local optima. The best way to solve this is a method we've seen before - random restarts! We can restart at new positions multiple times and run the algorithm to conclusion, and take the maximum value we see overall - this should give us the global optimum. Ideally, we will see the same value every time, but in the off chance that we don't, this randomness allows us to get to a better answer!
 ",jc6w44hrp9v2ki,[],,0.0,167.0,545,,[Solution] Challenge Question 8 - Optimization Algorithms,"[challengeqtns, lesson3]"
5ad7d4670d63974e20c391bc,"Solution for Challenge Question 9 @474.


1) Given the following population, complete the following table to show the fitness levels and probabilities of selecting each of the following individuals.
 
IndividualFitness (f)Probability of Selection0010010.1251100020.250100120.251001020.250010010.125
 
We just need to compute the fitness function as per the formula given above for each individual. We then select individuals based on their fitness - given that this is the entire population, their probabilities need to sum up to 1; therefore, we can simply normalize using the fitness values to get the selection probabilities.
Given the fitness value of an individual is f, we can say the selection probability is directly proportional to f, and therefore is represented as f*x.
Now we know that the sum of all fx = 1.
Therefore, x*(1+2+2+2+1) = 1.
x = 0.125.
 
2) Now, for the individuals above, perform a single 1-point-crossover and a single mutation to come up with the child with the highest possible fitness. The point for crossover is the point between b3 and b4.

We know that fitness increases with the number of 1s we have. Therefore the best parents will be one that has the most 1s in the first three bits, and another that has the most 1s in the last two bits (since the crossover point is between b3 and b4). We can then mutate a zero to get the highest possible fitness.
We can pick two individuals with the highest possible selection probabilities for this.
 
Parent 1: 11000
Parent 2: 10010
Child 1: 11010
Child 2: 10000
Upon mutation:
Child 1: 11110
Child 2: 10001
 
Thus, Child 1 has the highest possible fitness value of 4. We can't get a 5, since the definition of the fitness function ensures it is not possible; we cannot get a 6 in just one iteration since we are allowed only one mutation and will have at least two zeroes based on our population.
",jc6w44hrp9v2ki,[],,0.0,170.0,546,,[Solution] Challenge Question 9 - Optimization Algorithms,"[lesson3, challengeqtns]"
5ad7d4670d63974e20c391bd,"Since match outcome (ie, AvB, BvC, CvA) is a categorical variable, I do not understand what is meant by ""the difference in expected outcome for the 3rd match"".  Sure, we assign numerical values to the categories (team1 win = 0, team2 win = 1, tie = 2), but those numerical assignments are arbitrary and do not necessarily correlate to an inherent ordering of the possible outcomes.  As such, the standard ""expected value"" calculation, E(X) = sum[xP(x) for x in X], would not apply.

Perhaps an ordering could be created such as ""amount of winning by team 1"", then set team1_win = 1, tie = 0.5, team1_loss = 0, in which case the ordering could mean something, but it isn't clear we are allowed/supposed to transform the variable space as part of the exercise.

Hence, what definition are we supposed to use to compute ""expected outcome""?",jc6w44hrp9v2ki,"[{u'text': u'Upon further investigation, it does appear that the ""total variation distance"" (sum of abs diff of categorical probabilities) is the standard metric to compare the difference between two probability distributions for the purposes of sampler convergence on Bayesian networks. However, other metrics are used as well, such as the Euclidean distance and more. The following papers explore measuring convergence rates with alternative metrics:

1. Concentration inequalities for Gibbs samplingunder dl2-metric:
https://projecteuclid.org/download/pdf_1/euclid.ecp/1465316765

2. Convergence of Markov Chain Monte Carlo Algorithms with Applications to Image Restoration:
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.329.7092&rep=rep1&type=pdf

I will assume the instructors intend for us to use the total variation distance metric on this assignment, and if not, to kindly let us know.', u'responses': []}]",,1.0,162.0,548,"I interpreted that sentence to mean that the ""difference in expected outcome for the 3rd match"" means the total absolute difference among the posterior after a sample M vs. the posterior after a sample M+1

A little more detail...

After the first sample that is usable you will get a posterior distribution of M0 = P(BvC | AvB = 0, CvA = 2) = [probability B wins, probability C wins, probability ties]

then after you get the next sample that is usable you will update your posterior distribution M1 = P(BvC | AvB = 0, CvA = 2) = [probability B wins, probability C wins, probability ties]

Then to find the difference in expected value of P(BvC | AvB = 0, CvA = 2) you find the sum of absolute values of differences between the three outcomes of the last two samples.

difference = abs(m0[0] - m1[0]) + ... etc.

Just checking the difference in the first value of the three that are within the posteriors should still allow you to converge but with less precision.

For this assignment we are saying it converges if we get 10 consecutive differences below a delta value (say 0.0001)

I think I answered your question, so let me know if you are still confused on the wording of the assignment.",What is the definition of &#34;expected outcome&#34; in Assignment 3 part 2e?,[a3]
5ad7d4670d63974e20c391be,"I'm testing inference on P(T=true) as suggested by README part 1c. The result is 0.0375978, which is far away from 0.2
My inference part of code is exactly the same format as what provided in README:
<code>F_A_node = bayes_net.get_node_by_name('faulty alarm')
engine = JunctionTreeEngine(bayes_net)
Q = engine.marginal(F_A_node)[0]
index = Q.generate_index([True],range(Q.nDims))
prob = Q[index]</code>
      just replaced the 'faulty alarm' with 'temperature' and replaced F_A_node with T_node
My T_Node don't have parent nodeI set the distribution of T_Node to [0.8,0.2]
What could possibly go wrong that cause my P(T=True) !=0.2?


",jc6w44hrp9v2ki,"[{u'text': u'I actually replaced 'faulty alarm' with 'temperature', the result is still P(T=True) = 0.0375978. I didn't state that clearly before, thank you for pointing out. just clarified that in the description of my question.', u'responses': [u'Do you have different node ids for all of your node declarations?

From the Readme,

A_node = BayesNode(0,2,name='alarm') indicates that the 0 is a node id that needs to be unique for every node. If you have the same_id for multiple nodes, you may be overwriting one of them into your T_node.

Also, double check your distributions to make sure you didn't accidentally copy paste and not change a variable.



', u'Thanks for reminder. It turns out that I set the distributions for G and FG wrong, which cause error in P(Temperature=True)']}]",,0.0,144.0,549,"The code you quoted is testing the marginal probability of the alarm being faulty, not the temperature being high.",what could possibly go wrong for inference on P(T=true),[a3]
5ad7d4670d63974e20c391bf,"Hi,I got exception error from 1 c.Could you please tell me what is wrong?

thank you in advance.""output"": { ""points_available"": 10, ""message"": ""1c failed due to error: EXCEPTION IN (run.py, LINE 2 85 \""if prob - bound <= correct_prob <= prob + bound:\""): unsupported operand ty pe(s) for -: 'tuple' and 'float'1c failed due to error: EXCEPTION IN (run.py, LI NE 303 \""if prob - bound < correct_prob < prob + bound:\""): unsupported operand type(s) for -: 'tuple' and 'float'1c failed due to error: EXCEPTION IN (run.py, LINE 321 \""if prob - bound < correct_prob < prob + bound:\""): unsupported operan d type(s) for -: 'tuple' and 'float'"", ""return_type_check"": false, ""points_awarded"": 0 }, ""description"": ""(1c). Test for the inference task for various power plant situations: marginal alarm, gauge, and temperature. (10 points)""",jc6w44hrp9v2ki,"[{u'text': u'', u'responses': [u'I passed the test.I think ""....gauge=:True:"" in the first item in tuple caused of the issue.Am I right?thank you.']}, {u'text': u'I still got the exception.Do I need to return just float or tuple for ic?', u'responses': [u'I'm pretty sure it's a float.']}, {u'text': u'I'm getting a similar error on my first run of bonnie.  Everything passes locally so I don't understand why the power_plant network would not exist.  I suppose that I am returning the network the wrong way or something... but I cannot seem to understand since it returns fine with local tests and probabilities are even returned correctly in my prob tests.

1c failed due to error: EXCEPTION IN (run.py, LINE 283 \""prob = pn.get_alarm_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment1c failed due to error: EXCEPTION IN (run.py, LINE 300 \""prob = pn.get_gauge_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment1c failed due to error: EXCEPTION IN (run.py, LINE 318 \""prob = pn.get_temperature_prob(power_plant, True)\""): local variable 'power_plant' referenced before assignment"",', u'responses': []}]",,2.0,140.0,550,"Are you returning a tuple from your function? Use the second argument to the function to determine which marginal probability to compute (i.e. True/False). You should be returning a float from the function.
Are you passing local unit tests?",exception error from 1c,[a3]
5ad7d4670d63974e20c391c0,"I am receiving all points awarded, but in part 2d I am receiving a message, how can we confirm (besides adding from the json file in bonnie) the total points awarded for the assignment?

thanks
Ivan ",jc6w44hrp9v2ki,"[{u'text': u'Is it ""Type of returned values is wrong""? I'm getting the same even though I got all the points.', u'responses': [u'That should be fine. It means one of your returned answers had the wrong type, but bonnie still checked it to be correct.']}]",You can check your latest submission on bonnie.udacity.com for the last score. If you receive all points awarded you're good to go.,0.0,187.0,551,,Points awarded,[a3]
5ad7d4680d63974e20c391c1,"I'm having two minor issues with 2a and 2b... what parameters need to be passed to the ""generate_index"" function for the distributions on A,B,and C... I'm getting the error ""cannot copy sequence with size 4 to array axis with dimension 2"" ... and I'm not sure of how to set up the engine.evidence for calculate posterior... comparing it to the other examples, I would assume something like ""engine.evidence[AvB_node] = 0"" means that A won, does that seem right? the pbnt documentation is terrible...",jc6w44hrp9v2ki,"[{u'text': u'Hi, I have the same confusion. Can you help explain more on the generate_index function?
Thanks in advance.', u'responses': [u'From my initial look, the generate_index function should always just be called with empty arrays as args:

generate_index([], [])
(Still don't understand what those arguments (or the function) do and can't find examples - probably best way is reading the source code.

Notwithstanding, if you're getting errors it's probably from your node generation. From the source code, the pbnt BayesNode constructor signature is:

BayesNode(id, numValues, index=-1, name=""anonymous"")
That numValues parameter is key - remember that for 2a/2b we're no longer dealing with boolean nodes, so you need to update numValues accordingly...', u'I see... thanks for the explanation!']}]",,0.0,127.0,556,"finally got the generate index part figured out.... the second value when initializing the node is the size of the node... that was definitely not obvious

and got the second part... that generate_index function really needs to be explained better...
",minor confusion / clarification with pbnt,[a3]
5ad7d4680d63974e20c391c2,"Mid Term Topic List includes Machine learning topics, whereas as per the course schedule some ML topics are scheduled to be covered after the mid term.
Please clarify whether ML topics will be a part of mid term or not?
",jc6w44hrp9v2ki,[],ML topics that are specifically listed in that link can/will be on the midterm.,0.0,200.0,557,,Mid Term Topics,[midterm]
5ad7d4680d63974e20c391c3,"Hi,

I've been struggling for calculation_posterior for over 2 hours. And I have 3 questions.
1. regarding set an evidence for a none boolean situation. I want to give evidence when A won against B. Can i wrote in below way?
engine.evidence[AvB_node] = [1,0,0]
2. when i try to calculate the probability on B won over C, I was wondering how do I do for all three cases. So i was thinking calculate them one by one. Is this the write way?
Q = engine.marginal(BvC_node)[0]index_0 = Q.generate_index([0],range(Q.nDims))
... then [1], and [2]
In above cases, when i print it out, the value is not correct.
So i was wondering where did i go wrong?
",jc6w44hrp9v2ki,"[{u'text': u'Thanks for the answer, I agree. However after I changed to it, seems it is still wrong.
I also changed the part to do the index calculation:


and when I try to print info out, the results are just 0,1,2:
engine = EnumerationEngine(bayes_net) 
engine.evidence[AvB_node] = 0 --> initial state
engine.evidence[CvA_node] = 2
 
Q = engine.marginal(BvC_node)[0]
index_0 = Q.generate_index(0,range(Q.nDims))
index_1 = Q.generate_index(1,range(Q.nDims))
index_2 = Q.generate_index(2,range(Q.nDims))
print (""index_0:"",index_0) --> 'index_0:','0'
print (""index_1:"",index_1) --> 'index_1:','1'print (""index_2:"",index_2) --> 'index_2:','2'posterior = Q[index_0,index_1,index_2] --> this line seems wrong even from compilation... i dont know why', u'responses': [u'Q will return an array, so to get the values, you have to use Q[index_0], Q[index_1], Q[index_2].', u'I ran into a similar issue here as well. Stepping through the code helped me. One clue is that the method has the posterior response already set as [0, 0, 0]. If you inspect Q you will find the variable table which can be converted into a list.', u'Thank you Kruti for the reply, it is the problem!
After change to Q[index_0], Q[index_1], Q[index_2], I got the right answer.']}]",,0.0,127.0,558,"Your evidence[AvB] will be 0, not [1,0,0]. If you see in the readme, they have mentioned
AvBthe outcome of A vs. B (0 = A wins, 1 = B wins, 2 = tie)

So in AvB, you will specify that A won against B by giving it the value of 0. Similarly, to say B won against A, its value will be 1 and it will be 2 for a tie. 
Your method to calculate posterior should work after this change.",question in game calculate posterior,[a3]
5ad7d4680d63974e20c391c4,"I am struggling to build distribution for the outcomes. How do you calculate difference in skill level having


(T2 - T1) | T1 wins | T2 wins| Tie |
|------------|----------|---|:--------:|
|0|0.10|0.10|0.80|
|1|0.20|0.60|0.20|
|2|0.15|0.75|0.10|
|3|0.05|0.90|0.05|

and 



|skill level|P(skill level)|
|----|:----:|
|0|0.15|
|1|0.45|
|2|0.30|
|3|0.10|

I feel like it is very simple but don't seem to put it together.



",jc6w44hrp9v2ki,[],,0.0,125.0,561,"Instaed of a boolean with two values, your team nodes will now have 4 possible values (skill level), and the match nodes will have 3 possible values (Team 1 wins, Team 2 wins, Tie).So you create a distribution of the probable skill level for each team, which is given in the table. Then, you have to calculate the distribution for, say AvB, keeping in mind all the combinations of the skills between the two teams. So your distribution table for AvB will contain a distribution for -
Skill Level A    Skill Level B   P(A wins)    P(B wins)   P(Tie)

      0                      0              (calculate values from the table)
      0                      1
      0                      2
      0                      3
      1                      0
and so on.",2a - skill difference,[a3]
5ad7d4690d63974e20c391c5,I'm very confused about how to proceed with Gibbs sampling. I've been racking my brain on this for quite some time. Do we have to assume some fixed values or enumerate over all the variables? Can anyone give some hints on how to go about the implementation?,jc6w44hrp9v2ki,"[{u'text': u'So we don't randomly choose the new value of the variable, is that correct?We have to find its conditional probability with respect to all the other variables, if I understand correctly.', u'responses': [u'Yes that is correct.', u'Correct!']}]",,0.0,143.0,563,"Make sure you read through the discussion on @465. There is a lot about Gibbs sampling. In Gibbs sampling, you generate samples of the state by changing one variable of the state at a time. You can randomly choose which variable to change. To choose what value to change that variable to, you have to choose based on the conditional probability of that variable given the values of the other variables in the state.",How to proceed with Gibbs sampling?,[a3]
5ad7d4690d63974e20c391c6,"slides 31-33
B(q) = -(q * log2q + (1-q)log2(1-q))

plugging in either q=0 or q=1



(should be a - in front of each equation)

Both yield undefined according to Wolfram alpha
They don't make any mention of this in the lecture.
Did I make a mistake in my math or am I missing something here?
",jc6w44hrp9v2ki,[],"I believe the image links are broken so I might be missing something. 

But to answer your question: This is the equation for the binary entropy function. 0log0 in this case is considered to be 0. Check this for more information.

",0.0,116.0,564,"I think you need to consider the limit when q->0. It is
$$\lim_{x\rightarrow 0}x*log_{2}x = 0$$
Here is a figure for them
",Question about entropy algorithm,[lesson7]
5ad7d4690d63974e20c391c7,"Just a clarification on the random sampling off the proposed candidate. I keep getting this error in Bonnie for my Submission on 2d

""MH always generating samples which look like Gibbs""

Is Gibbs, we randomly selecting ""one variable in the the initial_state. Is this the same for MH sampling or do we have to randomly select an entire initial_state (all variables in the lists) for this method?",jc6w44hrp9v2ki,"[{u'text': u'I got all the points for 2d, even with this error message:
MH generating samples which look like Gibbs 40 times out of 50 times', u'responses': []}]",,0.0,142.0,565,The latter.,MH always generating samples which look like Gibbs,[a3]
5ad7d4690d63974e20c391c8,"From the book ""A truth table over n attributes has $$2^{n}$$ rows, one for each combination of values of the attributes. We can consider the 'answer' column of the table as a $$2^{n}$$-bit number that defines the function. That means there are $$2^{2^{n}}$$ different functions""

I don't quite follow this statement. I understand that for n attributes, there are $$2^{n}$$ rows in the truth table. What does it mean for the ""answer column""? One column from the truth table corresponds to one attribute. Shouldn't it be answer row? If a function is defined by a $$2^{n}$$-bit number, why this function can have $$2^{2^{n}}$$ different number? 

What did I miss here? Thanks. 

",jc6w44hrp9v2ki,"[{u'text': u'My guess is that the ""answer column"" is the column representing the result value of the entire boolean algebra statement? E.g., the state space of the statement:

A AND NOT ( B AND C )

can be represented in a table with 2^3 rows, with 3 columns. The ""answer column"" would be a fourth column representing the evaluation of the statement for the values of (A,B,C) for the given row.

That's just my guess, though, not sure about the other parts of your question. Hope it helps somewhat though!', u'responses': [u'Thanks Zachary. Your answer is very helpful. I made the truth table
ABCA AND NOT ( B AND C )FFFFFFTFFTFFFTTFTFFTTFTTTTFTTTTF
and then think the ""answer column"" could be the 4th column here. If the function can be defined by a 2^3=8 bit, it indeed has 2^8 different type. For example, 
0000 0000 defines function 0
0000 0001 defines function 1
0000 0010 defines function 2
...
1111 1111 defines function 2^8＝255

That's my understanding so far. I may be totally off. 

']}]",,1.0,109.0,566,"For every row of the truth table, its labeling or classification label may be 0 or 1. So that for a truth table with $$q$$ rows, there are $$2^q$$ different possible labelings, all corresponding to a particular function. $$q=2^n \Rightarrow 2^q = 2^{2^n}$$Consider the simple table for 2 boolean variables, it has $$2^2$$ rows; say column 1 is the value of the first variable, column 2 the value of the 2nd variable
00011011

then it has classification labels [in column 3 here] for the rows, that could be 
000010100110
that corresponds to the boolean function $$False$$

however, that 3rd column could be $$0000=False$$,$$0001=v_1 \wedge v_2, 0010=v_1 \wedge \neg v_2, 0011 = v_1, 0100=v_2 \wedge \neg v_1$$,$$0101=v_2,0110=v_1\oplus v_2,0111=v_1\vee v_2, 1000=\neg v_1 \wedge \neg v_2$$,$$1001=\neg(v_1\oplus v_2),1010=\neg v_2,1011=v_1\vee\neg v_2,1100=\neg v_1$$,$$1101=\neg v_1 \vee v_2,1110=\neg v_1 \vee \neg v_2$$, or $$1111=True$$
count them up or simply observe that they are binary number representations, there are 16 functions $$=2^4=2^{2^2}$$",the number of different decision trees for n attributes,[lesson7]
5ad7d4690d63974e20c391c9,"Hi,

I followed the online instruction, downloaded and installed the vagrant.
How do I built up the VM to run my code locally?

I ran ""vagrant up"" and ""vagrant provision"". Seems both are working fine.
How should I proceed next?

Also side question, how do we usually test 2c-2e? should we write the test vector ourself?



",jc6w44hrp9v2ki,"[{u'text': u'what is the point of the Vagrant? It is very vague as to why we might need it?', u'responses': [u'
You don't need it per se.  It's a virtual machine with python and packages installed to match bonnie's environment.  I used it for A-3 because even after installing the correct version of numpy trying to run my code on my machine was giving some strange python import error that I didn't feel like sorting out.   

Hope that made some sense. ']}]",,1.0,101.0,568,"If vagrant up  worked, then you should be able to use   vagrant ssh   which will ssh  into the guest.  Once inside,  cd /vagrant   to switch to the directory where your code lives.  Changes you make in the guest in that directory are reflected on the physical machine. 

I wrote small tests to test the parts which were missing from the supplied code. ",How to run Vagrantfile as VM to test locally,[a3]
5ad7d4690d63974e20c391ca,"In my local test, the posterior distribution of BvC generated by MH sampler is [0.32, 0.36, 0.32], which is very different from that in 2b. 
I have been struggling to get a correct one. When I have no idea to improve, I submit it and got all the points. 
I am not sure what is going on. 
Does this mean Bonnie allows large error or Bonnie does not check the values?
Or maybe the delta value I have tried is not the best. ",jc6w44hrp9v2ki,"[{u'text': u'That is far enough away that you probably have a bug somewhere. Bonnie does seem to be forgiving though on the range of values it allows', u'responses': []}]",,0.0,140.0,569,"You can tighten the delta (I have seen some who used 0.00001) and you can increase the convergence match factor (N). 

However, given that you have full points from bonnie, I would leave things be.",Passing Bonnie with wrong values in 2d part,[a3]
5ad7d4690d63974e20c391cb,"Are we allowed to add more imports on probability_solution.py?  2b requires EnumerationEngine, but this is not imported in the beginning of the script.  Is it ok to just add it?

from Node import BayesNodefrom Graph import BayesNetfrom numpy import zeros, float32import Distributionfrom Distribution import DiscreteDistribution, ConditionalDiscreteDistributionfrom Inference import JunctionTreeEngine",jc6w44hrp9v2ki,[],,0.0,118.0,570,"Yes, you can add the additional imports as required.",Imports in probability_solution.py,[a3]
5ad7d4690d63974e20c391cc,"Hey All. Just a flag for assignment 3. Since the Udacity videos and textbook are quite thin on material on the Metropolis Hastings algorithm, I've been looking around at other material, and wanted to put a solid plug in for the lecture from Daphne Koller's awesome Probabilistic Graphical Models course:

https://www.coursera.org/learn/probabilistic-graphical-models-2-inference/lecture/UPVWC/metropolis-hastings-algorithm

Have found this to be a really clear explanation in fairly simple terms, complementing the material from our course.",jc6w44hrp9v2ki,[],,0.0,135.0,571,,Great Stanford Lecture on MH Sampling,[a3]
5ad7d46a0d63974e20c391cd,"Maybe the description is wrong, but my Bonnie output has two different results with description of 2d. 

{
""output"": {
""points_available"": 5,
""message"": ""Incorrect distribution generated after 500000 runs. Should have reached something near [0.259, 0.428, 0.313] instead of ['0.19', '0.50', '0.31'].\n"",
""return_type_check"": true,
""points_awarded"": 0
},
""description"": ""(2d). Test for MH convergence. (5 points)""
},

{
""output"": {
""points_available"": 19,
""message"": ""Gibbs Calculated posterior [0, 0, 0] is too far from actual posterior [0.259, 0.428, 0.313].\nMH Calculated posterior which is too far from actual posterior.\n"",
""return_type_check"": true,
""points_awarded"": 2
},
""description"": ""(2e). Testing compare_sampling. (20 points)""
},



{
""output"": {
""points_available"": 10,
""message"": ""MH generating samples which look like Gibbs 46 times out of 50 times."",
""return_type_check"": true,
""points_awarded"": 10
},
""description"": ""(2d). Test that MH is implemented correctly. (10 points)""
},

If the first one is testing for MH convergence, what about those 19 points in 2e? If I'm not wrong, both MH and Gibbs convergence are a part of that.Am I missing something here?



",jc6w44hrp9v2ki,"[{u'text': u'I see. But for 2d, we were only supposed to implement one iteration, right?', u'responses': [u'Yes, one iteration.']}]",,0.0,140.0,572,Those are sub-sections of 2d. You would see multiple sub-sections for 2c as well. The total of the sub-sections would match the ones in the README.md,Two different results for 2d,[a3]
5ad7d46a0d63974e20c391ce,Getting this error on assignment 3. Not issues on previous submissions. Has anyone else seen this?,jc6w44hrp9v2ki,[],,0.0,131.0,573,"from README.md

Submit this file using python submit.py assignment_3.
",submit.py: error: too few arguments,[a3]
5ad7d46a0d63974e20c391cf,"Can you please release assignment 4 as soon as possible? I would like to get started on it since we will also have the take home midterm to complete during this time.

The course schedule has stated the assignments will be released on Monday and we have until the following  Sunday, but typically the assignments have been released Wednesday. Those 3 days make a huge difference for any student working full time. Please help us and release the assignment on time.",jc6w44hrp9v2ki,"[{u'text': u'UPDATE: From the instructors week 8 e-mail:

> but some students consider it one of the easier assignments - you should not need the entire duration to complete it.

This is good news!', u'responses': []}, {u'text': u'Thank you for the response Ravikiran. What you are saying regarding releasing on Wednesday makes sense. I'm also happy to hear the assignment that is given in parallel with the Midterm is on the lighter side.', u'responses': []}, {u'text': u'God, how I could use an easier assignment as these assignments have been ROUGH! Educational but rough. I would say I would enjoy the breather but I think the midterm is going to be rough too.
Anyway, look forward to the assignment :)', u'responses': []}, {u'text': u'Can we get an ETA on release since it is now Thursday?  Appreciate it.', u'responses': []}]","The course schedule states that the assignments will be released the ""Week of"" the mentioned Monday, and we have released them on Wednesday or earlier as stated in our Week 1 Announcement followups. Please check @7 . We do believe this is sufficient time to complete the assignments, and we intentionally keep a buffer period of a few days so that students with extensions can submit before we start loading Bonnie for the next assignment.

Assignment 4 is also reported to be among the easier assignments by some students, and we keep it open for an extra week during the midterm so that students can get their work done earlier if they wish to, so that they can get a breather before A5.

We will do our best to release the assignment as early as possible, but please note that Wednesday is the day we aim for.",0.0,184.0,574,"Not sure if you'd noticed, but the calendar shows we get an extra week for that project.",Release of assignment 4,[a4]
5ad7d46a0d63974e20c391d0,"for Gibbs_sampler my solution fails for EXCEPTION IN (run.py, LINE 518 \""test_sample = pn.Gibbs_sampler(game_net, list(initial_state))\""): [Errno 27] File too large"",
anyone know how do I fix? 
thanks",jc6w44hrp9v2ki,"[{u'text': u'This is very unlikely to be caused by comments in your code.

It is more likely that you are using up too much memory or less likely that you are outputting too much data to disk by prints and/or other output.', u'responses': [u'fantastic! removing comments fixed the error. thanks a lot
', u'How big was your source file with the comments?    My probability_solution.py is almost 800 lines with 24K bytes including lots of comments.  No issues on size.', u'I removed abt 20 comments throughout all of my functions, strange that Bonnie cannot handle it', u'I would be very surprised if the issue was the comments themselves -- like I said, I have a *lot* of comments and had no issues.  I'm guessing that something else was cleaned up either in your code when you deleted the comments or on the server.  ', u'But hey, as long as you got it working...', u'thanks a lot, yes, as long as it worked =)']}]",,0.0,114.0,575,"got the same error!! any solutions or suggestions?
did you try removing comments, can it possibly be caused by them?",for Gibbs_sampler,[a3]
5ad7d46a0d63974e20c391d1,"Hi Everyone,

When calling GibbsSampler() iteratively, I am wondering how you guys handle evidence?

For eg, in last iteration, the sample returned is [1,2,1,2,3,4]; the last two are evidence and should never be selected/updated in the sampler; but we DON""T have an argument related to evidence in the function given, therefore we cannot tell our code which one not to update?

Waiting for your help..

Thank you,

Jiaji",jc6w44hrp9v2ki,"[{u'text': u'I added a parameter to my sampler functions with a default that indicated no evidence so that evidence could be passed in but would not result in an error if not provided.', u'responses': []}]",,0.0,114.0,576,According to @465 is acceptable to hardcode the evidence in the sampler function.,2e How to handle Evidence,[a3]
5ad7d46a0d63974e20c391d2,"Hey folks,

I'm not sure the best way to implement P( A | AvB, CvA, C, B). I'm conflicted between two ways:

1. From the book / lectures, I'm feel like what they're looking for is the joint distribution:
P( A | AvB, AvC, C, B) = P( A | AvB, B) * P( A | AvC, C)

However, in my mind it's much more natural to think of P( A ) as a multinomial that's getting updated as more ( game, team ) evidence is provided. Since, in my mind at least, it would be extremely rare to get the knowledge about each game at the EXACT SAME TIME, I think it should really be a method where you update the prior based on the first game, and then the second (like the below).

2. Updating the prior version:
P( A | AvB, AvC, C, B) = P ( A'' )
where:
P( A' ) = P ( A | AvB, B ) 
P( A'' ) = P ( A' | AvC, C )

Does anyone else have thoughts? I'm implementing both for now, and will throw them at Bonnie and see what happens :).",jc6w44hrp9v2ki,"[{u'text': u'Also, are people using the EnumerationEngine in their Gibbs Sampler? I thought we weren't allowed to use any of the engines, but it seems here that they might be OK to use?', u'responses': [u'will make a new post for that one', u'No. Don’t use the enumeration engine in the Gibbs sampler. It states in the ReadMe that you will get 0 points if you do that.', u'Thanks! That's what I thought :)']}]",,0.0,117.0,577,,Update Prior or not?,[a3]
5ad7d46a0d63974e20c391d3,"I assumed this was not OK based on the directions:

```
 ""YOU WILL SCORE 0 POINTS ON THIS ASSIGNMENT IF YOU USE THE GIVEN INFERENCE ENGINES FOR THIS PART""
```

But it seems like some people might be? Can anyone clarify?",jc6w44hrp9v2ki,[],,0.0,120.0,578,"Answered in a comment in ""Update Prior or not?"" - don't do it!",Using EnumerationEngine in GibbsSampler,[a3]
5ad7d46a0d63974e20c391d4,What would be concrete examples of distributions that are intractable?,jc6w44hrp9v2ki,"[{u'text': u'The easiest definition for me of a tractable distribution is ""one that can be expressed in closed form"". This is true for a most theoretical distributions - the normal, poisson, gamma, beta, etc. And it's true that most processes in ""the real world"" _roughly_ follow a distribution with a closed form (for example, it's easy to imagine human heights as normally distributed).

But as you go to the limit with the precision with which you want to describe the distribution of human heights, it becomes intractable very quickly (meaning it can't just be expressed using a normal anymore). There will be tons of little sub-populations that mess it up and cause it not to be normal. You can try to control for these things, and you'll get closer to the theoretical normal if you do. But there is always more detail that can be added / controlled for: first there will be sex, then age, then nationality, parents' heights, nourishment, etc. etc. Controlling for each will get you a little closer to the theoretical distribution, but you'll never get _quite_ there.

And that's OK! People use the normal to model all sorts of processes - and it wouldn't be a model anymore if it was perfectly accurate, anyways (then it would cease to be a model, and just be a copy of reality).

So, given all that, I think an easier way to think about it is ""what conrete, real world distributions are NOT intractable?"" ;) And the answer is pretty much all of them are not. Hope that helps!', u'responses': []}]",,1.0,120.0,579,,Intractable distributions,[a3]
5ad7d46a0d63974e20c391d5,"so I think I have Gibbs and MH working for single iterations...

but I'm missing something fundamental about convergence...

for each single iteration of Gibbs or MH, I should be returning a new sample

from that single sample I can get what the expected value and posterior of BvC is

then I run another iteration of Gibbs or MH and get another sample

from that sample I can get a different expected value and posterior of BvC...

I understand that we need to somehow come to the same conclusion as the calculate_posterior() function when getting the posterior for BvC...

But how does that happen?  should the posteriors for BvC be aggregated and averaged over each iteration?  how is BvC changing over multiple iterations vs a single iteration?",jc6w44hrp9v2ki,"[{u'text': u'This might help if you're still struggling. http://csg.sph.umich.edu/abecasis/class/815.23.pdf', u'responses': []}, {u'text': u'thank you for the clear explanation!  for some reason I had it in my head that we were calculating some aggregation of BvC rather than just the rate of occurrence', u'responses': []}]",,0.0,136.0,580,"A sample will have a single proposed value for BvC.  That value will be 0 (B wins), 1 (C wins) or 2 (tie).  You need to count how many of these that you get and then calculate the distribution from there.  Then compare how the distribution changes with the new value.

An example:

if my result of 3 samples was [1, 1, 1] (e.g. one for each outcome) the probabilities would be [0.33, 0.33, 0.33].   If I ran another test that resulted in a tie, the new  sample count would be [1, 1, 2] and the new probabilities would be [0.25, 0.25, 0.50] and the differences would be [0.08, 0.08, 0.17].  The difference totals to 0.33 which is greater than the delta so keep on sampling.","convergence, single iteration vs multiple iterations",[a3]
5ad7d46b0d63974e20c391d6,"For MH, when we're calculating alpha, so π(x_cand)/π(x(i-1)), what's the correct way to compute π?

like this? π(x) = P(BvC=x[BvC] | x[B], x[C]) In other words, the probability we get the value we randomly generated for BvC given B and C, because the skill levels of B and C are already present in x and are the only thing that affects the outcomes of BvC. This seems to be how other people are interpreting MH, but doesn't intuitively make sense to me because then the evidence isn't ever used: we're sampling from the uniform distribution so the evidence isn't weighed there, and then it's not incorporated into π, and therefore alpha, either. 

So maybe it's like this?
P(x|e) = P(BvC, A, B, C | AvB, CvA) or in other words, the probability that we'd get this combination of BvC, A, B, and C given the evidence for AvB and CvA. 
so this would boil down to P(BvC|e) * P(A|e) * P(B|e) * P(C|e)
is that the right approach?",jc6w44hrp9v2ki,[],,0.0,126.0,581,"What helped me was Anthony Meyer's comment in @465:

    I don't think that method considers the likelihood of your entire state.
 
    I think you need to consider the whole state.
 
    Check out equation 14.2 from the book.
 
    P(A,B,C,AvB,BvC,CvA) = P(A)*P(B)*P(C)*P(AvB | A, B)*P(BvC | B, C)*P(CvA | C, A)
",Computing pi(x) for MH - best way?,[a3]
5ad7d46b0d63974e20c391d7,"
So I'm trying to determine the factor for part 2E. I know you're supposed to use delta and some count checks like number of iterations and consecutive samples to determine when the run has ""converged"" to compare Gibbs_count to MH_count, but for MH the resulting posterior is often not nearly as close to the correct posterior as for when the Gibbs sampling stops. I have to do a burn in phase to get a value that looks close to the correct posterior distribution and similar to the Gibbs convergence but then MH immediately passes all the checks and I'm left with just a burn count for iterations rather than naturally approaching it. Basically delta is always small so it doesn't matter as a check for MH converging for me.

Any ideas what might cause this? Gibbs approaches the correct posterior no problem and correctly stops when it gets very close where as MH seems to ""not have enough walk"" in it so I can't really tell how many iterations it's taking to converge other than an arbitrary burn in number of iterations.",jc6w44hrp9v2ki,"[{u'text': u'So it's the sum of differences not the MAX of differences? That must be my problem.', u'responses': [u'That is how I did it -- I originally had it be that any single difference was > delta but that converged way too quickly.', u'Thanks. That makes a lot of sense. I was thinking it might be a short cut to use max but now I see it is TOO much of a short cut. 

For calculating the final factor, since we already know what the methods should be approaching, shouldn't we allow them to converge until they are both within delta of the known stopping point? That seems to be a fairer comparison of number of iterations required.', u'For convergence, you aren't supposed to know the ""known stopping point""  You're supposed to find when the algorithm no longer is changing significantly and therefore has ""converged"" to a distribution.  It doesn't have to exactly match the ""known"" values and  in fact these algorithms are often used when the ""known"" value can't be reasonably calculated.', u'Interesting. I see now that just because one converges faster, it doesn't necessarily mean it is ""right"".', u'I took the ""difference in expected outcome"" in the README pretty literally and am using the expectation value of the BvC probability distribution as the value I'm comparing. As in P(0)*0 + P(1)*1 + P(2)*2. Seems like there are a few different ways to do this that will converge but might need different hyperparameters and runtimes.', u'Multiplying by zero is saying you are ignoring P(0).  It can be way off and you will never be influenced by it.  Multiplying P(2) by 2 means you are giving it twice as much influence vs what you are giving P(1).   Not sure this makes sense to me.', u'What I did is laid out in @580.']}]",,0.0,147.0,582,"I did a burn-in for both.  The TAs have mentioned it may be necessary several times.

You can also sharpen the delta (e.g. go to 0.0001 or even smaller)
You can also lengthen the convergence match count (N) to 20 or 30 (though that didn't seem to make much of a difference for me).

Also, be sure you're calculating your difference using the sum of absolute differences for all three elements of the distribution.  See @580 for an example.",Convergence,[a3]
5ad7d46b0d63974e20c391d8,"I can't complete submission.
Everything works until I reach
Submission processing
GT Login required
Username:
Password

it goes away prints a bunch of stuff and then I keep getting 

""Username and password failed (Do you use two-factor?)""
and then it quits

I do have 2FA but I am not getting request for a code
My credentials are correct because they work with bBuzzPort
I dowloaded the to2fa token but it did not work

I have uploaded the assignment to T-Square in the event I can't get this to work
Help please.

Thank you much",jc6w44hrp9v2ki,"[{u'text': u'', u'responses': [u'Even I have the same issue']}, {u'text': u'Thank you. I did exactly as commented. I also tried without 2FA. It did not help', u'responses': []}, {u'text': u'Yes I have that link and that is exactly what I have done as instructed in there. It still does not work. And yes the the 2FA is obligatory -- which is probably a good thing.
Perhaps I am missing something but I feel we are on our own making the tools work for us. I imagine I can reach out to technical support but not sure they will be able to help.

Thanks anyway', u'responses': []}, {u'text': u'This makes me scared to switch over to two factor. I am still not on it but my time is limited. Is it only Felipe that it does not work for?', u'responses': [u'I had no problems with it once I downloaded the new auth token and correctly installed it.

I followed the following process:

Login to Bonnie (should require 2nd factor auth via GT -- if it did not, log out (of Bonnie and GT) and try logging in again.  If it still does not, something is not setup right in your 2nd factor auth).Click on the following link: https://bonnie.udacity.com/auth_tokens/two_factorOn that page click on the link: https://bonnie.udacity.com/auth_tokens/new (which will download a new file named ""jwt"")If you are on a Mac, copy that file to your .nelson folder in your home directory with the name gtomscs_jwt.  You should have a file in that directory with that name already.   I did the following:
cdcd .nelsonmv gtomscs_jwt gtomscs_jwt.oldmv ../Downloads/jwt gtomscs_jwt
if you are on a PC, you will need to do similar things to move the jwt file to %APPDATA%\nelson\gtomscs_jwt

It generates a new token each time you run it.  I don't know if when you generate a new one, it invalidates the old one or not.  I would suggest you always have the latest token in that file.

The new files and the old files have the same format, though the old file (at least on my system) seemed to insert a space  before the token value so it was one byte larger (118 bytes). ', u'Thank you Connor.
This makes sense
I am trying this on my Mac. No luck so far.

BTW I use anaconda
my nelson directory is in ~/anaconda2/lib/python2.7/site-packages/nelson.
i have downloaded it to that directory and I can see the other nelson files including the sessionbuilder.py
still it does not work. I get the same errors. I even tried giving it the .json extension but it did not help.

One thing I noticed is that it does not matter whether I have 2FA enabled or not. I tried with it and without it. It fails either way
Also, it always get GT Login required - never Udacity (not that I think I should). 
I traced though the sessionbuilder.py. I can see where the trap is but can't figure out yet why it fails to authenticate me. It is happening outside of it

I will try it in a windows machine to see if it works there
Thanks again

BTW, probably no that anyone cares but  in case anyone is wondering why I am now discovering this problem....well I missed the first two assignments due to major surgery.
', u'Well, I have spent sometime debugging this issue in my MAC. I have traced to a GT_login function in sessionbuilder.py. That is where it fails.

It starts with a root_url = https://bonnie.udacity.com
it creates r = http.get(root_url + '/auth/cas', headers = {'accept': '*/*'})
using r It creates a host = https//login.gatech.edu
it does an http.post and that changes r = https://login.gatech.edu/cas/login;jsessionid=AA91DFA6810E0BE8748496236B1BA130?service=https%3A%2F%2Fbonnie.udacity.com%2Fauth%2Fcas%2Fcallback%3Furl  which seems to be correct (it goes to bonnie student site) 

then it  doe a conditional test:
if not r.url.startswith(root_url):   (where root_url = https://bonnie.udacity.com) and that is exactly where it fails.
It never gets past this point
I don't know how .url.startswith works but it look like string check to me  trying to determine if the url starts with https://bonnie.udacity.com which clearly doesn't
Nothing to do with my credential or 2FA.

Does anyone know if this was reported before and fixed? 
 

', u'On Slack, Zach Keller reported that he was able to get it working with Ananconda by creating the  ~/.nelson directory and placing the file into that directory.', u'Thank you Conor. I did that. No luck for me.
I have also done it all with my windows 10 computer. No luck either.
In fact, I am convinced it is not even getting to the point where it looks at jwt. It never gets past authenticating me with gatech.edu.
I would suspect it has to do with my credentials but I have verified them over and over by login directly into gatech.edu 
It would be nice if someone was looking at log files that could tell me what is happening in the server.
:-(
']}]",,4.0,183.0,584,"See https://bonnie.udacity.com/auth_tokens/two_factor to get the token (that may be what you mean by you have downloaded the to2fa token). If that is not working, it's likely that you did not install it in the correct place.

If that doesn't work you can disable 2FA at passport.gatech.edu.

Update: 2FA is obligatory for OMSCS going forward, according to recent emails from the advisors, so best to try to get it working rather than disabling it",Cant complete submission,[a1]
5ad7d46b0d63974e20c391d9,"This week you should watch the first section of Lesson 7, Machine Learning (through Random Forests), and read Chapters 18.1-5, 18.8, 20.1-20.2 in AIMA (Russell & Norvig).

All Students: Please remember to sign up to Gradescope! You will not be able to submit the midterm if you do not do so. Please refer to @287.

Assignment 3: Bayes Nets Sampling
Due: February 25 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 3 is due tonight AoE! Please check @463 for details, and look at all the posts in the a3 folder on Piazza!

Assignment 4: Decision Trees and Forests
Due: March 18 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 4 will be released this week! Please stay tuned for details. It will remain open during the midterm and beyond, for a total of nearly three weeks, but some students consider it one of the easier assignments - you should not need the entire duration to complete it.

Grades
We have been having some issues with T-Square, because of which we have been unable to release grades despite having finished grading for A1. We’ll get it sorted out this week for sure. We apologize for the massive delay.

Midterm:  March 5 - 11, 2018
Here is the list of topics that may be covered on the exam.The midterm exam will be posted on T-Square on Monday, March 5, as a PDF form.  You can type directly into the form, or print, hand-write, & scan (or some combination of these). Submission will be through Gradescope, so it is extremely important that you enroll yourself if you haven’t already. We will use T-Square for backup. Please do not submit pictures taken with your phone - it interferes with Gradescope, and is often illegible and hard to discern for the graders. Also, please submit only a single PDF. 
We will have a variety of question types - some multiple choice, some short answers, some fill-in-the-blanks, and some questions which may require you to show your work.
The exam is take home, open-book, open-notes, open-videos, with no time limit aside from the open period. No internet use is allowed (except for course materials, e-copies of the book and for uploading your submissions). The exam will not have questions about the assignments, and will not include any mandatory programming questions (apart from possibly pseudo-code).
Watching the videos, going through the course materials and solving the challenge questions can help immensely.

Office Hours:
Here is the OH calendar.  
As always, here are the syllabus and the schedule.  
",jc6w44hrp9v2ki,"[{u'text': u'Hello, 

I suppose mid-term will include all the topics covered till now including the Machine Learning portion till this week, which is, 'first section of Lesson 7, Machine Learning (through Random Forests), and Chapters 18.1-5, 18.8, 20.1-20.2 in AIMA (Russell & Norvig).' Is that correct?', u'responses': [u'Yes. Please do also have a look at the list of topics in the post. That is the comprehensive list.', u'Sure, thanks!']}, {u'text': u'Quick question, I submitted my assignment_3 to Bonnie yesterday, but accidentally forgot to submit to tsquare.  I'm using Bonnie in both of my classes, so I often forget which one asks for tsquare submission as well.  Is this a problem?  What am I to do if I can no longer submit zip file to tsquare?', u'responses': [u'it's not a problem. T-square is for back-up. Don't worry.', u'thanks!', u'Yeah I did same thing glad to hear it is okay.']}, {u'text': u'Quick question about allowable materials for the midterm:

""No internet use is allowed (except for course materials, e-copies of the book and for uploading your submissions).""

Are existing piazza posts considered ""course materials""? I ask because I am working through challenge questions to prepare for the midterm and I am wondering if I will be able to refer to the given solutions or whether I should invest some time into cleaning up my chicken scratch :)

I understand there will not be ongoing discussion of exam materials here on Piazza, obviously. But are questions that have already been discussed fair game?', u'responses': [u'Yes, existing posts are considered course materials.
We will also have rules in place to ensure there are no further discussions during the midterm. Those will be made clear in the exam and in an announcement.', u'I'm not clear about ""No internet is allowed"".
Is the exam going to be protracted? Should I keep the laptop on for the whole period?', u'The exam will not be ProctorTracked.  

This is how I'm interpreting the restrictions:

You do not need to keep the laptop open the whole period.  You can work on the test periodically throughout the week but you may not use other sources to identify information that you use on the exam even when you aren't working on the exam.  For example, you not allowed to work on question 1... stop...   go to work..  while at work think of some internet resource that might have information relevant to question 1 and go look it up... come home that evening and use that new information for your answer to question 1.

Once you start the exam, your resources are limited to:

The Textbook (physical or virtual)Your notesYour assignment codeYour development environment (e.g. I believe you can write code to test your answer)Piazza (for this class)Your head (what knowledge you've accumulated in this class or outside of it)

You should not use any other resources once you start the exam.

You may start the exam at any time after it is released.

You may work on the exam from the time you start on it until the submission deadline.

You may stop/start work on the exam during that time frame, but you must live under these restrictions on access to data associated with the course/exam for the period from when you start the exam to when you make your final submission.', u'Agreed with everything Conor says here. I would like to add to the list of resources:
The Udacity videos for this class are also allowedAny links in the exam document itself are allowed. We sometimes require a small amount of extra reading on certain questions.
These will be elaborated upon in the exam as well.

And just to point out an important point: ""you are not allowed to work on question 1... stop...   go to work..  while at work think of some internet resource that might have information relevant to question 1 and go look it up... come home that evening and use that new information for your answer to question 1.""

Thanks Conor!']}, {u'text': u'Another midterm question. 

""with no time limit aside from the open period""

Just trying to reconcile the idea that we have no time limit but that we're not allowed to use internet resources (which implies that the exam is proctored. Does ""no time limit"" mean that we can start the exam and work on it intermittently over several days, or do we have to work on it in one contiguous proctored chunk of time, just without a strict time linit?', u'responses': [u'It's not proctored', u'It's a non-proctored, take home exam. You can work on the exam during the entire open period. What they're saying is that you can start and stop at any time during the open period. You're not limited to 2 hours or whatever once you start the exam.', u'What Nick and Mark said is correct.', u'Thanks!', u'If it's not proctored, what does it mean by no internet?  What's in place to make sure students are not using the internet?  Are TAs just trusting the students not to use the internet in completing the midterm?']}, {u'text': u'Anyway we can get an ETA of Assignment 4? I understand these things can be hard to get out sometime, but it is frustrating when it isn't released along with no statement that there is a delay or anything. I'm going by the Wednesday release statement made by TAs in other threads and just want an ETA.', u'responses': [u'Not sure why they didn't announce it, but it looks like they already pushed assignment 4 to their github repo. 
https://github.gatech.edu/omscs6601/assignment_4', u'Looks like it was pushed and the Assignment opened but there was an issue where the T-Square announcement failed to show up. Hence it was made again last night.
Apologies for the confusion.', u'No worries. thanks for letting me know.']}]",,0.0,272.0,586,,Week 8 Announcement,"[announcements, midterm]"
5ad7d46b0d63974e20c391da,"so I submitted to bonnie and it says my distributions for the game network are wrong...  it's showing the the distributions for A,B, and C and AvB, BvC, CvA are swapped somehow...  I assigned everything as outlined in the assignment and when I manually check the distribution tables they are correct...

so what's going on here?",jc6w44hrp9v2ki,"[{u'text': u'Swapped in what way?  Order?  Nodes?', u'responses': [u'Specifically this is the error:
""Incorrect game distribution. Should be [[[0.1, 0.1, 0.8], [0.2, 0.6, 0.2], [0.15, 0.75, 0.1], [0.05, 0.9, 0.05]], [[0.6, 0.2, 0.2], [0.1, 0.1, 0.8], [0.2, 0.6, 0.2], [0.15, 0.75, 0.1]], [[0.75, 0.15, 0.1], [0.6, 0.2, 0.2], [0.1, 0.1, 0.8], [0.2, 0.6, 0.2]], [[0.9, 0.05, 0.05], [0.75, 0.15, 0.1], [0.6, 0.2, 0.2], [0.1, 0.1, 0.8]]] instead of [ 0.15000001  0.44999999  0.30000001  0.1       ].

and vice-versa for the skill distributions... this is not the case and all my local tests pass... I can look at the match and skill tables and see that they are as they should be... why would bonnie say they are wrong?', u'is it expecting me to append the nodes in a specific order or something?  why would it not call out the nodes by name?', u'That looks like the conditional distribution for one of the AvB, BvC and CvA nodes (4 rows of 4 rows of 3 elements).  It seems you might not be configuring the AvB nodes correctly.  They should be conditional distributions conditioned on the skills of team 1 (the first 4) and the skils of team 2 (the 2nd 4) with the associated win patter (the 3 values in each element).  So if team 1 has skiill 0 and team two has skill zero the probabilities would be x, if team 1 has skill 1 and team 2 has skill 0 the probabilities would be y (and so on until you have a 4x4 matrix of 3 element probabilities.', u'It seems like you assigned a discrete distribution to that node with 4 values.', u'I know, that's the strange part... if I print out the distribution table for each node, A, B, and C are 1x4 and AvB, BvC, CvA are 4x4... the local ""probability_tests.py"" confirm that my sizes are correct... so why on earth is Bonnie telling me I'm wrong?', u'for the match nodes, it shouldn't be 4x4... it should be 4x4x3..

This example is setting up a 2x2x2:

dist = zeros([G_node.size(), T_node.size(), A_node.size()], dtype=float32)
dist[0,0,:] = [0.9, 0.1]
dist[0,1,:] = [0.8, 0.2]
dist[1,0,:] = [0.4, 0.6]
dist[1,1,:] = [0.85, 0.15]
You need something like this that has value ranges from 0 to 4 in the first two columns for dist and 3 values in a list on the right hand side of the equals', u'Of course G_node, T_node and A_node needs to change.', u'sorry, that's what I meant, it's not 4x4, it is 4x4x3', u'I appended my nodes to the bayesnet in the order A,B,C, AvB, BvC, CvA... does the bonnie check expect them to be appended in a different order?  that's the only thing I can think of that might be happening', u'more specifically, shouldn't the local unit tests given with the assignment fail if the sizes are wrong?', u'Unless you extended the unit tests considerably, they don't do a lot of testing other than verifying shape of one of the nodes of each type.  You could have 5 of your 6 nodes configured correctly but the last node incorrect causing the problem and if that node isn't the one in the unit test, it wouldn't catch it.

I extended my unit tests to validate all the nodes.', u'Sorry this is late. But I got the same error due to swapping parent-children relationships.']}]",,1.0,173.0,587,,Bonnie says distributions are wrong...,[a3]
5ad7d46b0d63974e20c391db,"Hi All!

Assignment 1 grades have been uploaded on T-Square. Your score must be the same as the score of your last submission before the deadline on Bonnie. If there is any problem with your grades please write your name and T-Square ID in the follow-ups. I will check your submissions individually.

Median for the assignment is 75.0 and mean is 67.492. Standard deviation is 30.1375

The results of the Botfight are out as well!
Here is the list of top 10 winners:
1. Campbell, Collin
2. Bin Salm, Abdullah
3. Gaggar, Parth
4. Mora, Agustin
5. Zhuang, William
6. Town, James
7. Lenarz, Matthew
8. Adkins, Keith
9. Dickson, Anthony
10. Keller, Zachary 
Winners - feel free to discuss your overall strategy.

#pin",jc6w44hrp9v2ki,"[{u'text': u'I got 75 on Bonnie. T square shows zero. Id : sumer3Name : Saalis Umer', u'responses': [u'Updated. please check', u'Thanks', u'', u'I have the same issue. Can you fix mine as well Kshitish?
id: bjoseph8', u'I have the same issue(got 75 on Bonnie but 0 on T-Squere). May I ask you to check for this?

Id: jkim3302

Thank you', u'Hi Kshitish

I guess that you might be very buisy. I fully understand that.
I think, however, grade is very important part and feel like it's a little bit lagging.
If you check for me(and many other students) or give any delay notification, that would be great.

Thank you', u'I can see 75 as your grade on tsqaure. Please check. if there is any problem- send an email to me kmdeo2008@gmail.com']}, {u'text': u'Close!! Good job to the rest of the top 10! Really hope to hear some posts from them on their strategies.', u'responses': [u'What about your strategy?', u'I used a pretty simple opening move set but also had a custom eval function. OpenMovesEval is fairly conservative so its fine in the beginning when the search space is large and it's difficult to see all outcomes, but it's not as good after the first couple of moves.

I switched eval functions to my custom eval in the midgame when I could search to better depths but before I was searching to end game. My custom eval prioritized cornering/reducing the total moves for one of the enemy queens - it was really aggressive so it was pretty fun to watch it hunt one of the enemy queens. Probably too aggressive though - it led to kind of single minded behavior that made it take too many risks, which was probably my downfall in the standings.', u'Umm top 10 out of 600 isn't so bad!']}, {u'text': u'I'd like to point out for people who think they have done poorly and are considering dropping the class, you shouldn't. If you got a 75% or higher you got an A! If you got a 45% or higher you got a B! So, you are doing just fine, roll with the punches and keep on going.
', u'responses': [u'
Minor correction:  according to the syllabus, 75 is a B, not an A (which needs a grade above the median), but still pretty good overall.', u'Actually, not true, 75 is an A. Reason being is if you take these scores:
95,95,75,75,75,25,25 
75 is the median but 75 is also above the median. So, 75 is an A.', u'I don’t really understand what is the point of calculating grades here for an assignment. We are getting the actual score. I asked the TA earlier about this. grade curving considering medians will be only for final course grade.', u'Let's say you were trying to minimize your effort to get an A. Staying above the median in each assignment/ test, does not guarantee that you will get an A, but it would be highly unlikely that you don't. ']}, {u'text': u'Same here I got 75 on Bonnie. T square shows zero.
id: slee859', u'responses': [u'Updated. Please check', u'thanks!']}, {u'text': u'Hello,
I see 0 on my gradebook.
Shawn Lee
slee3020

Thank you', u'responses': [u'Please check']}, {u'text': u'Hi Kshitish, I'm also seeing 0 on Tsquare but received 95 on Bonnie. My id is wzhuang7.

Pretty surprised that I did well in the botfight! I couldn't even beat Kshitish. Although I did notice that there was some inverse correlation between my ID+AB scores and Kbot. My algorithm was pretty standard ID+AB with a custom heuristic. The biggest improvement came from implementing killer moves which would identify both game-winning and game-losing moves and then break off that branch of the search. Then, as opposed to the open move definition of moves, I defined the total number of moves as the total unique combinations of moves for both queens (eg using the product minus duplicates instead of the sum). My intuition was that in the scenarios of 1 move for Q1 and 9 for Q2, this would be a much worse position than 5 moves for Q1 and 5 for Q2. The product accounts for this while the sum values them equally. I also hard coded some opening moves: P1 tried to maximize the number of total combined moves while P2 tried to minimize the opponent's total moves. ', u'responses': [u'I did the same thing you did! Except I didn't hard code those first moves. I also unrolled the AB loop so that at depth = 1 it wouldn't call AB again and just return the best move. My custom heuristic is a slight variant, I actually calculated all possible moves, removing duplicates (q1, q2) == (q2, q1) and moves where q1 and q2 would be in the same place.', u'Please check. Updated. ', u'Yes, it's updated. Thanks!']}, {u'text': u'Hi, just wanted to know how this works. If I got a median = 75, does this mean I get an 'A' grade for assignments? Also, if I got 85(say) for assignment 2, and the median is 90(say), how does the best of 5 work? Can you please elaborate on the grading procedure?
I heard you will not provide a grade for each assignment, which I think it very unfair. If assignment 1 was very hard, and I spent around 50 hours on it and still got only 75 (which is median). But if assignment 2 turned out easier, and I got 85 only due to lack of time (say below median), my effort on assignment 1 is not even considered (85 > 75) because it may end up in the best of 5 only on ""score""? How is the median not kept into consideration?    
', u'responses': [u'The grading policy is given in considerable detail in the syllabus document. To put it simply:
Your final score for the course is calculated as (Total of top 5 Assignments) * (60/500) + (Total of midterm and final) * (40/200).

We then calculate the median for the entire class based on this final score, then add extra credit to everyone's scores and threshold based on the median.

Thus, your final letter grade is computed based on your overall score, and not based on grades assigned to individual assignments. We have the top 5 scores policy for multiple reasons. For example, we understand that some students might experience difficulty with the learning curve for this class and do much better on later assignments; on the other hand, a student might run into an emergency which does not allow them to complete one assignment.

While it may seem unfair that this policy disregards effort on the assignment with the lowest raw score, in practice it does not make a major difference overall - since the overall effort over the course of the sem is what contributes to your grade (as we take the median for the overall final score). The stats for A1 are sometimes skewed as students are adjusting to the course (and to the OMSCS program - this is the first course for many students in the program) and you might see the stats settle into a trend for later assignments.']}, {u'text': u'Hi... I also noticed i got zero for assignment 1 while i got 75 in Bonnie. Can you please re-check the grade for me? my id is ywang862. Thank you', u'responses': [u'Updated. Please check', u'thanks']}, {u'text': u'Hi,

id: yhe364
name: Yizhuo He

I think I should get 95 according to Bonnie, because I only lose 5 points in 2b. But the returned score is 75.
Please help me check. especially for 2b, my last submission time is 2018-01-28 14:19:17 UTC.', u'responses': [u'Please check', u'I see the update. Thanks.']}, {u'text': u'id :sramaraj6

I also have scored 95 in the bonnie asI failed against kshitish. However I have been scored 75. Can you check this', u'responses': [u'Same here.

id: jyang604
', u'Updated. please check', u'Thanks']}, {u'text': u'id: dvaseekara3

Also received a non-zero grade and have been assigned a 0.  Could you please check?', u'responses': [u'Updated. Please check', u'Still showing 0']}, {u'text': u'I'm curious to know if the instructors would be willing to share what Kshitish's secret eval function was.  I wasn't even able to beat iterative deepening unfortunately, but the task of custom eval function seemed like the most difficult part of this assignment so I'm curious to see what they thought the best was/what the winners of the bot fight came up with. 

I had ended up using a slight variation of OpenMoveEvalFn, where instead of calculating moves for both queens and subtracting opponents moves for both queens, only taking the number of moves for my queen which had the fewest and subtracting the number of moves for my opponent's queen that had the fewest.  This way I would minimize my risk of losing (since any single queen getting stuck would cause me lose) and try to increase the chance my opponent had of losing (since again only a single queen really matters).  Obviously this wasn't the best way thought so curious to hear other approaches!', u'responses': [u'I tried that approach and it seemed to work worse for me, though it really makes sense that it should be better.  I ended up sticking with OpenMoveEvalFn as is, except optimized a bit.  I put most of my effort into optimizing my code.  I wrote my own board class to use bit manipulation.  I managed to get up to 80% win's against Kshitish, but I never could hit 85.']}, {u'text': u'How can I check my bonnie score again? Because I forgot what it used to be. Thanks', u'responses': [u'Your score is correct. I checked bonnie and tsqaure. I guess there should be an assignment 1 folder right?', u'Please create a private post- to discuss further on this.']}, {u'text': u'I’m seeing a 0 in T-Square also. Name: Anthony DicksonID: adickson8', u'responses': [u'Updated. Please check.']}, {u'text': u'I'd like to thank RNG for the win.

When looking at game states, I created a set of the possible moves and removed any duplicate moves from swapping the queens to reduce the branching factor. My final agent did iterative deepening until there was 100 ms left in the round.

For every iteration of the agent, I would play my agents against each other locally until a clear winning approach could be determined and then try the next idea. I really didn't think I had a chance in the bot fight but the entry fee was right. I didn't beat Kshitish, I think I scored 75% as my high score. While examining the moves made in lost games, I could see where the agent lost the game in round 6-8 but couldn't come up with a heuristic that could be calculated fast enough to beat the open eval with winning and losing moves.

I tried custom eval functions to partition the board, look at the minimum moves for each queen, consider the product of the queen moves, and probably some other approaches that I've forgotten. I threw them all away because the time that it took to calculate the heuristics meant that I couldn't hit another level in the depth search on early rounds.

For up to the first three rounds, if my agent was player 2, I would reflect moves unless the move was to a corner of the board. Why a corner? Because I logged thousands of games and kept track of when my agent lost. I also tried the edge of the board, but the corner agent beat the edge of the board agent iteration. The reflection of moves also meant that overall I stayed under the total time limit.', u'responses': [u'Congratulations Collin :-)

It sounds as though strategies that specifically involved avoiding corners or cornering one of the opponent's queens were best for the botfight. My agent that managed 100% in 'normal time' had no particular 'expert' domain knowledge, aside potentially from a rigorous algebraic simplification of the calculation of how many distinct moves, for the custom eval function; as well as, maybe, you could say, the small book of moves / values that it had ascertained itself.', u'

Congrats Collin!  Excellent work.  You're too humble giving credit to the RNG.  It sounds like you had some good strategies in place.
']}, {u'text': u'I am also seeing a 0 on my Assignment 1 score.

id: bjoseph8
Name: Benny Joseph', u'responses': [u'Updated please check']}, {u'text': u'Hi, my grade also isn't correct, it doesn't reflect the extra credit from the bot fight.
id: jtown8
Name: James Town
Thanks, Jim


Also, as others have said, I am surprised I did well in the bot fight.  I had a lot of trouble coming up with a better heuristic, everything I did would beat my vanilla AB-ID, but do worse in Bonnie than that same vanilla AB-ID.  So I focused on going as deep as possible.  Each time I went through the iterative deepening I saved the result, then the next time through I started with the best ones first to help AB out a little.  It turns out, sorting everything takes way too much time so any gains I would get were canceled out.  Plus the scores are just estimates so I might have even been hurting my times by fully sorting.  Instead, I just ran through the list and put the best score I'd seen so far in the front of my list and then the rest to the back.  This didn't take too much calculation time, but enabled me to go about one level deeper each time round. ', u'responses': [u'James- I checked your score. Its correct. Please create a private post to discuss further. ']}, {u'text': u'
Also shocked  to see my name on the top ten.  I only scored 50% against Kshitish.  I guess it pays to take a chance.

In my case, the RNG was certainly my friend.  I randomized my tree building process to make my moves less predictable in case Kshitish was optimized against algorithms that worked from left to right.  What may have also helped is the use of dynamic programming. Once I calculated a node's eval function score, I stored it so it could be referenced later.  This freed some computing time for searching deeper in the tree. I also allowed my search to go to 9 seconds.  I tried to keep my eval function simple and efficient to not take away from tree searching time.  I added a simple proximity detection calculation  that attempted to avoid the opponent at the same time as minimize the opponent's moves.  This approach wasn't perfect in that it helped me in some games and hurt me in others.  On average it seemed to help more than hurt, but it frustratingly didn't help enough to beat Kshitish.  ', u'responses': []}, {u'text': u'Kshitish you got to tell us the general strategy of your algorithm. It seems better than the top 10!', u'responses': [u'I beat Kshitish like 75% of the time, I'm sure others in the top 10 had similar if not better results. We just didn't get points because we needed at least 85% win rate.']}, {u'text': u'I was awarded more points on Bonnie than are showing on TSquare. Please double check, thanks!', u'responses': [u'Thanks for letting us know.', u'Wait. I am able to see correct marks. Please create a private post to discuss further. ']}, {u'text': u'Hey Kshitish,
I'm still seeing the wrong grade
id:  dvaseekara3 ', u'responses': [u'Updated please check']}, {u'text': u'Hi Kshitish, I also got 95 on Bonnie and 75 on my grade, please check. Thank you.

id: dli94', u'responses': [u'Updated. please check', u'Thank you!']}, {u'text': u'Hi Kshitish,

I got 75 on Bonnie but T-square shows 0.

ID: szhang427
Name: Sijia Zhang

Thank you. ', u'responses': [u'Updated', u'Thank you!']}, {u'text': u'Hi Kshitish,

My score on t-square doesn't reflect the extra credit from the bot fight.

ID : pgaggar3
Name : Parth Gaggar', u'responses': [u'The extra credit score will be released as a separate gradebook item.', u'Thank you!']}, {u'text': u'I had made a private post; but it looks like my grade on T-square does not match bonnie. ID is vlegros3', u'responses': [u'Hi Victor- Your ID does not match in tsqaure or bonnie. Is your tsqaure name different than your piazza name?
', u'I don't think so. I'm mostly accessing Piazza from Buzzport.', u'And name in all systems should be the same, ""Victor Legros""', u'Also, I withdrew yesterday evening. So if you're just checking now, that might explain why I'm no longer showing up? I had submissions for assignments 1 & 2, but not for 3.', u'If you withdraw, T-Square immediately hides all your records from the class. That must be it. Thanks for letting us know.']}, {u'text': u'I got graded 0/100
id: yeckstein3
name Yauheniya Eckstein', u'responses': [u'I am not able to find your name. Are you facing the issue till now?
', u'Is the issue fixed?']}, {u'text': u'Hi, my assignment1 grade used to be appeared, but it's not there anymore.

Could you check it out?', u'responses': [u'Same here: jtown8', u'Updated']}, {u'text': u'Hi, my grade is 0/100.Would you please check for this?id: jkim3302Thank you in advance.', u'responses': [u'Please check for this issue. Still it's 0/100 instead of 75/100.

Thanks', u'Updated', u'Thank you~!!']}]",,0.0,313.0,588,,Assignment 1 Grades released (and Botfight results!),[a1]
5ad7d46c0d63974e20c391dc,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.
 

On to Probability!


DISEASE TESTING
Consider two medical tests, A and B, for a virus.
Test A is 95% effective at recognizing the virus when it is present, but has a 10% false positive rate.
Test B is 90% effective at recognizing the virus, but has a 5% false positive rate.
The two tests use independent methods of identifying the virus, The virus is carried by 1% of all people.
 
a) Say that a person is tested for the virus using only one of the tests, and that test comes back positive. Which test returning positive is more indicative of someone really carrying the virus? 
 
b) What is the probability that a person does have the virus if both tests come back as positive?


PRACTICE  
You have the following table:


P(A∩B∩C) = ?
P(¬C∩A) = ?
P(¬A)  = ?
 

 

Solution: @629
",jc6w44hrp9v2ki,"[{u'text': u'My answers:
(a) P(Virus|A test positive) = 0.0876, P(Virus|B test positive) = 0.1538. So B test positive is more indicative of carrying virus
(b) P(Virus|A test positive, B test positive) = P(V|A,B) = P(V, A, B)/P(A,B) = $$\frac{P(A,B|V)*P(V)}{P(A,B|V)*P(V)+P(A,B|\sim V)*P(\sim V)} = \frac{P(A|V)*P(B|V)*P(V)}{P(A|V)*P(B|V)*P(V)+P(A|\sim V)*P(B|\sim V)*P(\sim V)}$$ = 0.633

P(A AND B AND C) = 0.01
P(NOT C AND A) = 0.37
P(NOT A) = 0.47', u'responses': []}, {u'text': u'I agree
$$P(V|A) = \frac{P(A|V)P(V)}{P(A)} = \frac{P(A|V)P(V)}{P(A|V)P(V) + P(A|\neg V)P(\neg V)} = \frac{0.95 \times 0.01}{0.95 \times 0.01 + 0.1 \times 0.99} \simeq 0.08756$$
$$P(V|B) = \frac{P(B|V)P(V)}{P(B)} = \frac{P(B|V)P(V)}{P(B|V)P(V) + P(B|\neg V)P(\neg V)} = \frac{0.9 \times 0.01}{0.9 \times 0.01 + 0.05 \times 0.99} \simeq 0.15385$$
So B is the more indicative test

$$P(V|A,B) = \frac{P(A|V,B)P(V|B)}{P(A|B)} = \frac{P(A|V)P(V|B)}{P(A|V,B)P(V|B) + P(A|\neg V,B)P(\neg V|B)}$$
$$= \frac{P(A|V)P(V|B)}{P(A|V)P(V|B) + P(A|\neg V)P(\neg V|B)} = \frac{0.95 \times 0.15385}{0.95 \times 0.15385 + 0.1 \times 0.84615} \simeq 0.63334$$

Symmetrically,
$$\frac{P(B|V)P(V|A)}{P(B|V)P(V|A) + P(B|\neg V)P(\neg V|A)} = \frac{0.9 \times 0.08756}{0.9 \times 0.08756 + 0.05 \times 0.91244} \simeq 0.63334$$

Practice
$$P(A\cap B \cap C) = 0.01$$
$$P(\neg C \cap A) = 0.37$$
$$P(\neg A) = 0.47$$', u'responses': [u'Thanks for calculating symmetrically. I calculated the answer of b like Junwei but your working explains the chain rule well which has always been confusing.']}]",,2.0,227.0,591,,Challenge Question 13 - Probability,"[lesson5, challengeqtns]"
5ad7d46c0d63974e20c391dd,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.


DECK OF CARDS
Suppose you are given a box containing d decks of cards.  
Each deck has 52 cards, 26 of which are red and 26 are black. You are told that the box contains one fake deck that only has black cards.
 
a) You reach into the box, pick out a deck at random, shuffle it, deal a card at random and get a black card.
What is the probability that the deck you chose is the fake deck?
 
b) Now suppose you continue dealing cards from the deck, each time replacing the chosen card and re-shuffling. You do this for a total of k times and see k black cards. What is the probability that you picked the fake deck?
 
c) Suppose you wanted to decide whether a chosen deck was the fake deck by dealing a random card (replacing it each time) k times.
The decision procedure returns fake if all k cards come up black, otherwise it returns normal.
What is the unconditional probability that this procedure makes an error?




Solution: @630, or check Mark's answer below.",jc6w44hrp9v2ki,"[{u'text': u'a) $$1/(d+1)$$
b) $$1/(1 + 0.5^k (d-1))$$
c) $$1/d + ((d-1)/d)* (1/2)^k$$ - Not sure', u'responses': [u'for a) check when $$d=1$$ the only deck is fake, or transfer your answer for b) when $$k=1$$
for c) I think your $$1/d$$ term represents $$P(F)$$, that term should be $$P(\neg KB|F)P(F)$$', u'Yes, I am getting answers identical to yours, Mark. I had made some silly calculation mistakes in my answers. Part b) answer is equivalent to your answer.']}, {u'text': u'a) What is the probability that the deck you chose is the fake deck?

$$P(F|B) = \frac{P(B|F)P(F)}{\sum\limits_i^d P(B|D_i)P(D_i)} = \frac{1/d}{(d+1)/2d} = \frac{2}{d+1}$$

b)  What is the probability that you picked the fake deck?

$$P(F|KB) = \frac{P(KB|F)P(F)}{\sum\limits_i^d P(KB|D_i)P(D_i)} = \frac{1/d}{(0.5^k)(d-1)/d~+~1/d} = \frac{1/d}{(d-1)/(2^kd)~+~1/d} = \frac{2^k}{d-1 + 2^k}$$

c) What is the unconditional probability that this procedure makes an error?
$$E$$ for Error, $$N$$ for Normal

$$P(E) = P(N|F)P(F) + P(\neg N | \neg F)P(\neg F)$$

$$P(N|F) = P(\neg KB| F) = 0$$

$$P(\neg N|\neg F) = P(KB | \neg F) = 0.5^k$$

$$P(\neg F) = \frac{d-1}{d} = 1 - \frac{1}{d}$$

$$P(E) = 0 + 0.5^k \left(1 - \frac{1}{d}\right) = 0.5^k \left(1 - \frac{1}{d}\right) = \frac{d-1}{2^kd}$$', u'responses': [u'Wouldn’t part c just be 1-part b? The probability of error is the probability the deck actually is fake and you didn’t get all black cards (=0) + the probability the deck isn’t fake and you pull all black cards (= 1- part b ). It doesn’t seem like your part c gives that answer but I could be missing something. I do get the same for part b though. Edit - never mind, I see where the difference is. It’s not the conditional probability given all black cards but the joint probability the deck isn’t fake and you pull all black cards.', u'I have the same answer for (c), which is $$1-\frac{2^{k}}{2^{k}+d-1} = \frac{d-1}{2^{k}+d-1}$$. I also follow the logic of Mark. So why 1-(b) is not the answer?', u'You need to account for the fact that $$P(KB) = P(KB|\neg F)P(\neg F) + P(KB|F)P(F)$$, NB particularly the $$P(F)$$ term

$$=\frac{d-1}{2^kd} + \frac{1}{d} = \frac{2^k + d - 1}{2^kd}$$

$$P(\neg F|KB) = \frac{d-1}{d - 1 + 2^k}$$

$$P(\neg F|KB)P(KB) = P(KB|\neg F)P(\neg F)$$

$$P(KB) = \frac{P(KB|\neg F)P(\neg F)}{P(\neg F | KB)} = \frac{d - 1 + 2^k}{d - 1} \frac{d-1}{2^kd} = \frac{d - 1 + 2^k}{2^kd}$$', u'P(Error) = P(Error | Fake) * P(Fake) + P(Error | not Fake) P(not Fake)
P(Error | Fake) = 0
P(Fake) = 1/d
P(Error | not Fake) = (1/2)k
P(not Fake) = (d-1)/d

= (d-1)/d *(1/2)k']}]",,2.0,226.0,597,,Challenge Question 14 - Probability,"[lesson5, challengeqtns]"
5ad7d46d0d63974e20c391de,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion. 


This post is now OPEN FOR DISCUSSION.


LOTTERY
We have decided to develop a new gambling app, which works as follows:
The player gets assigned a lottery ticket with three slots they can scratch.Each slot can be a ‘Win’ or ‘Lose’.The wins and losses in each ticket are predetermined such that there is an equal chance of any ticket containing 0, 1, 2 and 3 winning slots. In other words, a ticket has 1⁄4 chance of containing 3 wins, 1⁄4 chance of containing 2 wins 1 loss, and so on.


At any time the player has these options:
-Scratch any unrevealed slot on the current ticket (and reveal that slot), or
-Get assigned a new lottery ticket.
Note: Getting new tickets is free, while scratching a slot costs $1.5.
Each ‘Win’ pays out $2.6 in prize money, each ‘Lose’ pays out nothing.

1. If you scratch all 3 slots in a ticket, what is the expected return? Please calculate it as [expected total prize money - the amount you spent playing]. 
2. If you get a new ticket and scratch a randomly chosen slot, what is the probability of winning that scratch? 
3. Suppose you got a new ticket and scratched a slot, it is a ‘Win’. What is the probability that you will win on the next scratch of the same ticket?
4. Suppose you lost on your first scratch, should you continue with this ticket? Assume that you want to have a positive return. 
5. Suppose you won your first scratch but lost on the second, what is the probability that you will win on the last scratch of this ticket?
6. If you play the game optimally, will you win money in the long run?



Solution: @631


",jc6w44hrp9v2ki,"[{u'text': u'1. P(3wins) * (3*$2.6 - 3*$1.5) + P(2wins) * (2*$2.6 - 3*$1.5) + P(1win) * (1*$2.6 - 3*$1.5) + P(0wins) * (0*$2.6 - 3*$1.5)
= (0.25 * $3.30) + (0.25 * $0.70) + (0.25 * -$1.90) + (0.25 * -$4.5)Expected Return = - $0.60

2. Probability of winning random scratch: P(win) = 6/12 = 0.5

3. Probability of winning scratch if win. P(win | win) = 3/6 = 0.5', u'responses': [u'1 is just an arithmetic error, $$\frac{3.3 + 0.7 - 1.9 - 4.5}{4} = -0.6$$ not $$-0.1$$', u'Oops. You're right. Thanks. Edited to fix it.']}, {u'text': u'1 1 $$E[payout] = \sum\limits_i payout_iP(payout_i) = \frac{2.6}{4} + \frac{5.2}{4} + \frac{7.8}{4} = 3.9$$
$$\Rightarrow E[return] = E[payout] - price = 3.9 - 4.5 = -0.6$$

2 $$N$$ is the number of winning slots on the card
$$P(win) = \sum\limits_iP(win|N_i)P(N_i) = 0 \times \frac{1}{4} + \frac{1}{3} \times \frac{1}{4} + \frac{2}{3} \times \frac{1}{4} + 1 \times \frac{1}{4} = 0.5$$

3 $$P(win_2|win_1) = \sum\limits_iP(win_2|N_i, win_1)P(N_i|win_1)$$
$$\mathbf{P}(N|win_1) = \frac{\mathbf{P}(win_1|N)\mathbf{P}(N)}{P(win_1)} = 2 \times \langle 0, \frac{1}{12}, \frac{1}{6}, \frac{1}{4} \rangle = \langle 0, \frac{1}{6}, \frac{1}{3}, 0.5 \rangle$$
$$\Rightarrow P(win_2|win_1) = 0 + 0 + 0.5 \times \frac{1}{3} + 1 \times 0.5 = \frac{2}{3}$$

4 A looking at whether the return on the card generally is worth it
$$E[payout|\neg win_1]=\sum\limits_i payout_iP(payout_i|\neg win_1) = 0 \times 0.5 + 2.6 \times \frac{1}{4} + 5.2 \times \frac{1}{4} + 7.8 \times 0 = \frac{7.8}{4} = 1.95$$
$$\Rightarrow E[return] = E[payout] - price = 1.95 - 3 = -1.05$$

B Alternatively, looking at the return for scratching one more time
$$P(win_2|\neg win_1) = \sum\limits_iP(win_2|\neg win_1, N_i)P(N_i|\neg win_1)$$
$$\mathbf{P}(N|\neg win_1) = \frac{\mathbf{P}(\neg win_1 | N)\mathbf{P}(N)}{P(\neg win_1)}$$
$$ = 2 \times \langle1 \times \frac{1}{4}, \frac{2}{3} \times \frac{1}{4}, \frac{1}{3} \times \frac{1}{4}, 0 \times \frac{1}{4} \rangle$$
$$ = \langle 0.5, \frac{1}{3}, \frac{1}{6}, 0\rangle$$
$$\Rightarrow P(win_2|\neg win_1) = 0 \times 0.5 + 0.5 \times \frac{1}{3} + 1 \times \frac{1}{6} = \frac{1}{3}$$
$$\Rightarrow E[return] = \frac{2.6}{3} - 1.5 \simeq -0.6333$$

5 $$P(win_3|win_1, \neg win_2) = \sum\limits_iP(win_3|win_1, \neg win_2, N_i)P(N_i|win_1, \neg win_2)$$
$$\mathbf{P}(N|win_1, \neg win_2) = \frac{\mathbf{P}(win_1, \neg win_2 | N)\mathbf{P}(N)}{P(win_1, \neg win_2)}$$
$$\propto \langle 0 \times \frac{1}{4}, \frac{1}{3} \times \frac{1}{4}, \frac{1}{3} \times \frac{1}{4}, 0 \times \frac{1}{4}\rangle$$
$$= \langle 0, 0.5, 0.5, 0 \rangle$$
$$\Rightarrow P(win_3|win_1, \neg win_2) = 0.5$$

6 No

putting 4B & 5 together makes me think they should add to 4A, though, so maybe there are some arithmetic errors there, I need to check', u'responses': [u'For #3 does the prior probability go up to 1/3 instead of 1/4 since you know that you don't have the case of a card with all losses? i.e. P(win2 | win1) = 0 + 0.5 * 1/3 + 1 * 1/3 = 0.5', u'Indeed, even the $$P(N=3|win_1)$$ should be 0.5 so the answer is $$\frac{2}{3}$$. Edited accordingly', u'@MarkBenjamin1@gatech.edu, don't you think the probability layout <0.5,1/4,1/4,0> you calculated in 4.A contradict with how you got in 4.B P(N|¬win1) =⟨0.5,1/3,1/6,0⟩, I think the latter is right.', u'For 5, I have P(win3|win1,¬win2)=P(two winning slots) = 1/4

Edit: the equality above is not valid. I think 1/2 is correct. ', u'Chenxi, No, think how the different values would be phrased in normal language. 4A is the the predicted payout from scratching the card twice more, 4B is the predicted payout from the next scratch

Incidentally I think the reason 4B + 5 != 4A is that although 5 is symmetrical with $$P(win_3|\neg win_1, win_2)$$, the relevant part of 4A is $$P(win_3|\neg win_1, win_2)P(win_2) + P(win_3|\neg win_1, \neg win_2)P(\neg win_2)$$', u' @MarkBenjamin1@gatech.edu, 
I get what you were doing in 4A and 4B which is in line with ""4A is the the predicted payout from scratching the card twice more, 4B is the predicted payout from the next scratch""
But why P(payout i|¬win1)  != P(N|¬win1) ? Could you explain this?

Your 4A has P(payout i|¬win1) =  <0.5,1/4,1/4,0>

while your 4B has 4.B P(N|¬win1) =⟨0.5,1/3,1/6,0⟩', u'Hey, nice try, check the solutions for more details!']}]",,2.0,219.0,599,,Challenge Question 15 - Probability,"[lesson5, challengeqtns]"
5ad7d46d0d63974e20c391df,"I remember that I did not lose 25 points in assignment 1.
When I check my score, I find somehow I deleted my local feedback file for part 1a. I lose 5 points for 1 and 1b. I want to find out whether I lose 20 points in 1a part. 
But Bonnie system for AI class only keeps the uncompleted assignments. 
Can I access the feedback of assignment 1 in some way?
",jc6w44hrp9v2ki,"[{u'text': u'Thank you, Brian and Kshitish.', u'responses': []}]",Updated Please check,0.0,180.0,600,"See @274

Also, I think Assignment 1 scores are posted in the gradebook section of T-square now.",Is there any way to check my score on Bonnie for assignment 1?,[a1]
5ad7d46d0d63974e20c391e0,"I seem to miss something about how to calculate P(7) previous example said P(7)=mean/(mean+7)  P(7) = 7.5/14.5 = 0.51 but the answer is 0.25

",jc6w44hrp9v2ki,"[{u'text': u'with the equation, I get only to 0.27

p(7) = 1/1.5sqrt(2Pi) *e^[-(7-7.5)^2 / (2*1.5)^2]
1/1.5sqrt(2Pi) = 0.266
e^[-(7-7.5)^2 / (2*1.5)^2] = 1.027
0.266 * 1.027 = 0.27', u'responses': [u'The mistake is in (2*1.5)^2, $$(2\times 1.5)^2$$ that would be $$(2\sigma)^2$$ or $$4\sigma^2$$, it's $$2\sigma^2=2 \times 1.5^2$$', u'I just redid all of my calculations and still got 28%. Where did I go wrong?
', u'$$\frac{-(-0.5)^2}{2 \times 2.25} = -\frac{0.25}{4.5}$$ not $$\frac{0.25}{4.5}$$
$$e^{-0.056} \simeq 0.946$$ not $$1.056$$', u'thanks, i got it now']}, {u'text': u'I was able to solve this problem using the tutorial in the video as follows + PDF as provided in Udacity video lecture.

https://youtu.be/wPtaH5ABYFE ', u'responses': [u'thank you, i was able to solve all but the last p(7) part']}]",,0.0,125.0,603,"Unless I missed something, the answer is found by plugging the mean. std deviation, and x, 7 in this case,  into the equation on the left.    ",Video 11 calculate P(7),[lesson7]
5ad7d46d0d63974e20c391e1,"I was wondering if it would be possible to get solutions or explanations for the assignments, to actually learn some of the things I missed. For example, I wasn't able to pass Alpha Beta with Iterative Deepening, wasn't quite able to nail down Tridirectional search or the MH sampler. It would be great to know where I went wrong and how the algorithms are supposed to work. In assignment 2, the OH kept referring to the ""stopping condition"" and how it ""wasn't intuitive"". It would be great to know what it should have looked like in the end, or what the secret evaluation function was and why it was so hard to beat, stuff like that.",jc6w44hrp9v2ki,"[{u'text': u'+1 - I also didn't beat ABD and Tri-direct A*', u'responses': []}]","Thank you for the feedback Lily!
We'll discuss it and get back to you.",1.0,168.0,606,,Assignment solutions\explanations,[other]
5ad7d46d0d63974e20c391e2,"I found these slides when looking up more info about how to use entropy to determine information gain when building a decision tree from a data set.  I think it helped me, so hope it helps others.

https://homes.cs.washington.edu/~shapiro/EE596/notes/InfoGain.pdf
",jc6w44hrp9v2ki,"[{u'text': u'Thanks for posting this. I don't think we were supposed to go this far yet.', u'responses': []}]",,0.0,140.0,607,,entropy &amp; information gain when building a decision tree,[a4]
5ad7d46e0d63974e20c391e3,"I am having a hard time wrapping my head around how Likelihood Weighting is a consistent sampling method. I'll use the example from video 6.42 Likelihood Weighting 2.



The instructor says ""The wet grass node will always get good values based on [the evidence +s, +r], but the cloudy node won't. And so it will be generating values at random without looking at [the evidence] and most of the time or some of the time it will be generating values that don't go well with the evidence. Now, we won't have to reject them like we do in rejection sampling, but they'll have a low probability associated with them.""

However, in the previous video, he says that the weighted probability for each sample is defined by the evidence likelihood, so all samples will have the same weight for this evidence, regardless of how well the cloudy variable fits with the evidence.",jc6w44hrp9v2ki,"[{u'text': u'When Sprinkler and Rain are fixed, Cloudy is chosen randomly based on its own probability. The weights then are determined by the probabilities of Sprinkler given Cloudy and Rain given Cloudy. So depending on which value Cloudy randomly became, the weights will be different.

Therefore, if Cloudy is a value that is ""don't go well with the evidence"", that will be reflected in the lower weight.', u'responses': [u'Ah, makes perfect sense. Thanks, Mansoo! In the previous example the evidence didn't have any dependencies, which is what had me confused.']}]","I would have to look, but I believe in the previous video he may not have been talking about likelihood weighting but instead just normal sampling.

Any of the TAs know for sure?  Video is a little slow while I'm traveling.",0.0,153.0,608,,Likelihood Weighting,[midterm]
5ad7d46e0d63974e20c391e4,"Hi,

Quick question. Suppose I choose K=4. Then I have equal number of + and - (for example, 20 + and 20 -), so the output would be random? (50% + , 50% -)? If I have many conditions like this, does it mean K=4 is not a very good choice, because it just randomly pick a sign?

Thanks,
",jc6w44hrp9v2ki,"[{u'text': u'I don't actually know the answer, but I can think of some better alternatives to random choice. When it is tied two to two as in your example, you could examine the fifth-closest as a tie-breaker. Or, you could throw away whichever one of the four is the farthest away thus forcing it to be two to one.', u'responses': []}, {u'text': u'If you're talking about an new example very close to the decision boundary and the 4 closest are split between 2 +'s and 2 -'s then to break ties I would pick the group with the shortest average distance.
$$\text{argmin}_c(\frac{1}{n}\sum_{i}^{n}||{x_{i}^c} - x_{e}||)$$', u'responses': []}]",,2.0,134.0,609,,K-NN,[lesson7]
5ad7d46e0d63974e20c391e5,"I read with great interest the work of Dr Thad on the Wild Dolphin Project. There seems to be a lot of potential there and was wondering if there is any significant progress?

Seems to me though that we are still trying to teach the dolphins human ""language"" rather trying to learn from them or at least try to learn how they communicate. Of course, this is easier said than done. Most likely they do not communicate in the way humans do, especially under water and in short distances they might ""project ultrasonic images"" of what they want to communicate rather than just ""sound"" it out or even use some combination thereof. It is not merely an issue of sounding out the frequencies but it a combination much like the ultrasound machine that interprets the reflected waves to form the image on the screen. So using that piece of cloth for item association as I have seen in the video is not ideal because it is barely distinguishable with ultrasound especially when under water and wet. It is like trying to teach a color blind person to distinguish colors red and green.

So if any TA's or even Thad can update us on the project it would be much appreciated.

Thanks
",jc6w44hrp9v2ki,[],,0.0,144.0,610,,The Wild Dolphin Project: CHAT (Cetacean Hearing and Telemetry),[lesson7]
5ad7d46e0d63974e20c391e6,"
Assignment 4 - Decision Trees and Forests

Hi everyone,

The fourth assignment is out!
 
Please find the git repo of the code 
https://github.gatech.edu/omscs6601/assignment_4. 

Please read the assignment description from README carefully.  
This Assignment is due on: March 18th, 2017 at 11:59PM UTC-12 (AOE) on both Bonnie and T-Square. 

You are allowed to make 1 submission every 60 minutes.
Note that the test could run for several minutes each time you submit on Bonnie.We will be taking the results of your last submission on Bonnie. 

There will be a separate post soon about a Youtube live session going over Assignment 4. 

A Kaggle challenge competition will be announced soon for the bonus points on this assignment. 

Good luck on your midterms!
",jc6w44hrp9v2ki,"[{u'text': u'Could you clarify what is meant by “Select tests to be as small as possible (in terms of attributes)” in the first part? Wouldn’t each split just use a single attribute? Also, is this tree in part a supposed to get perfect separation or is any tree with less than ten nodes acceptable?', u'responses': [u'bump']}, {u'text': u'Disregard, I am an idiot.', u'responses': []}, {u'text': u'the README says numpy as allowed, yet it is not present in the requirements.txt.

Why?

Which version is expected so I can use the same one in my virtual environment?
', u'responses': [u'Bonnie uses numpy 1.12.0. Updated this in the requirements.txt file as well.  ', u'Thank you!']}, {u'text': u'It doesn't seem to be available for submission on t-square', u'responses': [u'It should be available now. Please do submit it on T-square as the backup. ']}, {u'text': u'exceeded the timeout of 3600 seconds.

^ Any suggestions... ?', u'responses': [u'Vectorize and or reduce the number of trees/forests you are using. ']}, {u'text': u'Could we please use future's print_function as well as the four imports listed?', u'responses': [u'You may use any functions from the allowed imports. ']}, {u'text': u'Hi, 

I encounter an error when try to install numpy 1.12.0:
Mengyuns-MacBook-Pro:assignment_4 mengyunz$ pip install -r requirements.txt 
Collecting numpy==1.12.0 (from -r requirements.txt (line 1))
  Using cached numpy-1.12.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
Requirement already satisfied: future==0.16.0 in /Applications/anaconda2/lib/python2.7/site-packages (from -r requirements.txt (line 2))
Requirement already satisfied: nelson==0.4.0 in /Applications/anaconda2/lib/python2.7/site-packages (from -r requirements.txt (line 3))
Requirement already satisfied: requests==2.13.0 in /Applications/anaconda2/lib/python2.7/site-packages (from -r requirements.txt (line 4))
Requirement already satisfied: requests-toolbelt>=0.7.0 in /Applications/anaconda2/lib/python2.7/site-packages (from nelson==0.4.0->-r requirements.txt (line 3))
Installing collected packages: numpy
Exception:
Traceback (most recent call last):
  File ""/Applications/anaconda2/lib/python2.7/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Applications/anaconda2/lib/python2.7/site-packages/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/Applications/anaconda2/lib/python2.7/site-packages/pip/req/req_set.py"", line 784, in install
    **kwargs
  File ""/Applications/anaconda2/lib/python2.7/site-packages/pip/req/req_install.py"", line 851, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""/Applications/anaconda2/lib/python2.7/site-packages/pip/req/req_install.py"", line 1064, in move_wheel_files
    isolated=self.isolated,
  File ""/Applications/anaconda2/lib/python2.7/site-packages/pip/wheel.py"", line 345, in move_wheel_files
    clobber(source, lib_dir, True)
  File ""/Applications/anaconda2/lib/python2.7/site-packages/pip/wheel.py"", line 323, in clobber
    shutil.copyfile(srcfile, destfile)
  File ""/Applications/anaconda2/lib/python2.7/shutil.py"", line 97, in copyfile
    with open(dst, 'wb') as fdst:
IOError: [Errno 13] Permission denied: '/Applications/anaconda2/lib/python2.7/site-packages/numpy/__config__.pyc'

Thanks,
Mengyun
', u'responses': [u'ok, after delete the whole ""numpy"" folder, it worked.']}]",,1.0,297.0,612,,Assignment 4 Released,[a4]
5ad7d46f0d63974e20c391e7,,jc6w44hrp9v2ki,"[{u'text': u'For part 1a, has anyone been able to build the tree with less than 10 nodes and satisfy all the conditions mentioned in part 1a? I am unable to build the tree with less than 10 nodes if I follow  this condition - ""If multiple tests have the same number of attributes and classify the same number of examples, then break the tie using attributes with lower index numbers (e.g. select A1 over A2)"".', u'responses': [u'I have the same question. Can we combine features in order to get less than 10 nodes? That's not something that a decision tree would normally do but given the DecisionNode class, you could easily write a lambda to check two features at once and that would allow for a smaller tree. Another option would be to force a depth limit and not be able to fully separate the classes in the training data (but stay under 10 nodes). Are either of these the preferred solutions here?', u'I found a solution that uses fewer than 10 nodes. It wasn't one of the first ones I tried. I found it by trial and error. I originally tried minimizing entropy, which did not yield a solution with under 10 nodes.', u'Did you use only binary splits on one variable? If so I just need to keep looking!', u'Yes, each node only considers a single feature (or is a leaf).', u'Even I found a solution which uses fewer than 10 nodes, but it wont satisfy the last condition (one in above post). So just wondering if it is okay to go ahead with it?', u'I can confirm that bonnie deducts points if you solution doesn't have fewer than 10 nodes.', u'And I can confirm that getting under 10 nodes is possible. Donavan's comment above sent me back to the drawing board. The trick is that you have to consider splits that standard splitting criteria (gini or entropy) think are sub-optimal. Basically, if you play around with it, you can get a smaller tree than the one you would get using gini. You don't have to combine features or do anything fancy. Just split on the right features in the right order. My revised tree ended up under the 10 node limit.', u'I don't think anyone is questioning if fewer than 10 nodes is possible.  The question is if it is possible while following the directions explicitly -  ""If multiple tests have the same number of attributes and classify the same number of examples, then break the tie using attributes with lower index numbers (e.g. select A1 over A2)"".  First we should use the entropy (or gini) values to place nodes higher in the tree.  Then, in the case of ties you should use the node with the lowest remaining index left.  Following these directions I have not seen a way to get fewer than 10 nodes.', u'I solved this with less than 10 nodes, but not totally sure that I'm not doing something sneaky (thought it does appear to follow all the rules laid out)...   Only used 2 decision nodes and 3 leaf nodes and it does pass the test.', u'I have the same question regarding the 5 node solution, I wonder if it would be considered a ""dirty trick"".

My 9 node solution was derived following the instructions....except for one step where I had to chose the attribute that classified the least number of examples correctly.
', u'Connor, I'm guessing I'm doing the same thing you are. It doesn't explicitly say you can only use one attribute at a time, just to make the number of attributes used in each test as small as possible.', u'John, rather than ""dirty"", I think it would be considered ""smart"" :-)...

Jacob, yeah, I think we're on the same track...

Bonnie seems to be happy enough with it.']}, {u'text': u'Can I remove one of the attributes from the table to build decision tree? It seems that it's possible to build a decision tree by removing one of the attribute and still get all the results.

It passed the bonnie tests but want to confirm if that is allowed.', u'responses': [u'It's not a requirement that the decision tree use all of the available attributes. Removing an attribute from the table could change some of the indices of other attributes, though, which might mess things up.', u'Hmm.. there's nothing to remove or add -- the table isn't an input to your function.  You just need to write a decision tree that uses the feature array (which will have all 4 attributes, but as Donovan said, you can ignore any that you aren't interested in).']}, {u'text': u'I could make tree on paper with 9 nodes. I need some idea about coding. I am able to create root node based on example given in the assignment. However how can I create tree structure like parent child (or do I need to do that even?) ?', u'responses': [u'I think I need to use below to set child nodes 
left (DecisionNode): left child node. right (DecisionNode): right child node.']}, {u'text': u'If I copy in the sample decision tree from the assignment instructions 

    decision_tree_root = DecisionNode(None, None, lambda a1: a1 == 1)  
    decision_tree_root.left = DecisionNode(None, None, 1) 
    decision_tree_root.right = DecisionNode(None, None, 0) 

    return decision_tree_root


I get this error
======================================================================
ERROR: test_hand_tree_accuracy (__main__.DecisionTreePart1Tests)
Test accuracy of the tree example.
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""decision_trees_submission_tests.py"", line 43, in test_hand_tree_accuracy
    decision = self.hand_tree.decide(self.ht_examples[index])
  File ""G:\git\assignment_4\decision_trees_submission.py"", line 46, in decide
    return self.right.decide(feature)
  File ""G:\git\assignment_4\decision_trees_submission.py"", line 42, in decide
    elif self.decision_function(feature):
TypeError: 'int' object is not callable


I'm not sure how I'm supposed to be using the decisionnode class and why I'm getting this error. I think I'm missing something fundamental to this', u'responses': [u'Nevermind - I misunderstood how the arguments work. 0 and 1 are not lambda functions; they're class labels. ']}]",,0.0,281.0,614,,Assignment 4 Part 1 Discussion Thread,[a4]
5ad7d46f0d63974e20c391e8,,jc6w44hrp9v2ki,"[{u'text': u'
Part 2c: generate_k_folds()
""""""Split dataset into folds.

Fold is a tuple (training_set, test_set).
Set is a tuple (examples, classes).
""""""
If K-1 folds are going to be used to training and 1 fold for testing, why are we further splitting a fold into train/test? If we are (for whatever reason) what is the train:test split in each fold? ', u'responses': [u'There are k folds because there are k ways to arrange the data where k-1 sets are in the training data and 1 set is the test data. Each fold is a different distribution of training/test data.', u'I believe what you're asking is ""why create a test set if, in K-folds, we're already creating different test sets""?

There's some overlapping terminology here. The initial split is often said to create a training  set and a holdout set (sometimes called an independent test set). It's called holdout because you hold it out of your training entirely, and never touch it, look at is, or inspect it in any way until you validate your learner's performance at the very end. The test set that occurs during k-folds validation can then be called just a test set.

So why create a holdout set? The goal of training a models is, ultimately, to be able to classify unseen  data. To simulate unseen data, you prevent your learner from ever having seen some sample of data- the holdout set. You may see that this presumes that the distribution of your training set and the distribution of your holdout set are the same, an assumption often necessary for getting anywhere. To include this holdout set in your training anywhere and to make reports on it's accuracy would be cheating- you now have no way of quantifying how well your model generalizes against unseen data.

The idea behind K-folds (or leave-one-out validation) is to be able to determine (primarily) how well your model generalizes after training on a particular data set. If all your model did was memorize the data it was shown (overfitting), then it wouldn't be able to generalize to your test set (the remaining fold). Using K-folds allows you to tweak the hyper parameters of your learner and evaluate its performance across different samples of data without, and this is the important part, ever looking at the holdout set. Then, once you've tuned the algorithm to your liking, you can run against the holdout set and truly say that ""my model is this accurate when performing against unseen data"".

There's a good post about this on stack overflow as well.']}, {u'text': u'Are we only meant to deal with binary trees in part 2b? I ask because I was thinking of using the DecisionNode to build the tree but it only seems to support a binary decision (left, right) vs. having multiple possible outputs from a decision node.Also, are we to assume that feature[-1] contains the labels for each example or are these passed into the classes variable? This isn't really clear in the assignment description or docstrings and the structure of the data passed into build the decision tree would be helpful to have some clarification.', u'responses': [u'I am also not sure how to convert the continuous features into binary features. Just setting them to be 0 or 1 if they're greater than or less to the median or mean hasn't worked for me. Another option would be to make bins for each feature, and increase the feature dimensions by a factor of the number of bins. I'd also like a little more guidance on this part though. Should our solution be general? Or is it good enough to get it working on part23_data.csv?

As for your second question, even though the docstrings for fit and __build_tree__ say the classes parameter is the available classes, it's actually a list the same length as features, where the ith feature set in features has the ith class in classes.', u'""
Your features and classify should be in numpy arrays where if the dataset is (m x n) then the features is (m x n-1) and classify is (m x 1)
""

So features pass to the function should not contain class info, therefore cannot use features[-1]', u'I have the same question as Jim and Donovan.  My classify is passing Bonnie w/ 72%, but failing the unit test.

Due to how the unit test is written (build binary tree using continuous training data, then compare the classification of the tree to training data classifications), I can't think of a way to create the binary tree to be 100% accurate other than pretty much having nodes checking if the features of the testing data are precisely what was in the training data, which is going to break whenever you have any new points in the testing data.', u'Borrowing from Farooq's link below (https://www.academia.edu/7032069/An_example_of_calculating_gini_gain_in_CART) there is an example of how to determine binary decision nodes using a gini index with continuous data. Worked to get me past 2a', u'In AIMA section 18.3.6 details information on how to deal with variations in attributes. Although i have not been able to figure this out yet myself', u'One issue i am struggle with is if there are four features in the data say A1, A2, A3, A4 (as given in our test dataset) and I decide to follow the instructions for A1 i.e. split it / partition it into two halves based on alpha_best of that feature, so one goes on left of the tree and one on the right and then continue doing so for the sublists as instructed, what happens to attributes in A2, A3 and A4 are they to be ignored, seems like ignoring a lot of data? anyone figured this yet?', u'I was able to solve this finally with 0.98 accuracy, without disclosing more I can say you do not ignore any of the feature columns in any way', u'Elaine, did you ever get your issue resolved?  I think I am stuck where you were at the moment.  Any tips?']}, {u'text': u'Is gini_gain same as information_gain? from the description of the gini_gain() function it seems like it is  difference of gini_impurities

', u'responses': [u'I was able to solve this one though', u'So is gini_gain the same as information gain? Based on the tests, it is not. So, I'm stuck trying to understand what exactly they are looking for here.', u'My understanding is that Gini gain is the information gain based on gini impurity, not based on entropy. So you need to use gini impurity to calculate gain.', u'http://www.bogotobogo.com/python/scikit-learn/scikt_machine_learning_Decision_Tree_Learning_Informatioin_Gain_IG_Impurity_Entropy_Gini_Classification_Error.php

this article has a really good example of how to use gini to calculate information gain.

Im on my phone, cant really turn it to an actual link. Will do that when i get home
', u'I found this paper:
http://www.academia.edu/7032069/An_example_of_calculating_gini_gain_in_CART
Good thing is it does not have code, it does have a actual example and that helps understand better. I was able to solve it doing the example first and then writing code for assignment', u'By the way, the html file that comes with the code and has code examples still refers to entropy instead of gini.', u'Thanks Farooq!', u'Thanks Willie and Farooq.  I tried wikipedia....but it just didn't do it for me :)', u'That article Farooq is referring too is what finally got it for me even though it is still a little misleading. It took me a while to get the right divisor in the gain calculation for adding the values in. ', u'there is a blog post of the same if you don't want to connect to academia. (I think it's the same. I got the link from that page) http://ameenzhao.blogspot.com/2014/09/cart-notes-3-example-of-calculating.html', u'so I get how the equation works in theory, what I don't understand is how we're supposed to implement it with the inputs given for the function in code...

all examples I've seen compute information gain using just two lists, but the current_classes input is a list of lists... are we supposed to compute the information gain between the previous list and each separate current list and then sum them together?', u'+ for Julia! Thank you thank you!']}, {u'text': u'When generating k-folds, what is the expected behavior when we cannot evenly split the samples?  Are we to drop the minimum to evenly split the samples, or just work with uneven splits?', u'responses': [u'I worked with uneven samples and passed Bonnie.', u'Just to add, without giving away too much, some folds will have higher samples, and some lower.', u'How could folds with varying sample counts pass the unit test?  The two tests assert a specific fixed number of test and training samples in each fold.

I'm not saying it wouldn't pass bonnie, but do your unequal sample counts pass the unit tests?', u'Several times in last 4 assignments we see the Unittests dont really match bonnie behavior, My understanding is unittests are only there to give us a idea of what kind of test bonnie will be doing it does not mean bonnie is going to test exactly for that same thing. Several times I have also tried to reverse engineer the Unittests to figure out what is really expected from the problem we are trying to solve.

For example: unittest for 2b checks for 100% correct classification, however if you do get 100% correct classification wouldn;t that mean overfitting so i just modified the unit tests to instead print the accuracy for me instead of doing a assert', u'I guess I've been more deferential to the unit tests!  I don't recall having to change them to make any of the assignments work (although i have certainly added a lot as i work).

Given 2B's unit tests' unlimited depth, training on the full set of data, and access to all of the features, it SHOULD get 100% correct classification - you're right that it can overfit, but 2b doesn't mind that.

For 2C I inferred the expected behavior from the unit tests (and used constant sized sample collections), and it works fine in Bonnie.

So Manu's experience is that varying sample counts works, and mine is that constant sample counts also works.', u'100% correct classification on the train set may be overfitting, but it's a good test to have to make sure your implementation behaves as expected.', u'Evanda, when I use constant sample size collections I have to leave some rows out since the dataset is not evenly divisible by k. This results in an error message on Bonnie of ""You did not correctly create your k-folds. Number of training + testing doesn't equal the dataset"" How did you create evenly sized folds when the data did not evenly split? I feel like I'm missing something here.  Thanks.', u'Sandy - the different samples i generated are each the same size as each other, but they were not the perfect 1/k and (k-1)/k of the examples because of the remainder.  Rather than describe how i calculated it (which you might be able to discern by looking at the unit test), I'll give an example with different k and different number of examples:

If there were 101 examples, and my k=5, I'd wind up with 20 samples in each test group and 81 in each training group -- not exactly 1/5 (which would be 20.2) and 4/5 (which would be 80.8).

If there were 33 examples, and my k = 4, I'd wind up with 8 samples in the test groups, and 25 in each training group.', u'This helps a lot, I was approaching it wrong. Thank you!']}, {u'text': u'For 2b I am getting an error message from Bonnie: ""error"": ""{\""msg\"": \""The total output length exceeded the limit of 65536 bytes.\""}"". Everything seems to be passing locally and I am returning a valid list of classifications from the classify method (same length as the # of features passed in). Anyone else get this, or any idea on what it means? If not could a TA can give some insight into when this error is thrown?', u'responses': [u'Hi Sandy,This error would occur typically when the error message was too big to be displayed. I would recommend you to check whether your function gets stuck in some loop due to which this error usually pops up. ', u'I had the exact same issue. It turned out to be the ""maximum recursion depth exceeded"" problem. I didn't see this either with my local tests, and it was because the unittest that tests our decisiontree is deterministic. If you use your k fold method to generate random train data, you should be able to see some issue. Most likely that's the issue bonnie is complaining about. That being said, I do wish that the bonnie message was more informative. It took me many submissions (one hour apart) to narrow down the issue.', u'Ah, thank you Willie, thank makes sense. I'll dig into that later today.', u'Update - Your advice was sound Willie, I found a bug in my tree builder once I wrote and applied my own k fold method. My recursion wasn't stopping on an edge case. Everything good now! Definitely confusing that the error message is as such, doesn't seem like your typical recursion related message. Thank you again.', u'I think if we use print statements in our code the above error can happen any time even if there is no bug in our code.

I think the code on bonnie is redirecting std out and/or std err into a stream and the stream has limited size so if there are lots of print statements they accumulate and at some point the stream is full causing the above error']}, {u'text': u'For 2c, is it really the intent of the assignment that we need to implement our own randomness?It would seem that way, given the wording of the instructions. But implementing a good randomness is not a trivial task - I just wanted to be sure before I go and invest effort into writing something to give me random numbers to work with', u'responses': [u'You can use https://docs.scipy.org/doc/numpy/reference/routines.random.html']}, {u'text': u'For 2b, has anyone else gotten the following error message from Bonnie?

TypeError: tuple indices must be integers, not tuple

I'm not getting it locally and am not using any tuples, so I'm stumped on how this is happening.', u'responses': [u'If anyone else gets this error message, I solved it by casting all inputs to k_folds to numpy arrays.']}, {u'text': u'Hi,  

I seem to be missing something obvious here. In generate K-folds, each fold is a (train, test) tuple. So the data is split into k subsets of which each is further split into a train/test split. However, the decision_trees_submission_tests in the function test_k_folds_training_set_count (and likewise for the test) seems to be checking one individual fold's counts with the entire data's split counts. Thus, I fail those assertions. Copying the test case from the test file:

example_count = len(self.train_features)                 --------------------Total number of examplesk = 10test_set_count = example_count // k                      --------------------Expected number of test examplesten_folds = dt.generate_k_folds(self.dataset, k)for fold in ten_folds:    training_set, test_set = fold    assert len(test_set[0]) == test_set_count           ---------------------Expected number of test examples in just on fold


Any ideas on what I should do?', u'responses': [u'


Hope this helps you understand what k-fold is', u'Willie I don't think that whatever link/image etc you tried to paste got copied. I'm guessing what you tried to point me to would've described the entire dataset divided into different train/test splits in each individual fold. That way, the number of examples in each fold (train+test) would be equal to the overall dataset. I was trying to comply with the comments (instructions) in the generate k-folds method which say ""Randomly split the data into k equal subsets""...', u'oops, hope you can see it now. guess only i can see the image when it is using a external link. have to upload the image instead.', u'I also have a similar question.  Is it ok for the testing sets in each fold to have overlap, or do we need to randomize the sets, and then split it into k equal parts, with each equal part becoming the testing set for that fold and the rest for that fold becoming the training set?', u'Sigh, I'm confused as well, I don't think Harsh's question was actually answered... or maybe it was and I just don't get it...

Say that we have 10 samples and we have k = 5

The output of generate_k_folds should be a list of length 5 right?
And if so, each element in that list of length 5 will be a tuple of the form (training_set, test_set)
And then training set should have 8 rows and test_set 2 rows right?

I don't get why the unit test (and bonnie) ask for ""len(test_set[0])"" instead of ""len(test_set)""', u'I got the answer in slack

https://omscs-study.slack.com/archives/C0J321WR3/p1521327584000045

""0 is features 1 is classes""']}, {u'text': u'in __build_tree__(), can we repeat attributes to split? I assume we can, otherwise the tree's depth is 4 at the maximum. ', u'responses': [u'Yes. You always split on the attribute with the best gain. ', u'The book does a subtraction of attributes in the pseudo-code. I wonder if information gain, make this detail irrelevant since re-splitting on the same attribute with the class subset wouldn't give you anymore information']}, {u'text': u'What is the container type we need to return for examples and classes?I had assumed that examples would be numpy arrays and classes would be lists, because that is how they are given to us. However Bonnie is telling me that it is trying to hash the list and throwing an error.

I wish this had been better documented, unless I'm missing something obvious?', u'responses': [u'For examples, it should be a list of lists and classes it should be a list. ']}, {u'text': u'I am not seeing the point of normalizing the gini gain. Is it really necessary? The maximum gini gain for alpha_best should be the highest regardless of normalization... or not?', u'responses': [u'Nevermind, I hadn't looked closely at the data yet. I assumed the data was going to be simply binary (not the case).']}, {u'text': u'Sorry if I missed, but is there documentation on steps to normalize gini gain?', u'responses': [u'You need to simply use Gini gain for comparison. ']}, {u'text': u'Jainesh, in Part 2c regarding k fold cross validation, can you please clarify how we are supposed to handle the case where k does not split the dataset evenly?  In k fold cross validation, the data is supposed to be split into k disjoint sets, which means that generally, the size of each of those sets will not be exactly the same unless some samples are discarded.  However, the instructions and the unit tests for Part 2c say that the k sets must be of equal size.

Suggestions?', u'responses': [u'In such cases, you simply divide the dataset into k parts with a remainder. Now you give one element of this remainder to each fold until it's empty. So your folds will be uneven in such cases. But overall one datapoint will not affect the model a lot.', u'Using this method shouldn't the unit test return 138 instead of 137 as 1372 = 137 with a remainder of 2, so your first two folds have an extra 1 data point?', u'For those folks working on Part 2c and trying to get their number of samples in each fold correct:

***the unit test given in the Assignment 4 github directory is not identical to the test that Bonnie uses to grade the section***  I coded this part in the generally accepted way to create folds in k-fold cross validation, and it passed Bonnie even though it did not pass the unit test in the Assignment 4 directory.

Just fyi.  Good luck everyone.']}, {u'text': u'Anyone who need help with k-fold, I found this explanation very simple and lead me to bonnie passing my agent.https://youtu.be/CmEqvD_ov2o?t=7m56s', u'responses': []}, {u'text': u'I'm a little confused on the gini gain portion of 2a.

I got the gini impurity figured out, but the lists being passed into gini_gain are what's confusing me...

what do previous_classes and current_classes mean?  why is one a list but the other is a list of lists?', u'responses': [u'since I already have the gini impurity, I can calculate the impurity for the previous_classes vector, but I'm stumped after that...

I'm trying to follow along with the examples already posted: http://www.academia.edu/7032069/An_example_of_calculating_gini_gain_in_CART

I assume current_classes is going to just be the left and right split in the tree?  and then I would need to calculate the individual gini impurity values for 0 and 1 to plug into the formulas as shown in the example?', u'to clarify further...

all examples I've seen compute information gain using just two lists, but the current_classes input is a list of lists... are we supposed to compute the information gain between the previous list and each separate current list and then sum them together?', u'You have the right idea about previous_classes and current_classes. Look at page 3 in the article you mentioned and try to understand every number used in the equations. That will guide you in the right direction for calculating gini gain with the lists in current_classes.

Once you start 2B, all the pieces will fall into place.', u'Did you figure this out?', u'yeah, I finally got there thanks to another answer below']}, {u'text': u'Still not understanding why the problems are set up the way they are... 

In order to build the tree, I need to know which features belong to which class... we can't just arbitrarily split the data...

The build_tree function just gets a list of features and a list of possible classes... how do we know which class the features belong to?  The inputs for the functions we are supposed to build are pretty poorly explained', u'responses': [u'Each row of the features (e.g. feature[0]) is matched to the class with the same index (classes[0])', u'So features[1327] yielded classes[1327]', u'thank you, since the instructions say ""available classes"" it's misleading as it just seemed to me to be a list of possible classes not the actual classes assigned to the feature set']}, {u'text': u'Need a clarification about 2c. After we split the entire dataset into k folds, how do we split the data in each fold into training set and test set? Do we have to reserve 10% of the data in each fold for testing and use the remaining for training?', u'responses': [u'I'm confused, because the unit test is expecting the length of the test set in each fold to be example_count // k, but the way I understood the question, that would be the length of each fold. Am I misunderstanding the question? This is how I went about it - 1. Randomly divide the entire dataset into k subsets (folds) of equal size2. Divide each fold into training set and test set (90% of data from fold - training set, 10% data - test set)', u'
Each fold is the entire data set contained in two sets: training and testing.

The training set has total set - 1/k entries.   The testing set has 1/k of the entries.

The slice that you use for the testing set is different for each fold.  Willie Wei's picture above shows how the testing slice moves through the total data set (note that the data set is randomized first, then you choose slices so that you aren't slicing out contiguous portions of the original data but instead are slicing out random portions).
', u'Got it! Thank you :)']}, {u'text': u'confused about k-folds... I'm returning exactly what is asked for in the assignment description but getting told my counts are wrong... if I look at the unit tests given with the assignment they seem to have the test and train sets backwards...

if I have k=10 for example, this needs to be partitioned into 10 equal subsets and 1/10 of that becomes the test set and 9/10 become the training set, correct?

Also, I am getting 138 for the size of my test set, rather than 137 that the unit test is expecting, since it only takes the first item... I assume this isn't a problem for bonnie as others have mentioned, but what seems especially odd is that the size the unit test takes for the training set is the total size of both dimensions rather than just the row count... so the answer obviously ends up being wrong... does bonnie make sure to only take the size of one dimension?

', u'responses': []}]",,3.0,288.0,615,,Assignment 4 Part 2 Discussion Thread,[a4]
5ad7d46f0d63974e20c391e9,,jc6w44hrp9v2ki,"[{u'text': u'Anyone getting the following msg?
I have no idea what this is telling me..
{
  ""error"": ""{\""msg\"": \""The total output length exceeded the limit of 65536 bytes.\""}""
} ', u'responses': [u'Never mind. I think it was due to improper implementation of depth_limit, cause it to throw recursion depth overflow error. ', u'I'm having the exact same issue, what did you do to solve it? how did it overflow? I did change the fit method to pass in the depth_limit so that it builds a tree with deep > 0 (Default 0), is this whats wrong? Thanks a lot', u'ok, my issue was my split value sometimes causes one tree branch to be empty, which causes my information gain to be invalid. Tree cannot be split ever since, causing the recursion to overflow. I wish bonnie told me recursion overflow error, instead of this 'output length exceeding limit' error.']}, {u'text': u'-', u'responses': [u'This may be a silly question, but are you stripping down the ""classify"" features to match the features each tree was trained on?  That tripped me up for a bit, and was an annoying bug.']}, {u'text': u'.', u'responses': [u'<mispost>']}, {u'text': u'-', u'responses': [u'-', u'  ̂ͬͪ͂̈́ͯ͌̎ͤͥ̽ͯ̏ͪͦ̐̚͏̧̟̙̟͕̰̪́͟ ͇͖͇̫̳̙̃̌ͤ͐̎̉̕ ̵̨̖̖̼̘̲̭̼̣͇͛͆̅ͤ̔̒͛́͂͐ͥͭ͋̓̐͆ͧ̃ͧ͢ ̛̮̯̣̹̣͊͂̒ͮ̔ͫͯ͡͝͡ ̴̡̢͇͓̲͚̟̺͎̼̺̦̹̟͍̗̺̣̫͑̇̍̇ͬ͛̍ͧ̓ͩ̏ͤ͆̆̎͡ͅ ̶ͥͨ̄̐̎͆ͩ̑͆́ͪ̄͊̽̈ͮ̾̌̀͝҉̼̳̫̮̩̞͓ ̸̢̫̦̥̳̰ͥ́ͭ͂ͩͯͨͩ͑̐ͩ́̂ͨͯ̀̈́ ̠̫̱̭̗̮̮̖̮͈̾̓ͮ̏ͭ̽ͮͬ́͝ ̷̌̑͋̓͊̉ͦ̍̉͌̎ͫ̈́ͬ͝҉̰̪͕̞͚̯̣͙̱̱͈̙͉̤͕̜̙̤́͝ͅ ̨̩̪͇̯̩̔̒͗ͧͤͮ̀̑̐̍̈ͯͭ͋̽̀̀̚͟']}, {u'text': u'Regarding ""ii. From the sample in the first step, choose attributes at random to learn on (in accordance with a provided attribute subsampling rate)."", are we expected to randomly choose attribute with replacement, i.e. repeated attributes or not? Would be good if TAs can clarify this step. ', u'responses': [u'The attributes and examples are to subsampled with replacement. ', u'To clarify further, my understanding from the canonical RF algo is:

at each stage choose a subset of the attributes (usually proportional to the square root of the number of attributes, but here we're using a given subsampling rate, which makes sense)select from that subset based on the normal gini impurity metricresample at the next stage with replacement

Is this what we're expected to do in this case? The second point is the only one that doesn't come out clearly for me in the instructions...']}, {u'text': u'Hi, 

For part 3, I not getting the desired accuracy. Since all the parameters are fixed, is there any way I can improve my RF accuracy? (not the challenge classifier part).

Thanks', u'responses': [u'I think you should start checking cross-validation accuracies and they should typically be higher than that achieved by a single Decision Tree.
I believe that you should check whether your classifier builds the trees as you desire it with the given parameters. After, that you might want to check on the voting system for the RF classifier to determine the class of the test inputs. ']}, {u'text': u'Hi,

Are we allowed to change the code in the constructor for RandomForest. For example, add new instance variables, etc. ?
Alternatively, are we free to define whatever data structure we choose for self.trees ?

Thank you.', u'responses': [u'You may do that but at your own risk. The given structure of the code is enough to complete the assignment according to us. You should ensure that your code doesn't break or cause issues when calling the functions that were asked to be completed in the assignment description. ']}, {u'text': u'The book and lectures don't give a lot of detail on Random Forests. Are there specific implementation details that we should be considering when building our random trees? For example,
how should we handle splits that result in empty branches?Are all possible example and attribute subsamples valid or should we be rejecting some?Should we split on mean or search for the best split based on gini gain?
I think the main algorithm is clear, but there are a lot of other details that go into generating a tree that haven't been specified and I feel like there might be specific assumptions that are throwing off the accuracy. 

I ask because the accuracy for my random forest is highly variable. It can range from 0.5 to 0.8 average accuracy over 10 runs given the parameters specified. However, there isn't a clear way to tune the parameters since they are passed in by Bonnie. So there must be some specific assumptions in the way the tree is constructed that make a difference.', u'responses': [u'I am having the same issue as yours', u'I would suggest that you think a bit more on these topics as it will benefit your understanding of this topic. 1. Hint: Terminating Condition
2. We subsample attributes and examples both with replacement for each tree in the Forest 
3. We split on the mean/median of one feature, calculate Gini gain on this split and then decide which feature is the best to split on. 
If your cross-validation error remains stable enough then a similar behaviour can be expected in the testing data as well. Else, your model is overfitting the training data. I would recommend you to check your terminating conditions for your build tree function. Do let us know if you need further help!', u'What are the expected terminating conditions? The document outlines 2 terminating conditions. 
If all elements of a list are of the same class, return a leaf node with the appropriate class label.If a specified depth limit is reached, return a leaf labeled with the most frequent class.
Are there others beyond these that are expected?#3 is an important consideration above. I was finding the best split based on analyzing the gini gain for every pair of nodes that describes a class boundary for each feature. If it is just the mean, then this may be making a difference, and why I am getting some branches that are empty.I'm not sure if I understand the comment about cross-validation error and overfitting the training data in regards to Random Forests. Since we aren't in control of the depth, number of trees, or subsample rates and these are all controlled by Bonnie, what leverage do we have to control overfitting in the Random Forest example?Thanks for your feedback. I will give some of these ideas a try.', u'In case anyone else gets stuck with handling empty branches, don't forget to look at the terminating conditions in the book: 
']}, {u'text': u'Jainesh,  If (subsample rate) x (dataset size) does not equal a whole number, would you like us to round up or down?  Or, does it not matter?', u'responses': [u'Frankly speaking, one data point should not matter that much to your classifier else your classifier is not a good one. ']}, {u'text': u'For anyone hovering between .6 and .8 and a lot of variance between runs, I went from that situation to consistently > .9 average over 10 iterations with a simple modification.  I knew my trees were correct, that the voting was correct, and that my trees would classify correctly assuming they were given the proper input.  

Without giving too much away, consider the specific parameters under which the trees were built initially then consider the data (examples) you provide to those same trees once you wish to classify all examples. ', u'responses': [u'Can you elaborate on this please?  Stuck between 0.6 and 0.8 for a few hours now and am out of ideas.

The input parameters for creating the tree are # of trees, depth-limit, and sub-sampling rates.  These can't be tweaked as bonnie passes in values for these. 

I'm not sure how the data for classification can be modified to help improve the performance.  ', u'John, thank you. This was exactly the cause of my problems and I saw the same jump you're mentioning in accuracy.']}, {u'text': u'During classification in Random Forest, we send the trees built on subsampled features and attributes. My question is, the `features` used in classify() should be the subsampled features array or the entire features array? 

<Edit> Figured out the details. Reading the above comment helped.', u'responses': []}, {u'text': u'I have a doubt about the 2nd case: ""From the sample in the first step, choose attributes at random to learn on (in accordance with a provided attribute subsampling rate).""

There are only 4 attributes in each example in ""part23_data.csv"" dataset, so if the attribute_sample rate is 2 and at random we pick say attribute A2 and A4 does that mean the tree should be leaned only using these 2 attributes for all the examples sampled for this particular tree?
', u'responses': [u'Yes. The rate will be 0.5(2/4) in that case then. This rate applies to each tree but attributes chosen may be different though. ']}, {u'text': u'How are you all testing this part (other than submitting to Bonnie)? ', u'responses': [u'Created a main() in the decision_trees_submission file. Used the part23_data for learning. Helped with debugging. Good luck.
-Q.']}, {u'text': u'Grading: average test accuracy over 10 rounds should be >= 70%

            ""output"": {                ""points_available"": 30,                ""points_awarded"": 15,                ""autograder_comments"": ""3 results: Unsatisfactory: Random forest accuracy of 0.700404166744. ""

Why unsatisfactory? Looks satisfactory to me', u'responses': [u'You need to achieve 75% test accuracy to get full credits for the part.']}, {u'text': u' When submitted to Bonnie, my Random forest accuracy is around 74% ~ 80%. In all my Bonnie submission with complete Random forest implementation(around 10), RT accuracy of one submission is 74%, which is below the 75% threshold.
1:  Is that true that as long as my last submission to Bonnie has accuracy>75% I'll got 30/30 points for RT part?
2: My DT accuracy is consistently 99% when submit to Bonnie, If my RF accuracy is only around 74% ~ 80% does it mean there is something wrong in my RF implementation?
3: I implement my RF step by step according to the description in assignment readme part 3. What could possibly go wrong in RF implementation that cause unsatisfactory accuracy?
', u'responses': [u'I'm stuck in the same boat where my accuracy is between 0.6 and 0.8.  Only thing that improves the accuracy for me is increasing the number of trees used.  Anybody else have any solutions?', u'I was having this problem and my solution centered around addressing the difference between the shape of the individual trees in my forest versus the shape of the new features being classified.', u'Hi J, 
Can you elaborate on ""addressing the difference between the shape of the individual trees in my forest versus the shape of the new features being classified""? ', u'nvm, got this resolved after seeing this conversation on slack: ', u'solved my problem by following slack comments:
""""""
Conor Cahill [8:27 PM]If, when building the tree, you sliced out the feature attributes to only include the randomly selected ones, then you have to remember to do the same thing when you are classifying.
""""""
', u'Thanks Zhiwei and Conor that hint fixed it for me.']}]",,2.0,270.0,616,,Assignment 4 Part 3 Discussion Thread,[a4]
5ad7d46f0d63974e20c391ea,,jc6w44hrp9v2ki,"[{u'text': u'I keep running into Bonnie timeout errors when trying to go for the last 10 points on this assignment. Any chance the challenge classifier could have a separate submit area set up like in Assignment 1 so we can build more trees, etc? Or is that basically part of the challenge? I can get much better results locally than on Bonnie because it appears I have very little time left after the other tests to run my challenge classifier.', u'responses': [u'Hi Nathan,We believe that the Vectorize portion of the assignment can be tested well locally. Thus, the timeout should not be an issue cause of that. The Challenge classifier that you implement too typically should not take more than a couple of minutes to run on the data as well. So I would suggest you first check your code locally for proper implementation of vectorization and then the challenge classifier if you believe that you are facing such an issue.', u'I had timeout problems as well.  My case turned out that I didn't vectrorize my gini_impurity properly.  I was using sum instead of np.sum.  That was making my challenge classifier take 10 minutes instead of 30 seconds.', u'@Pepper Miller Thanks for the tip! Had the same issue as you and solved it the same way.']}, {u'text': u'It seems like the classes of the file challenge_train.csv are in the first column rather than like part23_data.csv in the last column. Can we assume it will be the case in Bonnie and hard code the classes to be the first column? or we have to first identify which column is the classes? ', u'responses': [u'Hi Danyang,You can assume that the datasets on Bonnie would be same files as given to you for training. Also, there is a provision in the function that allows to pass on the column that contains the class labels. ']}, {u'text': u'To be clear, is the challenge a binary classification problem and the classes are in the first column of the data?', u'responses': [u'Yes. ']}, {u'text': u'I'm trying to use Random Forests in the challenge classifier, but am just missing the 80% accuracy required in the training test. Any tips to tune the random forest classifier and make it more efficient?', u'responses': []}, {u'text': u'Is boosting required to hit the required accuracy?', u'responses': [u'the answer is no--there is at least one approach that can pass bonnie without invoking boosting.', u'<removed>']}]",,0.0,256.0,617,,Assignment 4 Part 4 Discussion Thread,[a4]
5ad7d46f0d63974e20c391eb,,jc6w44hrp9v2ki,"[{u'text': u'.', u'responses': []}, {u'text': u'For the first question, just to clarify, we're multiplying each element in the matrix itself, not doing a matrix multiplication, correct? 

The docstring says:

This function takes one matrix, multiplies by itself and then adds toitself.
Which sounds like a matrix multiplication (multiply the matrix by itself). But then the non-vectorized implementation given is:

non_vectorized[row][col] = (data[row][col] * data[row][col] +                            data[row][col])
Which is multiplying each element of the matrix by itself.

In any case, might be good to clarify the docstring in the future.', u'responses': [u'Your interpretation is correct. We are meant to do element-wise multiplication.']}, {u'text': u'The numpy version on vagrant vm is 1.8.2, instead of the one we use 1.12...it threw some error due to a numpy method param deprecation, but testing on bonnie is good. just FYI in case someone saw that error too.', u'responses': [u'+1 thank you thank you!']}]",,0.0,250.0,618,,Assignment 4 Part 5 Discussion Thread,[a4]
5ad7d4700d63974e20c391ec,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.


D- SEPARATION

Which of the following relations are always true for the network above? 
a) P(A, I) = P(A) P(I)b) P(C | B,F) = P(C | F)c) P(B,H | E,G) = P(B | E,G) P(H | E,G)d) P(A,B | G) = P(A | G) P(B | G)e) P(D | F,J) = P(D | J)


Solution:
Thad:  I believe I go over the answer in this video:
 https://youtu.be/uFVBuqN0DRQ?t=1h6m12s

Also recommend looking at understanding d-separation in this video:
 https://youtu.be/Th2YZgnG4YY?t=13m58s


",jc6w44hrp9v2ki,"[{u'text': u'a) P(A, I) = P(A) P(I)
True - A and I are independant
b) P(C | B,F) = P(C | F)
False 
c) P(B,H | E,G) = P(B | E,G) P(H | E,G)
True - Given E and G(which tells us about F) B and H become independant
d) P(A,B | G) = P(A | G) P(B | G)
False - G tells us about C through D
e) P(D | F,J) = P(D | J)
 False - Explain away effect would change the probability given F', u'responses': [u'c is false; H is not independent of G [not given F], nor is B [not given C or D], so H & B both explain away G. That is, $$P(B,H|E) = P(B|E)P(H|E)$$ however when you add $$G$$ they are no longer independent']}, {u'text': u' 
a $$P(A,I) = P(A)P(I)$$
b $$P(C|B,F) \ne P(C|F)$$, $$P(C|B,F) = P(C|B)$$
c $$P(B,H|E,G) \ne P(B|E,G)P(H|E,G)$$
d $$P(A,B|G) \ne P(A|G)P(B|G)$$
e $$P(D|F,J) \ne P(D|J)$$', u'responses': [u'Since A and I are connected through unknown variables, are they truly independent?', u'A & I are independent in the absence of evidence of C, G; Evidence of B,E,F, or H would counteract evidence of C. Evidence of C,D,F, or H would counteract evidence of G', u'Thanks Mark...   Looking back over my notes, this was one of the examples in the inactive triplets where the joining node (in this case c) was not known and therefore the parents were independent (so a is independent of b and therefore A is independent of I). ']}]",,2.0,206.0,620,,Challenge Question 16 - Bayes Nets,"[lesson6, challengeqtns]"
5ad7d4700d63974e20c391ed,"How did we get to 0.541? I am struggling with math here. B stands for log (base 2) and log base 2 times 0/2 is infinity. what am I missing?
",jc6w44hrp9v2ki,"[{u'text': u'Remember that B(0/2) is actually -(0/2*log(0/2) + (1-0/2)*log(1-0/2)) doing that should result in B(0/2) = 0From B(q) = -(q*log(q) + (1-q)*log(1-q))Log base 2.', u'responses': [u'oh totally missed that. thanks for pointing it out!', u'log(0/2) is undefined mathematically even if it is log of base two, so multiplying by anything undefined is illegal. 
', u'I think we can assume in this case that with the 0/2*log(0/2) gives us 0 because of the 0/2 in front. I may be wrong about that, but in the example from the video, that outcome is 0.', u'Yes, they are saying that the outcome is zero, but the way that it is represented and defined can not be correct. Just because there is a zero in front does not mean you can multiply something with a zero that is undefined and get zero. log(0) is undefined, and therefore nothing can be multiplied with it.

The only way that I can see this 0*log(0)=0 is if we take limit of log(0) as it approaches from infinity. That would be correct mathematical formalism. What is represented here does not appear to be correct mathematically. I believe that is the issue that some of us are having because just assuming log(0) is zero is not mathematically correct.', u'The explanation for why the entropy of probabilities $$p_{1}=0$$ and $$p_{2}=1$$ is zero is because entropy is a measure of uncertainty. If the probability of an event is certain (0 meaning the event will never occur, and 1 meaning the event will always occur), there is no uncertainty; hence $$B(p_{1})$$ and $$B(p_{2})$$ is 0.']}]",,0.0,117.0,622,"The explanation for why the entropy of probabilities $$p_{1}=0$$ and $$p_{2}=1$$ is zero is because entropy is a measure of uncertainty. If the probability of an event is certain (0 meaning the event will never occur, and 1 meaning the event will always occur), there is no uncertainty; hence $$B(p_{1})=B(p_{2})=0$$. When the probability is 50%, the uncertainty is at its highest, $$B(0.5) = 1$$.",Video 32 Math,[lesson7]
5ad7d4700d63974e20c391ee,"Hello, 

In video 36 (Boosting), I am unable to understand how the Error (epsilon = 0.21) is calculated. Can someone please explain?

Thanks

",jc6w44hrp9v2ki,[],"Normally, error can be calculated as 1-accuracy where accuracy is (# of correct classifications)/(# of correct classifications + # of incorrect classifications). In that calculation, each sample is assumed to be equally weighted - getting one wrong is same as getting any other wrong.

For boosting, we update the weights based on the previous iteration. In step one (left square), the error1 was 0.3 and this results in alpha1 of 0.42. We use this alpha to increase the weight of the 3 incorrectly classified samples and decrease the weights of the correctly classified samples. So now the error calculation for error2 uses the updated weights, so even though 3 samples were incorrectly classified, error2 is smaller than 0.3 because their weights were smaller (because they were classified correctly in the previous iteration).",0.0,128.0,623,,How to calculate error in Boosting?,[lesson7]
5ad7d4700d63974e20c391ef,"Folks-
Tomorrow, Sunday 3/4 at 11am EDT, 8am PDT I will be on YouTube Live to answer questions about the midterm and the class in general.Please enter questions on the Piazza post hereBoth the live and recorded video will be found here
https://youtu.be/QlpJb7sRXyw

the Live (Text) Chat during the broadcast will be at
https://www.youtube.com/live_chat?v=QlpJb7sRXyw&is_popout=1

IMPORTANT LINKS FROM HANGOUT


Thad's CS6601 midterm overview office hours (Fall 2016)   
2.5 hours of step-by-step work through of that semester's midterm https://youtu.be/xz4ovRUe_zk

Thad's midterm review (Spring 2016)
>1 hour of step-by-step work through of that semester's midterm
 https://youtu.be/uFVBuqN0DRQ
Best of luck folks! We hope you find the midterm useful for improving your understanding of the material! The TAs and I have spent many hours refining the questions with that goal in mind!


",jc6w44hrp9v2ki,"[{u'text': u'Do you have any advice or suggestions on how to approach the midterm?', u'responses': []}, {u'text': u'Can you solve step by step the game tree with Alpha Beta pruning from Challenge question 1 or 2?', u'responses': [u'and follow on for challenge question 2 - could you discuss a generalized strategy for re-ordering nodes to maximize alpha beta pruning? Thank you', u'Andres - Challenge Questions 1 and 2 have solutions in the post's signature.

Sandy - You order all max nodes in descending order and all min nodes in ascending!']}, {u'text': u'Can you explain the stopping criteria for Bi-directional breadth-first search and Bidirectional Uniform Cost Search?', u'responses': [u'Every time the two frontiers meet calculate the combined path.

When the top nodes of the two heaps (forward and reverse) sum up to more than your shortest path up to that point, terminate search and return shortest path.']}, {u'text': u'Can you solve Challenge question 16? Or present a full join distribution example (different from the one on the book?)', u'responses': [u'See

 https://youtu.be/uFVBuqN0DRQ?t=1h6m12s

also, I highly recommend watching this section on understanding d-separation

 https://youtu.be/Th2YZgnG4YY?t=13m58s



']}, {u'text': u'the link tells me that I don't have permission to view this page!', u'responses': [u'there is another link above it. try it out.', u'Did you try both links?

One of them didn't work for me.', u'https://youtu.be/QlpJb7sRXyw
', u'Yep sorta in on that. That isn't there', u'Thad isn't there and that link is supposed to be for recorded session not live', u'https://youtu.be/QlpJb7sRXyw is the correct link. Thad just popped up live for a second. He is still setting up.', u'Yeah I saw. ']}, {u'text': u'Assuming no internet means no Piazza. i.e. unplug your cable modem to be safe.', u'responses': [u'for the entire week???', u'Well, while you are working on the exam?? Which leads to the obvious question, how much time is really required to complete the exam?', u'Referring to Udacity and Piazza for the 6601 class *only* are OK.  Looking at other classes on these platforms is not OK (and probably would not help).

Do not ask for help from others on Piazza, Udacity or any platform (like stackoverflow). As it says on the syllabus ""You may not collaborate with anyone at all on the midterm or final. Do not discuss or share the questions and answers with your classmates or any other parties until after the tests are due.""

For clariification questions on the midterm, make it a private post to the TAs and me.  Each TA who made a question is monitoring Piazza for issues.

In general, any disputes will be settled by whatever is the standard is used in the book.



']}, {u'text': u'Does piazza count in ""course materials""?', u'responses': [u'Several outside lecture materials are linked in our materials, do these count as outside materials?', u'Piazza is allowed and it sounded like the biggest concern was literally googling the questions or posting them on SO. I would ask about external links in the chat or a different follow up because they're never gonna look at this one again']}, {u'text': u'click on the youtube video link....having trouble with the text chat', u'responses': []}, {u'text': u'Hello, 

Could you give some insight to the correct approach for tri-directional search and its stopping criteria, particularly A*?

Thanks', u'responses': [u'Related: is it possible to have a 'shared frontier'? I read this somewhere, but didn't investigate.', u'A conservative approach is to extend the stopping criteria I gave for bidirectional.  You grow until you first connect 2 of the 3.  Then grow until the min sum of traveled distance to date for all children between those 2 are more than your discovered path between the 2.  Then continue until the third city is connected.  Again, continuing growing until  the min sum of traveled distance to date for all children between those 2 are more than your discovered path between the 2. ']}, {u'text': u'Should we complete Assignment 4 before attempting the midterm?  Do them at the same time?', u'responses': []}, {u'text': u'Can you share some insight on partition-based bidirectional search, especially stop condition?', u'responses': [u'eh......I'd have to go look that up.  Sorry.  Any TAs got an answer offhand?']}, {u'text': u'Can you put up all the solutions to the challenge questions which are for the midterm? A number of them have some answers but not confirmed as correct by any TA.', u'responses': [u'The probability and Bayes Net ones. Also, only have 2 bayes nets and have none for the current chapter.', u'Pinged Theo and posting what I have with me right now.', u'Done Brett!
Sorry for the delay.', u'Thanks guys. Helpful for sure.']}, {u'text': u'Thank you Thad!', u'responses': [u'Welcome!']}, {u'text': u'Will office hours be held during the week? Obviously not to ask questions about the midterm itself.', u'responses': [u'Hi Minh!
No office hours during open midterm week.']}]",,1.0,282.0,624,,Thad&#39;s midterm office hours 3/4 11am EDT/8am PDT,"[midterm, announcements, office_hours]"
5ad7d4700d63974e20c391f0,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


Cough & Cold
P(LD = T | Cough = T) = ?
P(LD = T | Cough = T, Fever = T) = ?
 
Show the work that led to your answers.
 
 

 

 
Solution: https://youtu.be/uFVBuqN0DRQ?t=44m
 

",jc6w44hrp9v2ki,"[{u'text': u'Part 1 is manageable

$$L$$ for LD, $$H$$ for Cough, $$C$$ for Cold, $$E$$ for Fever
$$P(L=T|H=T) = P(H=T|L=T)P(L=T)/P(H=T)$$
$$P(H=T) = \sum\limits_{c,l \in \{T,F\}}P(H=T|C=c,L=l)P(C=c,L=l)$$
$$= \sum\limits_{c,l \in \{T,F\}}P(H=T|C=c,L=l)P(C=c)P(L=l)$$
$$ = 0.8 \times 0.3 \times 0.1 + 0.3 \times 0.3 \times 0.9 + 0.75 \times 0.7 \times 0.1 + 0.05 \times 0.7 \times 0.9$$
$$= 0.024 + 0.081 + 0.0525 + 0.0315 = 0.189$$
$$P(H=T|L=T) = \sum\limits_{c\in \{T,F\}}P(H=T|L=T,c)P(L=T,c)$$
$$ = \sum\limits_{c\in \{T,F\}}P(H=T|L=T,c)P(L=T)P(C=c)$$
$$= 0.8 \times 0.1 \times 0.3 + 0.75 \times 0.1 \times 0.7$$
$$= 0.024 + 0.0525 = 0.0765$$
$$\Rightarrow P(L=T|H=T) = \frac{0.0765 \times 0.1}{0.189} \simeq 0.0405$$', u'responses': [u'I also got:
P(LD = T | Cough = T) = 0.0405

A bit stuck on:
P(LD = T | Cough = T, Fever = T) = ?', u'Couldn't we do the sum of the possibilities of each case since the net is so small ie:
P(LD,H,F,C)+P(LD,H,F,-C)= .0287', u'For the second part I think $$P(LD| Cough, Fever) = P(Cough | LD, Fever)P(LD|Fever) /P(Cough|Fever)$$
Now,
$$P(Cough|LD,Fever)=P(Cough|LD,Fever,Cold)P(Cold)+P(Cough|LD, Fever,∼Cold)P(Cold)$$ which inturn solves to $$P(Cough|LD,Cold)P(Cold)+P(Cough|LD, ∼Cold)P(Cold)$$

$$P(Cough|Fever) = P(Cough|Fever, Cold)P(Cold) + P(Cough|Fever, \sim Cold)P(Cold)$$
Lastly,
$$P(LD|Fever) = P(LD) $$ due to independence
', u'@mark where did the 0.1 come from in your final calculation (0.0765 * 0.1)/(0.189) ~= 0.0405', u'$$P(L=T|H=T) = P(H=T|L=T)P(L=T)/P(H=T)$$', u'Thanks...
I think I am misunderstanding the algorithm. The way I am approaching is as follows. The value 0.0405 seems much more plausible compared to my result. Where is my understanding incorrect?

$$P(L=T | H=T) = \frac{P(L=T , H=T)}{P(H=T)}$$  [ by definition ]
$$=\frac{\sum_c P(L=T, H=T, C=c)}{\sum_l\sum_c P(L=l, H=T, C=c) }$$ [ Law of total probability and Markov Blanket ]
$$=\frac{\sum_c P(L=T) P(H=T | C=c,L=T) P(C=c) }{\sum_l\sum_c P(L=l) P(H=T | C=c,L=l) P(C=c) }$$ [ Use Bayes Net ]
$$=\frac{P(L=T) \sum_c P(H=T | C=c,L=T) P(C=c)}{\sum_l P(L=l) \sum_c P(H=T | C=c,L=l)P(C=c) }$$ [ Distribute ]

Use Conditional Probability Table: 0.0765/0.189 = 0.40476

I am off by a factor, and the value I have derived seems too high intuitively, but I feel that the steps taken are correct?

']}]",,1.0,196.0,628,,Challenge Question 17 - Bayes Net,"[lesson6, challengeqtns]"
5ad7d4710d63974e20c391f1,"Solution for Challenge Question 13 - @591

 
Disease

a) Test B!
 
For Test A:
True Positive = 0.01*0.95 = 0.0095
False Positive = 0.99*0.1=0.099
Precision = 0.0095/(0.0095+0.099) = 0.087558
 
For Test B:
True Positive = 0.01*0.90 = 0.009
False Positive = 0.99*0.05=0.0495
Precision = 0.009/(0.009+0.0495) = 0.153846
 
See definition of precision and recall here:
https://en.wikipedia.org/wiki/Precision_and_recall

b)  P(V|A,B) = 0.633
For more details check Mark's and Junwei's answers on the original post. Mark also calculates the probability symmetrically.


PRACTICE

P(A∩B∩C)=0.01
P(¬C∩A)=0.37         (0.03+0.34)
P(¬A)=0.47           (0.06+0.09+0.27+0.05)",jc6w44hrp9v2ki,[],,0.0,147.0,629,,[Solution] Challenge Question 13 - Probability,"[lesson5, challengeqtns]"
5ad7d4710d63974e20c391f2,"Solution for Challenge Question 14 - @597

Deck of Cards
a) P(fake|black) = P(black|fake)P(fake) / P(black) 
                      = P(black|fake)P(fake) / ( P(black|fake)P(fake) +  P(black| not fake)P(not fake))
                      = (1)*(1/d) / ((1)*(1/d) + (1/2)*((d-1)/d))
                      = 2/(d+1)

b) P(fake|k black) = P(k black|fake)P(fake) / P(k black)
                        = P(k black|fake)P(fake) / ( P(k black|fake)P(fake) +  P(k black| not fake)P(not fake))
                        = (1)*(1/d) / ((1)*(1/d) + (1/2^k)*((d-1)/d))
                       = 2^k /(2^k +d-1)
 
c) P(k black, ¬fake) = (d-1)/(d*2^k)",jc6w44hrp9v2ki,[],,0.0,144.0,630,,[Solution] Challenge Question 14 - Probability,"[challengeqtns, lesson5]"
5ad7d4710d63974e20c391f3,"This solution is for Challenge Question 15 - @599


LOTTERY

Each lottery ticket has 1/4 chance of containing no wins 1/4 chance of containing 1 win, 1/4 chance containing 2 wins, 1/4 chance containing 3 wins. We can have multiple different arrangement for tickets containing 1 win or 2 wins, so the probability distribution looks like the following:
 
WWW    1/4
WLL       1/12
LWL       1/12
LLW       1/12
WWL      1/12
WLW      1/12
LWW      1/12
LLL         1/4
 
The slots are identical, so the order in which you scratch doesn't matter in this question.""Scratching a random slot"" has the exact same outcome distribution as ""scratch the first slot"".
 
(a) On average we get 1.5 wins in each ticket, so the expected return is
2.6∗1.5−1.5∗3=−$0.6
 
(b) Without Prior knowledge, each slot has a 50% chance containing a win, so the answer is 1/2.
 
Here we see that each slot has a 50% chance containing a win, and a win gives only 2.6/1.5 = 1.73 times the payout. For every lottery ticket we lose on average $0.6. Looks like a pretty bad deal, right?
The next few questions tell us that we shouldn't jump onto the conclusion so fast. The subtlety here is that scratching a slot on the ticket reveals information about the other slots, and we can decide whether or not we should continue based on this information.
 
(c) Because the order we choose to reveal the slots does not matter. Let's assume that slot 1 gave a win, and we are planning to scratch slot 2 next.
 
We have 4 possible outcomes in this case
WWW    1/4
WLL       1/12
WWL      1/12
WLW      1/12
 
$$P(Slot2 = W | Slot1 = W)\\= \frac{P(Slot2 = W , Slot1 = W)}{P(Slot1 = W)}\\ =\frac{(\frac{1}{4}+\frac{1}{12})}{(\frac{1}{4} + \frac{1}{12} + \frac{1}{12} + \frac{1}{12})}\\ =\frac{2}{3} $$
 
 
The intuition behind this is that if we get a win for slot 1, we are more likely to have a ticket that has 3 wins or 2 wins.
 
Using the method from above, we can compute the entire probability tree:

 
(d) No, from the probability tree, our odds are pretty bad if lost on the first scratch.
(e) 1/2, from the probability tree branch for ""WLW""
 
(f) From the probability tree, the optimal strategy is to keep playing if we get wins, and get a new ticket whenever we see a lose. Note that all branches after an L has winning probability smaller than 1/2.
 
Assume each play costs x dollars to play, and the payout for each win is y dollars, the average return for each ticket will be:

$$R = -x + \frac{1}{2}[y-x+[\frac{2}{3}(y-x+\frac{3}{4}y)]]\\ =-x -\frac{1}{2}x - \frac{1}{3}x + \frac{1}{2}y + \frac{1}{3}y + \frac{1}{4}y\\ =-\frac{22}{12}x + \frac{13}{12}y$$
 
 
substituting x = $1.5, y = $2.6 we get

$$R = -\frac{22}{12}*1.5 + \frac{13}{12}*2.6 = $0.067$$


A positive return. Which means we will win money in the long run if we play smart.
 
The minimum payout for which we can break even from this game is actually:

$$R = -\frac{22}{12}*1.5 + \frac{13}{12}*y = 0 \\ y = \frac{22}{13}*1.5 = $2.54$$
 






",jc6w44hrp9v2ki,[],,0.0,149.0,631,,[Solution] Challenge Question 15 - Probability,"[lesson5, challengeqtns]"
5ad7d4710d63974e20c391f4,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.


MORE PRACTICE





Solution: @637 - Please try solving it on your own before looking at the answers.



",jc6w44hrp9v2ki,"[{u'text': u'$$P(C|A) = \sum\limits_{b\in\{T,F\}}P(C|A,b)P(A,b)$$
$$=0.95 \times 0.6 \times 0.2 + 0.84 \times 0.6 \times 0.8 = 0.5172$$

$$P(C|!D) = \sum\limits_{a,b \in \{T,F\}}P(C|\neg D,a,b)P(b|!D)P(a) = \sum\limits_{a,b \in \{T,F\}}P(C|a,b)P(b|\neg D)P(a)$$
$$\mathbf{P}(B|\neg D) \propto \mathbf{P}(!D|B)\mathbf{P}(B) \propto \langle 0.24 \times 0.2, 0.87 \times 0.8 \rangle \propto \langle 0.048, 0.696\rangle \simeq \langle 0.065, 0.935 \rangle $$
$$\Rightarrow P(C|\neg D) \simeq 0.95 \times 0.065 \times 0.6 +  0.84 \times 0.935 \times 0.6 + 0.32 \times 0.065 \times 0.4 + 0.15 \times 0.935 \times 0.4$$
$$\simeq 0.5727$$

$$P(E|B) = \sum\limits_{c,d \in \{T,F\}}P(E|c,d)P(c|B)P(d|B)$$
$$\mathbf{P}(C|B) = \sum\limits_{a\in\{T,F\}}\mathbf{P}(C|a,B)P(a) = \langle 0.95 \times 0.6 + 0.32 \times 0.4, 0.05 \times 0.6 + 0.68 \times 0.4 \rangle = \langle 0.698, 0.302\rangle$$
$$\Rightarrow P(E|B) = 0.93 \times 0.698 \times 0.76 + 0.92 \times 0.698 \times 0.24 + 0.63 \times 0.302 \times 0.76 + 0.2 \times 0.302 \times 0.24$$
$$\simeq 0.8066$$

$$P(E|A,B)$$ is a bit more involved; at some stage', u'responses': [u'for $$P(C|A)$$ why arent you considering E and D? The Markov Blanket of C is A,B, E, D. Should this not factor into the calculation?']}]",,1.0,203.0,632,,Challenge Question 18 - Bayes Nets,"[lesson6, challengeqtns]"
5ad7d4710d63974e20c391f5,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.



NO FREE LUNCH 

Compare k-NN (k-nearest neighbors) and Naive Bayes with respect to the No Free Lunch Theorem.  Answer with True or False! 
 
1. Naive Bayes is less sensitive to outliers than k-NN.2. K-NN is a better classifier for real time data compared to Naive Bayes because it can quickly classify the data points into clusters.3. With a large dataset, k-NN uses less space than Naive Bayes.4. K-NN is more likely to overfit, which is why you need to test out different k-values to find the best one.5. Both classifiers work well when the data is not independent.


 
Solution: Video - Please try solving it on your own before looking at the answers.

",jc6w44hrp9v2ki,[],,0.0,183.0,633,,Challenge Question 19 - Machine Learning,"[lesson7, challengeqtns]"
5ad7d4710d63974e20c391f6,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.


k-NEAREST NEIGHBORS
Here's some data. There are two classes, o (blue) and x (green). 

a. If we use 1-NN to classify the data points, what will be the leave-one-out cross validation error? (your answer should be between 0 and 1)
 
 
b. Consider k = [3,5,10]
i. What is the validation error for each (your answer should be between 0 and 1)
ii. Which value leads to the minimum number of validation errors?
ii. Which value leads to the maximum error?


In case of a tie, take circle.
 

Solution: @638 - Please try to solve it on your own, before looking at the answers.

",jc6w44hrp9v2ki,"[{u'text': u' 
A
1
 

B
i 9/11, 9/11, 1
ii 3 or 5
iii 10(or 1)', u'responses': [u'Well done!']}]",,0.0,183.0,634,,Challenge Question 20 - Machine Learning,"[lesson7, challengeqtns]"
5ad7d4710d63974e20c391f7,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.



DECISION TREES
In the table above, X1 - X10 are training examples. A1-A8 are features. y is the class label.
 

 
Please assign values for the nodes N1, N2, N3 in the following decision tree such that the tree gives 100% accuracy for the above data.
Note that each of the nodes N1, N2, N3 should be assigned ONE feature (A1-A8). The gray nodes are class labels present in the y column.
Please compute the information gain for each node using log bases and formulae as mentioned in the class notes. (Note: The node labels may be repeated.)
 

 
Please fill in the values for:
 
N1: Information Gain:______ , Node Label : ___N2: Information Gain:______ , Node Label : ___N3: Information Gain:______ , Node Label : ___

Solution: @639 - Please try solving it on your own before looking at the answers.

",jc6w44hrp9v2ki,[],,0.0,196.0,635,,Challenge Question 21 - Machine Learning,"[lesson7, challengeqtns]"
5ad7d4710d63974e20c391f8,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.
 
This post is now OPEN FOR DISCUSSION.



XOR

Can you design a Neural Network with just 2 neurons that implements the logic of XOR?
Why or why not? Show your results.



Solution: @640 - Please first try it on your own before looking at the answers.


",jc6w44hrp9v2ki,[],,0.0,215.0,636,,Challenge Question 22 - Machine Learning,"[lesson7, challengeqtns]"
5ad7d4710d63974e20c391f9,"This solution refers to Challenge Question 18 - @632

Please first attempt these on your own before looking at the answers.


MORE PRACTICE




1. P(C|A)Answer: 0.862000
Applying the rule of total probability,

$$P(C|A)=P(C|A,B)P(B|A)+P(C|A,!B)P(!B|A)$$

Since A and B are independent, $$<nobr>P(B|A)=P(B)</nobr>$$

Plugging in the values,
$$P(C|A)=0.95*0.2+0.84*0.8=0.862000$$
 

2. P(C|!D)Answer: 0.572645

There are two possible ways you can get this value:

$$P(C|!D)=P(C|A,B)P(A)P(B|!D)+P(C|A,!B)P(A)P(!B|!D)+P(C|!A,B)P(!A)P(B|!D)+P(C|!A,!B)P(!A)P(!B|!D)$$

$$P(C|!D)=\frac{P(C,!D)}{P(!D)} = \frac{P(C|AB)P(!D|B)P(A)P(B)+...}{P(!D|B)P(B)+P(!D|!B)P(!B)}$$

If you look closely, the second formula is the same as the first one if the terms P(B|!D) and P(!B|!D) were expanded using Bayes Rule.
 
The key thing to realize is that as knowing B, C and D are conditionally independent and knowing D does not impact A.
For the first formula, we would need the values of P(B|!D) and P(!B|!D). These can be found by Bayes Rule.

$$P(B|!D)=\frac{P(!D|B)P(B)}{P(!D)}=\frac{P(!D|B)P(B)}{P(!D|B)P(B)+P(!D|!B)P(!B)}=0.064516\\P(!B|!D)=1−P(B|!D)=0.935484$$
 
The second formula would intrinsically calculate these values and just involves plugging in the right values from the provided probability tables. If we compare this with just P(C)=0.5908, we can see that knowledge of D impacts C. 

3. P(E|B)Answer: 0.806558

Since E is actually dependent on C and D, we need to to use total probability to find this value. Knowing B renders C and D conditionally independent.

Thus:
$$P(E|B)=P(E|C,D)P(C|B)P(D|B)+P(E|C,!D)P(C|B)P(!D|B)+P(E|!C,D)P(!C|B)P(D|B)+P(E|!C,!D)P(!C|B)P(!D|B)$$

Since C is dependent on A as well, we would need to expand terms like P(C|B) using total probability like we did for the first part.
 

4. P(E|A,C)
Answer: 0.922689

This one was the trickiest. To calculate this value, we need to iterate over D, since that is the other incoming variable for E.

$$P(E|A,C)=P(E|C,D)P(D|A,C)+P(E|C,!D)P(!D|A,C)$$

Now, D depends on B, but ABC is an active triplet, so knowledge of both A and C impacts B which would impact D.

$$P(D|A,C)=P(D|B)P(B|A,C)+P(D|!B)P(!B|A,C),P(!D|A,C)=1−P(D|A,C)$$

Finally:
$$P(B|A,C)=\frac{P(C|A,B)P(B)}{P(C|A)}$$


",jc6w44hrp9v2ki,[],,0.0,175.0,637,,[Solution] Challenge Question 18 - Bayes Nets,"[lesson6, challengeqtns]"
5ad7d4710d63974e20c391fa,"This is the solution for Challenge Question 20 - @634

Please first attempt to solve it on your own without looking at the answers. 


k-Nearest Neighbors


a. With 1-NN, leave-one-out, we will have a cross-validation error of 1.0 since each of the 11 points is closer to a neighbor of a different class horizontally than they are to a point of their actual class (diagonally). 
 

b.
i. 
For 3-NN , cross-validation error is 9/11 (only two green points in the bottom group are correctly classified [3,1], [5,3])
 
For 5-NN,  cross-validation error is 9/11 (only two green points in the bottom group are correctly classified [4,2], [5,1])
 
For 10-NN, cross-validation error is also 1.0 since all data points are incorrectly classified.

ii. k = 3 and 5

iii. k = 10",jc6w44hrp9v2ki,[],,0.0,140.0,638,,[Solution] Challenge Question 20 - Machine Learning,"[challengeqtns, lesson7]"
5ad7d4720d63974e20c391fb,"This is a solution for Challenge Question 21 - @635

Please attempt to solve these on your own before looking at the answers.


DECISION TREES [SOLUTION]

N1: A7 
N2: A3
N3: A4
 
$$Gain(N1) = B(\frac{6}{10}) - (\frac{6}{10} * B(\frac{4}{6}) + \frac{4}{10} * B(\frac{2}{4})) = 0.01997$$
 
For N2 and N3, since you know they end up perfectly partitioned, you know that the remaining entropy is 0. So the information gain is simply - 
$$Gain(N2) = B(\frac{2}{4}) = 1.0$$
$$Gain(N3) = B(\frac{4}{6}) = 0.918$$


Also take a look into the following answer by a student last semester:

""Creating decision tree based on attributes with highest information gain, gives a different tree (non balanced) than mentioned in the question:""
 

 
 
""However, If I create a balanced tree out of it, it matches the above tree""
 
",jc6w44hrp9v2ki,"[{u'text': u'I understand how to construct a tree based selecting features based on information gain. I dont completely understand the concept of creating a balanced tree? What is the criteria to balance the tree?', u'responses': [u'Hey Tasuku, an unbalanced tree is just fine. We balance it just for this exercise since it is required. You should be getting faster traversals with a balanced tree.']}, {u'text': u'+1 to Tasuku Miura's question. Also, instead of A7, we could have chosen any of A6, A7 and A8, right?', u'responses': [u'Why did we not choose A3 as the root node despite having the gain of 0.0464 which is clearly greater than gain of A4 (0.0199)?', u'Hey Rupal, check the answer above. Also you can choose either root node, as long as the decision tree classifies all samples.']}]",,0.0,151.0,639,,[Solution] Challenge Question 21,"[lesson7, challengeqtns]"
5ad7d4720d63974e20c391fc,"This is a solution for Challenge Question 22- @636


XOR
",jc6w44hrp9v2ki,[],,0.0,172.0,640,,[Solution] Challenge Question 22 - Machine Learning,"[challengeqtns, lesson7]"
5ad7d4720d63974e20c391fd,"Hello everyone,

There are no new video lectures for this week. Please read through this post carefully as it contains important information about your midterm.

Midterm Exam
Due: March 11 at 11:59PM UTC-12 (Anywhere on Earth time)

The midterm exam will be released at midnight AoE (i.e., in a little under 10 hours). It will be available only on the Assignments section on T-Square, as a PDF. You will need to submit through Gradescope only, else your exam will not be graded. Please do submit a copy on T-Square for backup as well.

You will have exactly one week to complete and submit the exam. 

Please read the first page of the exam carefully - all necessary instructions have been provided. You may lose points if you do not follow these instructions.

Please make a private post on Piazza if you have any questions about the content of the exam. If you do not make your post private, that amounts to discussing the exam on a public forum, which amounts to cheating. We reserve the right to deduct points from your score. If we feel that the information provided in the exam is sufficient or that our answer might give out too much, we will refrain from answering. This is at the discretion of Dr. Starner and the TAs.

We will allow posts to be made public if they are “meta-questions”, i.e., about Gradescope, submission, PDF issues, software, etc.

Tomorrow, we will make a Clarifications thread on Piazza to answer common questions that may arise. Please refer to the Clarifications thread periodically to make sure that you have interpreted all questions correctly. 

There are still some students who are yet to register for Gradescope. If you are one of these students, we will be unable to grade your midterm and you will receive a zero.

Assignment 4: Decision Trees and Forests
Due:  March 18 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 4 has been released! Please check @612 for details.

Office Hours:
We will not be holding office hours this week, as we do not answer questions about the midterm on open forums.

As always, here are the syllabus and the schedule.

",jc6w44hrp9v2ki,[],,0.0,276.0,641,,Week 9 Announcement,"[midterm, announcements]"
5ad7d4720d63974e20c391fe,"Hello everyone,

The midterm exam has been released and can be found in the Assignments tab on T-Square.
The deadline is 11th March 2018, 11:59pm AoE.
 
There was a delay in putting it up as an assignment on Gradescope, but you should be able to see it there now as well.

Please read through the instructions on Page 1 carefully before you begin.
We have ensured to the best of our ability that the questions and instructions are clear. However, if we believe there are any clarifications or announcements to be made to all students, we will be adding them to this thread.
Once again, if you have any questions about the content of the exam, please make a private Piazza post.

Clarifications:
Clarifications will be added below this line, along with a timestamp in EST.
Question 1: 
[03/06 11:30 PM ET] You should interpret Expectimax to be the same as Expectiminimax.
(The term Expectimax is used interchangeably with Expectiminimax in the videos.)


Question 2:
[03/05 12:36 PM ET] The path length between N and X should be 36. Please ignore the 20.[03/06 12:06 AM ET] When calculating Manhattan Distance and 8-way distance, you need to account for the presence of barriers as given in the diagram on Page 7.

Question 3:
[03/06 1:11 PM ET] In A, the illustration depicting the Selection phase represents a random example and not the initial population.[03/06 1:11 PM ET] In A.4, if your algorithm terminates before you reach the end of the table, leave the rest blank. [03/07 1:15 AM ET] In A.4-5, The step |dx| must be exactly 25. You should not use smaller or larger step sizes.[03/08 12:50 AM ET] In B.4, The starting Temperature may be assumed to be enough to allow atleast some degree of stochasticity[03/08 5:43 PM ET] In A.5, ""Will never reach such a state"" is also a valid answer.
Question 4:
[03/05 9:24 PM ET] In B.2, the left hand column should read A through I, that is, the second F should be a G.[03/06 11:54 PM ET] In B.2, only write a domain if a variable was not assigned a value. Write the domain of the variable at the time the search terminated.[03/08 3:26 PM ET] In C, each person must be served exactly one food, one style, and one drink. This should be implied in the constraints already presented.
Question 5B,2:
[03/06 12:57 AM ET] ""In a bag, there are 6 blue marbles and an unknown number of black marbles. Now, one marble is picked and is replaced by an unknown number of new marbles of that color.""
 The two unknown numbers in the above question are not the same unknown number. For example, if the bag contained 3 black marbles, and a marble is drawn, it can be replaced by 10 new marbles of that same color.

Question 6C:
[03/07 7:00 PM ET] P(E | F) is asking for P( E=True | F=True). Give a single number with 6 decimal places, not a distribution.

Question 7:
[03/06 4:45 PM ET] Thad: Precision and recall are mentioned in the ""Topics for the Midterm"" in the class schedule. They are standard machine learning terms covered in later sections in the book, but I do not recall if we mention them explicitly in the lectures. To aid in learning, you may visit the Wikipedia article on Precision and Recall (https://en.wikipedia.org/wiki/Precision_and_recall). I am hoping that having students think about the terms deeply during the midterm will help them with the upcoming assignments.[03/10 1:19 PM ET] The calculation of mean, std and covariance includes only the training data. Use population standard deviation. 
Clarification regarding showing your work:In this exam, we do not have any questions that require you to show your work so we would be only looking at your final answers. However, you may attach your work at the end of the exam but we do not guarantee that it would be considered for grading purposes. 
",jc6w44hrp9v2ki,"[{u'text': u'How do I make a private post ? Do I just need to select ""Instructors"" instead of ""Entire class"" in the Post to section ?', u'responses': [u'That's right. There's a Piazza classroom setting to set the default as private for all posts that could be set temporarily, too, possibly avoiding accidents', u'Ah, wasn't aware of that. Thanks!', u'I already asked a private question and got really fast response too. So, if somehting is unclear for you (as it was for me) go ahead and ask.', u'@Mark Could you share how to set the default to private?', u'It's an option for the instructors to set for the class, Rupal, not students', u'oh ok got it']}, {u'text': u'It would help if the timestamp for last modification was added, maintained (at a fixed place).', u'responses': [u'They are adding clarifications in order as they receive them and are timestamping each entry.', u'I realize that. As things stand, we need to scan all the question each time. If there is a global last-modified-at timestamp available, we could scan only if there is an update after the last time we checked.', u'I think you're looking for bottom right hand corner of the post ""Updated 14 hours ago by..""', u'Why do you need to scan each question every time? Just use the Note History at the top.', u'Thanks']}, {u'text': u'I suggest that the TAs put these questions in order so bleary-eyed students don't miss them :) I almost missed the errata I was looking for for question 5 because it's at the bottom. ', u'responses': [u'Thank you! ']}, {u'text': u'', u'responses': []}]",,0.0,323.0,647,,Midterm Exam Clarifications Thread,"[midterm, announcements]"
5ad7d47f0d63974e20c391ff,"Hi,

I'm confused with the lession 7 video 20 calculation.
first, what is P( P | S ) = 0.001, 0.25 mean? I know 0.001 means given word ""piazza"" the probability of getting spam is 0.001, but how about 0.25?
second, for the calculation=

for the denominator, it is = P (!P, B, !D), why it is become = P(!P, B, !D | S) * P(S) +P(!P, B, !D | !S) * P(!S)?

thanks,
mengyun",jc6w44hrp9v2ki,[],,,,776,"oh i know, the 0.25 mean P ( P | !S)
then that make sense, denominator part is just a total probability.",machine learning video 20 math,[other]
5ad7d4850d63974e20c39200,"PSA: Check your uploaded pdf in Gradescope to make sure your answers are still in the submitted file.

Hi Everyone, 

Just wanted to share my experience. I added a bunch of pages at the end of my exam and merged them with the original exam (fields filled in using Acrobat DC) using PyPDF2. I uploaded this merged file to Gradescope, only to discover that the exam answers had disappeared upon upload. However, form data was still saved and visible in Acrobat DC. Eventually figured out a workaround: open the merged file back up in Chrome and use Chrome's print-to-pdf capability to make a new PDF file for Gradescope.

Sharing this here in case someone else is planning to merge additional pages onto a completed exam - check Gradescope when you're done to make sure your answers are still there.

tl;dr: Had a scare because I thought Gradescope was not accepting a completed exam. Found workaround using Chrome.
",jc6w44hrp9v2ki,"[{u'text': u'If anyone is planning on using Apple Preview to input their answers, that's what I did, and it worked fine. I didn't try adding extra pages though', u'responses': [u'I did apple preview and added extra pages of solutions. Some answers didn't show up in gradescope on my first submission, so I did the same (print to pdf) and checked to make sure everything is up. ']}]",,,,829,,"Gradescope, PDF forms and PyPDF","[midterm, gradescope]"
5ad7d4860d63974e20c39201,Which grades (and statistics) will be available prior to the withdrawal deadline on 14 March?,jc6w44hrp9v2ki,"[{u'text': u'Will these include the medians?', u'responses': [u'How does the median on midterms work? People who get above median get full 20%?', u'No, median just sets the cutoff for the letter grades. ', u'We'll post the stats as well, but please note that these are merely to give you an idea of where you stand. The final letter grades are calculated based on the stats for the Final Score (40% for exams, 60% for top 5 assignments) with the roster after drop day. Please check the Grade Categories section of the Syllabus.', u'Hi Ravi,

Could we just clarify, that a 90 is not necessarily a guaranteed A? Say for instance the median of students who stay in the course after March 15 is 100, then everything less than 100 would be a B?', u'I believe the policy is that if the median is above 90, everyone above 90 gets an A. I wouldn't take this as 100% confirmed just yet, but I'll check with Prof. Starner and get back to you on this.', u'Let's hope so :-)', u'I'm with Mark on this one.', u'Confirmed, if the median is above a 90 we'll be awarding an A to everyone above 90.
Please keep in mind that the buckets for B and C may or may not change.', u'Nice, good news, thanks :-)', u'For assignments and exams in which median is < 90,

Median + 1 point will be ""A"" or Median + SD will be ""A""', u'1) It's the aggregate semester grade, not the grades for individual components;
2) Median itself is an A, so say the Median is 86, then everyone who gets $$\ge 86$$ gets an A']}]","We will be releasing the grades for Assignments 1 to 3, and the midterm grades (before regrades), before Drop Day.We'll try to release Assignment 2 Extra Credit by then. Unfortunately we will not be able to serve all requests for regrades on the Midterm prior to Drop Day.",,,843,,Withdrawal Date,[grades]
5ad7d48c0d63974e20c39202,"Hello everyone,

Assignment 2 Grades have been released to T-Square. Apologies for the delay. Your score should be the same as your last submission before the deadline on Bonnie.

If you have a problem with your grades, please leave your name and T-Square ID in the followups and I'll help fix it. We are still in the process of doing this for A1, so please bear with us; however, we do not foresee any issues arising with A2 in this regard.

The results of the Race will still take some time to release.

Mean84.83Median96Standard Deviation21.25

",jc6w44hrp9v2ki,"[{u'text': u'It's not there. Does it take a while for students to be able to see?', u'responses': [u'You can see the grades under Assignments (returned). Seems the Grade view will be updated in some time.', u'It should be visible now. My mistake. Thanks for pointing it out!']}, {u'text': u'Okay if the median is 96 and I got a 90 that means I am in B range big time. After all that work, that is disappointing.', u'responses': [u'When I saw the median I felt deflated.  I thought a 94 on the assignment was a sure A, so I gave up once I got there.  If these stats are indicative of what we'll see for the rest of the semester it seems almost impossible to get an A considering a lot of the lower scores will drop off as we inch toward the drop date and the median will be pushed upwards.  Ah well, I'll buy some stronger coffee, limit my sleep, and soldier on to the end of the semester.  Sadly, my dream of a 4.0 may die in this course :)', u'Yep, I'm at 4.0 now but this class might kill it. Ironic it is the class I have spent the most time working in.  I am also amazed at how many people did so well. I think it was the allowing of bi directional on tri-directional which I stupidly chose not to do. Wish I had now.']}]",,,,904,,Assignment 2 Grades Released,"[a2, announcements, grades]"
5ad7d48d0d63974e20c39203,"
Kaggle competition for Assignment 4!

You can find the Kaggle competition for bonus points on Assignment 4 here. https://www.kaggle.com/t/f8ee3286939c4f86a19a4fafe45739d7
You can make submissions until March 25th, 2018 at 11:59 PM UTC-12 (AOE). You are allowed only 3 submissions per day. Note that the Assignment 4 is still due on March 18th, 2018 at 11:59 PM UTC-12 (AOE).
 
Files:
The following files are available on the Kaggle Competition under the data tab:
kaggle_train_data.csv - Training file with first column as class, and the rest as features
kaggle_test_data.csv - Test file with no class labels
generate_kaggle_submission.py - Script to help you generate your submission file

Instruction:
To get a classification result using your ChallengeClassifier, move all three files into your Assignment 4 folder and run generate_kaggle_submission.py, then submit kaggle_result.csv to the competition. After you make a submission you will see your accuracy for approximately 50% of the test data. The other half will be hidden until the end of the competition and will be used as the final result of the competition. In other words, what you see on the leaderboard is not guaranteed to be your final score.
Please use your Georgia Tech ID or Georgia Tech Account name or real name as your Kaggle display name so we know who you are.
 
After you are happy with your result, please submit all the files you wrote to T-square. You don't need to submit generate_kaggle_submission.py if you used that to generate your result.
Package restriction is the same as the main assignment, and you are only allowed to use Decision Trees or Random Forests or Ensemble Learners on them for your classification.

Extra credit points:
Points will be awarded as the following:
1. First place: 15 bonus points
2. Second place: 12 bonus points
3. Third place: 10 bonus points
4. Everyone else who achieves an accuracy of more than 61%: 7 bonus points
 
So you don't have to beat the class this time. Everyone has a chance of getting the bonus!
 
Other info:
generate_kaggle_submission.py contains contains these two functions:
 
accuracy_test(num_folds): This function uses your ChallengeClassifier, generate_k_folds, accuracy functions to perform a cross validation of your model on the training data. This gives you an idea of how accurate your model is. You can turn this off if you just want to generate a submission file.
 
generate_kaggle_submission(): uses your ChallengeClassifier to train a model on kaggle_train_data.csv, then generate a prediction file called kaggle_result.csv, using the unlabeled test data.
 
Feel free to use your own script for generating the submission file.

Good Luck with your exams! 

",jc6w44hrp9v2ki,"[{u'text': u'Just out of curiosity: How will you figure out whether we only used ""Decision Trees or Random Forests or Ensemble Learners""?', u'responses': [u'You would be submitting your decision_tree_submision.py and any other files if coded to T-Square. Thus see to it that you have set the seed in numpy random so that we can generate the same results. ', u'To followup on this, are we supposed to set the random seed in our classifier? It makes sense for verification, but didn't read such a requirement anywhere else. Just want to confirm. ', u'You can make the random state an argument of your classifier, or call ""np.random.seed"" right before you run the fit function.', u'Great, for my best submission so far I didn't know about the seed.  I bet I won't beat it with a seed set before Friday.  I guess I can hope my best isn't my best when the other 50% is added.']}, {u'text': u'Can we get some hints/pointers on this? I'm scoring ~ 0.86 on the test, but on kaggle can't pass 0.58', u'responses': [u'I would advise you to try to attempt to tune your Random Forest first. If that does not work out, you should try Ensemble Methods like Bagging and Boosting. Also, your score displayed on the current Public Leaderboard is not your final score as it shows your score with only 50% of the test dataset. So chances are that your score might improve or worsen on the full test dataset. ', u'.86 to .58 sounds like you’re overfitting. If you aren’t already you could try using Monte Carlo cross validation to  ensure you aren’t just getting a unique split or that you aren’t tuning your parameters to your test set. And general other strategies to prevent overfitting. ']}, {u'text': u'is 0.609 considered as 61%?', u'responses': [u'No. Also, your score displayed on the current Public Leaderboard is not your final score as it shows your score with only 50% of the test dataset. ', u'Thanks. When will the final score be released?', u'Is there a confidence bound between the displayed score & the hidden score, or a rule of thumb such as 'normally, $$\le 0.1\%$$ difference'?', u'Depends on quality of shuffling, which seems not so great in this case. K-fold on local should theoretically give a close estimate - look at the stds on your k-fold for a sense (hint: the variation is huge, because the dataset is on the small side). ', u'I know that, the question is whether there is a confidence bound as in kaggle splits the data for scoring in such a way that it guarantees some closer correlation', u'I don't think so- wouldn't such a bound mean kaggle can predict if a student's estimator is right or wrong on a given sample from features only? This is a harder problem than predicting class labels. ', u'I'm hoping Jainesh has some information to share', u'Kaggle splits the dataset into 2 sections. one that contains points whose accuracy will be shown and another whose won't be shown until the end of the competition.  It does this randomly unless suggested not to do so. In our case, I have used the random split option to split the dataset in the above manner. So you may deduce any conclusions from here if needed for the bonus. ']}, {u'text': u'Do we need to submit the code for the bonus to Bonnie? Can the code be different from our final Bonnie submission?', u'responses': [u'You need to submit the modified code for the Challenge Classifier along with the whole file on T-square. ', u'Will there be a separate submit on T-square since we are allowed to submit even after the 3/18 deadline?', u'I will put up a separate submission link on T-square for this that will remain open until the Kaggle Deadline. ', u'Hi, just for further clarification, we need to submit our code (including all 5 parts) for A4 on T-Square by tomorrow (18th March). Is that correct?


For the Kaggle competition, which has an open window till 25th March, we can use our A4 code and once we're satisfied with our results on Kaggle, we'll be submitting the same on a separate link on T-Square. In other words, the code submission for Bonnie and Kaggle could be different, if one is not able to finish the competition by A4 submission deadline?']}, {u'text': u'Kaggle says I need to be invited to participate and will not even let me download the files. 

""This is a limited-participation competition. Only invited users may participate.""

Do I need to be invited? 

Thanks,
Jim', u'responses': [u'Never mind, I figured it out.  If someone else is having the same problem the link above is the invite link. ']}, {u'text': u'Hi, 

Kaggle lets me select up to 5 submissions for final consideration. Can someone explain what the rules are on this? Is the average accuracy of the 5 submissions used in determining the final score? Should I submit my best guesses 5 times and select them all? ', u'responses': [u'The rules at https://www.kaggle.com/c/omscs6601ai-sp18-assign4/rules say 2, it would be sensible to treat those as the actual rules rather than Kaggle's default that allows selection of 5
Submission Limits
You may submit a maximum of 3 entries per day.
You may select up to 2 final submissions for judging.', u'You may ignore that instruction for now. We will take your best score in the final standings. And you have the submission limit of 3 entries per day. ', u'Best score on public leader board? Or best score on private set? ', u'Just to add more questions, the ones that may not depend on the answer to Jon's question :-) what instruction are we ignoring? The instruction to limit our selections to 2, the instruction to select the submissions we are promoting for scoring, or the instruction to select 5?', u'Best overall score with the full data set. Currently, the score is only corresponding to your class labels being tested for half of the test dataset. Positions of many people may change after the final standings are up. 
You may ignore the instruction about 5 selections as we will take your best attempt for the final standings. Rest all rules apply. ', u'Hi Jainesh, 

I guess what I'm asking is... we don't get to choose which submission we want to use, do we? Your system automatically picks a ""best"" submission. All I want to know is: how? Do you take the submission with the best public leaderboard score? I am asking because what if I have a submission I think is better than my best public leaderboard sub? How can I ensure the system uses that one?', u'Should we submit every version of our Kaggle code to T-Square and map them with file names or comments to the Kaggle submissions?', u'I've been storing my submissions and the code that generated them in a private repo on github.gatech.edu. Would it be possible to share my private repo with the TAs for verification purposes? Creating git commits is much easier than attempting to keep a manual log of how code files correspond to kaggle submissions.', u'I have a separate kaggle branch myself.', u'Hi Jonathan,We will use the best score that your code achieves over the complete test dataset. ', u'Hi Christopher, We would only require the code for your best score on the Kaggle competition to be submitted on T-square. ', u'Hi Andrew, I appreciate your efforts of maintaining a proper record of it but we would prefer T-square submissions. ', u'Thanks for the reply, Jainesh.  My current best score was from the first batch of three before I read this thread and the request to set a seed for random.  If by chance (so to speak) one of those three submission turns out to be the best after the second half of data is run will they still be eligible?', u'Hi Jainesh, 

I had over 10 submissions. It turns out that my best submission on private is not the code I put on T-square (it's a different set of params). Do I resubmit? The deadline is past, but there was no way to know which code version would get the best score prior to the deadline.']}, {u'text': u'When I try to submit a file (today, yesterday it was working ok) I get the following screen.  I've tried different computers and browsers.  The first couple of times it said this for hours:


The most recent submission said this after a few minutes.  Any idea why?
', u'responses': [u'Hi John,Can you try to submit it with another account on Kaggle?We can take your case separately if there are more issues. (You may put up a private post.)', u'seems like submission is disabled, i cannot even see the option to submit now...service may be down.', u'After my post above I noticed the link/button gone.  I'm in the middle of trying to submit using the Kaggle API.


EDIT: Working now.', u'Kaggle is testing it's horrible API, and forcing users to use the API and hiding the website submission button. But their API has so much issue (you may have luck after submitting many times), that users are complaining on their discussion forum. I randomly saw kaggle brought back the submission button, but would have the same issue that John got.

So I have to keep trying their API (Successfully submitted twice in the past 2 hours)
', u'tried to submit via API but always hit errors:
kaggle.rest.ApiException: (404)Reason: Not Found', u'If you come across a fix please do let us know. This is new to us too.', u'it's resolved by itself, i think it's because kaggle was deploying their newer API.']}, {u'text': u'What about code that takes hours to run?', u'responses': []}, {u'text': u'We had import restrictions for Assignment 4, do they also apply to this kaggle competition?', u'responses': [u'Yes.']}, {u'text': u'Can we discuss strategies when it's past submit period? I've sadly spent a lot of time on this and have been unsuccessful at trying to crack 61% accuracy. At this point of spending so much time on the dataset, I just want to know what people did that worked.', u'responses': [u'I can't really say.  I designed my decision tree with influence from my random forest learner.  Maybe something in my design is different in a way that I don't understand.  I didn't use anything fancy, e.g. boosting.

Edit: just realized you were talking about discussion after the deadline.', u'One of my submissions without a seed (early on before I knew about that) was .63 and another was .61.  Since then I have been able to obtain one with a .61 seed.  Still working on it.  One thing I am doing now is looping on my Challenge tree, diffing the results with my lucky .63 submission.  If I ever get 0 (best diff is 12 so far) I can in theory guarantee a repeat of that .63.  Within 5 or 6 I can guarantee over .61 and maybe surpass .63.So that's kinda like boosting, but I started with a .63 result without that.', u'We would encourage you to do so after the deadline. Because this is a dataset that has been created for a Ph.D. study for one of our colleagues and we would like if more people can get better insight into it. We will also reveal the actual data feature fields after the deadline.']}, {u'text': u'Ugh just realized this is due tomorrow-week!  Now I might have to get more sophisticated when I don't really have the time. Ha

Edit: obviously misread something somewhere, and the midnight March 25 AOE on Kaggle misled me to think the event is over, but now I know I can make 3 more submissions before midnight tonight.', u'responses': []}, {u'text': u'So I didn't submit any of my code for the kaggle challenge to buzz port because  1) none of my submission scored over 60% and 2) I tried so many things (tuning, implementing AdaBoost, etc.) over about 20 submissions that I wouldn't know which one to submit as my ""best"".

As it turns out, on the private leader board my ""best"" submission did get over the 61% threshold.  Am I simply out-of-luck since I didn't turn in my code?

EDIT: seems like a lot of us had the same plan: ""I'm going to keep submitting until I get over 61% at which point I'll submit THAT code and THOSE parameters"".  We never reached 61% on the public leader board so we didn't submit any code.  Apparently, one of our submissions got us over 61% on the private leader board.  How could we know which one it was (prior to the deadline) to know what version of code to submit?  I was afraid of submitting code/parameters that didn't match what turned out to be my ""best"" submission.  I'm hoping an instructor can weigh in on this topic.', u'responses': [u'I am in the same boat, I simply forgot to submit on tsquare ... ', u'I completely missed that we needed to submit the modified code to T-Square also--and did get over 61% on the private board. :(', u'If you guys were to submit on T-Square would you be able to narrow down the code for the submission that got you the best score?  If they opened up the assignment so we could submit I'd only be guessing that it was one of my AdaBoost configurations that got me the best score, I doubt I'd be able to reproduce the results :(', u'I am in the same boat too... ', u'I'm also in this boat. Forgot to submit to T-Square...', u'Same boat as well - i have the exact code that i used, but forgot to submit...', u'Same here. I kind of just gave up and chose to not submit after constantly failing to reach 0.61 and getting worse and worse results..', u'I also forgot to submit to t-square :(
Is there any way to receive bonus points for us?', u'I thought I was the only one. I didn't turn in my code as well :(', u'You may email your code to jaineshdoshi@gatech.edu if you forgot to upload it.', u'Hey Jainesh, I forgot to submit to t-square as well. Will do so.

Question - how do we decide which one to send as I am not sure which of the 5 that I picked would have helped with a higher score on private dataset.

Or, do we submit all 5 of them?

Plz clarify.', u'never mind, I see the private score for each submission.

Well its unfortunate that one of my lower score on public dataset (not picked by me in top5), is amongst the top 5 for private LOL :-)

It seems like a hit or miss, not sure how others handled/strategized this variability.



']}, {u'text': u'Is the accuracy obtained in the private leaderboard the value that will be used for determining the extra credit?', u'responses': []}]",,,,910,,Assignment 4 Bonus Kaggle Competition,[a4]
5ad7d48f0d63974e20c39204,"
Hello everyone,

The mid-course survey is now available in the Tests and Quizzes tab on T-Square! Please fill it out when you get the time. It needs to be completed by 18th March, midnight AoE. It is not mandatory, but we would love to hear from you.

This week you should finish Lesson 7, Machine Learning, and read Chapter 18.6-11 & 20.3 in Russell & Norvig.  

Midterm Exam
Due: March 11 at 11:59PM UTC-12 (Anywhere on Earth time)
The Midterm Exam is due in a little under 11 hours. We hope you’re doing well! Please remember that submitting to Gradescope is mandatory; T-Square submissions are only for backup.
As of 1 PM AoE, we have answered nearly all questions on the midterm to the best of our ability - please remember that it is nighttime for all TAs now, and we cannot guarantee that we will be able to respond to any further queries before the deadline.
We will work on grading your exams as soon as possible - our plan is to get the preliminary grades out before drop day. We will release the grades to Gradescope first, and to T-Square later (after regrades). Please keep an eye on your email inbox for any notifications from Piazza and/or T-Square.

Assignment 4: Decision Trees
Due: March 18 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 4 is out! Please check @612 for details.

Office Hours:
We will be resuming Office Hours this week – here is the OH calendar. 
As always, here are the syllabus and the schedule.

",jc6w44hrp9v2ki,[],,,,932,,Week 10 Announcement,"[a4, announcements]"
5ad7d4900d63974e20c39205,"This is the solution for Question 3A of the midterm. Click @940 for the other questions.

1. If the initial population represents generation 1, which generation reaches the solution? (a generation changes every time you do crossover) (1.5 points)

3rd Generation

Rubric: Either correct or wrong. No partial credit.


2. Draw/write the 4 shapes that were represented in your final generation. (4 points)

You could have a slightly different graph depending on the way you handle ties in the selection phase. You should, however, end up with the 4 shapes you see in the 3rd generation in the illustration above (in any order). 

The goal of this question was to test your understanding of Genetic Algorithms, and help you understand some of their key characteristics along the way. We also wanted to demonstrate how you can model a problem and solve it with GAs. 

Rubric: Each correct shape counts as 1.


3. Check all statements that are true: (2 points)

(True) In the example above, a perfect solution (fitness score of 7) is not guaranteed for every initial population.

(False) For a very large number of points in the given problem, traditional search algorithms would be preferred over Genetic Algorithms (with mutations).

(True) Mutations help Genetic Algorithm avoid getting stuck in local optima.

(True) Hill Climbing is a deterministic algorithm.


a) True. Without mutations there is no guarantee that Genetic Algorithms will ever explore the whole feature space. If your initial population for example is consisted of four identical individuals, you will never reach the perfect solution, no matter how long you keep going.

b) False. As the number of points increases, so does the branching factor, which in turn creates a ton of problems for traditional search algorithms like BFS, DFS etc. Genetic Algorithms and other iterative improvement methods are much more efficient -> https://iccl.inf.tu-dresden.de/w/images/b/b7/GA_for_TSP.pdf.
c) True. Genetic Algorithms require mutations to introduce some stochasticity and enable them to reach parts of the feature space previously unattainable. (e.g. initial population of identical individuals)
d) True. Every time you run Hill Climbing from the same location it will return the same result (local peak). You can use Random Restart, Simulated Annealing, Stochastic Beam Search and other such algorithms to change that.

Rubric: Each correct answer counts as 0.5.


4. Implement 10 steps of the Hill Climbing algorithm and fill the table below: (3 points)



The Hill Climbing algorithm, as described in the book, would terminate at step 8, and would return x = 175 and f(x) = 0.986405 (since both of its neighbors have a lower fitness score). The table above shows the correct solution.

Rubric: If you filled the whole table, oscillating after step 8 between x = 175 and x = 150, you will still get full credit.You will not get full credit however if you kept going to 200 and further. 


5. If the fitness score of the optimal state is f max = 1, how many iterations will be required before you arrive within 0.01 (fitness) of that state? (1.5 points)

You will never arrive within 0.01 of that state.



This was a trick question, aimed to test your understanding of the step-size issue in hill climbing. Too big a step, and you can miss the solution by a large margin, get stuck in oscillation or just end up with a bad approximation. Too small a step size and you might go on forever, getting stuck in plateaus and local minima. Without some stochasticity, you are not guaranteed a good enough approximation.

Rubric: We realize that the wording of the question was unfortunate and confused a number of you. Thus, we will give full credit to people who gave a proper explanation or answered anything along the lines of “Will never reach such a state”, “Infinite” etc., and also to people who answered step 8 (0.986405) because they rounded to 2 decimals. If you answered ‘never’ but with a wrong explanation and wrong calculations we will not give full credit.

",jc6w44hrp9v2ki,"[{u'text': u'Regarding Hill climbing being deterministic the book says on page 122:
""Hill-climbing algorithms typically choose randomly among the set of best successors if there is more than one""', u'responses': [u'Hi Giacomo,
to my understanding this is just a suggestion about ties, so I don't believe it can classify the whole algorithm as deterministic on its own. The optimization algorithms we've seen in this course have many different implementations in literature so we can only refer to their general form.', u'Hi Theodore, thank you for the reply. The general form from the book is not deterministic: it says 




""neighbor ← a highest-valued successor of current"" and that ties are usually broken randomly. 
Plus the way the question is formulated it only takes one non deterministic instance to make the statement false.



', u'Well.. technically there is no deterministic way of breaking ties ^^. Only if you consider something like order of expansion but then it's still random for all intents and purposes. I feel like this is a stretch. ', u'I was definitely seeing the same thing as Giacomo and viewed the tie-breaking as a nuance that the solution would be keen on capturing, rather than overlooking. If you start in a trough and the next step in either direction has the same score - and you choose randomly between these two options - you necessarily cannot guarantee the same solution every time you start from this location. The book doesn't mince words here, and the algorithm's general form backs this up... It's quite explicit that in edge cases with ties, we will break the contract of a deterministic algorithm where the same inputs always yield the same outputs.

Because of how nuanced the real answer is, I honestly thought this was a trick question to see how closely people paid attention to all conditions for an algorithm - including edge cases.', u'If I can add something to Andrew's reply, I would say that if you use a heuristic or use data with more than two dimensions, it's not hard to imagine a situation in which multiple options have the same value so it's not an obscure edge case.', u'<removed>', u'+1. I totally support Giacomo and Andrew on this. Here is the definition of ""deterministic"" from Wikipedia:

In mathematics, computer science and physics, a deterministic system is a system in which no randomness is involved in the development of future states of the system. A deterministic model will thus always produce the same output from a given starting condition or initial state.

As mentioned in the Hill-Climbing algorithms, there are places where randomness is needed. Thus, the output can't be guaranteed the same every time. 


', u'I concur with Giacomo, Jianhua and Andrew's understanding - I went with the described principle of randomness in picking the successors, leading to different results.', u'I don't feel like tie-breaking is proof for non-deterministic behavior for any algorithm since it's not a core characteristic. In a Minimax implementation, for example, you could choose randomly between two equally good successor states, or by order of expansion, or in any other way imaginable. Most books would not even specify that, and some might even suggest different approaches. In Wikipedia's Hill Climbing, for example, there is not reference to tie breaking.

There is also a version of Hill-Climbing called Stochastic Hill Climbing, which introduces real randomness to the algorithm. It wouldn't be called that if Hill Climbing was already stochastic!
Also the word 'typically' is key here -> ""Hill-climbing algorithms typically choose randomly among [...]"", as it suggests that this is more of a design decision and not a core part of the algorithm. 

This is my view on the topic, but I will also refer to Prof. Starner for this.', u'Hey guys, we've taken your concerns into consideration and decided to give full points to everyone for this one. ', u'thx Theo for the followup..', u'That does seem reasonable, even from the perspective of someone who got it right according to the original interpretation, I'm just chiming in to say I feel no devaluation of my grade when people are given credit for the interpretation described. Kudos for the reasonable approach, Theo :-)']}, {u'text': u'I struggle with the claim that x=200 should not be in the table. I took the instructions to mean that the table should show the input (x) and the calculation of the fit function (f(x)), not whether the state is returned or not. 

The hill climbing algorithm would still run on the 9th iteration with x =200, but would not return the state, so there is no 10th iteration. ', u'responses': [u'Hi Julie,
In every iteration the algorithm checks all of its neighbors {150, 200} and returns a state. It will never check the neighbors of x=200, so it will not run on it.
The words 'step'/'iteration' were used to refer to the loop of the algorithm, not every separate instruction.  ', u'I agree that this is confusing, because it would still have to evaluate the value at 200, which is why I also included it in mine, and then stopped because it was lower then the value for 175.

I'm hoping that including it won't be more then like 0.5 off or something, seems like a very minor misunderstanding...', u'+1
Makes sense to me that 200 is included in the table since there is no other way to see a decreasing f(x).  You need the datapoint at 200.  In the table above, it's even included (but grayed out) so you can see the algorithm working...', u'I agree with Carey MacDonald. I included 200 in my iteration because the algorithm still evaluates first and then decides it stops when it finds that f(200) decreases. If you follow the code in the textbook, it will make you calculate f(200), that's why I included it in my table. 
I exhort the professor and TAs to consider this when grading the question.', u'If x=200 was included then x=-25 should have also been included since it was evaluated (and every other state twice).
Regardless, we will take this into consideration as to the amount of partial credit.', u'I too went from 175 to 200 then back to 175 as 200 got a lower score. I think we all understood in principal just interpreted how to show it. We all saw it oscillates around the 175 mark.', u'Agreed, I too assumed we had to show that we evaluated x = 200 to note the drop back down, hence the first local maximum. I understand that the whole table should not be filled in, but I think if someone evaluated x = 200 (and not x = 225) that shows an understanding of hill climbing and deserves full credit. Thank you for considering this in the grading.', u'I also included x=-25 and x=200 as evaluated points -- thanks for the response that it will be considered for partial credit, Theodore.', u'Hi,
To quote the question : ""Implement 10 steps of the Hill Climbing algorithm and fill the table below"" .... I feel this is pretty cut and dry in the sense it is asking us to fill the table ( all 10 rows ) starting with X = 0. 
yes, we all could see it oscillate when plotted as a graph... but I feel , a full table still deserves a full credit...', u'I don't think it make sense to give just partial credit to [..., 175, 200, 175] and [..., 175, 200].

The question didn't mention anything about how should we indicate the perfect value. As long as the answer demonstrates a valid oscillating consideration, everyone should get full credit.

We can design the algorithm to pick an arbitrary direction at the beginning, then it is possible to not include -25 since you went for the ascending direction right away--then you just keep climbing. Unless the definition of a hill climbing algorithm requires you to always check both directions. In the case of fixed steps, one of the neighbors is always already checked. I couldn't see why we need to check every state twice. Can someone clarify?', u'Incidentally, not that it matters very much, I think 0.9795 as the value for $$f(150)$$ is not in accordance with the rubric rounding rules0.1234999 becomes 0.123500, 0.12546 remains as 0.12456  – unless there's an fp rounding error, I make the true value>>> 1 - abs(60 - (180 + 2 * np.degrees(np.arctan(-1.5)))) / 360
0.97949962485566788
so it should strictly be 0.979500 rather than 0.9795', u'I agree that implementing 10 steps of the Hill Climbing algorithm is confusing. If the calculations match well with answer from the following question about the optimal state, it should deserve full credit. ', u'I was doing calculation on scratch paper and saw the drop off at x=200. (I also did the calculations for x=-25 to sanity check on my scratch paper). I specifically wrote row 9 and then put a note next to row 8: ""<-- return this row"" to show that I understood the concept of hill climbing. In this case, I feel like points are being deducted even though I tried to show my work and demonstrate my understanding of the concept.', u'Students who had an arrow on step 8 or wrote 'return this row' or in any way demonstrated that they knew what they were doing were given full credit. 

There is a fairness issue here. We cannot give full credit to people who just kept going to step 10 after the local maximum. This would make the question a simple calculation exercise and would be unfair to people who actually demonstrated understanding of the algorithm. 

In my opinion, the only valid way to keep going after x=175 (if you want to fill the whole table) is to oscillate between 175 and 150, and that's why such an approach was given full credit. 

A case could be made for people who included only x=200. Not going on after 200 shows that you understood that hill climbing had to stop after the peak. I believe there should be a distinction between those people and those who kept increasing x till the end.

Do keep the suggestions coming!', u'@Theo ... if the table is populated for all 10 rows and then if someone answers with '8' in the following question , doesn't that demonstrate a clear understanding of the algorithm and the way it oscillates at the 8th data point , in this example/question', u'So, if I stopped after showing x=200, because the algorithm does go to that step, can I ask for a regrade.
I did not show any indication that there will be a return there, however I did want to show that the step will be done to check if one of the neighbor nodes is worth considering and on finding none, will return the current node without assigning the neighbor node under consideration to current node.

Please let me know, if I can submit for a regrade. Don't want to risk losing any more points.', u'I included 200 because the calculation for that step is required to know if you need to continue or not... I'm on the same boat as everyone else here not understanding why it was marked wrong.  The instructions themselves need to be more explicit if you expect to dock for including that value.', u'I for one also included 200 but didn't go any further. Please kindly consider giving full credit for our case.', u'I included x = 200 to demonstrate that the algorithm will stop at x = 175 (no indication shows returning). I have a correct answer ""never"" for the optimal state question however I did not provide explanation because it was not asked. I got partial credit for this, should I submit for a regrade?', u'People who stopped at 200 and left rest blank got 2/3, whereas those who kept going till the end got 1.5/3. Please let me know with regrade requests if you feel that you belong in another category. If we decide to change the rubrik we will do it for all students without a need for regrade requests. 
Thank you and let me know if I got something wrong!']}, {u'text': u'Theo,

One clarification for parent selection, from the 3A snippet below - was this meant to be done for all individuals with each generation or was it for only the FIRST Parent selection with each generation. In your diagram above, I don't see you carrying the squared values over to the 2nd generation for all parent from 1st generation. I thought it was about giving equal opportunities to others. Could you clarify?

""



Every time you pick an individual as a parent, square its probability so that you give a chance to other individuals as well. Then select the new most promising individual as the second parent, square its probability, and keep going until all 4 parents are selected. 



""', u'responses': [u'Hi Rajesh,
the selection is performed in every new generation. You calculate the new fitness scores, the new proportional probabilities of these scores and then perform the selection. 
In every new generation you erase the old parents along with their fitness scores and probabilities.']}, {u'text': u'For part 2, will the order of the shapes matter? So 54123 is the same as 41235 for the purposes of answers? ', u'responses': [u'Yes Chris, order of chromosomes will matter.']}, {u'text': u'Can someone explain why a single solution is presented for the genetic algorithm? Why does it have to be the third generation? It's a non-deterministic algorithm, so I'm struggling to understand why there's only a single correct answer.', u'responses': [u'The instructions used a deterministic algorithm.  You weren't supposed to randomly generate which parent to pick back on probability, you were supposed to always take the most likely and then square its likeliness to cause the other ones to be more likely to be picked.  Obviously this isn't how it would work in practice but this was the implementation they asked for, which I assumed was in order to make it easier to grade.', u'I think because in this case they removed all stochastic elements (mutations, random selection, etc...).', u'Gah, I totally misunderstood that - I actually implemented random draws from a multinomial with squaring the probabilities and reparameterizing it after each draw. What a pain.

""After that, you will be making a selection based on those fitness scores. Measure the proportional probabilities of the population and pick the most promising individual as your first parent (if it is a tie, pick any one).""

I see now what they meant, now that you point it out. I guess I had a ""strong prior"" on implementing it with the standard random draw since its so simple, and I just read over it...', u'Just a follow up to the instructors - in the future I would replace ""pick the most promising individual"" with something more explicit. Potentially something like:

""select the individual with the highest proportional probability""

As I re-read this to try to see why I misinterpreted it, I think it was the ambiguity of ""pick"" and ""promising"" to me. ""Pick"" made me think of ""pick/sample from a distribution"", and since ""promising"" doesn't really have a precise definition I think I just glossed over it. I thought of ""the most promising individual"" as, by definition, ""the one that got picked by the random draw"", not ""the one with the highest proportional probability"".

I think this is especially the case because this particular problem statement (about the bees and all that) contains a lot of metaphorical language anyway, while the others by and large don't, so I leaned towards ""that's just imprecise language for the standard thing"" rather than ""they're asking for a different and specific other thing"".', u'Yeah I ended up picking randomly and thus messing myself up (even though I got the right outcome). Oh well', u'Well I also got the generation number wrong as well, since there is actually a set of parents that will give you the right answer on the 2nd generation (assuming they're chosen to breed).

In any case, makes me confident I should go ahead and submit my work in the future, since I think anyone seeing my work would understand that this was a pretty simple misunderstanding.']}, {u'text': u'Delete', u'responses': []}, {u'text': u'On the generation depending whether your counting the generations after cross occurs would lead to a count of 2. Same result for final generation just counted the generations after the crossection. Could this be taken into consideration
', u'responses': []}]",,,,939,,Question 3A – Optimization Algorithms,[midterm]
5ad7d4900d63974e20c39206,"Hey everyone,

Nearly 300 students submitted the midterm, and we're working hard to finish grading. In the meantime, we will post the answers to all questions along with the approach(es) you must use to get there. Please go through the solutions to see which questions you got correct, and where you might've gone wrong.
 
We will release the grades on Gradescope by drop day. Please go through each of your questions, and the solutions we post here. If you spot a discrepancy, you can submit a regrade request through Gradescope. Please refer to the solutions here before you make a regrade request. You will have until 8pm EST on Thursday, 15th March, to do so. At 8pm EST we will be closing for regrades. We will then resolve all requests and try to release the grades and stats by 16th March (barring any unforeseen circumstances). The grades will only be posted to T-Square after regrades have been completed.
 
The solutions posts will be linked here as and when they are ready. They should go up gradually over the course of the next two days. If you do not see a thread for a question, please check back in some time as the TAs may not have uploaded it yet. 
 
Question 1: Game Playing
@965 (1A)@966 (1B - 1)@967 (1B - 2,3)
 
Question 2: Search
@951
 
Question 3: Optimization Algorithms
3A: @9393B: @953
 
Question 4: CSP
4A: @9574B: @9584C: @959
 
Question 5: Probability
5A: @9685B: @970

Question 6: Bayes Nets and D-Separation
@948
 
Question 7: Machine Learning
7A: @9847B: @961

",jc6w44hrp9v2ki,"[{u'text': u'Will you provide the stats from gradescope by drop day as well?  Thank you.', u'responses': [u'We can do that.']}, {u'text': u'300? Isn't there 600 people in this class?', u'responses': [u'We started out with a little over 400 students (@52) and have had some students drop the course.', u'But they were supposed to stay enrolled to help the curve :( ', u'It... is... on :)', u'Yeah, they need to not drop the class as I need all the help I can get.', u'Brett, at least you have my help...', u'It depends on whether you are above or below the curve. Assuming by your response you are below, glad you are with us. :)', u'I hear the class only gets easier from here and that everyone ends up doing better than they expected. Don't be worried']}, {u'text': u'Probably outside the scope of this specific class, but are there stats available with respect to the completion rate of OMSCS?', u'responses': [u'I met Becky Wilson one time at my kids basketball game. I asked her this exact question. She said that they were trying to figure this out. The problem was that in traditional school when you dropped out it was fairly obvious but in this program they just stop registering for classes. So it isn't obvious that they quit until after they disappear. Plus the first graduating class is only a year and a half passed and that there are alot of people going very slow through the program. So, to answer your question I think is premature with the length of how long people have been completing. Anyway, this conversation happened a year ago but you could do a google search and see if more information was available now.', u'I was a TA for 3 semesters so I submitted timesheets to her every week.  What is she like?', u'Thank you Brett.']}, {u'text': u'ML link is wrong. Pl correct
Question 7: Machine Learning
7A: @970', u'responses': [u'@984', u'Thanks for pointing it out!']}]",,,,940,,Midterm Solutions Megathread,[midterm]
5ad7d4910d63974e20c39207,"Hi everyone,


Assignment 3 Grades have been released to T-Square. Your score should be the same as your last submission before the deadline on Bonnie. As a reminder, the deadline for assignment 3 was February 25th, 11:59 PM UTC-12.

If there are any issues, please leave your full name and T-square ID as a followup.
 
Mean: 92.09
Median: 100.0
Std. Dev.: 15.55
 

",jc6w44hrp9v2ki,"[{u'text': u'Name/ID: Andrew Hoeft (ahoeft3)
I could be mistaken, but I believe there's an error in my grade. My final submission and my reported grade differ by >30 points. It looks like I was given the grade from my second-to-last submission.', u'responses': [u'Hi Andrew, the grade you see on T-square is the one that corresponds to your last submission on Bonnie.']}, {u'text': u'i have the same concern as above
', u'responses': [u'Hi Daniel, it looks like some of your submissions on Bonnie were after the deadline. The grade you see on T-square should match the last submission within the deadline.', u'Mansoo, Thanks for your reply but my last valid submission produced the xml I sent you and this was a before the submission deadline. ']}, {u'text': u'If the median is 100 nobody gets an A here, right ?', u'responses': [u'+1', u'>= 100 gets an A', u'there's no letter grade for each assignment', u'What's the point of helping others in this class if it's in our advantage to make sure everyone's grade is minimized?']}, {u'text': u'Hi,
My grade is not posted. Should I wait for some hours? Or could anyone help me to check? Thanks', u'responses': [u'Hi Anan, for some odd reason, T-square didn't release your grade with everyone else's.

It should be there now, please let me know if you still can't see it.', u'Got it!']}, {u'text': u'My last score on Bonnie is not the one here. Could you please check the timestamp of the last submission. It was done before the deadline. and there is 10+ point difference. Thank you.', u'responses': [u'Hi Navnit, it looks like some of your submissions on Bonnie were after the deadline. The grade you see on T-square should match the last submission within the deadline.']}, {u'text': u'Well done for releasing the grades so quickly, Mansoo', u'responses': []}]",,,,943,,Assignment 3 Grades Released,[a3]
5ad7d4910d63974e20c39208,"Bayes_Nets_Solutions.pdf

Regarding 6C P(E|F,D):
Both 0.697450 and 0.69745 will be accepted for full credit.",jc6w44hrp9v2ki,"[{u'text': u'Will partial credit be awarded for part A and B? ', u'responses': [u'Yes. Since A, B has multiple checkboxes, almost everyone got at least some credit for partially correct answers.']}, {u'text': u'I have all the nodes correct, but forgotten to mark the connection between D->F, which is clearly a typo because without it D will not be in the markov's blanket of F which is one of the most obvious clues. I did remove the connection between E->D and kept A->D to balance the markov blanket and the least child clues. Will I still get partial credit?', u'responses': [u'Sorry I can see now that partial credit is granted.']}, {u'text': u'Wait... do we only get partial credit for 6C.3 if we rounded the answer and put down 0.69745 instead of 0.697450?', u'responses': [u'From the instructions ""0.12546 remains as 0.12546""', u'Just making sure, because the instructions also say 0.1234999 becomes 0.123500, and Mansoo had his answer as 0.697450. ', u'Full credit is 0.697450
Partial credit is 0.69745', u'Why do values of 0.654625, 0.654624, 0.654626 that are OFF by .000001 get full credit, but 0.69745 not get full credit for dropping a padded zero... How is 0.69745 not equal to 0.697450?', u'To clarify, I *did* get the correct answers for the other parts (up to 6 decimal places). I just dropped the padded zero because to me 0.69745 == 0.697450. I'm not sure why that would result in partial credit, especially if you've added extra leniency to the other questions.', u'Because it specifically asked for 6 decimal places.', u'This is ridiculous. I recommend you check this with with the Professor in charge of this course. What is the pedagogical value of not accepting 0.69745, specially when the instructions say ""0.12546 remains as 0.12546""? This is a matter of principle, if I need to go to the Dean to argue about this, I will.', u'Super frustated after doing all that work and double-checking, just to lose points for dropping a padded zero. But I guess being technically right is the only right case here.

Still fuming, but thanks for the quick responses and clarification Mansoo. After a week long midterm and losing points over technicalities, I'm gonna go lie down and repeat to my self that 0.69745 != 0.697450 in Starneria.', u'I'm sorry but I agree that this is very silly. I also dropped the padded zero thinking it was pointless in this case. We clearly arrived at the correct answer. I don't see why we should be penalized.', u'It is just not acceptable, 0.697450 is the same as 0.96745 according to representation rules of decimal numbers.', u'I dropped the padded zero as I thought it fell into the category of ""not needed"". In this case the answer is 0% off the actual.

Do all answers with a probability of one require 1.000000?', u'This is especially ridiculous since for hill climbing question (@939) you dropped the extra 0s!', u'We've decided to accept 0.69745 for full credit for P(E|F,D) for 6C. We've updated the grades with this change already, but as always, if anyone needs a regrade, you can submit it on gradescope after the grades are released.', u'Thanks for the update Mansoo!', u'I did not include padded 0 on any problem since instructions did not say 0.12546 becomes 0.125460. instruction unclear', u'I wonder why the exam does not accept fractions as the answer. It would've avoided all the rounding chaos.', u'Glad they're giving partial credit, but just wanted to come to the defense of the TAs here. The instructions did say that 0.1234999 should be rounded to 0.123500. In this case, the solution was 0.6974498, so that's rounded to 0.697450 with the 0 at the end. It wasn't exactly 0.697450, but only got there after rounding. 

I agree that there's no pedagogical reason for deducting points on this though, only probably makes grading easier at large scale if answers are standardized. ']}, {u'text': u'For Part C - 2) P(E|F)  Answer is  ""0.552711"" but if we round intermediate probabilities to 6 digits it turns out to be ""0.552710""

As per the rules, I rounded all intermediate probabilities to 6 digits.

�(�|�) = 0.706541
�(! �|�)= 0.293459

With this I got final answer as P(E|F) as 0.552710. Will I get full credit or partial?', u'responses': [u'0.552710 is full credit.', u'Thanks', u'For part C2 I got 0.552712, should it also be awarded full credit?', u'Yes, please submit for a regrade if you didn't get full credit for that.']}, {u'text': u'Requested for regrade', u'responses': []}, {u'text': u'Does anyone have problem open Bayes_Nets_Solutions.pdf? When I click the link, it shows can't reach the site.   ', u'responses': []}]",,,,948,,Midterm Problem 6 Bayes Nets Solutions,[midterm]
5ad7d4910d63974e20c39209,"
 [*] >95
[*] >90
[*] >85
[*] >80
[*] >75
[*] >70
[*] >60
[*] >50
[*] <= 50",jc6w44hrp9v2ki,[],,,,950,,Average of your top 2 out of the first 3 assignments?,"[grades, polls]"
5ad7d4920d63974e20c3920a,"1) -> Size: 16
-> Nodes: A , W , G , E , O , J , S , P , N , C , X , Z , F , M , R , D

Most of you got this right. There is partial credit awarded depending on the rubric.

2) No. If g(n) is the Diagonal distance and h(n) is the Manhattan distance, then h(n) might be greater than g(n) in some cases where a shorter path is available. Therefore the heuristic overestimates and is not admissible.

Most of you got this wrong.

3) -> Size: 10
( The nodes are A , W , G , E , P , C , J , O , Z , D.  )
-> Yes

Most of you got this right. ",jc6w44hrp9v2ki,"[{u'text': u'Now that I'm rereading the question for number 2, I understand the correct answer.  I think most of us (at least this is what happened to me) assumed that the 8 way diagonal was the new heuristic, not the new actual cost.  You had to read it super carefully.  In the case where 8 way diagonal is the new heuristic and the actual cost is the same as the graph given previously, it would be admissible, oh well.

For number 1, how much is lost if we have a slight misorder?  For some reason (not sure without looking at my notes) I mixed up the order of C and X, but got everything else right.', u'responses': [u'Yes, I thought the same thing!', u'Yup I thought the same thing. I didn't even think twice about it. I just looked at the Manhattan distances vs. the costs on the original graph and said it is obviously admissible. ', u'Same thing for me on the path-so-far vs heuristic misunderstanding, alas.', u'Same here... guess a lot of us misread the question', u'same, misread the question.
', u'Yep misread question. Of course now that I am reading it right I would have gotten it right but sucks that I misread it. Minus 2 more after sucking up the bayes net question. Not looking good so far.', u'Doh. same.', u'Add me to the list.', u'Me too. Ooops. ', u'Partial credit has been awarded based on the rubric, please check.', u'Ya, I misread the question as well, sigh...']}, {u'text': u'Given that ""4-way Manhattan distance is calculated as the minimum number of squares moved to reach the destination, such that the bot can move vertically and horizontally on the grid, but not diagonally"" and that the graph is undirected, wouldn't nodes G and O heuristic values be 22 and 24 respectively by traveling upwards back through A? This caused my expansion to explore some extra nodes at the bottom of the graph...
', u'responses': []}, {u'text': u'The order of nodes for the answer for question one looks like it assumes a standard Manhattan distance.  However, in the clarification thread the instructors told us that the Manhattan distance needed to avoid obstacles.  ""When calculating Manhattan Distance and 8-way distance, you need to account for the presence of barriers as given in the diagram on Page 7.""  That would lead to a slightly different ordering.', u'responses': [u'That is the answer and order I had and I went around obstacles with standard manhattan distance...', u'Thanks, I double checked my math and it turns out to be an addition problem.']}, {u'text': u'If you watch the professor's explanation of the Grid challenge question on https://youtu.be/O0-f1j5_X0A?t=3m25s he clearly states that even after the goal node is discovered we still must check other frontier nodes to ensure they do not include a shorter value to the goal. As alluded to in the video this would put those nodes on the explored list (see13:00 and again at 14:10 for examples). I have additional nodes after goal node D for this reason. Can you explain why the solution doesn't have values after D? For instance for the second graph I include FRSX after D,and therefore have an explored set of size 14.', u'responses': [u'it didn't stop when D is discovered (added to the frontier). Search stops when 'D' is popped from the frontier. Because it is a priority queue, when D is popped, there's no way other nodes after it have smaller cost.
Here is the status of the explored node list and the frontier list, right before node 'D' is popped out.

explored list: ['A', 'W', 'E', 'G', 'P', 'C', 'J', 'O', 'Z']frontier: PQ:[[154, 'D'], [159, 'F'], [167, 'X'], [163, 'S'], [162, 'R']]', u'I totally missed the priority queue reference in the question... grrr. Thanks for the explanation.']}, {u'text': u'', u'responses': []}, {u'text': u'I was tricked by my innate sense of direction and neglected to populate R onto my frontier when Z was popped... How punished will I be for my inferior algorithm traversal?', u'responses': [u'I do think G comes after P for 3, unless I'm completely crazy 20+4*28=132; which is greater than 21+23+41+4*40=125 for P...', u'heuristic for G should be 20+4*22 i think', u'Hmm... I didn't really consider that backtracking through A was possible for calculating Manhattan distance...']}, {u'text': u'3. I got as answer: A , W , G , E , P , C , J , O , ( missed Z) , D. I received 1/3 points. This grade seems a little harsh given that I only missed 1 node due to human error. I'm not sure whether I can ask for a regrade or not, because the TAs might take away more points...', u'responses': []}]",,,,951,,Midterm #2 - Search,[midterm]
5ad7d4920d63974e20c3920b,"Solution for Midterm Q 3 B Simulated Annealing

Please refer to the book or videos for the Algorithm Steps.
The Energy value (in this case Total Power of the devices in the circuit) is calculated by the expression:$$ P = I_{sp}^2 R_{sp} + I_{L}^2 R_L $$


1.This was a basic Question on Simulated Annealing which required simple calculation of acceptance probabilities for the given Temperature Schedule in the Maxwell-Boltzmann Probability Distribution.For accepting the current row, the energy difference was to be calculated with respect to the previous row. $$ \Delta E = E_{\text{curr}} - E_{\text{prev}} $$Acceptance Probability For Simulated Annealing:$$P(\text{Accept}) = e^{-\Delta E / T} \text{ iff } \Delta E < 0 \text{ else } 1$$

 


Isp

Rsp

IL

RL

Power

Anneal Temperature

Probability of Acceptance of Set

25

50

10

100

41250

-

1

22.5

50

12.5

100

40937.5

10000

0.969233

20

75

10

125

42500

5000

1

25

75

10

125

59375

2500

1

25

100

5

125

65625

1500

1

22.5

100

7.5

150

59062.5

1200

0.004216

25

75

5

150

50625

1100

0.000466

20

100

10

150

55000

1000

1

25

100

5

150

66250

900

1

15

100

15

150

56250

825

0.000005




Rubric: 0.15 points for each Power/Energy Calculation
0.25 points for each non-One Probability Calculation
0.13 points for each One-Probability Calculation
-0.25 points for Incorrect rounding off decimal places in the answers
Total: 0.15*9 + 0.25*4 * 0.13*5 = 1.35 + 1 + 0.65 = 3

Intention: This question was to highlight the importance of the Temperature schedule of Simulated Annealing. The Probabilities of Accepting points with poor fitness scores is very low and it is highly likely that the above algorithm outputs a local optimum instead of the global optimum. 


2.This too was a basic Question on Simulated Annealing which required simple calculation of acceptance probabilities for the given Temperature Schedule in the Fermi-Dirac Probability Distribution.For accepting the current row, the energy difference was to be calculated with respect to the previous row. $$ \Delta E = E_{\text{curr}} - E_{\text{prev}} $$Acceptance Probability For Simulated Annealing:$$P(\text{Accept}) = \frac{1}{1 + e^{-\Delta E / T}} \text{ iff } \Delta E < 0 \text{ else } 1$$

 


Isp

Rsp

IL

RL

Power

Anneal Temperature

Probability of Acceptance

20

75

10

125

42500

-

1

25

50

10

100

41250

20000

0.484380

22.5

50

12.5

100

40937.5

12000

0.493490

20

100

10

150

55000

6000

1

25

100

5

150

66250

3000

1

22.5

100

7.5

150

59062.5

2000

0.026759

25

100

5

125

65625

1500

1

25

75

10

125

59375

1200

0.005441

15

100

15

150

56250

1000

0.042088


Rubric: 0.125 points for each Power/Energy Calculation
0.24 points for each non-One Probability Calculation
0.1 points for each One-Probability Calculation
-0.25 points for Incorrect rounding off decimal places in the answersTotal: 0.125*8 + 0.24*5 * 0.1*3 = 1 + 1.2 + 0.3 = 2.5

Intention: This question was to highlight the importance of the Stochasticity of Accepting Points with Poor scores in Simulated Annealing. The Probabilities of Accepting points with poor fitness scores is non-zero and it is more likely that the above algorithm outputs the global optimum. This also highlights that the Anneal Temperature Cooling rate for Simulated Annealing should not be too low or it would get stuck in local optima.

Comments:
Most students have done these tables correctly. A few have misunderstood the algorithm and assigned non-one probability to sets where they should be accepted with probability = 1 as they have a better score. A few students had written the probabilities > 1, any Probability can never be greater than 1. 

3.
Choose the option(s) that are true for Simulated Annealing.

The probability distribution function chosen in the second trial above is not good and will never lead to simulated annealing converging to the global optimum.

The probability distribution function need not be the Maxwell-Boltzmann distribution in order to converge to the global optimum in simulated annealing.


Answers:
Option (1) is incorrect It states that Simulated Annealing will never converge at the global optimum with the Fermi-Dirac Probability Distribution function which is incorrect as it allows enough stochasticity to allow the algorithm to accept points with poor fitness scores so as to search the space for global optima if missed earlier. 

Option (2) is correct
Option (2) precisely supplements the argument for option (1) that as long as the algorithm searches the space randomly even after attaining an optimum, it is likely to find the global optimum for the problem eventually. Thus the probability distribution doesn't matter here as long as it allows enough randomness and the algorithm has a temperature schedule that does not severely limit its reach.

Rubric:1 point for selecting option (2) only
0.5 if both options are selected
0 if only option (1) is selected

Comments:
Option (1) was a strong statement that could not True always and tried to point the students in the direction of Option (2) which was the only correct statement among the two. 

4.
“Simulated Annealing is guaranteed to converge to the optimum solution under a temperature schedule that has an infinitesimal reduction in temperature at each step.”The above statement is: True / FalseAnswer: True. 

Explanation:
This is because the algorithm will eventually search the entire space with the allowed randomness thereby converging at the global optimum eventually. 

Rubric:1 if marked True
0 if marked False

5.
Matching the modified versions of simulated annealing to other algorithms:
 


Modified Simulated Annealing Algorithm

Algorithm

1.  Simulated Annealing with a Temperature Schedule as:
   

A. Hill Climbing

2. Perform Simulated Annealing concurrently on many starting points

B. Random Restart

3. Using an extreme temperature independent probability
   distribution    Prob(Accept) = 1 iff ∆E > 0 else 0

C. Beam Search


Answers:


1.

B

2.

C

3.

A





Explanation:
1. The Temperature Schedule essentially allows selecting a point with a very high acceptance probability irrespective of its fitness scores with respect to the current point's fitness score. Thus, this will behave similarly as the Random Restart Algorithm
2. Performing Simulated Annealing concurrently with many starting points improves searching the instance space much faster and the same idea is utilized in the Beam Search algorithm.
3. Accepting Points with better scores only is exactly the Hill Climbing Algorithm

Rubric:0.5 for each match that was correct


",jc6w44hrp9v2ki,"[{u'text': u'4.
“Simulated Annealing is guaranteed to converge to the optimum solution under a temperature schedule that has an infinitesimal reduction in temperature at each step.”The above statement is: True / False

I think this statement is False because it is missing the most important component: That is the temperature schedule not only needs to have small reduction at each step, but it also needs to start HIGH. The statement in the exam only account for half of the requirement of converging to the optimum solution. Professor Thad also mentioned both components in the video. No? How does it guarantee to converge if it starts from temperature say, 10?', u'responses': [u'This was already posted in the clarifications thread. ', u'I answered false for the same reason. And that clarification should have large blinking lights around it, as it is not a minor correction. It kind of completely restates the question.']}, {u'text': u'According to the book (p126) 

""In a random-restart search, each search process runs independently of the others. In a local beam search, useful information is passed among the parallel search threads.""

Doesn't this effectively mean that starting simulated annealing on many concurrent start points is effectively random restart because each run is independent of the others?
', u'responses': [u'That is why the question said which algorithm resembles the others (not is exactly the same). The point here was that both have a similar idea to search more of the space quickly for the optimum due to parallel searches. ', u'The main sticking point for statement in the book highlights the key difference between a random restart and beam search.

Oscillating the temperature of one simulated annealing run means that there is some prior information passed from one run to another, and while it may be probable that a worse state is accepted, the probability does have some dependence on the delta E, which means that the information is not entirely thrown away and is used in some capacity for the next iterations. 

On the other hand, running SA with parallel starting points without communication across the thread would not provide any optimization because all will just run to termination. 

This was probably me overthinking at the time, but since it's a question of resemblance and not an exact correct answer, I don't believe this should be an entirely incorrect interpretation.', u'The information shared in the Simulated Annealing with temperature oscillations is not at all useful as compared that shared in a beam search. The chosen random point is essentially accepted and Simulated Annealing is performed on it almost independently of the earlier instance of the algorithm. Hence, we believe that it resembles a random restart.', u'I disagree with the usefulness of the information. For one, there is no y axis in the temperature so there is no objective way to say so. Secondly, depending on the global optima found in the cooldown, and the random point selected in the next iteration, the delta may be big enough to affect the probability and the succeeding random point selections. 

I also want to point out the other fact wasn't acknowledged is that the parallel threads do not share information as beam search would, which means there is no optimization gained from it, which means that it qualifies as a random restart algorithm. 

I'm not disagreeing that the your interpretation is incorrect. I am saying that there should be some acknowledgement that another interpretation is available and should not be entirely thought of as entirely incorrect. ', u'Firstly, the information sharing that you talk about is across time (history) and not across iterations. Secondly, the information is not useful as after the temperature goes very high, any point is randomly chosen with a very high probability (~1), thereby no useful information is taken from the previous points. The y axis is the temperature axis and the graph has been drawn enough to indicate that it is a very high temperature to cause the acceptance probability close to 1. Values of temperature are not provided as this is not a specific example and the intent needs to be understood. Information sharing is not the only thing that is innovative about beam search. And for it being a random restart, there is only one instance of the algorithm at a time so it is different from having multiple instances running concurrently to search the space faster. I am sorry that we do not believe that your interpretation is admissible for this case. ']}, {u'text': u'How will responses be graded that omit the trailing zero on part 2 for both answers that begin with .4? Is this considered “incorrect” rounding?', u'responses': [u'They have been given full credit. ', u'Thanks!']}, {u'text': u'for part 1, 

22.5

100

7.5

150

59062.5

1200

0.004216


Here the probability comes out to 0.004216499 which i believe should round off to 0.004216500 and then to 0.004217 instead of 0.004216.', u'responses': [u'Both answers have been given credit. ']}, {u'text': u'""enough to allow at least some degree of stochasticity"" does not mean ""high"", particularly when dealing with ""infinitesimal"" values. ', u'responses': [u'The intention was clear in the clarification, we did not want to explicitly state that and give you the hint directly on the question. ']}]",,,,953,,Midterm Question 3B Solution,[midterm]
5ad7d4920d63974e20c3920c,"So for question B 4 I initially put false because I had a counter example of T being really low but then changed it to true after the clarification from the TA below:

[03/08 12:50 AM ET] In B.4, The starting Temperature may be assumed to be enough to allow atleast some degree of stochasticity

I thought that meant, ""Oh you can assume T is high"". But the more I think about it, I think that they meant T just isn't 0 to begin with so I think the answer should be false and with a low T the algorithm basically behaves like hill climbing.

Did anyone else interpret the clarification like I did?",jc6w44hrp9v2ki,"[{u'text': u'well, I thought the statement was obviously wrong, so i didn't even bother to look at the clarification. Bummer~', u'responses': []}]",,,,955,"If T starts somewhere above zero such that ""at least some degree of stochasticity"" is allowed, then the ""infinitesimally small"" steps means that the entire space will be explored (eventually, ie, in the limit as t goes to infinity), and the fact that those steps are downward means that at the limit, the system will be trapped in the vicinity of the global optima.  This is the idealized extreme case of the simulated annealing process which is proven to converge!  (Cue Thad shaking laser-cut wooden box in the video on SA.  Less than... ideal).  In practice, most of us do not have infinite time to wait for convergence ;)",Midterm Q3.B.4,[midterm]
5ad7d4920d63974e20c3920d,"4.A.1


The domain of each variable correspond to the open space in each column above, therefor, the domains are:

A: 1 5 7 8
C: 1 8
D: 1 2 4 8
F: 1 2 5
G: 1 2 4 5 7
H: 1 4 5 7 8

4.A.2



The book defines minimum remaining values as ""choosing the variable with the fewest 'legal' values"", (page 216). C has only two legal values, 1 and 8, which is less than any other variable. Therefor, C is the next variable to set.

The book defines least constraining value as preferring ""the value that rules out the fewest choices for the neighboring variables in the constraint graph"".  As the image above illustrates, assignment of C=1 rule out 6 other values: A=1, E=1, F=1, G=1, G=5, and H=1. An assignment of C=8 only rules out 5 other values: A=8, E=8, F=5, G=1, and H=8. (Of course I'm ignoring the fact that either assignment to C removes other possible values from C). Therefor, C=8 is the least constraining value.",jc6w44hrp9v2ki,"[{u'text': u'I think you may have a typo in your answer for part 1. According to your chart E should be [1, 2, 4, 8]', u'responses': [u'Looks like a couple of typos in the chart.
D should be E
E should be F
F should be G 
G should be H', u'Thanks guys! I'll fix those right now. You're both right.', u'I think A is also wrong since it should be 1,5,7,8 just based on empty spaces', u'Thanks again. Not sure how I screwed that up so bad.']}, {u'text': u'What is the partial credit scheme for Part A.1? I made a small overlook and marked F's domain as 1,2,5,7 but i'd hate to lose all the marks on the question.', u'responses': [u'It's based on the number of variables you got totally correct. You'll see that soon when we release grades.']}, {u'text': u'Unfortunately, I misunderstood the question. I thought it asks for the domain of the final solution. So, I went further to get the final solution for the problem. Finally I got:
A: 5
B: 3
C: 1
D: 6
E: 8
F: 2
G: 4
H: 7

Will there be any partial credits for writing out the final solution for the first part. 

In order to finish part 2, in fact I wrote out the domain for the next step correctly, and I got the point in part 2.
', u'responses': [u'There is, unfortunately, not much I can do if you misinterpreted the question. I can't give partial credit to an answer that didn't answer the correct question.']}]",,,,957,,Midterm Question 4A Solutions,[midterm]
5ad7d4920d63974e20c3920e,"4.B.1

Here is the constraint graph drawn out:



The degree heuristic is defined in the book as ""selecting the variable that is involved in the largest number of constraints on other unassigned variables"". E is part of 6 constraints: four to neighboring regions, and two via its ""feud"" as described in the question. Even if you modeled the feud as single constraint out of E, the degree heuristic is concerned with the number of variables it constrains, which is not affected by modeling it as a single constraint out of E.

The least constraining values heuristic is tied for all values except 2: 1 and 3 through 6 would all remove 6 possible values. 2, on the other hand, would only remove 5, as G already has a unary constraint that it cannot be 2.

4.B.2

Make sure to update the domains of neighboring regions (or regions connected by the feud) after each assignment. The values are then assigned in this order:

E = 2 from the previous answer, as stated in this problem: ""Begin your search AFTER the result from 1 is used to start off your search""

A = 1. MRV (minimum remaining values) selects any variable but F or B, which each have four remaining values, and everything else how has 2. In breaking ties, A is selected. LCV (least constraining value) is tied across all values, and therefor we select the lowest number, which is 1.

C = 3. MRV is tied across C, D, and I, tie breaker means C. LCV tied across 3 and 4, tiebreaker means 3.

D = 3. MRV is tied between D and I, tie breaker means D. LCV is tied across 3 and 4, tiebreaker means 3.

I = 4. MRV selects I (it only has the number 4 left in its domain).

B = 2. MRV is tied between B and G (both have two left in their domain). LCV selects 2. This is the only place where LCV actually makes an impact on the problem. None of B's neighbors have 2 remaining in their domain, but G and H both have 1 in their domain. Therefor, B is set to 2

G = 1. MRV selects G and LCV is tied for 1 and 3, therefor 1 is selected.

H = 3. MRV selects H, LCV is tied for 3 and 4, therefor 3 is selected.

F = 1. F is the only remaining variable, and LCV is tied for all, so 1 is selected.

If you have questions about ""why didn't you pick variable X and value Y at step N"", please please do this problem out again very carefully before you ask a question. There are lots of subtleties, and most people, including myself, do something wrong the first time around. I can guarantee I have had this solution verified by at least two other instructors (that I know of).


4.B.3
""A single variable (corresponding to a node in the CSP network) is node-consistent if all the values in the variable’s domain satisfy the variable’s unary constraints."" G is the only variable with a unary constraint, therefor it is the only variable that even could be not node-consistent. The constraint says G cannot have a value of 2. 2 is in the domain, therefor it cannot be node consistent.

""A variable in a CSP is arc-consistent if every value in its domain satisfies the variable’s binary constraints.""

A is not arc consistent because the 2 in its domain is incompatible with E's assigned value of 2.
D is not arc consistent because the 4 in its domain is incompatible with B's assigned value of 4.
G is not arc consistent because the 2 in its domain is incompatible with E's assigned value of 2.
H is not arc consistent because the 4 in its domain is incompatible with B's assigned value of 4.
I is not arc consistent because the 4 in its domain is incompatible with B's assigned value of 4.
",jc6w44hrp9v2ki,"[{u'text': u'so 4B.2 has only one correct answer? If I picked A next but assigned 3 to it, and therefore 1 to C. With everything else the same, how many points will I lose? Thanks,', u'responses': [u'I have the same concern, I made a couple of different assignments. Is there a partial credit for each correct assignment?', u'I believe I applied the methods correctly in 4B2 but made a mistake and assigned E=1 in 4B1.  Is there going to be partial credit since the 4B2 assignments are completely dependent on 4B1?', u'> Is there going to be partial credit since the 4B2 assignments are completely dependent on 4B1?Am in the ""neighboring"" boat; I got the node wrong and got the LCV right which cascaded into the next Q.
', u'It'd be really great to get partial credit for applying the methods correctly, disappointed to get no credit based on bad assumptions', u'Regrade window closes in 2 hrs and no response. Do we just ask?', u'The normal course of events is that you remember it until the end of the semester, when it is only relevant for people who are marginal with their grades, then those who are aggrieved at that stage raise it at that stage, so that saves a bunch of aggravation all round', u'Feels like bad practice. Resolve conflicts early to avoid downstream effects. I took ""no more regrades past xxx time"" to be a hard policy ', u'It's life, it's the path of least aggravation, just live with it :-)', u'Just to close the loop on this question:

I was not possible to give partial credit 4.B.2 given an incorrect solution on 4.B.1. Logistically, i was impossible to go through every possible solution (and there were MANY different answers on 4.B.1. However, we did award points where you happened to get the correct answer.

On the other hand, I definitely hear the criticism. And the fact that 4.B.2 was so contingent on 4.B.1 was problematic. You can bet that we are taking this into account when designing the final. Thank you all so much for the feedback.']}, {u'text': u'tricky lcv for B=2 :(

If only, I'd had a computer that could have easily seen that for me...

(Hopefully partial credit is being given for the blind...)', u'responses': []}, {u'text': u'Same as Tay. I forgot to consider G!=2 so I assign E to 1 in 4B.1. Based on E=1, even I understand and apply the same method as the solution, I got completely wrong for 4B .2 domain. For 4B.2, is it possible to not loss all the credits due to the previous question's mistake? Thanks', u'responses': []}, {u'text': u'What is the rubric for question 4.B.3?', u'responses': [u'+1', u'I have all correct answers for arc-consistency and some wrong answers for node-consistency (because I misunderstood node-consistency). Would you give credits for arc-consistency and node-consistency separately instead of nodes? ', u'I am in the same boat, Thanh.', u'Seem that we will not get responses before regrade window
']}, {u'text': u'Wow my understanding from the lecture material was way wrong for what Arc Consistent was.
Lesson 4, Quiz 14 solution video says: ""The network is arc consistent, because there are not any regions without a possible color"" I took that to mean that each region was arc consistent if they still had a possible domain considering all the current constraints and assigned values. FML', u'responses': []}, {u'text': u'Maybe I totally missed something, but here goes...

Can the constraints that E has imposed on itself, be modeled as binding on D and H? In the presented graph in the solution above, they are modeled as a E<>D which is applicable in both directions ?

* This at a problem domain level, E's unilateral decision not to have the same value as D or H, (where D & H have no such issues), are being modeled  as, ""in response"" D & and H have also declared not to have the the same values as E.

* While this may not make a difference at all times, in a case such as this (with a preferred order for selecting vars, values), there could be cases where the assignments end up being different because the selection order changed for H. Especially where we are looking a very specific assignment solution that would be achieved only by going down a particular path which is determined by the specific (variable and value ordering) policies.

* Should this not be done with unidirectional directed constraints arcs E->D & E-<H, and letting the backtracking take care of it?

What am I missing?

', u'responses': [u'D and H don't impose constraints on each other though. Its strictly from E to D and from E to H.

You're point about E's constraint being ""in response"" does not actually affect the outcome of the problem. Take a look in the book where it talks about the 'commutativity' of CSP's. The constraints should just be ""E !== D"" and ""E !== H"".

""While this may not make a difference at all times, in a case such as this (with a preferred order for selecting vars, values), there could be cases where the assignments end up being different because the selection order changed for H. Especially where we are looking a very specific assignment solution that would be achieved only by going down a particular path which is determined by the specific (variable and value ordering) policies."" Yes, the outcome would certainly be different if you selected things in a different order. What is your point here?']}, {u'text': u'Is there any chance for partial credit on question two if your variable assignment is consistent with the choice you made for the first question? If you get the first question wrong, you go off the rails immediately and only get some of the answers correct by accident.', u'responses': [u'Anan Zhang and myself ask the same above. But yeah, more fuel to the fire.', u'+1
', u'I missed the answer to this elsewhere, I also screwed up first part so my 4b went to crap too. What was decided on this?', u'I thought I saw somewhere that the answer was no but that is being taken into consideration for question design for the final.']}]",,,,958,,Midterm Question 4B Solution,[midterm]
5ad7d4930d63974e20c3920f,"4.C.1

There is no way to satisfy all the critics.


4.C.2
There are three valid answers here. Any of the following three were correct responses.

answer 1
Alf: beer steak rench
Barbs: bribe
Clyde: beer steak french

answer 2
Alf: bribe
Barbs: red wine chicken cuban
Clyde: red wine chicken cuban

answer 3
Alf: bribe
Barbs: red wine chicken thai
Clyde: red wine chicken cuban",jc6w44hrp9v2ki,"[{u'text': u'for 4.C.2 I didn't see anywhere specifying the order to put the answers for the food delivery. Any permutation of correct food/beverage/style is valid?', u'responses': [u'Order did not matter in grading.']}, {u'text': u'for 4.C.2

I put red wine, chicken, cuban to all three of them. Thinking that it obviously does not satisfy the requirement for Alf, so he's the one to bribe. I didn't put 'bribe' there, will I at least get partial credit?', u'responses': [u'I'd have to check your submission again, but yes, I tried to give partial credit for exactly that situation.', u'in my case, I left the bribed one (barb) blank and put down beer steak french for alf and clyde. is this acceptable?', u'Julie- I gave full credit for that answer, because a blank clearly indicates which person you're not serving and therefor would have to bribe.', u'cool thanks!', u'As for partial credit or giving full credit to things not exactly what I wrote above, I'll have to consult with the team.', u'Because i thought I still have to serve him even though he won't be pleased. so i wrote the resulting dish instead of bribe. Thanks for checking.', u'Just to point this out from the exam:""The bribed critic does not need to be fed.""', u'Thanks Noah, now I see that!! ']}, {u'text': u'for  4.C 1

why this doesn't satisfy all constrains 

Alf :- Beer Steak Cuban
Barbs: red wine chicken cuban
Clyde: red wine chicken cuban

total cost: 80', u'responses': [u'beer and cuban food can't be served together', u'please ignore, i got my answer.', u'Thanks Willie']}, {u'text': u'for 4C2

From the space provided it seems that we need to provide any one answer, so i provided the lowest cost one. as i haven't mentioned other two, will i be getting some points ?', u'responses': [u'You only needed to provide a single correct answer.']}, {u'text': u'Why can't this be an answer to 4.C.1? Which constraint does it fail to satisfy?

Alf: French Chicken, Red wine, Beer
Barbs: Cuban Chicken, Red wine
Clyde: Cuban Chicken, Red wine', u'responses': [u'Beer can't go with Chicken', u'There is no such constraint like that mentioned in the question.', u'""Chicken must be served with red wine"". I see what you're saying though, nowhere is it specifically said that there must be only one food, only one beverage, only one style, per meal', u'Yes, so I have served it with red wine.

And question does not mention anywhere that two drinks cannot be served to the guest.', u'""Alf: French Chicken, Red wine, Beer"" is not valid. Each person must be served exactly one food, one style, and one drink. We even clarified this in the midterm clarifications thread.', u'How can you supply an additional constraint to some question some where outside of the question paper?', u'We did this with many questions and made it clear there was a clarifications thread that you should keep an eye on to make sure you've interpreted the question correctly. Just to be very clear on this, we're not going to be assigning partial credit to questions that are not in line with the clarifications we made. I agree that the original question could have been more explicit about this, and that is why we added it to the clarifications thread.', u'My answer deserves full points. Constraint satisfaction problem needs to have all the wordings explicitly clear. TAs adding whatever new constraints at the last moment on clarifications thread is not justifiable way of designing question paper. We have put significant effort on finding a solution that satisfies all the constraints specified in the question. Now, TAs cannot reject a valid answer by changing question itself outside of the question paper.', u'Why doesn't this satisfy  4.C.1?
Alf: Steak, Beer, Cuban
Barbs: Chicken, Red Wine, Cuban
Clyde: Steak, Beer, Cuban

Looks like I misinterpreted the constraints?
', u'Hey Atharva,

In @641, we said: ""Please read through this post carefully as it contains important information about your midterm."" Our intent was to clarify exactly what the process would be for the midterm. In the same post, we also said ""Please refer to the Clarifications thread periodically to make sure that you have interpreted all questions correctly.""

Given this information, we believe that your interpretation of the question was incorrect. However, we do try our best to keep our papers self-contained, and I apologise for not being able to do that. We will aim to do better on the Final, and in future semesters, in this regard.', u'@James One of the constraints is that Beer cannot be served with Cuban food.', u'Is it justifiable to penalize those who applied their creativity in finding solution under the tight constraints set by the question setter, just by adding new constraints outside of the question paper to reject some valid solutions?

You have the option to give credit to those students who came up with valid solution that satisfies all the constraints explicitly mentioned in the question paper.

It is not a good idea to design question papers so casually and setting rules of the grading of exam so much in favor of helping the TAs to be able to evaluate the answers easily, instead of taking the responsibility of making mistake in designing questions and rewarding those who tried their best to come up with the solution for the question. Especially when people are paying for the course and the grades of this already difficult course having huge impact one's career.']}, {u'text': u'I say, spend the 40 Starnercoin on cuban style chicken with red wine for Barbs and Clyde, pay off Alf and his expensive taste for french style steak and beer, and take the remaining 10 Starnercoin and take your gf/bf to the movies.  Sure boss, I'll ""make it work"" alright, for all involved :)', u'responses': []}]",,,,959,,Midterm Question 4C Solution,[midterm]
5ad7d4930d63974e20c39210,"1. 
mean: 113
median: 105

The distance between the data point and training set is: [5.51724568965, 3.84187454246, 1.64012194669, 1.22065556157, 3.36005952328]. So the last three points are the 3 nearest neighbors. Their scores are [85, 105, 150].
median is 105 and the mean is (85 + 105 + 150) / 3 = 113.3333

Don't need to be accurate to 6 decimal places as long as 113 or 105 is in the answer.

2.
a. 700
The Euclidean distance between the new data point and the (x1000) training set is: [3800.00210526, 2400.001875, 1300.00038462, 700.000714285, 2700.00074074]. So the distance between this data point and its nearest neighbor is 700.

Don't need to be accurate to 6 decimal places as long as 700 is in the answer.

b. 0.534261 or 0.477858
mean(x) = 4.0, mean(y) = 4980.0, std(x) = 2.2803508502, std(y) = 2293.81777829 using population standard deviation
The normalized new data point is x= 0.438529009654, y = 0.357482624715
The distance between the normalized new data point and the normalized training set is: [2.4127443758, 1.6809203637, 0.716591073102, 0.534261413605, 1.46790356639]. So the distance between this data point and its nearest neighbor is 0.534261.

If sample standard deviation is used, the answer is 0.477858. Full credit is also given for this answer.
Don't need to be accurate to 6 decimal places as long as 0.534 or 0.477/8 is in the answer.

In this problem, the training set represents the full population where mean and std are calculated. Sample standard deviation is used when a subset of the set is used as an estimator for population standard deviation. 

c. 0.807630 or 0.722366
Variance = $$E[(x - \overline{x})(x - \overline{x})]$$
Covariance(x,y) = $$E[(x - \overline{x})(y - \overline{y})]$$
Covariance matrix = $$\begin{bmatrix}E[(x - \overline{x})(x - \overline{x})] & E[(x - \overline{x})(y - \overline{y})]\\ E[(y - \overline{y})(x - \overline{x})]& E[(y - \overline{y})(y - \overline{y})]\end{bmatrix}$$
Diagonal values are variance of x and y. 
covariance matrix = $$\begin{bmatrix}Var(x) & Cov(x,y)\\ Cov(x,y) & Var(y)\end{bmatrix}$$

$$\overline{x}$$ = 4
$$\overline{y}$$ = 4980
Var(x) = E[(1-4)(1-4), (2-4)(2-4), (4-4)(4-4), (6-4)(6-4), (7-4)(7-4)] 
Var(y) = E[(2000-5800)(2000-5800), (3400-5800)(3400-5800), (4500-5800)(4500-5800), (6500-5800)(6500-5800), (8500-5800)(8500-5800)]
Cov(x, y) = E[(1-4)(2000-5800), (2-4)(3400-5800), (4-4)(4500-5800), (6-4)(6500-5800), (7-4)(8500-5800)]

When population covariance is used, covariance matrix = $$\begin{bmatrix}5.2 & 5.14 \cdot 10^{3}\\ 5.14 \cdot 10^{3} & 5.2616 \cdot 10^{6}\end{bmatrix}$$
Then use the equation on wikipedia, distance = $$\sqrt{(TrainingPoint - NewPoint)^{T}\cdot InvCov \cdot (TrainingPoint - NewPoint)}$$
For example, the distance between the first training data point and new data point is $$\sqrt{(1 - 5, 2000 - 5800)\cdot InvCov \cdot (1 - 5, 2000 - 5800)^{T}}$$
distances = [1.79102087133, 1.87022629834, 0.853699870963, 0.807630081894, 1.9129361653]. The distance between this data point and its nearest neighbor is 0.807630.


When sample covariance is used, covariance matrix = $$\begin{bmatrix}6.5 & 6.425 \cdot 10^{3}\\ 6.425 \cdot 10^{3} & 6.577 \cdot 10^{6}\end{bmatrix}$$
Then use the equation on wikipedia, distances = [1.60193776697, 1.67278125456, 0.763572377543, 0.722366305515, 1.71098212089]. The distance between this data point and its nearest neighbor is 0.722366. Full credit is also given to this answer.

Don't need to be accurate to 6 decimal places as long as 0.807/8 or 0.722 is in the answer.

3. Median

4. Mentions of correlation, covariance and outlier
one point from training set $$(x_1, y_1)$$, the new data point $$(x, y)$$
mean of training set $$\overline{x}$$, $$\overline{y}$$
std of training set $$std_x$$, $$std_y$$

Euclidean distance with normalization:
distance = $$\sqrt{(\frac{x_1 - \overline{x}}{std_x} - \frac{x - \overline{x}}{std_x})^{2} + (\frac{y_1 - \overline{y}}{std_y} - \frac{y - \overline{y}}{std_y})^{2}}$$
= $$\sqrt{(\frac{x_1 - x}{std_x})^{2} + (\frac{y_1 - y}{std_y})^{2}}$$
 = $$\sqrt{\frac{(x_1 - x)^{2}}{Var(x)} + \frac{(y_1 - y)^{2}}{Var(y)}}$$

Mahalanobis Distance:distance = $$\sqrt{(x_1 - x, y_1 - y) \cdot InvCov \cdot (x_1 - x, y_1 - y)^T}$$
When cov(x, y) = 0, covariance matrix = $$\begin{bmatrix}Var(x) & 0\\ 0 & Var(y)\end{bmatrix}$$
InvCov = $$\begin{bmatrix}\frac{1}{Var(x)} & 0\\ 0 & \frac{1}{Var(y)}\end{bmatrix}$$
Then distance = $$\sqrt{\frac{(x_1 - x)^{2}}{Var(x)} + \frac{(y_1 - y)^{2}}{Var(y)}}$$ which is the same as Euclidean distance with normalization

The difference is in the covariance. When the covariance is positive, it means x, y have a positive correlation. When the covariance is negative, it means x, y have a negative correlation. 
So full credit is give to answers mentioning covariance and correlation.

From the wikipedia, you should also know that Mahalanobis distance is good to detect outliers, which can be used to improve the performance of KNN in related applications.

",jc6w44hrp9v2ki,"[{u'text': u'I used standard deviation using N-1 method (STDEV) in excel and get a different answer for B - 0.44049. Where am I going wrong?




', u'responses': [u'You used 0.392232 (point, x value) - normalized y', u'Thanks for the prompt response.  Should the normalized x not be 5 - 4 / 2.5491 which is 0.392232? similarly for y and then we should that for further calculation.  The extire excel sheet is here as well. 

MLBS.xlsx', u'you should do 0.319742 - normalized y, but you used x value - normalized y

(you used the x value of normalized new point - normalized y values of training data)', u'Yes. Stupid me! I get is now. Corrected it now.  Is there any partial credit for this. I would understand if not. Thanks again

', u'There is no partial credit.']}, {u'text': u'My Mahalanobis distance answer is different as well. Here is how I calculated it. (Image below but the entire excel sheet is here as well - MLBS.xlsx )

', u'responses': [u'Please see the answer']}, {u'text': u'Is correlation sufficient for part 4? My answer was  basically high-dimensional data that has strong correlation between many dimensions is good for Mahalanobis, vs curse of dimensionality is bad for Euclidean', u'responses': [u'I think I gave credit to this answer.

The scores are released. If I didn't, send me a regrade request.', u'You did, thanks :-)']}, {u'text': u'Question 7B- 3 - Can't say is a valid answer.
In some situations one may want to predict worst case scenarios, and choosing the mean over the median makes sense. (in the presence of hidden variables, what is the worse we have ever observed)
This is just bad evaluation design, one cannot ask an open question and expect yes o no type of answers. I agree, in general, one would take the median, but there could be specific cases in which taking the median makes sense. ', u'responses': [u'I had the same reasoning. Choosing mean/median needs more information about the data as well as the value of k under observation. Without such details, I suppose, its hard to say what to choose. 

I would like to know more about why median is better for presence of outlier in kNN, in all the cases. Could the instructors provide with some insight/resources to help in understanding this concept better?', u'Hi Rupal. Independently of what the instructors respond, I assure you in some cases you would want to use the mean. In fraud for example, outliers are your cases of interest, and if you want to be conservative in predicting losses you would rather use the mean than the median. ', u'Median is more robust to outliers, meaning it doesn't change much when there are outliers in the data set. Imagine finding the ""average"" net worth of a city that includes Bill Gates. His wealth pulls the mean way up, but as long as he's the #1 richest person in the area, even if it's by a single dollar, the median wouldn't change. 

Another way of putting it is that it's more a measure of the ""average person's wealth"" than the ""average wealth.""', u'Sasha, sometimes one wants to measure  or predict something different than the typical behavior. In many cases outliers are your most interesting samples: fraud, accidents, terror cells, strokes. In the model your neighbors are found using measures of similarity, that is not the point here, the question is what aspect of the outcome I want to focus. If you focus on the typical outcome, you will miss the signs that lead to discovery of the atypical.', u'I was answering Rupal's question by expanding on the concept. I'm going to stay out of the conversation about grading the midterm question.']}]",,,,961,,Midterm Question 7B Solution,[midterm]
5ad7d4930d63974e20c39211,"
QuestionA: Check the statement(s) that are true. (3.5 marks)


Expectimax in a deterministic environment is the same as Min-Max. TrueIn a deterministic environment, you can move to the next possible states with probability 1 which reduces it to a Min-Max problem. (Also, from the clarifications - ""You should interpret Expectimax to be the same as Expectiminimax. The term Expectimax is used interchangeably with Expectiminimax in the videos."")

Alpha-beta outputs a better move than min-max, given that they search till the same level. FalseBoth return the optimal move when allowed to search till the same level - alpha-beta might return it faster (if there's pruning possible). 

Min-max would give optimal moves for at least one player in a 2 player collaborative game. FalseMin-max would fail in a collaborative game - Max-max would return the optimal move. Since generating next-move works in a bottom-up fashion - evaluating game boards at a level and propagating the best moves upwards - if you select a sub-optimal move at one level, it has the chance of propagating to the top of the tree. Hence, it cannot work even for one player.

Iterative deepening can search deeper because it caches the best move at each level from the previous traversal of the game tree. FalseThis is not how ID works. For correct algorithm, please refer to the book, or the lectures. 

We do not need an evaluation function if we can search till the end of the game tree. TrueEvaluation Function is an estimation of the goodness of a state. We need this estimation when we don't know if a particular state will lead to Win or Loss (that is when we cannot search to the end of the game). According to the book - Evaluation function is an estimation of the true utility of the state.

Alpha-beta pruning and beam search are both methods that can reduce the branching factor of a game tree. TrueYes, for further details on both the methods, please refer to the book.

Move ordering for alpha-beta pruning is best performed by evaluating the utility of board states and then sorting them based on the utility values. FalseMove ordering is performed to avoid evaluation of board states (because evaluation can be computationally expensive). There's no point of move-ordering if you have already evaluated all board states.   

Marking scheme: 0.5 for each part. (7* 0.5 = 3.5 total) 
",jc6w44hrp9v2ki,"[{u'text': u'I had a different interpretation of #3. In the bot battle for assignment 1 and in most of our conversation around adversarial search we were playing games of one computer player against another computer player, or one computer player against another human player. For a collaborative game I would assume that this would still be the case, where 2 players participate, not that min-max was giving the moves for both players. In this scenario where two computer players in a collaborative game are each running a separate version of min-max, you would essentially get the behavior Max-Max and the answer to the question would be True.

Just because the computer player is assuming the worst from their team mate doesn't mean that it won't return even better moves if their team mate plays to their advantage. In the book in section 5.2 it says 
What if MIN does not play optimally? Then it is easy to show that MAX will do even better. 
I think there is some gray area to this question depending on how the game is structured. The question asked if Min-Max would return optimal moves for at least one player, and it would I think if the other player was working to MAX's advantage.', u'responses': [u'This is how I interpreted this question too', u'[[Misinterpreted what you said, Jim, never mind!]]', u'I also decided to say True for #3 based on reading that line from AIMA', u'I agree.
TAs, I think that you should consider accepting TRUE for #3. Please see the second paragraph from AIMA below:


', u'I also misinterpreted #3.', u'I'm another, is anything being considered here?', u'As I said in a different thread, try not to sweat it. Often in OMSCS at least, those kinds of questions are left unresolved all semester, only ever relevant for the small minority who are grade-marginal at the end of the semester, who are affected by some controversial decision either way; normally professors are either sufficiently generous with such marginal cases or theoretically there is some end of semester grade appeal procedure that no-one ever seems to need to resort to really.', u'@Jim, and everyone else who based their answers on this statement from the book - 
What if MIN does not play optimally? Then it is easy to show that MAX will do even better.
You have to understand that ""even better"" is in comparison to what Min-Max returns when both the players play optimally. It's still might not as good as Max-max which will return the best move in a collaborative game.  
This is in the case of zero-sum game. This is the complete paragraph from the book for reference -  ""This definition of optimal play for MAX assumes that MIN also plays optimally—it maximizes the worst-case outcome for MAX. What if MIN does not play optimally? Then it is easy to show (Exercise 5.7) that MAX will do even better. Other strategies against suboptimal opponents may do better than the minimax strategy, but these strategies necessarily do worse against optimal opponents.""Now for a non-zero sum game scenario, consider this example of a game where the rewards can be from 0 to 7. Now, the MIN player can choose from moves that have the following rewards: (7, 7) (0, 6) (6, 0). When the MAX player comes across this sequence in the tree, it will assume that the optimal move for it is to choose the path with move (0, 6) since it's a MIN level. But this may lock out the chance of (7, 7) ever happening, meaning neither player gets the optimal reward.

Hope this helps!

@Mark, we might be delayed in our responses but we try our very best to not leave questions unresolved. :)', u':-D']}]",,,,965,,Midterm Question1A GamePlaying,[midterm]
5ad7d4930d63974e20c39212,"1. Propagate the values through the game tree. (2 marks)







Marking Scheme - All correct - 2 marks- 0.25 for every incorrect node value
",jc6w44hrp9v2ki,[],,,,966,,Midterm Question1B Game Playing,[midterm]
5ad7d4930d63974e20c39213,"Part 2: Select the terminal nodes that are possible outcomes assuming optimal decisions by the player. (multiple choice) (1 mark)

Correct Answer: EFLM 

It's pretty straightforward as long as you remember the following points - 1. Min-max nodes behave as usual - Max picks the branch with the highest value of the evaluation function, and Min picks the one with the minimum value. So, you can go down only one way from a max/min node (as long as there's just one max and min).
2. At chance nodes, however, you can go down all possible branches (all of them are possible with some probability). 

Marking scheme - 1 mark for the correct answer
0 mark for everything else. 
No Partial marking


Part 3: If the range of possible evaluation function values is given to be [2,6], which of the terminal nodes can be pruned, given that we are evaluating the tree from left to right on each level? (1.5 marks)
Correct Answer: BDFH

BDH was easy to figure out - Chance nodes do not have a role in this calculation, it's pretty much the same as alpha-beta pruning in min-max given a range of evaluation function values. (If you did not figure out BDH, you probably need some more alpha-beta pruning practice for the finals!)
F was the tricky one!After evaluating E, we know that the min value possible at its parent chance node is 2.5 (3/2 + 2/2) assuming the minimum value for F, which is 2). Right above this chance node is a Max node. 2.5 is already greater than the 2 evaluated from the left branch of the Max node. So, given the range of [2,6], irrespective of the value of node F, the max node will select its right branch. Hence F can be pruned.(It also helps to remember that while finding the optimal move, decisions are made at the min and max nodes, and not at the chance nodes.) 

EDIT -----------------------

Considering the viewpoints expressed in the comments below, both BDH and BDHF have been awarded full marks.  

Marking scheme - 
1.5 marks for Correct Answer (BDFH)0.75 marks for BDH     after the edit - 1.5 marks for BDH0 mark for everything else - No partial marking


",jc6w44hrp9v2ki,"[{u'text': u'1-B3: if we pruned F, how do we compute the top chance node?', u'responses': [u'I agree, I think you need the actual value for the root node, rather than a range of values', u'I was about to agree here, but then I reconsidered (despite having gotten the question wrong). From the original lecture, I remember emphasis that the point of adversarial search is to find a single move that is as good as the best possible move, not to enumerate the list of all equally good moves. Extending that slightly, I'm not sure how knowing the exact values of the intermediate or top-level chance nodes affected by F would lead to you making any different move selection?', u'It's not the intermediate chance nodes that matter, it's the root node of the tree. The actual evaluation of a tree is the task; in the case of the question, the root node of the tree is a chance node, so its only meaning is its value, not its decision', u'Another point that needs to be considered is that  the pruning of F is contradictory to the answer of question 2 which includes F as a possible outcome.', u'I could agree that there's some ambiguity - if we consider the task to be evaluating the tree then we would need F (and I would get 0.75 extra points and be happy). As a game playing agent though, I don't think there's any value in knowing the exact value of the root node of the tree, as it wouldn't actually change your decisions...', u'The only point of a tree is the evaluation of the root node. Everything else is for the purpose of that evaluation. Obviously for a non-stochastic, decision, root node, the 'evaluation' may be a range of values per decision alternative – as long as the ranges are coherent inter se – allowing for a decision between the alternatives; while for a stochastic root node, only an actual value makes sense. 

As an illustration, in a particular case – with some different leaf node values for the sake of illustration, natch – when you allow pruning of nodes that are necessary to the actual value of the root node, then it's tantamount to someone giving you a game state [the root node], saying 'evaluate that with minimax, knowing that all states are worth from 2 to 6 inclusive', you calculate a bunch of calculations then say ""it's worth at least 2"" :-)

https://stackoverflow.com/questions/234075/what-is-your-best-programmer-joke#234419 & deep thought, the meaning of life is 42, etcetera :-D', u'""The only point of a tree is the evaluation of the root node""

I see your point, and think it's a very valid interpretation of the question, but I think this also centers on where we're differing (and, presumably, where both of our original answers differ from the graders). From my interpretation, the point of a game tree is to supply optimal decisions to an agent, based on available knowledge. If knowing the exact value of the root node vs. a range of possible values for the root node don't change the decisions, then is it really important? Put differently, if we both had a bot playing this game, would knowing that the root node was worth exactly 3.5 make your bot play differently/better than someone else's bot who had pruned F :) ?', u'Then, in your 'purely teleological' tree, the question is, what is the root node doing there? It has no meaning unless you need its evaluation. The fact that it is there, contradicts the interpretation of the tree as a tree for the sake of making a particular decision – at the root node.

Decisions lower down in the tree are normally going to constitute root nodes of their own should the game ever in fact reach that state, with different evaluations as a function of depth limited evaluation etcetera.

That tree, is a tree that represents the possible game states from the current state that is the root node. As I say, the root node is what the tree is all about, you can't say the tree is the max decisions at level 1, etcetera', u'This is a decision tree with some stochastic nodes, so the ""value"" of the root node is a probability distribution with an expectation value, not a fixed value.  The root node is a stochastic node, so it is not an intelligent agent and does not need any information about its child nodes in order to make a decision.  If node F is pruned, this changes our estimate of the distribution of the root, but does not change any of the decisions by the agents in the game.  I too got this wrong, but it was a good lesson and I won't make that mistake again.

Not to say I wouldn't accept another 0.75 points on my grade if the instructors decide to backtrack on this one ;)', u'Wouldn't it change the game in that the agent would not choose the left node at the root?', u'ah, just realized the root is stochastic. :-/ ', u'According to that logic you should say you could prune the root node itself, as its value is irrelevant to decision making

When you prune the root node, you may as well prune the whole tree

Heck, get the chainsaw Martha :-D', u'I kind of see Mark's point in this (after I've had my morning coffee). If theoretically, the game didn't terminate at the F node and still had nodes under it, not evaluating where F is would essentially cut off a portion of the game that may be traversed in an actual game where the players acted rationally. (And the alpha beta pruning is agnostic to whether or not the game terminates at F because by this logic, F and everything below it would not even be evaluated.) As I understood it, alpha beta pruning doesn't discard nodes that might lead to a winning move. 

E node is not necessarily the better node in this case and won't necessarily be selected every time a game is played, so doesn't it make it necessary to evaluate F as well? 

I think ultimately, the issue with pruning with stochastic games is that there's no canon in the book that tells us what to do. The challenge questions also just eliminated the min nodes that will never be traversed, so there's really no precedent for anyone as to whether F should or should not be pruned. ', u'Hi guys, 

Owen's perspective is what we considered when we arrived at BDHF as the answer. I'd argue that ""the only point of a tree is the evaluation of the root node"" is not generally correct statement. But since here there was no information as to what the game tree was for - if the decisions were to be made for the max layer under the stochastic root node or if the root node itself was part of a bigger game tree (in which case we need the value of evaluation function at the root node) - we arrived at the conclusion that both BDH and BDHF should be considered as correct answers. 

Thank you guys for putting your points forth.

I apologize for the delay. ', u'Hi Richa,

Thanks for the update, that's good news :-)']}, {u'text': u'Marking scheme - 
1.5 marks for Correct Answer (BDFH)0.75 marks for BDH 0 mark for everything else

Just to clarify this comment. So F is worth 0.75 and BDH together is worth 0.75 for a total of 1.5?', u'responses': [u'marking scheme has been updated. ']}, {u'text': u'Should part 1 not be EFJKM? Consider the side of the tree -

The right side of the max node has a 50% chance of getting a 2 (from Node J), if the left side if Node L, then Node J would be reached. Similarly the right side of the node has 50% chance of getting a 4 (Node K), If the other side is a 2, (Node L) - then K would be reached, otherwise M.


', u'responses': [u'optimal decisions => at the max node above GHIJKLMN, max picks the right branch to the chance node above KLMN worth 3.5 rather than the left branch to the chance node above GHIJ worth 3. Everything else beneath a chance node is subsumed into the expected value of the chance node', u'The right max node decision would depend on

50% of the time the left-side would be min (GHIJ) and 50% K 50% of the right side would be L and 50% min(M, N).', u'
50% of the time the left-side would be min (GHIJ) and 50% K  - This evaluates to 350% of the right side would be L and 50% min(M,N) - This evaluates to 3.5

The max node is deterministic, so it can choose between these 2. It chooses to go down the 3.5 route, which means ""50% of the right side would be L and 50% min(M,N)"" which implies L and M are the possible outcomes.

It will never go down the 3 path. Only circular nodes have a stochastic outcome, not the triangular ones.
']}, {u'text': u'1-B3: why not node I can't be pruned? Following the same logic as for F, the value in node I can be [2, 6] and thus the range for the chance node is [4,6], which is larger than 2 in node J and the min node will choose node J regardless of the value in node I. Make sense? If so, shouldn't the marking scheme be updated?
', u'responses': [u'You can't peek at Node J before you evaluate the chance node to its left, since we're going left to right here.']}, {u'text': u'Based on ans given for 1B1, the value for top choice node is 3.5 which is still 2-6 range. If we prune F, wouldn't the top choice node value be 1/2 * 3 + 1/2 * 3.5 = 3 ? which contradicts ans 1B1', u'responses': []}]",,,,967,,Midterm Question1B Game Playing (sub-parts 2 and 3),[midterm]
5ad7d4940d63974e20c39214,"This problem is a simple twist on Monty Hall problem. 

Rubric. Full points for correct answer, 50% for rounding errors and zero for an incorrect answer. (Rounding error means that you have either not rounded to six decimal places or your six decimal place rounding is incorrect)

5A1: No information about any cup has been revealed. So, P(Cup 6 is poisonous) = 1 - P(Cup 6 is water) = 1 - 1/total_cups = 1-  1/6 = 5/6 = 0.833333

5A2: Still no information about cup 6. So, P(Cup 6 is poisonous) = 1 - P(Cup 6 is water) = 1 - 1/total_cups = 1-  1/6 = 5/6 = 0.833333

Now, let's try to take a step back and generalize this problem. 

Suppose we have $$n$$ cups (1 with water) and $$m$$ reveals during a game. The probability of choosing a cup with the water behind it on your first attempt is $$\frac{1}{n}$$.
After the host has revealed $$m$$ cups, where $$0\leq m\leq n-2$$, the probability of getting a water cup if you pick a different cup (say cup 3) is the probability of not getting a water cup in the first place, which is $$\frac{n-1}{n}$$, times the probability of picking it after m reveals, which is $$\frac{1}{n-m-1}$$. So the total probability of any other cup being the water cup is $$\frac{n-1}{n(n-m-1)}$$

5A3: Substituting the values in the above formula, where n = 6 and m  = 1, we get P(cup 3 is poisonous) = 1 - P(cup 3 having water) = 1 - (6-1)/(6*(6-1-1)) = 1 - 5/24 = 19/24 = 0.791667

5A4 a) Even though we have 4 reveals, the probability of cup 6 being poisonous does not change. So, P(Cup 6 is poisonous) = 1 - P(Cup 6 is water) = 1 - 1/total_cups = 1-  1/6 = 5/6 = 0.833333

5A4 b) Now, only two cups are remaining (6 and 2). So, P(Cup 2 is poisonous) = 1 - P(Cup 6 is poisonous) = 0.166667. Note that, you get the same answer by substituting n =6 and m=4 in the formula we derived above.

5A5: If Tyrion plays optimally by switching then in the above formula, $$m = n-2$$ (final reveal), the probability of winning is $$\frac{(n-1)}{n}$$ . Now, this expression approaches one as $$n$$  approaches to infinity. Put it simply, larger $$n$$ yields a higher probability of winning. The maximum possible value of $$n$$ is 10 according to rules of our game. The correct answer is 10 and probability is (10-1)/10 = 0.9. (If you have any one of the values incorrect, then you get 50% of the points)

5A6 a) P(cup 6 is poisonous) = 1 - P(cup 6 has water) = 1 - (total_water_cups / total_cups) = 1 - 2/6 = 2/3 = 0.666667

5A6 b) There are two possibilities here:
Possibility one: Cup 6 contains water. The probability for this is 1/3. Of the remaining 4 (1 additional cup has been revealed) cups, one cup has water too. So the probability that this happens is (1/3)*(1/4) = 1/12
Possibility two: Cup 6 didn't have water. The probability for this is 2/3. Of the remaining 4 cups, 2 have water. So the probability this happens is (2/3)*(2/4) = 1/3
Total probability that cup 3 has water = 5/12. Therefore, P(Cup 3 is poisonous) = 7/12 = 0.583333

5A6 c) I have accepted both 'No' and 'Can't say' as the correct answer to this question after discussing with other TAs. There are multiple ways to interpret this problem and I will explain in brief why both might be correct depending on the argument.

The argument in favor of 'No' is that it depends on which cups you switch to -  ""always switching cups"" can mean more than one switching strategy. ""You could switch back to cups you've already switched to or you could switch only to cups you haven't switched to before.Either way, they're two different strategies. Now, not all of the interpretations lead to the optimal outcome, they can't all be optimal, and therefore ""no"" is a valid answer"" (these are the inputs from another TA).Now, due to multiple switching strategies with one being optimal and other not, one can argue that we can't say anything until we have more information. So, I agree with both these answers and have given full credit to both.",jc6w44hrp9v2ki,"[{u'text': u'WIFOM', u'responses': [u'""All right: where is the poison? The battle of wits has begun. It ends when you decide and we both drink, and find out who is right and who is dead"" ""But it's so simple. All I have to do is divine from what I know of you. Are you the sort of man who would put the poison into his own goblet, or his enemy's?"" ""All right: where is the poison? The battle of wits has begun. It ends when you decide and we both drink, and find out who is right and who is dead."" ""But it's so simple. All I have to do is divine from what I know of you. Are you the sort of man who would put the poison into his own goblet, or his enemy's?"" -The Princess Bride 

;)']}, {u'text': u'I made a totally stupid mistake here - I put the probability of the chosen cup being safe, rather than being poisoned, for every question. I got the answers ""correct"" every time, but my submission shows the complement of the ""poisoned"" probability, rather than the ""poisoned"" probability.

It was just intuitive to me that the player would want to measure their _chance of success_ given a cup choice, rather than their _chance of failure_ (its complement). But I should have checked the wording more throughly.

Is there a chance of partial credit for something like this? I think my work shows that I understood the problem, since I have the complement of the correct answer in every one of the questions.', u'responses': [u'I also saw that these were all marked as wrong for me, now that the gradescope grades are out. :(

Could a TA let me know if this is explicitly wrong, or is it worth submitting for a regrade request on these ones?']}, {u'text': u'I asked during the exam and got a clarification that the question “what is the probability cup three is poisoned” was conditional on the prior question, though the question didn’t indicate that. I don’t think that clarification was made public, so I could see how someone who put .833333 for that answer would have a valid argument that the question wasn’t clear about it being a conditional probability. Just wanted to let you know in case the question comes up! ', u'responses': []}, {u'text': u'If ""he plays optimally with his switching strategy"" is not ""switching at every opportunity"", then what is the optimal switch strategy to ensure the probability of winning is (n−1)/n? Is it always switch to the cup never picked before?', u'responses': [u'Wait until the end and then switch']}, {u'text': u'From above:  5A2: Still no information about cup 6. So, P(Cup 6 is poisonous) = 1 - P(Cup 6 is water) = 1 - 1/total_cups = 1-  1/6 = 5/6 = 0.833333

I do not understand this logic. Information has been revealed and a poisonous cup has been effectively removed! Now there are only 5 mystery cups one of which is filled with water -- cup 6 has the same chance of being filled with water as the other 4 unrevealed cups.  So P(Cup 6 is poisonous) = 1 - P(Cup 6 is water) = 1 - 1/total_cups = 1 - 1/5 = 4/5 = 0.80   
', u'responses': [u'Alright.... I read up on Monty Hall problems https://en.wikipedia.org/wiki/Monty_Hall_problem and reluctantly concede!  If Mythbusters confirmed it, I'll go along with it.']}, {u'text': u'Question is not clear. I think you should ask 'we have a stochastic process (discrete) X_t indicates whether cup 6 is poisonous at time t, and F_t is the filtration for the 1st to t-th reveal results. what you ask should be pr(X_0 = 1 | F_1 = {2 is poisoned}), or pr(X_0 = 1|F_4 = {4 of them are revealed to be poisoned}). instead of pr(X_1 = 1 | F_1 = {2 is poisoned}), or pr(X_4 = 1|F_4 = {4 of them are revealed to be poisoned}). the way you ask is easy for me to link to the second probability formulation instead of the first one.', u'responses': []}]",,,,968,,Midterm Question 5A solution,[midterm]
5ad7d4940d63974e20c39215,"Rubric. Full points for correct answer, 50% for rounding errors and zero for an incorrect answer. (Rounding error means that you have either not rounded to six decimal places or your six decimal place rounding is incorrect)
 
5B1 Two cases here.
Case 1: Blue marble was picked first
P(Blue) = total_blue_marbles/total_marbles = 7/11
Now, 10 new blue marbles were added without replacement. Total number of blue marbles= 7+10-1 = 16 and total number of marbles= 7+4+10-1 = 20. P(Blue again) = 16/20
P(case 1) = (7/11)*(16/20)

Case 2: Black marble was picked first
P(Black) = total_black_marbles/total_marbles = 4/11
Now, 10 new black marbles were added without replacement. Total number of blue marbles= 7 and total black marbles= 4 +10 -1 = 13. P(Blue next time) = 7/20
P(case 2) = (4/11)*(7/20)

Answer = P(case1) + P(case2) = 7/11 = 0.636364


5B2: Again two cases here. We know that there were 6 blue marbles in the beginning. Let's assume that there were $$x$$ black marbles and later $$y$$ new marbles were added without replacement.
Case 1: Blue marble was picked first
P(Blue) = total_blue_marbles/total_marbles = $$\frac{6}{x+6}$$
Now, $$y$$ new blue marbles were added without replacement. Total number of blue marbles = $$6+y-1$$ = $$y+5$$ and total number of marbles=   $$6+x+y-1 = x+y+5$$. P(Black next time) = $$\frac{x}{x+y+5}$$
P(case 1) = $$\frac{6}{x+6}\times \frac{x}{x+y+5}$$

Case 2: Black marble was picked first
P(Black) = total_black_marbles/total_marbles = $$\frac{x}{x+6}$$
Now, $$y$$ new black marbles were added without replacement. Total number of black marbles= $$x+y-1$$ and total number of marbles =  $$6+x+y-1 = x+y+5$$. P(Black again) = $$\frac{x+y-1}{x+y+5}$$
P(case 2) = $$\frac{x}{x+6}\times \frac{x+y-1}{x+y+5}$$

Adding these two probabilities we get,
P(case1) + P(case2) = 0.6
$$\frac{6}{x+6}\times \frac{x}{x+y+5}$$ + $$\frac{x}{x+6}\times \frac{x+y-1}{x+y+5}$$ = $$\frac{x(x+y+5)}{(x+6)(x+y+5)}$$. Cancelling the numerator and denominator we get, $$\frac{x}{x+6} = 0.6$$. Solving for x we get answer as 9.

Answer = 9

Update: Although the majority of students understood that we were indeed looking for a general solution, few students interpreted the question in a different way and reached to multiple answers being a correct solution. I have updated their grades. See comments on this post for more details.

5B3: Majority of people got this one wrong. The key thing to understand here is that getting a white ball from bag 1 in the first turn and getting in the second turn are separate events. So, if you have calculated P(B1 | W1,W2) where B1 denotes bag 1, W1 denotes first white ball and W2 denotes second white ball, then you probably got it wrong. Instead, you have to calculate P(B11,B12 | W1,W2) where B11 denotes selecting bag 1 in 1st turn and B12 denotes selecting bag 1 in 2nd turn. We have to find

The correct answer is 147/1133 or 0.129744. Refer to the solution below. 


Update: In my original solution, I applied chain rule incorrectly. Due to no replacement, W1 and W2 are not independent. The updated solution is below.

P(B11, B12| W1, W2) = [ P(W1, W2 | B11, B12) * P(B11, B12) ]  / P(W1, W2) 
= [3/5 * 2/4 * 1/9] / P(W1, W2)
 
P(W1, W2) = total probability of W1, W2 for all cases: 
B11, B12 = 3/5 * 2/4 * 1/9
B11, B22 = 3/5 * 4/7 * 1/9
B11, B32 = 3/5 * 2/5 * 1/9
B21, B12 = 4/7 * 3/5 * 1/9
B21, B22 = 4/7 * 3/6 * 1/9
B21, B32 = 4/7 * 2/5 * 1/9
B31, B12 = 2/5 * 3/5 * 1/9 
B31, B22 = 2/5 * 4/7 * 1/9 
B31, B32 = 2/5 * 1/4 * 1/9 
 
Sum all cases = .2565079364
 
[3/5 * 2/4 * 1/9] / .2565079364 = 0.1299504951 - rounded = .129950",jc6w44hrp9v2ki,"[{u'text': u'', u'responses': [u'Oops. I really goofed on #2 and convinced myself that only a blue marble could have been chosen in the first draw. I need to do probability drills I think to keep myself from making bad assumptions like this.']}, {u'text': u'My answer for 5B3 that seems to accord with yours Sumeet, so hopefully the reasoning is correct; until you get the chance to hand write it
', u'responses': [u'Hoping this is correct too. I had the same as you.', u'I fell into the common trap of not treating bag-pulls 1 and 2 as separate events. I'm trying to get the intuition right for this problem.

On one hand, the correct solution makes perfect sense when I think about it like, ""What is the probability of drawing a white from Bag 1 on the first draw? Okay, now that a white has been drawn, what is the probability of drawing another white out of bag 1? Multiply those together since they are independent events and you have your answer"".

On the other hand, I (incorrectly) think about the problem like this: ""What is the probability that two white balls are drawn from Bag 1 consecutively? What is the probability of drawing two white balls in a row? Divide your first answer by your second to get the answer."" Also, does conditional probability state that P(Bag11, Bag12 | White1, White2) = P(Bag11, Bag12, White1, White2) / P(White1, White2)? I get a different answer with this approach because P(White1, White2) != P(White1) * P(White2 | Bag11, White1)

P(White1, White2) =
   (1/3 * 3/5)(1/3 * 2/4) + (1/3 * 3/5)(1/3 * 4/7) + (1/3 * 3/5)(1/3 * 2/5)
+ (1/3 * 4/7)(1/3 * 3/5) + (1/3 * 4/7)(1/3 * 3/6) + (1/3 * 4/7)(1/3 * 2/5)+ (1/3 * 2/5)(1/3 * 3/5) + (1/3 * 2/5)(1/3 * 4/7) + (1/3 * 2/5)(1/3 * 1/4)

P(White1) = (1/3 * 3/5) + (1/3 * 4/7) + (1/3 * 2/5)
P(White2 | Bag11, White1) = (1/3 * 2/4) + (1/3 * 4/7) + (1/3 * 2/5)
P(White1) * P(White2 | Bag11, White1) = 
   (1/3 * 3/5)(1/3 * 2/4) + (1/3 * 3/5)(1/3 * 4/7) + (1/3 * 3/5)(1/3 * 2/5)
+ (1/3 * 4/7)(1/3 * 2/4) + (1/3 * 4/7)(1/3 * 4/7) + (1/3 * 4/7)(1/3 * 2/5)+ (1/3 * 2/5)(1/3 * 2/4) + (1/3 * 2/5)(1/3 * 4/7) + (1/3 * 2/5)(1/3 * 2/5)

Looking to understand this. Thanks.', u'Thanks for sharing that Mark. I love the formatting on that and that's the correct solution and approach to this problem. Do you mind if I paste this into the original answer? It could save me some time. Thanks in advance', u'Please do :-)', u'Thanks Mark! :)', u'@Edward: Is it okay if we take some time to get back to you on this?', u'Yes, of course!', u'Approached it similar to Edward. Look forward to the response.']}, {u'text': u'Hi, I made a mistake in 5B1 in rounding off. I wrote 0.636363 as my answer, so its off by 0.000001. Is there any partial mark for this error?', u'responses': [u'Tolerance of 0.000001 is allowed.']}, {u'text': u'What is the cutoff of the correct answer for part 3?

I calculated 0.12995 which is abs(0.12995 - 0.129744)/0.129744 = 0.15877% which is about 1.5% off the correct answer.

I think I took a longer path to get the same answer which involved a larger cumulative rounding error, but I'd have to go found my work to show that.', u'responses': [u'I get exactly the same result as you. Here is what I did, and I can't see where it is wrong. I just calculated the probability of the 9 possible combinations (both white balls from B1, first white ball from B1 and second white ball from B2, ... and so on), sum them up, and then divide the first probability (both white balls from B1) value by the sum. If the logic is correct, then I think the difference is just caused by the rounding of fraction number in excel. 

', u'I got the same 0.129950, though I did a lot many calculations. Not sure, what went wrong even after considering all possibilities.', u'Tolerance of 0.000001 is allowed.', u'I got .129950 as well from calculating:
P(bag1, bag1| white1, white2) = [ P(white1, white2| bag1, bag1) P(bag1, bag1) ] / P(white 1, white2)

I think we took a completely different approach to what your solution was, the difference between them I haven't figured out. 

I also separately wrote a program to simulate picking a marble randomly from the three bags without replacement, and then picking another one and then checking to see what the probability of both balls being from bag 1 if they are both white, here are my results of running the simulations: 

100000000 iterations: 0.129959554493
100000000 iterations again: 0.129971667893
100000000 iterations again: 0.129834122362
109999999 iterations (close to as high as I could without getting a memory error): 0.129963503238
109999999 iterations again: 0.129968586006
109999999 iterations again: 0.129912718236

This leads me to think .12995 is the closer answer between .12995 and 129744. 
', u'Also in this boat - having a hard time understanding where this answer goes wrong. ', u'The teaching team has worked on this and we haven't been able to replicate this answer (we did, in fact, arrive at the same answer as the one in the solutions).

It would be helpful if one of you can actually show the exact steps that you took to arrive at the answer given above: we can then verify if it's valid. @Andrew: It is possible that both your solution and Jianhua's have made the same mistake to begin with, so we'd really like to see the exact set of steps and assumptions you made to get this answer.', u'P(B11, B12| W1, W2) = [ P(W1, W2 | B11, B12) * P(B11, B12) ]  / P(W1, W2) 
= [3/5 * 2/4 * 1/9] / P(W1, W2)

P(W1, W2) = total probability of W1, W2 for all cases: 
B11, B12 = 3/5 * 2/4 * 1/9
B11, B22 = 3/5 * 4/7 * 1/9
B11, B32 = 3/5 * 2/5 * 1/9
B21, B12 = 4/7 * 3/5 * 1/9
B21, B22 = 4/7 * 3/6 * 1/9
B21, B32 = 4/7 * 2/5 * 1/9
B31, B12 = 2/5 * 3/5 * 1/9 
B31, B22 = 2/5 * 4/7 * 1/9 
B31, B32 = 2/5 * 1/4 * 1/9 

Sum all cases = .2565079364

[3/5 * 2/4 * 1/9] / .2565079364 = 0.1299504951 - rounded = .129950', u'I've been running the program I wrote that has the 3 bags, with random draw 1 no replacement, and random draw 1 no replacement again, and it seems to be converging to .129950 instead of .129744. 

I even simplified the scenario to two bags, one with exactly 2 white marbles and no other marbles and the other with 2 white marbles and 1 non white marble. Calculating by hand the bayes rule + total probability method I got .375. Calculating it the way the solution is presented currently gave .6. 
If I run a simpler simulation (which allowed much higher trial size) it looks to converge to .375 as well.

Bag one = 2 white marbles
Bag two = 2 white marbles, 1 red marble

P(B11, B12 | W1, W2) = P(W1, W2| B11, B12) * P(B11, B12) / P(W1, W2) 
= [2/2 * 1/1 * 1/4] / P(W1, W2) 

P(W1, W2): 
B11, B12 = 2/2 * 1/1 * 1/4
B11, B21 = 2/2 * 2/3 * 1/4
B21, B11 = 2/3 * 2/2 * 1/4
B21, B22 = 2/3 * 1/2 * 1/4
Sum = 2/3 

[2/2 * 1/1 * 1/4] / (2/3) = .375


Solving it in the method that the solution was presented: 
P(B11, B12 | W1, W2) = P(B11 | W1) * P(B12 | W1, W2, B11)

P(B11 | W1) = [P(W1 | B11) * P(B11)] / P(W1) = [2/2 * 1/2] / [ (2/2 * 1/2) + (2/3 * 1/2)] = .6

P(B12 | W1, W2, B11) = [P(W2 | B12, B11, W1) * P(B12 | W1, B11)] / P(W2 | W11, B11) 
= [1/1 * 1/2] / [ (1/1 * 1/2) + (2/3 * 1/2)] = .6 

P(B11 | W1) * P(B12 | W1, W2, B11) = .6 * .6 = .36

Running a simple simulation with the two bags, with randomly picking a bag, randomly draw one marble with no replacement, randomly pick bag, randomly draw one with no replacement -> Gives the probability of both being from bag1 if they were white converging to .375. I can post my (not so pretty) code if needed. 
', u'This looks like it's the same as the question I replied to the solution with, if that helps in figuring out where this came from. ', u'Yeah, I just would like to understand where I'm going wrong with the hand calculations and also the simulation. Albeit, I'm not too good with probability questions and also not very good at python programming but it's driving me kind of nuts that both methods converged to an answer that was incorrect. I have my fingers crossed that the posted solution has some kind of monty hall-esque mistake happening somewhere. ', u'To be honest, I question about the logic of calculating the two probability of P(B11 | W1) and P(B12 | W1, W2, B11) separately, and then multiplying them together. This logic implies that drawing ball 1 and ball 2 are two separate events, since it calculates a global probability for P(B11 | W1), and then calculate another global probability for P(B12 | W1, W2, B11). However, since we draw the balls with NO replacement, the outcome of ball 1 will affect ball 2 at every round differently, depending on whether ball 1 and ball 2 are from the same bags. Thus, we need to consider all 9 possible combination of bags (B1B1, B1B2, B1B3, B2B1, B2B2, B2B3, B3B1, B3B2, B3B3) explicitly in each round. I doubt whether we can still calculate the probability for B1 and B2 separately, and then simply multiplying them together?

According to the problem description, we finish one experiment after drawing two balls from the three bags, thus It is more intuitive to me to consider drawing B1 and B2 as one single event. I also think this logic is consistent with the simulation we can set up. That is the reason why Andrew's simulation will converge to 0.12995. 

', u'I think I found the discrepancy between the two methods. 

In the solution it does: 
P(B11, B12 | W1, W2) = P(B11 | W1) * P(B12 | W1, W2, B11) 

But according to the chain rule: P(A, B | C, D) = P(A | B, C, D) * P(B | C, D)
so it should be:
P(B11, B12 | W1, W2) = P(B11 | W1, W2) * P(B12 | W1, W2, B11) 
[note the A,B,C,D variables aren't lined up, I went with the ordering in the original solution just to be consistent with it]

it would only be P(B11 | W1) * P(B12 | W1, W2, B11)  iff P(B11 | W1, W2) = P(B11| W1) 
but P(B11 | W1, W2) does not equal P(B11 | W1)  since B11 and W2 are not conditionally independent given W1. 
You can also calculate out P(B11 |W1, W2) and P(B11 | W1) and see that they are not equivalent. 

If you account for this difference in the solution, the answer becomes .129950 instead of .129744
I believe this is a mistake in the solution and that the real answer is .129950. 
', u'In case it is proven to be .129950, do we need to request regrade? Or it will be updated automatically? :)', u'I am taking a look at both solutions and re-evaluating both right now. If someone can explain their solution in my OH hour right now, I will appreciate it.', u'Update: Full credit for answer 0.129950 has been awarded. I have verified the solutions posted above and Andrew pointed out that the chain rule in the original answer is not applied properly and I agree with it. If any other student disagrees, please comment. For students who have answered 0.129744, please refer to Andrew's comment above and I have to discuss with other TAs if we should give 0 or keep your score same. I will post an update as an when it happens', u'You're quite possibly right
Maybe someone should try to put together a Bayes net graphic representation? Or justify the conditional non-independence in English, that may be more work than the graphical representation. My instinct says they are independent, although conditionally independent given $$W_1$$ is more thorny

Incidentally, to write $$\LaTeX$$, ��P(B_{1,1}|W_1)��– with normal dollar signs, natch – makes $$P(B_{1,1}|W_1)$$, it makes much easier reading & parsing :-D', u'Update. I ran a simulation and I got 0.129959554493. Grades have been updated based on that. All other solutions have been marked as incorrect. Sorry for the inconvenience.']}, {u'text': u'Any partial marks for getting answer wrong by Delta of 0.001. As this question is of 1.5 marks and any calculation mistake will cost complete points.', u'responses': [u'I think the common mistake had 105/804 rather than 147/1133>>> 105./804 - 147./1133
0.000852972559971521 so it may not merely be a calculation mistake', u'Although the decimal values are very close, 105/804 is incorrect and moreover, tolerance of 0.000001 is allowed.']}, {u'text': u'I think another possible answer for 5B2 should be can't be solved/multiple answers exist. The question didn't specifically say this was for the general case. To me at least, it implied that this event of pulling a marble and replacing it with a single marble occurred once -  for which there are many possible answers. 

For instance: 6 blue, 1 black. Black is picked and replaced by 9 black. 
Or - 6 blue, 12 black. Blue is picked and replaced by 3 blue to give 8 blue, 12 black which also equals .6

I know the solution posted was for the general case where the marble could be pulled multiple times, different marbles could be picked, and y is fixed (I believe the answer has to be y = 1), but the question doesn't indicate this at all. 

Please let me know if I'm incorrect anywhere in this thinking. ', u'responses': [u'Yea, I put on mine that there were multiple answers as well (and gave my answer as 12 with your exact example just to make sure I had a specific case as well).  It seemed to me there were too many unknowns to actually properly calculate this.', u'Exactly. I would even argue the assumption for the general case cannot be made here at all because the question specifically says ""Now"" multiple times. 

""In a bag, there are 6 blue marbles and unknown number of black marbles. Now, one marble is picked and is replaced by unknown number of new marbles of that color. Now one more marble is drawn out and the probability of that marble being black is 0.6. How many black marbles were there to begin with?"" 

This event happened exactly once. The marbles weren't reset to the original setting with both unknowns fixed and then the scenario repeated an infinite amount of times. ', u'The answer of 9 doesn't depend on there being infinite trials or anything like that. If a single marble is picked during event 1 and you are uncertain about its outcome then you have to propagate that uncertainty into event two's outcome by considering the chances of both possibilities occurring in event 1. You do this by using the law of total probability:

$$P(A) = \sum_nP(A,B_n) = \sum_n P(A|B_n)P(B_n)$$

In this case event A is the second marble being black over the possible event Bs which were first marble being blue and first marble being black.', u'I understand the answer and your explanation. But, what I am arguing is that based on the wording of the question we can't just assume such a probability calculation. 

The current wording is such that there are many possible answers. For example: 

Say there were 6 blue and 2 black marbles, the 1 black marble was picked, and replaced with 8 black marbles. 
That would render this statement a true statement: 
""In a bag, there are 6 blue marbles and [2] black marbles. Now, one [black] marble is picked and is replaced by [8] new marbles of that color. Now one more marble is drawn out and the probability of that marble being black is 0.6. How many black marbles were there to begin with? "" 

If someone did this exact thing, and asked this exact question and someone else answered 9, it would be incorrect in this instance. 

I think the problem is the question is phrased with ""How many black marbles were there to begin with?"" vs ""What is the probability of something"".

', u'I gave two other equally suitable possibilities (1 black ball originally there and picked, 9 balls added).   60 black balls there, blue ball picked, 35 blue balls added.   Both result in a situation where the probability of the next picked ball is black being 0.6.', u'If you fill in any of the unknowns then you're answering a different question. This question is asking for the number of black marbles such that the probability of pulling a black is 0.6 while not knowing what the first pull was.  ', u'Putting X and Ys in an equation is essentially filling in the unknowns... the 9 that you are specifying is filling in an unknown.

My point is that there are many other possible values that can meet the requirements of the question without being a single fixed value.  You can have 60 black balls in the bag and still end up with a P(black) being 0.6.  The explanation of how you get there is simply an explanation.  

I don't believe you can assert realistically that it is impossible to have a number of black balls other than 9 and get to a probability that the next ball picked is black of 0.6.', u'In fact, 9 black balls only works if you require that the 2nd unknown number of balls is exactly 1.  Any other of balls replacing the pulled ball will not result in a probability of 0.6.', u'""This question is asking for the number of black marbles such that the probability of pulling a black is 0.6 while not knowing what the first pull was. ""

So, what the others and I are trying to say is that according to the wording of the question, that is not what it is asking (I can see that is what they wanted it to ask). Instead it's asking something more similar to: 

There's a bag with 6 blue marbles and some black marbles. A marble was taken out, and an unknown number of marbles of that same color were put back in. Another marble was taken out, and the probability of it being black was 0.60. How many black marbles were there to begin with? 

vs 

There's a bag with 6 blue marbles and some black marbles. On an iteration, a random marble is taken out and replaced with an unknown number of marbles of the same color. How many black marbles must there be initially to guarantee that the probability of a black marble being picked on the second iteration will always be 0.60?

(even in the second form of the question I think it may need the phrase ""Assuming that the unknown number of replacement marbles allows the probability of a black marble being drawn on the second iteration to be 0.60. "" before the last sentence)
', u'I interpreted this question as asking: ""Give a possible number of starting black marbles, such that after replacing an unknown number of marbles, the probability of drawing black is 0.6"". There are certainly many possible such starting configurations, but the question was just asking for any one of them. I gave 12 as a specific example (using the same reasoning as Andrew Lum above).

The calculation above seems to be answering a related, but different question, which is: ""Choose the starting configuration which maximizes the probability P( B==0.6 ), where B is the probability of picking a black marble."" That maximization question was not what was written in the exam.

Given a question with probabilities, you can't just leap to the conclusion that you should attempt to maximize them.', u'""The marbles weren't reset to the original setting with both unknowns fixed and then the scenario repeated an infinite amount of times."" Our solution doesn't imply that anywhere. We're simply looking for one answer that always answers this question.

The use of ""now"" in our question also implies sequential events (now, as in after the previous events). I don't see how that changes the answer at all, please explain?

As for the problem of ""y being fixed"", if you give us another answer, the question ceases to be true unless you provide additional information apart from what is already given in the question. Am I wrong? It just turns out that the conditions in our question lead to y having a possible value of just 1.

The reason we are unable to accept this answer is because of that very reason - it requires additional information in order to be true. It does not always answer the question we have posed. In fact, this problem is very similar to 5B1 - the solution is pretty much the same except for the extra unknown.', u'Yes, I agree that now implies sequential.

Are you saying that having one black marble in there, it getting chosen and replaced by 9 black marbles is not a possible sequence of events?   That it would not result in the probability of 0.6 that a black marble would be chosen?

That appears to be a possible sequence and from the wording of the question a legal possible sequence.  Is their something in the question that I am missing that would eliminate that sequence?', u'Also, are you saying that something in the wording of the question makes it impossible that the unknown number of replacement values is other than one?  That it's impossible to replace the marble with two marbles of the same color?  Because if that does take place, the probability that the next marble chosen is black would not be 0.6.

I don't see that restriction in the wording of the question.', u'Hi Ravikiran, 

 "" ""The marbles weren't reset to the original setting with both unknowns fixed and then the scenario repeated an infinite amount of times."" Our solution doesn't imply that anywhere. We're simply looking for one answer that always answers this question. "" 

- My mistake on the infinite scenario description, yes you don't need infinite scenarios. But, 9 doesn't always answer this question as shown by the other possibilities shown. While 9 is the general solution if you solve for x, there are numerous (I think infinite, but haven't tried to prove that yet) cases where 9 would be incorrect answer to the question if someone grabbed a bag and did exactly what the question said. 

- I was trying to say that ""now"" implies the question is happening in the present tense and thus the question was being asked in real time, but we can forget about this as it might get too messy to explain what I was thinking. 
 
As for the problem of ""y being fixed"", if you give us another answer, the question ceases to be true unless you provide additional information apart from what is already given in the question. Am I wrong? It just turns out that the conditions in our question lead to y having a possible value of just 1.

- What we're trying to argue is that the conditions of the question aren't as restrictive as I know you were intending, and that to assume beyond that could be argued to be a mistake. The conditions of the question are: 
There's a bag with 6 blue marbles and some black marbles. 1 was randomly drawn out and replaced by some number of marbles of the same coloranother was drawn out and has .6 probability of being blackHow many black marbles were there at the beginning?
We are arguing that there are many possible combinations that could have happened in this case that also satisfy those series of statements. 

 ""The reason we are unable to accept this answer is because of that very reason - it requires additional information in order to be true. It does not always answer the question we have posed. In fact, this problem is very similar to 5B1 - the solution is pretty much the same except for the extra unknown."" 

- In my opinion, the question would require additional information to assume the calculations that lead to 9 being the solution. The question would have to say that this scenario could occur more than once, that the solution needs to be .6 for all cases (pulling blue or black marble), and that the unknown replacement number also stays the same. The question as it is worded now only happened once, and such there are many possible solutions that lead to that chain of events that aren't incorrect.  

Sorry, I don't mean to be hard on everyone, I'm just trying to explain my position (and apparently many other's position) on these probability questions as clear as I can. Perhaps someone who is better at explaining can explain it clearly. 



', u'I have a feeling that I'm in the Monte Hall problem solution denier category with this question's answer.  There's something I'm not understanding in how the pieces are put together that make this obvious to the instructors/TAs (and, clearly, several other students).', u'So the posted solution is correct if you take into context the class, what section the question was in, and also make the additional assumption that they want the general mathematical answer. What I mainly was just trying to argue was that the people who put as their answer - that there were multiple answers followed by some examples - should get some credit as the question in the current form is not well worded, and if you take each sentence literally line by line you can put in multiple answers that will cause the ""story problem"" to be true.I actually started out on the exam calculating the ""academic"" answer before I realized that the question was worded (at least in my opinion, worded clearly) such that multiple answers could satisfy the sentences and thus I ended up going with the multiple answers route. 

I still don't think I'm explaining it well to the people who automatically made the assumption to calculate the mathematical answer, but here's another comparison: 
If some one went up to you and told you that they had a bag with 6 blue marbles and some black marbles, that they took one out and replaced with with some number of marbles of the same color, and that the probability of picking a black marble was now .6, and then they asked you how many black marbles they had at the beginning: If you say 9 you can definitely be wrong in many cases (maybe infinite, though I haven't really thought too hard about that). For example they could have just had 2 black marbles and then replaced 1 with 8 marbles in this sequence of events. 

The word problem is phrased such that it happened just once, and since it happened just once there's actually many different sequence of events that could cause that outcome of a probability of .6. 

Now, if the same person who went up to you originally told you that they did the sequence of events twice, and that the second time they did it, the marble being replaced was a different color than the one that they pulled out the first time they did it; then, with this additional information you can calculate that they had to have started with 9 black marbles. 
', u'I have thought about this issue from the perspective of a student who is reading the question for the first time and I see where the confusion lies. Will give credit to students who have mentioned multiple answers possible with an example or an explanation.']}, {u'text': u'For those that like bayesian modeling or probabilistic programming, here's a cool way to solve this problem using the probabilistic programming package PyMC3:

I used a uniform prior over some reasonable guesses for the number of unknown black marbles and number of replaced marbles and then run MCMC to find the posterior distribution of black marbles that would produce a 0.6 probability in some made up data. All of the posterior distribution is pushed onto the value of 9 in this case.

 ', u'responses': []}]",,,,970,,Midterm 5B solution,[midterm]
5ad7d4940d63974e20c39216,"Hey everyone,
The Midterm Exam grades have been released on Gradescope.
 
The tentative statistics are as follows:

Mean75.48Median77.55Standard Deviation13.32

Note that these stats will change based on regrades and people who drop the course. We will release the final grades on T-Square after regrades on Friday, and give the updated statistics in a separate post.

Please go through the solutions post @940 before you make a regrade request. Please keep in mind that if your answer matches one of the answers explicitly mentioned as incorrect, the TAs may deduct points for an invalid request. You can make regrade requests through Gradescope, and can do so until 15th March, 8PM Eastern.

Please note that some of the questions do not have solutions posted yet. Please do not submit a regrade request until you have a look at the solutions to find out where you've gotten/lost points!

",jc6w44hrp9v2ki,"[{u'text': u'Awesome job on the quick turnaround in grading.  It is really appreciated.', u'responses': [u'!!!', u'Agreed! I am half-convinced they must have some AI auto grader they used for this.', u'Yes, Thank You for such a fast turn around.  Greatly Appreciated!!', u'There is some AI autograding in gradescope, mainly for the MCT questions. Even so, it needs human supervision', u'� �� � a truly massive achievement!']}, {u'text': u'Question -- As students drop the class today, and previously, does the Median get re-calculated for grading?

I am on the cusp with my grades in the lower middle, and struggling in the class, but Love the topic and want to push through. ', u'responses': [u'+1', u'I'm in the same boat as you.  I've put a lot of time and effort into this class and it has been a struggle for me, but I've decided to stick with the class to the end.  The syllabus mentioned to not focus so much on the grades and to focus on learning, so that's the approach I'm trying to take.  If my grade works out to be a B or better, great!  If not, so be it.  At this point I'm just pushing as hard as I can to the end.', u'Same here. Trying not to get discouraged, and pushing through to the end...', u'A thought for everyone making decisions is that assuming a normal distribution for the grades at the end, ~50% get an A, ~34% get a B, and ~13.6% get a C. Depending on your specialization and circumstances, a C may be the worst grade you can achieve without having to retake the class and delay your completion. 

So decide accordingly if you think you can achieve the top 84% for a B or higher or the top 97.6% for a C or higher. I did awful on assignment 2, as in well below the median. So I'm making my decision accordingly.

Just food for thought.', u'All,
Thank you for your perspectives!  I am going to push through and stick it out!  At the very least I will be making up the new ""bottom"" to help with the median for everyone else :-) .', u'All right you've convinced me.
Grades: 
Assignment 175Assignment 264Assignment 371Assignment 40Assignment 50Assignment 60Midterm Exam70.74
With 8 As and 1 B in the program, even an F won't sink me.  It's worth the risk of a bad grade for a chance at a B and being finished by the end of April.Worst case scenario I'll be taking AI again or ML instead.Sticking it out.', u'You can do it Chris. And even if you don't, I would retake the class as it doesn't change much from semester to semester and copying your own code isn't cheating. I noticed there are a few here where this is their second iteration.', u'Thanks, Brett.   The appeal of ML as an alternative is that I will have covered the material in this course, albeit perhaps poorly, and ML would be new ground.Also, the curve is generous and based on the mean.  But let's just hope I can pull this one out.', u'OTOH I think neither AI nor ML is offered this summer, so I would have all summer to perfect my AI code and to study.', u'The instructors have not created an environment beneficial to learning. Game theory tells us to maximize our own grade and minimize the grades of our classmates', u'Anyway I hear the class only gets easier from here and everyone in the reviews ended up doing better than they expected so if you're worried you should stay the course ;)', u'I thought the curve was based on the median...', u'The Machine Learning course curve, if you're referring to what I wrote.
Granted, I am assuming it's the mean.
""The material is alien, the math is dazzling, and the projects will take a long time; that said, there is a generous curve. IF you at least hand SOMETHING in / make an attempt, you will get a B. This is an endurance class, so hang in there!""https://omscentral.com/courses/CS-7641', u'Having taken ML, I would say that ML mean and median are pretty darned close. Also the curve policy is similar to AI - about half As. It's hard in a different way, though. Both good learning experiences. ', u'Thanks, Jonathan.']}, {u'text': u'Can I request that all the grades (assignments and midterm) medians/mean and std dev be redone after the drop date? I am nervous about my grade and want to see how it is affected after the fact.', u'responses': [u'me too, but seems like it will only get worse...and then too late to drop...but I'm sticking it out...', u'Yes, we'll release updated stats after drop day, probably sometime next week.', u'Thanks Ravi, appreciated.']}, {u'text': u'If we are still discussing solutions to the exam in the Midterm Solutions posts, should we submit before the regrade window closes? Will we be penalized for submitting a regrade request for problems that are still under discussion and might be concluded after the regrade window closes? ', u'responses': [u'We had kept them open while disputes were being resolved, and I believe these disputes were resolved without needing regrade requests to amend the grades. The window is closed now, and we will try to release the grades to T-Square as soon as possible.', u'Hi Ravi, 

We still have no TA response regarding partial credit on Q4B2. Maybe a TA could go to that thread and explicitly reply that Q4B1 and Q4B2 are essentially the same question and confirm that an error on 4B1 will result in losing 3+ points on 4B2? In principle, I don't think that was the original intended outcome given that the 4B1/2 were presumably separated (2 points vs. 4.5 points) for a reason. 

As it probably doesn't matter to my final grade, I haven't pursued the matter. However, I wouldn't characterize the issue as ""resolved"".', u'Apologies. I believe this has been answered now.', u'Thanks Ravi. There's a lot of questions - easy for something to slip through the cracks.', u'Hi Ravi, 

I just noticed on Gradescope that one of my regrade requests was marked as ""given credit"" but the score still shows it as marked incorrect. Just wanted to make sure this wasn't a mistake, am I able to resend a regrade request? If not, it's not too big of a deal. ', u'Could you tell me what question it was on?', u'5B2']}, {u'text': u'when should we start to be concerned that our midterm grade hasn't shown up on T-Square?', u'responses': [u'We still had to resolve a few cases where we couldn't find submissions for certain students. It has been fixed now, and the grades have been released to T-Square.']}]",,,,972,,Midterm Grades released on Gradescope,"[midterm, grades, announcements]"
5ad7d4940d63974e20c39217,,jc6w44hrp9v2ki,[],Marking as resolved.,,,974,,delete,[other]
5ad7d4950d63974e20c39218,"
Accuracy: 96/195=0.492308 

What is the precision of :

Bumps_into :1/8=0.125 

Weaves_and_bumps_into: 0/9 =0 

Bumps_into_each_other: 1/6= 0.166667

 
What is the recall of :

Bumps_into : 1/15= 0.066667 

Weaves_and_bumps_into: 0/15= 0

Bumps_into_each_other: 1/9= 0.111111


Check the statement(s) that are always true. (2 points)❏ Accuracy hides information on the specific nature of errors.  - TRUE. ❏ Precision can be calculated without knowledge of the negative classifications of arecognizer.
TRUE. Precision= TP / (TP+ FP)
No Negative classifications are needed. 
❏ Recall can be calculated without knowledge of the negative classifications of arecognizer.
FALSE. Recall = TP/ (TP+FN)
Negatives are needed. 
❏ When calculating precision over the entire recognition task for a multi-classproblem, one drawback of precision is that it is heavily affected by changes in thedistribution of instances across classes (class skew).
TRUE. 
",jc6w44hrp9v2ki,"[{u'text': u'Ugh, I put the precision numbers in the recall question and the recall numbers in the precision question.  Of all the silly mistakes to make!', u'responses': [u'Same here :-(', u'Same here. I even asked for clarification on this part, and got pretty much nothing as a response. A little frustrating.', u'Same..']}, {u'text': u'For True/False option 4 - When calculating precision over the entire recognition task for a multi-class problem, one drawback of precision is that it is heavily affected by changes in the distribution of instances across classes (class skew).

Shouldn't this be True when ""calculating accuracy"" (instead of precision) in the statement?
Precision is calculated per class, so it should catch problem of skew as it's not an aggregate (like accuracy).', u'responses': []}, {u'text': u'Instructors,
Regarding:

Accuracy: 96/195=0.492308

Can you explain how the calculation was made? Is this value:



Thanks', u'responses': [u'Not an instructor, but you can simply think of it in this way:All of the predictions the system got correct/Total number of predictions

The computer predicted correctly in the case where the Ground Truth Labels and Predicted Labels matched.

Correct Labels = 15 + 9 + 14 + 3 + 14 + 5 + 11 + 11 + 9 + 3 + 1 + 0 + 1 = 96
Total Labels = All predictions added up (sum entire table) = 195', u'Can you post the number of FP and FN please? I would like to understand where I went wrong with this. I got the 96 number correct.']}, {u'text': u'What is the number for:

TP
TN
FP
FN

???

', u'responses': []}, {u'text': u'', u'responses': [u'--Delete this--
I understood accuracy answer now!', u'Instructors, Any answer on the breakdown of the variables? Or endorsement of an answer?']}]",,,,984,,ML Question A Solutions,[midterm]
5ad7d4960d63974e20c39219,"Assignment 4 Youtube Live SessionI will be hosting the Youtube Live session for Assignment 4 on Wednesday, March 14, 10.30 pm EDT. 
Updated Link
http://youtu.be/OtqsrK9-o4Q
I will go over the assignment briefly, the Kaggle Competition and some points that might be helpful. 

I will also try to answer the most common questions that have been raised. 


",jc6w44hrp9v2ki,"[{u'text': u'That was a quick video...', u'responses': [u'I am sorry there were some audio issues. I should be up in a few minutes. ', u'I have updated the link.', u'Thanks. No screen share as some commented on youtube. Maybe you can add it in later?', u'Uh oh, building closing down. That's cool that GT buildings have automatic shutdowns now after hours.']}, {u'text': u'We can't see your screen, not sure if you intend to share screen while going through the code.
', u'responses': [u'Agree, without screen sharing, both the live and the recorded version will be of limited help. ', u'I already have screen sharing on. ', u'can't see it for the entire session. ', u'Ohh. ', u'I will try to upload a video with my screen shared on it. You should have told me earlier about this. I am sorry, I am new to this as well. I hope it doesn't happen the next time. ']}, {u'text': u'Do you think that implementing Boosting would help with accuracy for the challenge classifier?', u'responses': [u'Yes!']}, {u'text': u'Does the Kaggle submission file include the code containing the classifier? Or just the predictions?', u'responses': [u'Thank you!']}, {u'text': u'What do we need to do to improve Random forest accuracy?', u'responses': [u'Thanks. I'll try it out.', u'To follow up, my random forest training takes about 15 min, so tuning the parameters such as depth limit and number of trees will take a while. Any suggestions on this, or something I did wrong that leads to a long training time? Thanks. ', u'I have not needed parameters that take that long to train on the challenge classifier data. But because these parameters cannot be tuned easily by a usual gradient descent approach, brute force methods like grid search is usually the way out.
You can try with experimenting with ones like depth limit using the depth of a Decision Tree built using all the training data and then get an idea of the values that you should try setting it to. ']}, {u'text': u'Are there any alternative endogenous approaches to using greedy feature splits when creating decision trees?  Or are creating trees with greedy feature splits, within a context of random forest (randomly subsampled features and data points), the prevailing approach?', u'responses': [u'The greediest idea is to split by the feature that has the most information gain i.e. gives you the most information when you split the dataset based on that feature. The idea of Random Forests, with its subsampling parameters, is to generalize the model i.e. have the model not overfit the training data and be a better classifier for any unseen data. ']}, {u'text': u'When building random forest, do we choose attribute with replacement or not? Thanks. ', u'responses': [u'We subsample randomly from the attributes and examples with replacement. ']}]",,,,989,,Youtube Session Assignment 4,[a4]
5ad7d4960d63974e20c3921a,Will the Final exam be cumulative or will it cover only the material presented after the Midterm exam?,jc6w44hrp9v2ki,"[{u'text': u'Can it please please please not be a take home.', u'responses': [u'it's a take home

it has been a take home for the past two years. Don't think it will change']}]","https://docs.google.com/document/d/1BkFYxRrq0XXsarHe8JeBou03kHuWp6d_kWCQgjGezdU/pub

it's cumulative",,,993,,Final Exam content,[final]
5ad7d4970d63974e20c3921b,Has anyone here seen their bonus points from assignment 1 added to t-square?,jc6w44hrp9v2ki,[],,,,996,No - I asked about it and received a response saying that it would be added as a separate graded item near the end of the semester.,bonus points from botfight,[a1]
5ad7d4970d63974e20c3921c,"Hi, 

I am facing the usual issues after having enable 2FA. I am using windows. Can someone help with clearer instructions. I downloaded the jwt file, renamed it, gave it the .json extension copied it into the folder with submit.py  and in the AppData\roaming\nelson folder . Created an environment variable called APPDATA with the path upto the roaming folder. Updated the jwt with the latest after going to the link - nothing works and I get the same 
ValueError: Username and password failed (Do you use two-factor?)

What else am I supposed to do to get it to work?",jc6w44hrp9v2ki,"[{u'text': u'I'll start out by admitting that I don't run windows, I have a Mac and use a Linux VM for all my class work.

That said, there are a few things you listed that I don't think you should have to do.

The instructions that I see don't say that you should add the `.json` file extension - And I can say for certain that my Linux environment does not have the extension.  Verify your file name in the command line, as often GUI file explorers will hide them by default, meaning your file may actually be named eg 'jwt.json.json'.You shouldn't need to create an environment variable for APPDATA - This is a standard Windows environment variable.  In a command line, type `echo %APPDATA%` and you should see the directory name (remove your custom added environment variable).  Unless you have a customized windows install, it should be similar to `C:\Users\<username>\AppData\Roaming`Make sure that you have two copies - Looking at the instructions (https://bonnie.udacity.com/auth_tokens/two_factor), there is the legacy folder.  From my reading, you'd want to copy the file to the following two directories (replacing %APPDATA% with the output of the `echo` statement in #2) - Note that neither of these include a file extension:%APPDATA%\nelson\gtomscs_jwt%APPDATA%\bonnie\jwt

As said above - Good luck!
', u'responses': [u'Hi Chris, thanks for your response. All of the changes were incremental - like I didn't force the .json extension, it didn't work - then I tried with it and it still didn't. Likewise for the APPDATA env variable. Tried everything - all permutations, don't know what else I should do', u'Hi Harsh - One other thing you could try - The source code to Nelson is available (I'd bet that PIP installs it somewhere that you can actually edit the version that is running in place - sorry, Python isn't a language I speak fluently yet, so I can't tell you where/how to do so).  Looking at the source code available on the web (https://pypi.python.org/pypi/nelson/0.4.0), seems like you could add a print statement in the `build_session` function found in `gtomscs.py` to let you know specifically where it is looking.  Glancing at the source code (and admittedly not knowing anything with certainty), I wonder if the code won't work as expected on a 64-bit windows environment - Look at `sessionbuilder.py` in the `default_app_data_dir()` function - I don't know if a 64 bit windows would evaluate `sys.platform == 'win32'` as True or False...', u'Oh - another option - update the `submit.py` in the assignment source code, change the line that currently says `submit('cs6601' 'assignment_4', filenames)` to `submit('cs6601', 'assignment_4', filenames, jwt_path = './gtomscs_jwt')`, and put your token in the current assignment folder with a name of gtomscs_jwt (no extension).', u'err - sorry, maybe windows would rather have a backslash; maybe that should have been `jwt_path = os.path.join('.', 'gtomscs_jwt')`.']}]",,,,999,Good luck. I had had/have the same problem in both Mac and Windows 10  (posted on 2/25).  I had several good suggestions by other students. Unfortunately nothing worked. TA could not help and the school does not appear to have a technical helps desk for students. I even tried the Udacity helps desk but they never responded. :-(,Two-factor authentication issues,"[a4, python]"
5ad7d4980d63974e20c3921d,"On a lighter note, here's a fun paper listing various times AIs have discovered amusing or unexpected ""solutions"" that weren't quite what the human programmers had in mind. 

Title: ""The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities""
https://arxiv.org/pdf/1803.03453v1.pdf

I particularly liked the ""Tic-tac-toe Memory Bomb"", where a game playing AI learned to pick moves that would cause its opponents to crash. And the ""Elbow Walking"" robot, where the AI learned it could minimize the time its feet touched the ground by flipping itself upside down.

Enjoy!
",jc6w44hrp9v2ki,[],,,,1005,,Anecdotes of unexpected AI behavior,[other]
5ad7d4980d63974e20c3921e,"The assignment instructions state:

NOTE: We are only allowing four imports: __ future__.division, numpy, collections.Counter and time. We will be checking to see if any other libraries are used. You are not allowed to use any outside libraries especially for part 4 (challenge). Please remember that you should not change any function headers.

However, I am using a boosting algorithm that needs e^x and natural log. Are we allowed to use the math library to have access to those two functions?",jc6w44hrp9v2ki,"[{u'text': u'Oh awesome thank you.', u'responses': []}, {u'text': u'I'm using deepcopy in mine, that is ok too correct?  Seems like a standard thing to have.', u'responses': []}, {u'text': u'Is there a version requirement for numpy? In the previous assignment it was 1.11 which is a bit outdated... I'm looking to use a newer version actually.', u'responses': [u'1.12.0. I think every assignment comes with a requirements.txt file for you to pip install.']}]",,,,1006,Numpy provides those two functions as np.log and np.exp,Assignment 4 Imports,[a4]
5ad7d4980d63974e20c3921f,"are standard library imports allowed?

I am using:
import operator
import random",jc6w44hrp9v2ki,"[{u'text': u'I'm also using a standard lib (deepcopy).  I would think this would be ok.  I feel like the purpose of all of these projects is to implement things from scratch, so to avoid using implementations that can be found elsewhere, so importing those sorts of things is not allowed.', u'responses': []}, {u'text': u'@Arjun:  Keep in mind that NUMPY is already imported. so you have numpy.random already, generally considered (I think, though not a python expert) a better random library than the python random (at least equivalent). ', u'responses': [u'Yeah , given that the deadline is only a few hours away, I decided to rework the code to avoid external libraries. After looking at the medians in the last two assignments , don't think anyone can risk having points docked for stuff like imports.']}]",,,,1009,,Assignment 4: Standard libraries?,[a4]
5ad7d4980d63974e20c39220,"This week you should start Lesson 8, Pattern Rec Through Time (through New Observation Sequence for “We”), and read Chapter 15 in Russell & Norvig.  Additional readings can be found on the course schedule.  
Be sure to complete the mid-course survey on T-Square by tonight!

Assignment 4:  Decision Trees
Due: March 18 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 4 is due tonight! Please check @612 for details. The Kaggle competition is due next week; please check @910.

Assignment 5: Expectation Maximization will be out soon. Please stay tuned for more!

Midterm Grade Release: We had earlier said that we would release the grades to T-Square by Friday, but we still had a few mistakes and disputes to resolve. We have had to push the release back by a couple of days, but will make an announcement and release updated stats when it’s done. We apologize for the delay.

Office Hours: This week is Spring Break at Georgia Tech. As most of the TAs are on-campus students, we may not be holding Office Hours, and response times on Piazza may be longer than usual. 
As always, here are the OH calendar, the syllabus and the schedule.

",jc6w44hrp9v2ki,"[{u'text': u'According to the syllabus, Assignment 5 is going to be released this week, is this the case?', u'responses': [u'Yes.']}, {u'text': u'I have international version of AIMA book.  Somehow I am not able to relate video content of Pattern Rec Through Time to chapter 15 in the book title as ""Probabilistic Reasoning over Time"". Are they same ? or international version is missing relevant material.', u'responses': [u'The diagrams used are different in the videos and the book, I believe. However, the topics the concepts dealt with have considerable overlap.']}]",,,,1012,,Week 11 Announcement,[announcements]
5ad7d4980d63974e20c39221,"Hi, 

For Kaggle Challenge, could someone assist me with where to use seed() method. Should I use it in the generate_kaggle_submission.py or in my decision_trees_submission.py file? Also, do we need to use seed() method every time we call random or we can call it just once (say in Challenge classifier class) and it would generate results as expected?

Thanks",jc6w44hrp9v2ki,[],"Hi Rupal,
You may call the random seed when you start off the whole process as in before you start subsampling. You can do it in any file you prefer.",,,1013,"Put it where you think it should be, run generate, rename kaggle results, run again, do a diff.",How to use random.seed(),[a4]
5ad7d4990d63974e20c39222,"I started looking at some image processing with numpy to get ready for the next assignment.  From what I have seen, images will be a 3d array (x, y, vector of RGB values).

I'm still a numpy noob and am wondering from the numpy ninjas in the class, what is the best way to iterate over an image array in order to access each rgb vector while also retrieving an index for each vector when that vector is iterated upon?  I am trying to avoid nested for loops.",jc6w44hrp9v2ki,"[{u'text': u'To best answer your question, I would need to know:

1.  What will you be doing to each RGB vector when you access it? (Also, ensure the color channels are in the order you expect. If you are reading .jpg images into numpy arrays using OpenCV's imread function, the ordering will be BGR, for example.)

2.  What are the outputs (and their format) that you would like to produce?', u'responses': []}]",,,,1019,"You are looking for numpy.ndenumerateHowever, one of the great things about numpy is how fast it does operations over entire arrays (which was the point of the last question on assignment 4). If you find yourself iterating over the array, consider trying to do a vectorized operation instead. ",fastest way to iterate over a ndarray with keeping track of the index,[python]
5ad7d4990d63974e20c39223,"Assignment 4 Part 4 has differing thresholds for classification accuracy for data from training set vs test data, isn't that just rewarding overfitting the training data? if the training set is truly representative of the real data in test then wouldn't a better test have been checking that accuracy of labeling doesn't vary by more than X % ( where X =< 2 for example).

Or am i misinterpreting the intent of what the assignment is trying to test?",jc6w44hrp9v2ki,[],"Hi Arjun,Typically, we first try to see how well our classifier models the training dataset and then we apply it to the testing dataset to observe whether it generalizes the data enough. Thus, these two are different measures and need to be judged differently and so we set different thresholds for train and test accuracy.Coming to your question, the randomness in the classifier does not guarantee the classification of a point as correct or wrong some fixed percent of times (eg. it can not guarantee that any point will be classified 90% of the times correctly). The points that perform well and worse among different instances of the random classifier itself would be at random. The Random Classifier performs better overall on the data, due to the very nature of its concept. Thus the test for label classification in a random classifier in the way that you have suggested is not a good measure. I hope this answers your question upto some extent.",,,1020,,Rationale for Assignment 4 Part 4 grading thresholds.,[a4]
5ad7d49a0d63974e20c39224,Just would like to know when will assignment 5 be released?,jc6w44hrp9v2ki,[],It's out now.,,,1024,,Assignment 5 released?,[a5]
5ad7d49a0d63974e20c39225,"Okay, since I don't know numpy very well and I think we got to get better at slicing dicing for next assignment I found this book chapter that seems to do a good job explaining it...

https://www.safaribooksonline.com/library/view/python-for-data/9781449323592/ch04.html",jc6w44hrp9v2ki,"[{u'text': u'There was an awesome YouTube tutorial in ML4T where the guest lecturer went through vectorizing a decision tree step by step, but of course I can't find it now.', u'responses': [u'Here it is.
https://youtu.be/2e2Yr-Bpo-w?t=29m33s

Dave Byrd goes through his through his logic using no vectorization, then shows vectorization step by step and the time differences between them.

I learned a lot about numpy vectorization from this lecture.', u'Thanks!  That's the one.', u'Here is the link to download ppt file: https://www.google.com/url?q=http://quantsoftware.gatech.edu/images/a/a9/CDB_vectorize_me.pptx&sa=D&ust=1521564611660000&usg=AFQjCNEvEi4AQG0H1eaaRxG0o6HKKQkT-Q']}]",,,,1026,,numpy stuff,[a5]
5ad7d49a0d63974e20c39226,"Hello everyone,

We have finished addressing all regrade requests and resolved all disputes and corrections. The midterm exam grades have been released to T-Square. If there is any discrepancy between your grade on Gradescope and that on T-Square, please comment here with a followup and we'll look into it.

There were very few ( < 5 ) students who did not have a Gradescope submission from the ID we have on file, and had also not uploaded to T-Square. They have been given a 0. If you are one of these students, please check your email and get back to us immediately.

The updated stats are as follows:

Median78.65Mean75.61St. Dev.16.17

We will make a post soon with the updated stats for the entire class.

",jc6w44hrp9v2ki,[],,,,1030,,Midterm Grades Released on T-Square,"[announcements, grades, midterm]"
5ad7d49a0d63974e20c39227,"Hey everyone,

Now that the withdrawal date has passed, we have some updated stats for the course.

We have also created a ""Cumulative"" column based on our Final Grade calculation, which is currently calculated as follows: (60/500 * sum of first 4 assignments) + (0.2 * midterm). Thus, this is a score with a maximum of 80. This does not reflect what your final letter grade will be, since it does not account for dropping the worst assignment and performance on Assignment 6. It should just give you an idea of where you stand in the class. 

A1 - Game PlayingA2 - SearchA3 - Bayes NetsMidtermA4 - Decision TreesA5 - GMMsCumulativeMedian759710078.6510010069.52Mean77.4787.7493.5175.6192.6291.6265.86St. Dev.21.2217.4314.0116.1716.4819.1012.92

We will update this post shortly after grades are released for future assignments.

#pin",jc6w44hrp9v2ki,"[{u'text': u'Thank You!', u'responses': [u'-']}, {u'text': u'I still don't have my grade for assignment 1 on t-square despite numerous reminders to the TAs', u'responses': [u'@Kshitish Deo  ', u'Same here, thanks.', u'resolved?', u'Not yet, though Kshitish said he could see my grade and it was correct.  For some reason I still can't see it.  Thanks, Jim', u'James, you should see it now. Apologies.', u'resolved now?']}, {u'text': u'Thanks for posting this, makes me feel a bit better. I assume these numbers do NOT include all the people who dropped. Glad the first assignment is still median at 75. Assignment 2 and 3 Median is still depressing.', u'responses': [u'It's crowded at the top, no room for mistakes or a lazy weekend', u'I think these are updated nums. The midterm nums increased by a bit.

I agree with both Brett, and Ivan. These stats are scary; there is no room for lackadaisical effort this last leg of the semester...

Great luck to everyone!
-Q. ', u'Yes very intense competition. Not a good environment for collaboration since we want to minimize our peer's score', u'So you would argue cooperative game-playing incentives are not strong enough? :)']}, {u'text': u'Do these stats include the on-campus students? 

If not, how do they compare with the on-campus ones? And how do they compare with the previous offerings for this course?


', u'responses': [u'The on-campus version is offered only in the Fall.

The stats are more or less similar to previous offerings of the course!']}, {u'text': u'From the Syllabus:  ""Achieving a grade above the median will result in an “A.” A “B” will be given for final grades equal to the median and above 1 standard deviations below the median. Grades equal to or below 1 standard deviations below the median and above 2 standard deviations below the median will get a C. Grades equal to or below 2 standard deviations below the median and above 3 standard deviations below the median will get a D. Any grade equal to or below 3 standard deviations below the median will get an F. There will be chances to earn extra credit points during the semester. These are factored in at the end after all other curving is done.""

Could you explain how the curve works in regards to extra credit?  My understanding is that the median/curve stats will be calculated without extra credit.  The individuals grade with extra credit will then be evaluated against the classes median grade calculated without extra credit.

To rephrase in the form of a question:  Say the class median without extra credit is 92 and with extra credit it's 94.  Will an individual grade of 93 with extra credit included get an A or a B?  

Extra Credit clarification aside, is this high of a median homework grade normal for this class or is this an unusually smart batch of students?', u'responses': [u'""These are factored in at the end after all other curving is done."" That should explain it.

As we said in @843, if the median is above 90 (say 92), everyone who gets a final score above 90 (even if it's 91) gets an A.

We calculate the median without extra credit factored in. If this median is 83, and your score without extra credit is 82, and it's 85 with extra credit, you get an A.

As for your final question, why not both? We change the assignments around from semester to semester, and have a completely new set of questions for the exam each time. Sometimes the grades swing around a bit - sometimes lower, sometimes greater. Plus we've noticed a number of students doing well this time around.

', u'', u'Though I think I know already, extra credits are still part of the assignment, am I correct. So if I get 5 extra points, that means +(5*0.12) on the overall score not +5?', u'Correct.', u'If the median is above 90, do we default to standard grading buckets (90,80,etc) or is the B calculated as 90 to 90-stdev?', u'The latter.']}, {u'text': u'
How does that work when the median is 100, as it was on assignments 3 and 4?  The syllabus states (and I quote) ""Achieving a grade above the median will result in an A"".  That means scoring 100 on assignments 3 and 4 equates to a B.  Is that correct?
', u'responses': [u'The letter grades are assigned based on your Final Score for the course and not on individual assignments.', u'
Oh, okay... thanks!']}]",,,,1031,,Current Class Stats,[grades]
5ad7d49a0d63974e20c39228,"Hi everyone.

Assignment 5 is now released and active on Bonnie. The git repo is here.

Please read the README carefully.

The assignment is due on Bonnie and T-Square by April 1st 2018, 11:59pm UTC-12 (Anywhere on earth). The submission on T-Square is a backup just in case, and the submission to Bonnie will be officially used for grading.

Important: There is a TOTAL submission limit of 5 on Bonnie.

Your BEST submission will be counted towards the assignment grade. 

There will be a separate post soon about a Youtube live event going over Assignment 5.

Good luck!

Part-1 discussions - @1033
Part-2 discussions - @1034
Part-3 discussions - @1035
Part-4 discussions - @1036

EDIT 03/25/2018 2:00 AM EST: 
A small change has been pushed to the local tests file - `mixture_tests.py`.  

`generate_test_mixture` was generating synthetic data from a normal distribution for `test_gmm_train`. This would generate a few negative values, which might lead to the local test failing occasionally. After the change, it produces only positive values.
You are free to pull the changes, or code this change at your end, if required. 
Please note that Bonnie tests were not dependent on this - no changes have been made to Bonnie.  This does not affect your implementation.  


CORRECTION 03/25/2018 4:30 pm EST The return value of `likelihood()` function is NOT restricted to be in the range of [0,1]. The comments in mixture_models.py incorrectly mention that the return value is Float [0,1].

We apologize for this oversight on our part. No changes will be pushed for this, however.



",jc6w44hrp9v2ki,"[{u'text': u'Would it be possible to get a requirements.txt file for this project?', u'responses': [u'I second this.  Numpy version in particular would be helpful.', u'Third this.  When I attempt to run mixture_tests.py clean I get a 
ImportError: cannot import name NUMPY_MKL
Solution per here seems to involve updating numpy to 1.13.  I remember previous assignments being explicitly limited to 1.11.', u'Last I checked, numpy version on Bonnie was 1.12.0. I have tested with the same version on my system. But I am trying to get a confirmation on this. Keeping this unresolved till then. 
Also, @Nick I tested mixture_tests.py locally and I didn't have to update to 1.13 and I am running on 1.12.0. ', u'I should double check the scipy version as the code imports scipy; it seems that scipy 0.19.0 is the best match for numpy 1.12.0; pip or conda installing different scipy versions would upgrade or downgrade numpy; could you confirm please Richa?', u'@Richa -- in addition to posting to Piazza, would it not be a good idea to add a requirements.txt file to the project repository that specifies both NumPy and SciPy versions?  That way this doesn't come up every semester.', u'Numpy: 1.12.0
SciPy: 0.18.1', u'This link may be helpful for anyone struggling to get the required versions installed using pip: https://www.silx.org/pub/wheelhouse/.  Contains wheel files for windows that pip can deal with in the case that it fails to install when specifying a version number.', u'Here is the requirements.txt I'm using in my project.

https://gist.github.com/zelein/7f4e845cd951f6974dca26953398b049

It's a modification of the project4 requirements text so it may contain packages we no longer need, but oh well. I also added matplotlib as that was not mentioned but is a dependency. I didn't know what version to use so just picked 2.2.2 as that was the first version to show up in Google when searching for ""matplotlib python2""', u'Using PyCharm, scipy version 0.18.1 and 0.19.0 failed with an error like ""numpy.distutils. ... no lapack/blas resources found.""

I tried version 1.0.0, and it installed without error. Any idea if this version is okay, or do I need to use the link provided by Nick to install 0.18.1?', u'Added a requirements.txt now. Apologies for the delay.']}, {u'text': u'', u'responses': []}, {u'text': u'Considering there are only 5 submissions, I would not like to loose one/more to env issues. Can the Instructor team kindly provide a ""legal"" requirements.txt?  
', u'responses': [u'just submitted and passed. my setup is: numpy: 1.11.3, scipy 0.18.1 (unused/used only by provided skeleton code), matplotlib 2.0.0, ', u'Thanks Jonathan Tay']}, {u'text': u'It seems that Assignment 5 has not yet been released on T-Square. When will it be available so I can turn in the assignment?', u'responses': [u'Should be up now.']}, {u'text': u'I just submitted for the first time. All local testing passes. I get the following error response after only 6 seconds. Did it get killed for a specific reason? I can't afford to slice/dice my submission to figure out where the issue is with Bonnie.

Submission includes the following files:
 mixture_models.py
Uploading submission...
[=========================== 100% ===========================] 21246/21246
Waiting for results...Done!
Results:
--------
{
 ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", 
 \""cmd\"": \""sudo -H -u vmuser_ruspyjln bash -c \\\""cd /home/vmuser_ruspyjln; 
 ulimit -f 160000 ; ulimit -c 10000 ; 
 python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\""\"", 
 \""return_code\"": 137, \""run_stderr\"": \""\"", 
 \""stderr\"": \""bash: line 1: 30 Killed
 python run.py assignment_5 > run_stdout.txt 2> run_stderr.txt\\n\""}""
}
(ai5) C:\src\ai\assignment_5>

My Python freeze output:

certifi==2018.1.18chardet==3.0.4cycler==0.10.0functools32==3.2.3.post2future==0.16.0idna==2.6matplotlib==2.0.2nelson==0.4.0numpy==1.12.0pyparsing==2.2.0python-dateutil==2.6.1pytz==2017.2requests==2.18.4requests-toolbelt==0.8.0scipy==0.18.1six==1.10.0subprocess32==3.2.7urllib3==1.22wincertstore==0.2
', u'responses': [u'Nevermind. It's the bonus question. I took a chance and disabled it.', u'Did you figure out what the problem was in, maybe, a subsequent submission? There's no json or other output created. Worked for me after disabling the tests as well. Can't be a timeout since it fails so fast.... out of memory ?', u'Disabling the (bonus question)* not the tests, sorry', u'Try valgrind with --tool=massif then ms_print the output, as a method for checking your memory usage that won't involve managing python imports or modifications to a virtual python environment', u'Did we officially decide this is what you get when the bonus runs out of memory?', u'I'm also getting my submission killed and am uncertain why -- i'm generally vectorized and local tests (for parts 1-2) pass in reasonable time (some take ~30s), but all done in less than 10 mins.
Start\"", \""cmd\"": \""sudo -H -u vmuser_sefihbdu bash -c \\\""cd /home/vmuser_sefihbdu; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""FFF\"", \""stderr\"": \""bash: line 1:    32 Killed                  python run.py assignment_5 > run_stdout.txt 2> run_stderr.txt\\n\""}""

I have no implementations for parts 3 and 4 -- just
raise NotImplementedError()
so it wouldn't be those running long.

Any thoughts?', u'I ran into the same problem and am pretty sure that it was because I ran into the memory limit on Bonnie.  I ended up using https://pypi.python.org/pypi/memory_profiler to profile memory usage during local testing and saw that I was using over 500 MB of memory in local testing.', u'Great call Elaine!  Thanks so much.

Although my methods were nicely vectorized, one in particular used recursion and each time it held a copy of the full image matrix!!

Having flattened to iteration the memory is under control and bonnie is happy.

w00t w00t.']}, {u'text': u'would it be possible to get an official requirements.txt file for this project from a TA?

and is it really too much to ask that mixture_tests.py would be runnable within the provided vagrant environment..?
', u'responses': [u'Apologies for the delay. I've added a requirements.txt file now.', u'Thank you, any ideas on why the vagrant instance can not run mixture_tests.py?
Traceback (most recent call last):
  File ""./mixture_tests.py"", line 1, in <module>
    from helper_functions import image_to_matrix, matrix_to_image, \
  File ""/vagrant/helper_functions.py"", line 3, in <module>
    from matplotlib import image
ImportError: No module named matplotlib

This is even after running: 
sudo pip install -r requirements.txt

I am a python noob when it comes to managing dependencies, so I'm sure there is something super simple I'm missing...', u'Looks like the vagrantfile we've provided has never been updated - an oversight on our part, I agree. Apolgies for the inconvenience. We never got to know because I don't think it was being used very often.

I just checked the vagrantfile. It never installs matplotlib, that's the issue.

Would you be able to work with virtualenv instead? It might take us quite some time to update and test the vagrantfile.', u'Also, it's possible that matplotlib doesn't install on vagrant because it requires X server and that might not be present on vagrant (just my guess). Hence the recommendation to use virtualenv.', u'virtualenv is still black magic to me, and I don't really have the bandwidth to pick it up right now.

I was able to test on my local machine, and have passed all bonnie tests, it's just a bit nerve wracking when there are only 5 total submissions especially with the thought that some of those could get burned because of dependency version differences.']}, {u'text': u'Here's a stack-trace:

Traceback (most recent call last):=                          ] 8192/15823  File ""submit.py"", line 46, in <module>    main()  File ""submit.py"", line 42, in main    submit('cs6601', 'assignment_5', filenames)  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\nelson\gtomscs.py"", line 49, in submit    return abstractsubmit(submission, refresh_time = refresh_time)  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\nelson\abstract.py"", line 32, in submit    submission.submit()  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\nelson\abstract.py"", line 105, in submit    headers={'Content-Type': monitor.content_type})  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\requests\sessions.py"", line 555, in post    return self.request('POST', url, data=data, json=json, **kwargs)  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\requests\sessions.py"", line 508, in request    resp = self.send(prep, **send_kwargs)  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\requests\sessions.py"", line 618, in send    r = adapter.send(request, **kwargs)  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\requests\adapters.py"", line 440, in send    timeout=timeout  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\urllib3\connectionpool.py"", line 601, in urlopen    chunked=chunked)  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\urllib3\connectionpool.py"", line 357, in _make_request    conn.request(method, url, **httplib_request_kw)  File ""C:\Python27\Lib\httplib.py"", line 1042, in request    self._send_request(method, url, body, headers)  File ""C:\Python27\Lib\httplib.py"", line 1082, in _send_request    self.endheaders(body)  File ""C:\Python27\Lib\httplib.py"", line 1038, in endheaders    self._send_output(message_body)  File ""C:\Python27\Lib\httplib.py"", line 886, in _send_output    self.send(message_body)  File ""C:\Python27\Lib\httplib.py"", line 856, in send    datablock = data.read(blocksize)  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\requests_toolbelt\multipart\encoder.py"", line 397, in read    self.callback(self)  File ""C:\Users\hakohl\Documents\assignment_5-master\assignment_5-master\venv\lib\site-packages\nelson\uploadcallbacks.py"", line 20, in progressbar_callback    sys.stdout.write(""\r{}"".format(line))IOError: [Errno 0] Error

This happens just after a successful bonnie submission in the previous attempt with minimal changes to the code. Fails in a handful of seconds, so likely not a timeout. Can a TA explain if this is a code issue (unlikely) and whether this counts as a submission?', u'responses': [u'And, in general, whenever I submit the bonus function I get an error real quick - this or the one David described above. No json/grades or useful error logs. Anyone else in the same boat? Shouldn't the remaining test cases at least run if there's something wrong in my implementation of bonus(). ', u'Harsh, which OS are you on?', u'Windows', u'My suggestion would be to profile the bonus question on your local machine and make sure it doesn't consume too much memory. I'm guessing we'll need to slice the data up into chunks and process serially to keep the memory consumption under control.  Readme says it has to stay under 250mb of RAM.

So maybe create two matrices that when vectorized use up a 1gb of ram, then adjust code to process in 100mb chunks.

Neither matrix by itself can be bigger than 250mb or they wouldn't even be able to pass into the method as parameters.', u'already did that. not two but 5 matrices that process in chunks. that's how I moved from the error you described above (most likely OOM) to this one (which is probably something else). not sure these count as submissions - if they do I have 1 last bonnie attempt left :(', u'Here's another attempt - This time went on for quite some time (ran all the tests, I assume):

Uploading submission...[=========================== 100% ===========================] 15823/15823
Waiting for results...Done!
Results:--------{    ""error"": ""Updating autograder archive failed 128""}

Can any TA guide me here - are these attempts being counted - what are my scores on bonnie, anything at all?', u'You can always login to Bonnie directly to see how many submissions you have.  https://bonnie.udacity.com
', u'Thanks David,

The exact same code passed bonnie when I submitted it a third time. Not sure what the problem was - glad its resolved']}]",,,,1032,,Assignment 5 Released,[a5]
5ad7d49b0d63974e20c39229,"Assignment 5 - Part 1 discussions go here.

",jc6w44hrp9v2ki,"[{u'text': u'Hi Everyone,

QQ: in K-means algorithm when we are working with an image, by squares of the distances ||xn − μk||^2 we assume a squares of the  Euclidean distances between vectors. is this assumption correct?

Thanks
Alex', u'responses': [u'Yes.']}, {u'text': u'I don't understand how to interpret the image_values ndarray. It's 
numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]]
The inner ndarray[float] is the array of RGB values right? What about the outer arrays? ', u'responses': [u'rows, columns, rgb values

so image[0[[0][0] is the red value for the upper left corner (though, depending on the convention this could be one of the other corners).

Essentially ou will have rows of columns and you will have columns of pixel RGB values.', u'And note that when you get to part 2 this structure changes a bit because the image is given in grayscale, so no separate rgb values. (You don't have to calculate the grayscale, it is done for you.)']}, {u'text': u'As per my understanding, this is what I'm trying to do in the solution - 
1. Select random values from the data as initial means
2. Calculate the euclidean distance of RGB values of each pixel from the selected mean and add each point to the appropriate cluster
3. Find the mean of RGB values in each cluster and calculate the euclidean distance of each pixel from the mean.
4. Repeat step 3 till the new mean RGB and previous mean RGB are the same
5. Set each pixel in the cluster to the RGB of that cluster

But maybe I'm not vectorizing the arrays properly, because my code is in an infinite loop and I'm not reaching a point where new mean RGB = previous mean RGB

Is there something that I'm doing wrong?', u'responses': [u'You are provided means in some cases.  You should only select random means if you are not provided means.

Step 2 should be that for each pixel you calculate the euclidean distance from each mean and assign the pixel to the cluster for the mean which it is closest to.   You may have meant that in what you said, but it wasn't clear to me.

step 3 should be that you calculate a new mean for each cluster using the RGB values (no distance involved at that point).

If the new means are different, use the adjusted (new) means and start with step 2 again.', u'Yes, Conor. That is what I meant. I must be doing something wrong in my calculations then, because the approach is the same.']}, {u'text': u'How close do our updated pixel values need to be to the reference images? I am close enough to get the correct pixel values (error < 1/255 ~ 0.004), but since we only have 5 submissions I don't want to waste an attempt with an algorithm that is incorrect. I am passing the unit tests.', u'responses': [u'run the local tests a couple of times. If you are passing those, you should be fine. ']}, {u'text': u'In some posts for the assignments we are being advised not to use norm or euclidean. They might be basic but some of python implementation like scipy's can be faster. Is there a restriction on what we can and cannot use in this assignment in terms of libraries?
Specifically functions like :
- sklearn 
- scipy - cdist 
etc.', u'responses': [u'You should need to use only sp.misc.logsumexp from SciPy. None of the other SciPy functions are needed.']}, {u'text': u'my understand is
1. for each pixel calculate distance with each of the k-means pixel
2. Assign pixel to the cluster to which it has shortest distance
3. find the mean of RGP in each cluster and set it as new kmeans
4. Repeat step 1to 3 until k means doesn't change

IS this correct, any advice with numpy functions to be used?', u'responses': [u'Yes, that is correct.']}, {u'text': u'What run time for 'test_k_means' should give us confidence in our vectorization? 30 seconds? 5 seconds? <1 second?', u'responses': [u'less than 30 seconds is good. ']}, {u'text': u'If I pick the initial means randomly, does the test_k_means local test should pass?
I am getting random errors and convergence with different means. However, if I use the default initial_means, everything works as expected.', u'responses': [u'different initial means could converge to a different set or clusters. Don't worry, it is expected behaviour.', u'Not necessarily. Not using the given means, may lead the algorithm to converge on a different solution. KMeans does not guarantee global minima, if my understanding is correct.

What kind of random errors are you getting.
', u'Tasuku, the error was basically not passing the local test, both answers clarified the issue. Thanks!']}, {u'text': u'When I use the default initial_means, I can produce the exact same image as provided in image folder.
When I use random initial_means, I can still produce reasonable bird image, however it's different from what's provided in image folder. 
Is this kind of behavior expected?

below on left is my image with random initial_means; on right is the provided image. both with k=4
', u'responses': [u'Different initial means could converge to a different set or clusters. Don't worry, it is expected behaviour.']}, {u'text': u'I just seem to still be struggling with the basics of numpy vectorization.  Mental block.

all examples that i have seen with vectorization are only using a single value, rather than 3 point value, as in the RBG.  Does anyone have any good examples or numpy description pages that I can reference.  I have read through the ones that have been previously provided.

My issue seems to be that the RBG values are not treated as a single set, but rather as distinct additional dimensions in the array.  The vectorized function I created only processes a single value rather than passing them as a single set.

I am sure I am not even asking the question clearly....', u'responses': [u'The NumPy array: a structure for efficient numerical computation', u'Thanks Collin!  Reading now.', u'Rick, did you try flattening the image? (flatten_image_matrix)', u'Is flattening the image a good idea when we have RGB values?  Like, don't we need to keep the RGB arrays intact?  Or does flatten_image_matrix guarantee that for us?', u'Flattening the image helped me in my vectorization. You will keep the RGB intact, so don't worry. Since the unflattened image in 3D matrix, say 10*20*3, when you flatten the image, it'll give you a 2D matrix of 200*3. The RGB values for the points will remain intact, it'll just unfold the rows and columns into 1 dimension.', u'Thank You Collin & Richa!!

I might be over my mental block thanks to you tips.

Those still struggling with Numpy and Vectorization.  Please take a look at the artical that Collin posted above.  And pay special attention to ""signature"" parameter in vectorization. 

I believe I am over the mental block, if not, I will be back.

Thanks Again', u'Is there an advantage to using the helper functions over using a simple reshape of the np matrix? In testing, it takes around 10,000 times longer to use the flatten_image_matrix function. Not a huge difference but like a hundredth of a second vs a hundred thousandths. I know we're supposed to complete the tests quickly so I'm trying to go as barebones as I can but don't want to fall into the trap of the following quote....

Premature optimization is the root of all evil (or at least most of it) in programming -- Donald Knuth', u'Another good resource:  https://www.safaribooksonline.com/library/view/python-for-data/9781449323592/ch04.html']}, {u'text': u'Do we suppose to pass the unit test? Mine is close enough, but none of the unit tests (k = 2 to 6) passed.', u'responses': [u'Yes']}, {u'text': u'I'm running into an issue where the initial means for k=3 is causing no values to be assigned to cluster 1 and 2, but all the values are assigned to cluster 3. This causes the Maximization step to fail since I am attempting to take the mean value of 0. How can I work around this? Random restart?', u'responses': [u'Good to go.', u'Philip,
I seem to be having the same problem, any tips?']}, {u'text': u'My runtime for part 1 seems very long 25+min, in general ball park estimate is to how long a 'healthy' part 1 should be taking?', u'responses': [u'30 seconds from one of the above posts', u'Are you taking advantage of the helper functions? Probably a good idea to check which parts of your code are taking the longest. I'm only taking a few seconds per image.', u'you still have a total allowed runtime of 3600 sec on Bonnie, just in case nothing works, try submitting your implementation if you are close to the deadline.', u'Wow.. 30 seconds..

For part1, it's 5mins for me. Should I circle back and fix this or continue with the other parts? I am finding this assignment to be the absolute hardest by far..  :(

Thank you in advance!', u'Ok, nvm. Down to <10secs now. This vectorization business is pretty amazing...']}, {u'text': u'I've been over examining my Part 1 for about 6 hours now. I've checked my distance calculation, my mean calculation, all of my reassignments, and my convergence. I've confirmed accurate calculations.

No matter what I do, I always converge on an image that is similar to the correct output with some pixels incorrectly assigned, primarily in the top right corner of the image.

Any advice or pointers from anyone out there who had a similar problem?', u'responses': [u'Sounds like some kind of threshold problem. What is your tolerance for calculations like for verifying your convergence?', u'I figured it out. I wasn't comparing my new distances to the right values. Thanks for the reply.']}, {u'text': u'I wonder how I'm supposed to handle situations when k decreases during iterations. 

For example, starting with k = 3, one of the 3 initial means were kind of outlier in its distribution. Then it's fully probable that no element is assigned to that cluster after some iterations(k --> 2 in practice).

Currently I allowed it to decrease and do recurssion with it. 
But because I only have limited 5 submissions, I want it to be clear.

Thank you in advance.', u'responses': [u'I don't see when you'd reach such a situation. I haven't come across it yet. And if we start with k, we expect k clusters in the end. So, allowing it to reduce is not a good idea.', u'Thank you Richa.

I also haven't encounted such a situation yet. While writing my code with recursion, it was really important to update parameters properly and I came across with the possibility of decrease in k.

Thank you again.   :)']}, {u'text': u'Hello,

I am afraid that I am on a very steep mental hump, as I am still on part 1.

I have been struggling for the last 5 days with Numpy, and believe that at the very least I have learned it's basics. 

I pass the tests for k=2 and the images look identical, but when k>2, I can't seem to move past it.  The images are just slightly off.

When I calculate the distances and k-group'ings by hand, my numpy process appears to work correctly.  My guess is that the iterative process of and/or the averaging of the new values I am doing something wrong.

Any tip in a direction for me to consider would be greatly appreciated.  I am at a loss at the moment.
Image 1--Correct
Image 2-- Rick's WRONG Image

', u'responses': [u'Different initial means could converge to a different set or clusters. Check if you are passing the local tests.', u'Richa, yes, I have confirmed that I am running the tests scrips as is.  There just seems to be something slightly off.']}, {u'text': u'Help debugging would be so crucial:Where I have been stuck for a couple hours.... 1. I print out my images and they look almost exactly the same2. I do an image difference and the number seems small (1800) 3. When I test on smaller arrays the k-means seems to be converging according to paper calculations....Is there something I'm missing? Am I losing precision somewhere? ', u'responses': [u'I guess I set a threshold for when the weights  converged... dangit']}, {u'text': u'Helper Functions unflatten_image_matrix() has a defect

if(len(image_matrix.shape) > 1):
should actually be

if(len(image_matrix.shape) > 2):

else it will not unflatten greyscale images properly

', u'responses': [u'The input image_matrix is a flattened matrix, meaning it should have two dimensions for grayscale images. As per the docstring:

	Unflatten image matrix 	(Height*Width) by Depth to	Height by Width by Depth matrix.
']}]",,,,1033,,Assignment 5 - Part 1 discussions,[a5]
5ad7d49b0d63974e20c3922a,"
Assignment 5 - Part 2 discussions go here.


EDIT 03/25/2018 2:00 AM EST:
A small change has been pushed to the local tests file - `mixture_tests.py`.  

`generate_test_mixture` was generating synthetic data from a normal distribution for `test_gmm_train`. This would generate a few negative values, which might lead to the local test failing occasionally. After the change, it produces only positive values.
You are free to pull the changes, or code this change at your end, if required. 
Please note that Bonnie tests were not dependent on this - no changes have been made to Bonnie. This does not affect your implementation.  
 
CORRECTION 03/25/2018 4:30 pm EST The return value of `likelihood()` function is NOT restricted to be in the range of [0,1]. The comments in mixture_models.py incorrectly mention that the return value is Float [0,1].

We apologize for this oversight on our part. No changes will be pushed for this, however.

",jc6w44hrp9v2ki,"[{u'text': u'QQ about logarithmic scale: according to the readme we should use log probabilities, but what about variances, means and mixing coefficients should them be logarithmic values for them as well? if so then what is the correct way to to calculate gamma value(em.pdf page 16). will it be something like that 
gamma = ln(pi*N(x|mu, sigma))/logsumexp(ln(pi*N(x|mu, sigma)))???


Thanks
Alex', u'responses': [u'Can you share the response for this?', u'we need to calculate everything in log scale as it stated in readme, so in this case
ln(gamma) = ln(pi*Nx/Sum(pi*Nx)) = ln(pi*Nx) - ln(sum(pi*Nx)) - and so on we continue replacing multiplication and division with +/- of logarigms
and as soon as we have ln(gamma) value let's denote in with ln_gamma, gamma = exp(ln_gamma)

Hope it helped', u'Yep, that helped with the first 2 tests, thanks!']}, {u'text': u'I see that image matrix has negative values, but in that case I can't calculate ln of them, to use it in further calculations.
Could anyone please give some hints how handle this math ?

Thanks
Alex', u'responses': [u'I am sorry but where do you see the image matrix having negative values? That's not quite possible.', u'never mind it seems to me there is some error in my code', u'Ok double checked I see that 'dataset_1' in  'test_gmm_train' test has negative values, Does Anybody have the same? or it's problem of my environment I checked versions of numpy and scipy - they are correct', u'Yes, I'm seeing a mix of positive and negative values in dataset_1 as well.', u'You are right. The synthetic data was being generated from a normal distribution. Since the means were quite positive, there were very few negative data points that were being generated, but nonetheless we did have negatives in the synthetic dataset.
This could have led to failing the local tests once in a few runs (it depends on the implementation.) But since we have said here that we'd be testing only on images, ideally they should all be positive values. I have pushed a minor change in `mixture_tests.py` fixing the `generate_test_mixture` function. 

You are free to pull the changes or implement the check at your own end - regenerate the value in case the value generated was negative.   ']}, {u'text': u'Can someone give input on the semantics of the likelihood() function? I'm getting what looks like incorrect results from this calculation and am not 100% clear on what the function is supposed to do.

I'm assuming this function needs to return the log of a probability (not a direct probability)? So the range of values it should return is -infinity < return_value <= 0 (for probabilities 0 <= prob <= 1). Does that sound correct?

Also for the inner sum (over K) are we summing probabilities or logs of probabilities from the function N ?

', u'responses': [u'You are correct. It is supposed to return the log of probability. 

Refer to the READMe for how to calculate the log form of this probability.  ', u'Sorry, I’m not understanding how this should work. If we replace the likelihood with the log likelihood, wont this be negative? Then we’d be taking the ln of a negative number.Are we supposed to be moving the ln outside the first sum inside the sum? Or should we be using the negative log likelihood inside the summation?', u'Yep - I'm finding when to use log vs. not log confusing. This is my interpretation .. hope its right (let me know if not)

For the inner sum over k -We have a formula given for log(N) so to get N we need to use np.exp(log(N)) to get the value of N. Then sum the product weight * N over K. The inner sum over k will be positive since we are summing probabilities (not log probabilities)

For the outer sum over n -We take the log of the inner sum and sum those over n. This is taking the log of a positive (inner sum) so should be ok

Final result
The final result is then the log of likelihood and so it looks like the convergence is based on the log of likelihood (not actual likelihood)
', u'I am super confused too.
We take the log of the linear combination of N. Then when do we to apply the log(N) formula?
Or put it other words, why can't we just calculate all the individual N and sum them over?

Thanks.', u'The convergence test is based on the log-likelihood of the model. You can call your likelihood() function. Likelihood() function is actually log-likelihood. If you read the function description, it asks you to return log likelihood. You can call this function straight to check for the goodness of your clustering in each iteration of EM.

@Tony, you can do that. But it won't be efficient.']}, {u'text': u'When running EM for Gaussian Mixtures, I have k=2, but both means and both variances end up converging to the same values. Has anyone run into a similar problem?', u'responses': [u'Yes, and mine converge to 0 no less :-( No idea how to solve it but hoping to get some help on this thread', u'My means are non-zero, but always the same. My calculated variances are too large to be reasonable, given the data range, so that's what I'm re-analyzing now.', u'I got my variances under control, but my Gaussians are still converging to nearly the exact same distribution. For example, when running the first part of test_gmm_train where k=2, my GMM ends up with the following properties:

means = [ 3.05528585,  3.05944097 ]
variances = [ 2.75475268,  2.75468467 ]
mixing coeffs = [ 0.33431252,  0.66568748 ]

This actually passes the first assertion and moves on to k=4, but that section fails, and obviously something is amiss since the two distributions are the same.', u'@Donovan McMurray My calculated variances are quite large too (Did all the calculations referring to em.pdf). How did you get them(logically) in the mentioned range?', u'In my case, I was doing the variance calculation in a single line with numpy functions. I think something was wrong with my vector multiplication. (Linear algebra in large dimensions has a tendency to hurt my brain.) At the moment, I have a for loop running over all n pixels to do the variance calculation, and that's was fixed it for me. It's surely possible to convert that back to numpy functions, but I haven't done that yet. I guess my advice is to check the linear algebra of the variance calculation very carefully.', u'I guess you're right, the covariances calculation using vectorization is producing weird results. Will try your advice, thanks :)', u'You can tell from the test harness, that the means should end up being [2,4] (the original actual means that created the data set). I think once you see your convergence run to this result, you'll know your doing it correctly (assuming no local maxima).

I'm getting the same behavior Donovan described, where I'm settling on [3,3]. <sad face>
', u'lol, drop the transpose `T` and you can vectorize the variance calculation without issue; at least for the 1000 row dataset. Passed both tests in .058s.', u'Not sure am I the only one. For the k = 2 cases, one of my curve coefficient drop to zero and another one converge to 1.....', u'Isn't the matrix transposition in calculating sigma unnecessary since we are working with a univariate data set?', u'Yes, according to this: http://www.ics.uci.edu/~smyth/courses/cs274/notes/EMnotes.pdf 
That is exactly why the T is there, we'll see if it works though...
', u'Cause in the provided PDF, it has a capital sigma (E) which i think refers to a covariance matrix, however other sources i've looked at state that sigma (lowercase) is just the (sum of (Xi - Mu i)^2) / sum(all data points in that responsibility)', u'@Tony I have the same issue - did you ever resolve it?', u'I resolved i thanks to @Eric. I was also mixing up capital Sigma with little Sigma', u'stuck with similar problem, mean values are converging to the same value, input data values range is from ~0 to ~11 so it seems like they are calculated without  'attention' to each other. 
[ 4.93231758  4.93231758  4.91780588  4.91780588] - means
[ 6.04605584  6.04605584  0.03196352  0.03196352] - variances
[ 0.47219804  0.51258985  0.00231768  0.01289444] - mixing_coefficients

Has Anybody ran to the same issue??
PS: capital/little Sigma, about which formula are u guys talking ?', u'probably it will be useful for somebody: my error was caused by a mixing up capital/little Sigmas', u'I'm still seeing the issue of the means converging to the same value. I think I'm missing the hint on capital vs lower case sigma. Can someone elaborate on that?

Alex: I'm getting similar results:
means = [ 5.16020215 5.1602458 5.16056627 5.16093955]variances = [ 5.91955573 5.91954052 5.91943072 5.91930403]mixing coefficients = [ 0.34563176 0.15293266 0.08692269 0.41451289]

and I'm passing the local tests
', u'I'm not sure what the others above mean but little sigma is the standard deviation of a univariate distribution, and capital sigma is a covariance matrix, which is roughly the same thing but for a multivariate distribution. I suspect they were trying to calculate a covariance matrix instead of a scalar standard deviation and it was causing them problems.', u'Discovered I wasn't handling the prob vs log(prob) correctly in the calculation of gamma. I now get the different means.', u'Hey Steven,
Could you please elaborate on what you mean by prob vs log(prob)?  I'm facing a similar issue where my means are converging to the same value.

Based on my understanding,

gamma = pi_k * N(x|mu_k, sig_k) / sum(pi_j * N(x | mu_j, sig_J) 

where,

N(x | mu, sig) = -0.5ln(2 * pi * sig) - (x-mu)^2/(2*sig)

Given the above equations are the correct ones, i'm not sure what Im doing wrong.', u'Note that it should be ln(N(x | mu, sig)) = -0.5ln(2 * pi * sig) - (x-mu)^2/(2*sig).

The equation on left is equal to the ln(N(x | mu, sig)) per the README.', u'Thank you Tasuku, that fixed my issue!']}, {u'text': u'This might be an easy question but is the initial mixing coefficient always going to be a fraction of the number of components?', u'responses': [u'initial mixing coefficient will all be equal and they should sum up to one. ']}, {u'text': u'

In the README is says sigma is the std. The equation above shows as getting back to variance. I just want to verify that sigma is in fact std.
Edit: The end result will be the same, but just want to clarify.  ', u'responses': [u'Variance is what we're using for the standard deviation for the gaussian function (at least you need to use that to get the joint probability working.', u'Yes, thank you. Now, I'm trying to make the equation work in python. The paper talks about using the mixing coefficients  to maximize ln(N(X|mu, sgima)). I think it is section 9.20. Trying to understand how it fits in here.
 ', u'ok, I see it now... It helped me to breakdown the problem with the knowledge that the point belongs to all the clusters as stated in the intro section by Richa.']}, {u'text': u'Is part of the assignment supposed to be to calculate the normal probability ourselves, or is it acceptable to import scipy.stats and use scipy.stats.norm to get N(x|u,s2)?  Apparently it won't work properly unless you add the import for the stats submodule explicitly, so wanted to check to make sure.  I also used sp.spatial.distance.euclidean, but now I'm noticing that the instructions say to only use the libraries for basic calculations.  Is the euclidean distance considered basic in this case?', u'responses': [u'Now that I'm looking more closely at how we need to do the whole log thing, I assume scipy.stats.lognorm isn't good enough for our purposes?  It doesn't get the test for joint probability to pass, but I could be doing something else wrong.', u'Actually, that works as well. Are we allow to use it?

Carey: I did the raw calculation first then I was able to see that norm returned the same before applying ln. ', u'Please do NOT use norm or euclidean. These are pretty basic functions and they are easy to implement.', u'I mean, if its basic as you say, then it should fall into the range of the rules (only use the libraries for basic calculations).  But whatever, I already implemented it without norm and got it working that way, and it will be easy enough to remove the euclidean call.']}, {u'text': u'Still confused about the likelihood function. My means are converging but the likelihood function says they are getting worse each iteration. EM appears to guarantee that the likelihood should improve for each iteration so I conclude that my log-likelihood calc is wrong.

The comment in the code says the likelihood function should return a float in [0,1]. However, my understanding is that the likelihood function should return the log of a probability - i.e. the log of a probability value in [0,1] so the function itself should return a value in the range (-infinity, 0].

questions -
1) Does the expression 'N(x_n | mean_k,stdev_k)' refer to a probability or the log of a probability? i.e. is it in the range (-inf, 0] or in the range [0,1]?
2) is the likelihood function supposed to return a log probability value in (-infinity, 0] or a probability in [0,1]? Or is it neither of these ranges?
3) is it true that the likelihood value should be increasing for every iteration of EM?
4) is the logsumexp() function supposed to be used somehow in the likelihood calculation and if so how?

""""""Assign a log likelihood to the trainedmodel based on the following formula for posterior probability:
ln(Pr(X | mixing, mean, stdev)) = sum((n=1 to N), ln(sum((k=1 to K), mixing_k * N(x_n | mean_k,stdev_k))))

returns:
log_likelihood = float [0,1]', u'responses': [u'Disclaimer:  I haven't fully competed part 2 yet, but I have passed the likelihood test.

I did not use logsumexp in my likelihood function.

I did return the sum of the log probabilities.  A brute force mechanism (that takes a long time) is to calculate the joint log probability for each individual value (pixel) and add them up.

Haven't gotten EM done yet.', u'I am finding the docstring a bit confusing too. Is the likelihood just taking the sum of the joint probability over all pixels? Can we basically just use our joint_prob calculation but update it for all pixels and then sum that?', u'This saved it for me: logsumexp can take an additional b parameter that can be applied as a co-efficient to each element in the sum.', u'Also, for the log likelihood, the readme explains exactly how to do it by providing the formula for N. To remove the ln() on the left, have to raise the right side to power of e and that's where the logsumexp() function starts making sense. The real trick is getting the shape of your image vs shape of your means/variances/mixing to line up and figuring out how to distribute the mixing values through to the logsumexp().', u'Jim and Conor are correct - `likelihood()` is essentially sum of `joint_prob()` for all pixels. Again, looping over all pixels is not efficient. ', u'(3) Likelihoods are supposed to increase as the model get better - so yes ideally, the likelihood values should be increasing with every iteration.(1) The expression refers to a probability. 
(2) You are absolutely right, this is a massive oversight on our part - the return values of the function `likelihood()` is not restricted in the range of [0,1]
(4) It depends on the implementation. Sorry, can't help you here. ', u'May I ask why joint_prob shall return a float instead of a list of float?
For say there're K components, shouldn't joint_prob compute K elements of log probability corresponding to each of Gaussian?', u'+1 to @Yang Hu 's question', u'@Saalis Umer just figure it out: joint_prob needs to combine the probability of all the components with respect to their weightings.', u'Thanks @yang Hu...
so, for joint distribution we just need to take weighted sum of the below log formula?', u'Yes log sum', u'Richa: when you say that ""looping over all pixels is inefficient"" are you suggesting there exists an approach that does not involve calculating the joint probability for each pixel? Or are you just emphasizing the vectorization?', u'After applying the log probability formula for each component, I'm taking a log sum of all of them and that is giving me the wrong result. Is it because I'm not taking the weighted log sum? What should the corresponding weights be? Do we have to use the mixing coefficients here? ', u'When I calculate the likelihood, should I use the old parameters, or new parameters? According to ed.pdf, it seems to calculate it with old parameter. Just I would like to confirm.Thank you', u'Just want to check for ""test_gmm_likelihood"", did anyone get an answer of ""-364868.81814"" - > which round it to ""-364869.0"" ? The golden value is -364370
I checked my code several times likelihood and and seems it's correct.
Isn't that is just about calculate all the joint_prob on each pixel and add it up? ', u'I'm in the same situation(with exactly the same number to yours). In fact, my joint prob is also showing a little difference(ground truth: -0.982, mine before round: -0.98261558037712948)

I didn't figure out what errors there is (if any) and how to fix it.

If any one went though this, any comment would be really helpful. :)', u'<updated>

See Conor's post below and @1053. Thanks, Conor!', u'No, it isn't because of incorrect rounding in the test.  They did that on purpose to catch when you were doing the probability incorrectly.  If you're getting 0.9826 it's because you aren't handling the multiplication of the mixing coefficients correctly (you can't multiply the coefficient * the log of the gaussian.   See @1053']}, {u'text': u'Is the output from a single segment iteration (via the segment test) supposed to generate an image equivalent to ""party_spock3.png""? I find it looks closer to the _baseline variant.
But I'm not yet passing the best_segment test and am not sure where I am going wrong.', u'responses': [u'Yes, the test for `segment()`, that is `test_gmm_segment` is testing the segments returned after the model has been trained for 3 components over the original party spock image. party_spock3.png is what the result should look like. ', u'Nick, I got the same result you had, did you figure out what was the error?', u'I got the same result. Any idea?']}, {u'text': u'I have a question about training performance. I think I understand the basics of vectorization, and I understand not to simply use np.vectorize. I was previously using excessive np.repeat and np.tile functions, but I have since taken them out. Even after those optimizations, my GMM training is still taking ~10 minutes. Are there any other numpy functions that are necessary to avoid?', u'responses': [u'My train test completes in ~.5seconds.

Are you using apply_over_axis?', u'Do you have PyCharm installed? If so you can run profiling to see where the majority of your time is being consumed. For the assignment, I have been able to get away with only using the following functions: np.sum, np.float_power, np.exp, np.square, np.log, np.sqrt.', u'Yes, Nick, I am using apply_over_axis. Should I try removing those calls as well?

Adam, that's an impressively terse list. How do you manage, for example, finding the difference between each pixel value and each mean? I'm applying np.newaxis to each of those vectors, and then applying a regular minus operator.', u'apply_over_axis is not a vectorized operation. You'll find that removing those calls will significantly speed up your code.', u'If you're working with numpy arrays then subtraction can be written as (arr1 - arr2) or (arr1-const1). np.newaxis can also be written as arr1[:, None], but I'm not sure if that would change performance.', u'Thanks, Nick. Removing apply_along_axis did help a lot! I'm still probably not at maximum efficiency, but I can now run the first 6 unit tests in about a minute.

Good tip, Adam. I'm doing essentially a ""cross product"" of vectors but with subtraction instead of multiplication, if that makes sense. I do that by using np.newaxis, and if using None on an axis is the same thing, then I will probably leave it as I have it.', u'Study these pages closely and vectorization starts making a lot more sense: 
https://docs.scipy.org/doc/numpy-1.14.0/user/basics.broadcasting.html
https://cognitiveclass.ai/blog/nested-lists-multidimensional-numpy-arrays/
', u'I'm trying to avoid vectoring my joint_prob function. How does one do it? When I pass in the numpy array, it provides the entire array instead of each element.']}, {u'text': u'Are we supposed to be using K-means to initialize the means of the EM algorithm? I'm failing the test_gmm_train, and it's because my likelihood function is only about half of the test requirement. I'm wondering if I'm hitting a local maximum. In the tests it does say, it is ""start off with faulty means"". Then in the em.pdf it states:

Note that the EM algorithm takes many more iterations to reach (approximate)convergence compared with the K-means algorithm, and that each cycle requiressignificantly more computation. It is therefore common to run the K-means algo-rithm in order to find a suitable initialization for a Gaussian mixture model that issubsequently adapted using EM.
', u'responses': [u'You are not required to do that for the class `GaussianMixtureModel`.']}, {u'text': u'In test_gmm_train, k =2, test case, one of the variance getting smaller and smaller and also the ""N"" of that Gaussian curve will drop to zero as well and caused division by zero, any clue?
Is that the underflow problem?
Thanks.', u'responses': [u'Figure 9.7 in em.pdf talks about how GMM is susceptible to singularities like that. However, I think given the data we're provided with, the chances of that happening are pretty low. I don't have a special check for these singularities and I'm not experience any problems with that. I did have some positive feedback loops in my program that would cause what you're seeing, and in my case I was able to fix it by examining my linear algebra very carefully, and it worked itself out.', u'I am having the same problem Tony, any solution yet?', u'Sorry, I am still blocked :(', u'Am I correct to convert the dot product in the formula to square? Thanks
variance = Sum_i (Xi- mean k)^ 2 * gamma(i, k) / Nk', u'I got it, I was using the Gauss equation wrong, the sigmas were capital sigmas not lower case (ie I was squaring them even though they were squared already).  Hopefully this helps someone avoid too much hair pulling. -Jim', u'@Jim, does that mean you implemented a separate join prob and likelihood function? The ones that pass the test seem to expect non-squared standard deviation', u'Hmm that is interesting, you're right, they both pass locally with and without taking into account the squared std.  I wonder if the compound error from repeated training calls adds up, but for the one shot likelihoods and joint-probs, it is within acceptable limits? ', u'@James I am seeing the same issue, but I am not squaring the std for the Gaussian. Did you do anything else to fix this issue?', u'I think they pass with and without the squared because those test cases have variances of 1. I hope the TAs use a non-1 variance for the test cases for next time to help students catch this error much sooner. Would have saved me hours of time tonight.']}, {u'text': u'What does it mean if I am able to pass the local test for best_segment but my image is not exactly the same (as baseline)?
My best_segment() generates image which seems to be one level brighter than the baseline image. Does that mean, my GMM is not producing proper results or is it possible that the images produced might not be the same?
I am concerned because of limited submissions on Bonnie and I don't want to waste a submission if there is  something I can improve with local testing.', u'responses': [u'My guess is that, if your best segment;s likelihood is above the reference by certain threshold (3e4 in the test file), then that means your best segment is better enough, so your code generates better segmentation?

Need confirmation from TA.', u'Could you share your image in a private post? Most probably, it should not be a problem as long as you are passing the local tests.', u'Hi Richa, I have created a private post for further discussion.']}, {u'text': u'Hello,

When I run segmentation test (party_spock.png which has shape of 526x700=368200), I'm getting MemoryError on line where I'm trying to multiply my image and gamma. Which leads 368200 x 368200. Is this mean my algorithm is not correct? or should I find another way to do the multiplication?

Thank you', u'responses': [u'There is an error with your algorithm - you should not need to perform a multiplication that results in such a large array. I would advise you to look through the formula again and see if it lines up with what you've coded.']}, {u'text': u'delete me', u'responses': [u'I will contact god and see what can be done.
Joking aside, you need to delete yourself from the class if that is what you meant. Go to your settings and delete class from there, the TA's I don't think can do it.', u'I don't think any Cybermen are taking this class']}, {u'text': u'Does anyone have any pointers or direction for the train_model function. Thank you!', u'responses': [u'Follow the PDF very closely, specifically the equations on pages 438-439', u'Lily is pointing you in the right direction. In addition, you can also see the youtube live recording in which we went over the equations in em.pdf. Also, the discussions on this page are quite helpful.', u'Thank you both. I had the math right but my dimensions were not aligned. ']}, {u'text': u'Can someone help me understand equation Equation 9.23 in em.pdf file? Can we use likelihood function as denominator?

', u'responses': [u'It calculates the probability data point $$x_n$$ belongs to the kth Gaussian component. It is one value for each pixel so you cannot use likelihood function which calculates the marginal probability over all pixels.', u'If you look at it closely, it looks to me like the denominator is just a normalization factor. Once I made that assumption, everything started working as expected. i.e. the result of summing y_znk over n should be a distribution of counts over 1000 pixels.', u'Thanks Irene and David. This explanation helped me to think in right direction.']}, {u'text': u'If I understand this correctly, this is the sum of responsibilities over all pixels for a given cluster. Won't this value always be equal to1?', u'responses': [u'No. In your gamma matrix each pixel (row) should sum to one, but the clusters (columns) won't. You are summing each column - so the result should be an ""effective number of pixels"" for each cluster.
', u'Got it!  My brain was transposed. Thanks', u'The sum of N_k is the total number of pixels in the image. The separated k elements of N_k are the number of pixels inside of each cluster. Because this is Gaussian, that does not have to be a whole number.

For example, an image of 10pixels x 10pixels with 4 different components with even mixing should eventually converge to the following N_k: [25.0, 25.0, 25.0, 25.0]
Sum(N_k) = 100 which is the total number of pixels']}, {u'text': u'I'm having trouble understanding when to and how to implement the log form for the EM algorithm.
For instance, for the E step, I am taking the equation from the ReadME and performing logsumexp along the K axis to get the denominator for gamma. I am doing similar things for mean and the mixing coefficients (replacing logsumexp(x, y) with logsumexp(x, -y) for subtraction). But I have not figured out how to modify the variance formula to support log form. Can someone point me in the right direction?', u'responses': [u'I would say the simplest way is to take the log form wherever possible - so that would mean logs of the probabilities, logs of mixing coefficients, and so on. So you would take log for the numerator in the E step as well.

For the variance, keep in mind that em.pdf talks about covariance with the assumption that you're dealing with multidimensional data. Think about whether that applies for the problem we're trying to solve. It should be fairly straightforward.']}, {u'text': u'Calculate the jointlog probability of a greyscalevalue within the image.

This wording is stumping me... how can you have a joint probability distribution for a single value?

The assignment lists the log form of a normal distribution as:


So I get that I can code up this equation, but what is the joint probability created from when there is only one value for which we calculate a probability?
I guess I'm just not sure what it is I need to do for the joint_prob method if somebody could help me understand this part better...', u'responses': [u'I think ""joint"" here means across all the different latent gaussian distributions that could have generated the point. So we calculate the log probability that we got value x from a latent distribution N(mu, sigma), and then repeat that for all of the components, and then combine the likelihoods. ', u'so in this case the joint probability is across all the different components?', u'
""the joint probability is across all the different components?""
Yes.']}, {u'text': u'Perhaps it is just the late hour, but I'm getting some weird numbers. When considering x = 0.4627451 (with mu=0.10196079, sigma=1, and pi=0.2) I'm getting 0.393062706765989 for the log probability using the formula in the readme. I got the same result with Python and in a spreadsheet, so I know it's not a typo. 

That means that the probability is e^0.393062706765989 = 1.48, which is more than 1, which is no bueno. 

Do I have a problem in my calculation, or are we supposed to normalize the probabilities across the components, or something else?', u'responses': [u'Sorry, but how is pi 0.2? Isn't the pi in the equation the normal math pi, i.e., 3.14?', u'I think π refers to mixing coefficient here.
See equation 9.7 in EM.pdf and the paragraph therein that describes πk ', u'Let's not get these confused. The π in the log form of the Gaussian distribution is the constant pi ≈ 3.14159. However, the same symbol used in the equations of EM.pdf are not the pi constant, but do represent the mixing coefficient. The symbology is confusing and regrettable. I'm not sure why the author of EM.pdf would use a universally recognized symbol for the constant pi and declare it to mean something else.', u'Yay!! That's totally it, I forgot how Gaussian distributions work. Now I'm getting negative log probs. Thanks everybody! ']}, {u'text': u'My code passes all the part 2 unit tests. So I decided to submit to Bonnie but for the train_model() on Bonnie I get
Post-train likelihood is not significantly greater than pre-train likelihood. Your Train Model function may be incorrect.
I was kind of assuming that the unit tests were close to what Bonnie tests but it seems not. Any advice on where to start looking if Bonnie fails but unit tests pass?

Also from Bonnie I get 'Calculated pre-training likelihood matches the expected likelihood'. For a TA - can I at least assume from this that my likelihood() function implementation is correct? (It does pass the unit test also). i.e. that the issue Bonnie is reporting is directly in the EM implementation itself, not the calculation of likelihood', u'responses': [u'I've just received the same feedback, tried to run 'test_gmm_train' in loop, in my case it fails sometimes with the error ' Model likelihood increased by less than 190 for a four-mean mixture' I guess it depends on the initial values which selected randomly', u'Has Anybody faced the same? Any hints/ideas why it can happen?', u'hmm, this is kind of scary.. I am now pretty skeptical of the value of the training unit test.

I assume most folks will write their training code, test with the unit test and reasonably assume they are done with training after a unit test pass. Then wait until all the assignment is written before burning a Bonnie submit so as to verify as much as possible in that submit.

But if a pass on the training unit tests is not a reasonable indication of a Bonnie pass then such folks might only run into this problem close to the due date.

The unit tests are a good way to debug the implementation since we can see what is going on. But Bonnie provides exactly zero information as to what is wrong. So the only idea I have right now is to go back and start changing the unit tests somehow in the hope that they fail so I can debug what is wrong in the implementation. i.e so the unit tests don't pass a faulty implementation.', u'I had this same problem.  It turned out that my means were ints and weren't getting converted to floats when I updated them.  I changed their type to floats and it fixed my problem.  Later, I realized that I was in Python 3 instead of Python 2, so I'm not sure if that problem was environment specific.', u'If you are still having the problem, please make sure that you are doing all your calculations in log space. That's one of the most common reasons of part 2 passing on local and failing on Bonnie.', u'Still same problems for me - passing local tests and failing Bonnie. Can you be more detailed/ specific about what you mean by 'log space'. The various formulas provided specify log() in various places - does 'log space' mean just follow the use of log() in the formulas or something else?', u'It is not sufficient if the given formulae (from em.pdf and the comments in the code) are implemented as-is. As we have said in the assignment README, when performing multiplications, there is a possibility of underflow.

For example, if you need to compute $$\frac{(1.8*10^{-135})^4}{1.3*10^{-400}}$$

The result is within the range of Python floats, but the numerator individually is not. Python will evaluate the numerator separately (which underflows to zero) and return the answer as zero.

Instead, if you take the logs of all of these values and perform your computation, then finally take a numpy.exp() of your log value, you will see the correct answer returned.

We expect that all your calculations be performed thus. To put it simply, we expect you to calculate all formulae as given in em.pdf, but with the above precautions taken.

I hope this makes sense.']}, {u'text': u'How accurate should our training be? for example, on the 4-cluster test I know I should be getting means of [2,4,6,8] but the values I get when I meet the convergence criteria are

means = [ 1.50564602 3.13866773 5.51635671 7.81405416]variances = [ 0.41462792 0.90026998 1.54357914 1.01533236]mixing coefficients = [ 0.14899406 0.26529431 0.36907278 0.21663885]

Should I expect to be getting exact matches to the actual means?', u'responses': [u'No, not exact numbers, but mine are well within 1-5% when it comes to means and mixing coefficents', u'@Steven It should be much closer than the numbers you've provided.', u'Hi Steven, I'm getting similar results, let me know if you figured it out.', u'I also have similar values, I guess it's the reason of the intermittent failures of 'test_gmm_train'', u'Stuck here as well - anyone get past it?', u'I'm also seeing numbers like these, although I'm passing local tests. I've seen comments in the threads here that imply that we should do this part in log space, which I'm not doing, so that's the next thing I'm going to try if my Bonnie tests fail. Perhaps there's underflow that's causing this slight error?', u'@Sasha - people are referring to doing the various calcs in 'log space' but I'm confused about that terminology since the formulas given in the assignment appear to be specific about when to use logs and when not to.

For example, this formula seems to be precise about where to apply logs 


as does this one 

so what does it mean exactly to do a calculation log space?

', u'Please refer to my followup above about putting things in log space.']}, {u'text': u'What constitutes a better log-likelihood value? Is it better the closer to 0 it is? My likelihood values get more negative on each EM iteration, so, there is more than a 250 point change, but the unit test always fails. So, I'm not quite understanding what the unit test is really trying to assert.', u'responses': [u'Higher log likelihoods value are better. There's probably some issue with your implementation of the E and M steps.', u'For anyone else who reads this, what fixed it for me was, 1) I stopped squaring my variances when calculating the log Gaussian probabilities (derp!), and 2) I mistakenly kept my responsibility calculations in log space when I needed to convert the log Gaussian probabilities back by raising them to a power of e.', u'Is it supposed to be between 0 and 1? I got huge negative number, like -2000.Could you help me what I was wrong?', u'The line where it says log likelihood should be between 0 and 1 is a mistake.']}, {u'text': u'For the test_gmm_best_segment function I am getting a really large negative likelihood_diff. The difference is very large, roughly 4 times larger than the threshold limit of 30,000, but it fails because it is negative.

Should the test really be: (notice abs())

likelihood_diff = abs(best_likelihood - ref_likelihood)
instead of:
likelihood_diff = best_likelihood - ref_likelihood

Or am I just doing something wrong?', u'responses': [u'The likelihood needs to increase. Maybe there's some issue with your training function?', u'Okay, thanks. Mine always seems to get more negative in every instance. I will look more into it, thanks.', u'Jake, you might be having the same issues I had. Check my post above and see if it helps.', u'For anyone running into this problem, I found the issue to be in my likelihood problem. Even though it passed the local test, it was not providing proper output when the variances were not equal to 1.

Note to TA's: In the future, it would be helpful to revise the likelihood test to have variances other than [1.0, 1.0, 1.0] because if you square, cube, or square root them, you still get the same values [1.0, 1.0, 1.0] and may not find an issue.', u'We'll keep that in mind for next semester. Thanks, Jake!', u'Obviously, likelihood is pretty important for this assignment. So is there a unit test that a TA can provide that that does properly test the likelihood function. i.e. tests for a correct calculation when the variance != 1. It seems evident from Piazza that many students have tripped over the to square vs. not to square issue and unfortunately the way the supplied unit test is written it does not highlight that problem.']}, {u'text': u'Hi Everyone

I'm experiencing intermittent failures of 'test_gmm_train' test.(when it passes segment and best_segment tests are also pass) 
As far as I understand it depends on an input dataset(tried to run on the same 'positive' dataset multiple times, my code produces the same means variances and mixing_coefficients). I tried to play with the convergence function (conv_ctr_cap value) it didn't change things significantly. 
I wonder, as soon as test dataset randomly generated, and initial mean values are hadrcoded, is it possible to have a situation when for some random dataset initial values are close to converged values, that's why likelihood difference is small?
Has Anybody ran into the same issue/Any hints/advices how to overcome it.

PS: I'm still not 100% percent sure that my code is fully correct.

Thanks
Alex', u'responses': [u'I don't have an answer but I am at the same point and have the same question. Would appreciate if anyone has any thoughts on my test_gmm_train would fail intermittently.

Perhaps this is why per the README we  ""might be skeptical of the convergence criterion we've provided in default_convergence()"" ?', u'it looks like the reason of intermittent failures in my case was stale codebase, after I pulled the fix of negative values in the dataset it works', u'I too found an error in my code that l when fixed resolved this issue.']}, {u'text': u'Some feedback for the TAs and a hint to other students: for the joint probability, the data type of the means provided by the initialize function are in a slightly different shape than the means provided in the unit test. If you write slightly brittle reshaping code like I did, it will not throw an error, just quietly return a slightly wrong answer. Sigh.', u'responses': []}, {u'text': u'For calculating the responsibilities in the E step, is the following assumption correct?ln(Y(Znk)) = (ln(mix_coefficient_k) + ln(N()) - ln(sum over 1-k (mix_xoefficient_j * N())and ln(sum over 1-k (mix_xoefficient_j * N()) is the joint prob that we return from the function.
', u'responses': []}, {u'text': u'In our GaussianMixtureModel, mean, variances and mixing_coefficients are initialized as 1-D numpy array.

However, in test_gmm_best_segment( ), under the part ""# extract likelihood from reference image"". ref_means is a list (while ref_variances and ref_mixing are still numpy array). this gives me error when calculating ref_likelihood. I passed this local test after I changed ref_mans to numpay array in test_gmm_best_segment( )

My question is: will the test case on Bonnie also have mean, variances or mixing_coefficients as type list instead of 1-D numpy array? Is that something I need to handle in my code or is that just some minor error in local test?', u'responses': [u'Please use numpy arrays everywhere. Our Bonnie tests have been fixed to this standard as well. What you're seeing is a minor error in our local test.', u'Thanks for confirm']}, {u'text': u'Hey all. Just curious if anyone is experiencing intermittent failure on the `test_gmm_train`. Maybe 20% of the time that I run it my likelihood gain is slightly under the 250/190 thresholds. This could be just bad luck with random test mixture generation, or it could be something more sinister... Anyone else seen this?', u'responses': [u'I see it. I don't convert gamma, means, variances, or mixing coefficients to logs and I think this might be the issue. I'm going to convert them tonight.', u'With our test mixture you should be fine if it fails occasionally, but 20% seems a bit much. As Anthony says, have you done all your calculations in the log space?', u'Did the conversion help?', u'Thanks both for the answers! I'm still a bit confused by the whole ""log space"" discussion, given that the log form of the PDF for the normal distribution contains non-log-space values, but I found a different answer which seems to work. (See my note below under Mengyun Zhang's question)', u'to ""work in log space"" you need to split your equation into components that are all connected with multiplication, division, power, or root operations, then you take the log of each of those components and replace multiplication with addition, division with subtraction, power with multiplication and root with division.

so n*sqrt(y-5)  becomes log(n) + log(y-5)/2 
when you're done with the work, you use exp() to bring it back into normal space.

Note that you can't do this across portions of equations that have addition/subtraction (hence my y-5 inside the log()) since addition doesn't translate into log space.   You have to perform addition and subtraction in normal space (hence the logsumexp() function which uses exp() to take values out of log space, sums them (performs the addition) and then puts them back into log space).']}, {u'text': u'Question on segmentation. If I'm understanding this step correctly, we are to take the ""soft cluster"" results from the trained model and force them into ""hard cluster"" results by substituting the mean pixel value of the cluster that each pixel has the highest probability of belonging to.

If the above assumption is correct, am I also right to assume that we need to use the responsibilities matrix from the train_model step to judge which cluster each pixel most closely aligns to? I'm a little confused by this because the responsibilities matrix is not a class attribute and the train_model function is not set up to pass the responsibilities matrix outside of the function to segment. I could modify the code to do that, but I want to make sure I'm not way off base before heading down that path.', u'responses': [u'Can't confirm that this is the appropriate way to approach this but what you describe reflects the way I approached it as well.', u'The problem I'm having is that certain clusters show up as more likely for more pixels than others, and when there are say, 5 components, I often will only get three different pixel means chosen in my segmentation because two of the clusters are never the maximum value in the responsibilities matrix. At least, that's what I'm seeing. I wish there were more on this part, because I think it's where I'm going wrong, but not 100% sure.', u'I would say there are two ways to do the segmentation - one as you have described above, and the other similar to how you did it for k-Means.
Either way, this is done only at the end of the training, so it shouldn't hurt to do this computation one more time.
I would ask others to contribute here - I am not sure you would see just 3 components be the likely ones with k = 5, but I could be wrong.']}, {u'text': u'Looks like there is a typo in https://github.gatech.edu/omscs6601/assignment_5/blob/master/mixture_tests.py#L125

Either you meant round(..., 3), or -0.9826 ?', u'responses': [u'You are right. This doesn't seem correct. Thanks for pointing it out. ', u'I would be careful with values that look “right”, but are just close. I had the same situation as you for awhile, but was eventually able to pass the test case as-is (which is why I think it was written in that manner).']}, {u'text': u'Hi guys,

Just want to check for ""test_gmm_likelihood"", did anyone get an answer of ""-364868.81814"" - > which round it to ""-364869.0"" ? The golden value is -364370
I checked my code several times likelihood and and seems it's correct.


Isn't that is just about calculate all the joint_prob on each pixel and add it up? 

Thanks!', u'responses': [u'I got your number when summing the join_prob of all pixels one by one, but got the golden value after using logsumexp. 

Now a question for TAs, which number if more close to the ""real"" number?', u'Really? When I changed it to logsumexp, I got ""11.8298551114"" -> which round to ""12""
since after apply joint_prob, it's already log based, so I should be able to directly use ""sp.misc.logsumexp"" on it right? like: sp.misc.logsumexp(joint_1_d_matrix). based on Readme, then its like numpy.log(numpy.exp(first joint prob) + numpy.exp(second joint prob) + ...)

Am i doing something wrong here?', u'got it, i was wrong. joint_probability only use log_prob, for likelihood we should use prob then multiply mixing_coefficients', u'Thank you Mengyun.

Your comment helped me really much. I appreciate you~!!', u'Echoing Mengun's comment! I found the formula from the readme actually misleading here:



I implemented this with fidelity (I think!), did the sums, and got exactly... -364868.81814

Looking in more detail at the docstring though:

ln(Pr(X | mixing, mean, stdev)) = sum((n=1 to N), ln(sum((k=1 to K),
                                          mixing_k * N(x_n | mean_k,stdev_k))))
If you read that carefully, it implies that should use the traditional normal distribution (N(x_n | mean_k,stdev_k)):



I used this, and the multiplied, ln'd, and summed as in the docstring, and finally go the right answer. Seems to go against some of the guidance, but just happy to have it working!

', u'Awesome. Very helpful, Owen and Mengyun. Thank you.']}, {u'text': u'My joint probability test failed by 0.001 difference.
Has any had the similar issue? What is the cause of the issue?', u'responses': [u'if you round by 3 you should have -0.983
if you round by 4 you should have -0.9826
', u'thanks']}, {u'text': u'My GMM passes the unit tests, until it gets to segment. All of the means converge to the exact same value. What could be causing this? The unit tests prior to this don't give me any indication that my implementation is broken. Submitting to Bonnie scored me 30 points for part 2, so, I'm really not sure what to look for.', u'responses': [u'That shouldn't be happening. Your segment function should use the exact same training implementation, with the only difference being assigning points to clusters once you're done with that.

Are you sure that's how your code works?']}, {u'text': u'Can someone explain the responsibility matrix equation? 

From my understanding, we basically have a NxM matrix, where N = the number of pixels (image flattened) and M = the number of components. 

My understanding based on the equations and the office hour youtube video: 
The numerator, is the mixed coefficient for a cluster times the joint log probability for the pixel value. 
The denominator, is the sum of the numerators for each clusters. 

What I'm confused about, is that the sum of the mixed coefficients = 1. So what that means, is you get a responsibility matrix of just the mixed coefficients. Which doesn't make sense to me. 

For example let's say the mixed coefficients are: [0.5, 0.5]
The (numerator) values * joint probability = something like [ [1,1] [2,2] ]

This means the responsibility matrix will look something like: [ [0.5, 0.5] [0.5, 0.5] ]

I feel like I'm missing something very obvious and doing something very stupid. Any help would be appreciated. ', u'responses': [u'I think we want to normalize the values.', u'Hi J, Can you elaborate?

From my understanding, there would be a cycle where the mixed coefficient would never change, which doesn't make sense. ', u'The mixed coefficients do change, but not until the Maximization step.

In the Expectation step the responsibility matrix is updated, using the calculation you've included above.
After calculating these values they must be normalized to get them to sum to one.
Then, in the Maximization step, means, mixing coefficients, and variances are updated given the normalized responsibility matrix values.', u'so is the denominator in this case not just the likelihood we have already calculated?  it seems that we are just summing over the joint probs which is the likelihood...', u'I think that's true. Im not understanding why they don't sum to one but normalizing them seems to work for me on the local tests', u'I think I realized what I was doing wrong, I was calculating the numerator incorrectly, so I was calculating: coefficient * joint_prob. But the numerator should really just be the -0.5ln(2 * pi * sig) - (x-mu)^2/(2*sig) for a specific cluster. Also, I thought the denominator is only the sum of a specific pixel value, for each cluster. Whereas the likelihood is the sum of all pixels for each cluster. ']}, {u'text': u'Hi, I'm working on the 2. train_model function, and I have a questions regarding the default_convergence function.
In my calculation, both my prev_likelihood and new_likelihood (both in log) are negative.
Therefore, for example, if it changes from -1900 to -1700, it's an increase.

However when I look at the code, it's using absolute to calculate, therefore it's definitely wrong.
Did any other encounter this? How should we fix this? seems removed the abs also not working because after multiply a negative to 0.9 it's actually become larger, so the answer is also wrong.
    increase_convergence_ctr = (abs(prev_likelihood) * 0.9 <
                                abs(new_likelihood) <
                                abs(prev_likelihood) * 1.1)

    if increase_convergence_ctr:
        conv_ctr += 1
    else:
        conv_ctr = 0', u'responses': [u'An followup question, for train_model, what do we have to or check?
Looks like if we do only one time, we can also pass the local test, but should we check for 10 times and then return to see if we can converge?', u'got it.']}, {u'text': u'Can anyone provide some clarification for the conv_ctr variable for the default convergence method? 
Are we supposed to be keeping track of the counter each time we run the train_model?

So i.e. we start with counter 0, we run train_model, and the new likelihood is between .9 - 1.1 of the old likelihood, we increase the counter to 1. Then we run train_model again, if likelihood is again between .9-1.1 of old likelihood, we increase counter and if the counter is > 10, we return true (stop the EM flow). Otherwise we start over and set the counter back to 0. Is this an accurate interpretation of conv_ctr? 
', u'responses': [u'It's a convergence counter.

I initialized it to zero and then it is passed to and back from the convergence function (it's keeping track of the succeeding calls which are converged). ', u'The convergence function works like:

(conv_ctr, converged) = convergence_function(old_likelihood, new_likelihood, conv_ctr)
converged will be True if you have converged.']}, {u'text': u'If the rows of the responsibility matrix sum up to 1, why do we use 1/Sum(responsiblity matrix) in calculating the new mean and standard deviation?

So for me Nk is always [1, 1] right now. And N i'm assuming is the number of pixels', u'responses': [u'Nk is a sum of the columns of the responsibilities not the rows.  It should add up to 1 * number of rows', u'So N is the columns and K is the rows?', u'When you come up with responsibilities, I'm assuming you have flattened the image first.  So for each pixel of the image, you will have one row in the responsibility.   That row will have k values (one for each k).  The sum of the responsibility for each pixel should be a total of 1 (that's what the denominator is achieving).  Note that it's possible you have a different shape to your responsibility array (where k's are rows and pixels are columns) -- that would change this discussion a bit.

When you sum all the values in a column, you are calculating the total amount of responsibility assigned to that component (the k'th mean).    That's what Nk is. 

The sum of the responsibility for all of the components should be equal to the number of pixels since the sum of responsibility for the pixel is one.', u'Yes that's exactly how I have my responsibility matrix set up. N rows for each pixel in the flattened image and k columns for each component. Nk says to sum the responsibility from 1 to N though and doesn't have any instruction for k. So I assume sum rows that yield an 1 x K that I can use to divide into each row of the responsibility matrix.', u'you don't divide Nk into the responsibility matrix.  

You use Nk when you are defining the mean, variance and mixtures.', u'Nk is $$N_{k}$$, meaning the number of points belonging to cluster k. It is not N multiplied by k. The sum of all Nk's should be N.
With k-Means, we assign each point to a one specific cluster. However, in GMM, conceptually we are doing a ""soft assignment"", i.e., each point is partially generated by each cluster. The proportion of the point generated by cluster k is the responsibility gamma(znk). The sum of responsibilities for each point is 1.']}, {u'text': u'I have my code passed the test_train_model locally, but during test_segment, sometimes my mean/variance can go negative which cause likelihood become nan, is anyone encounter the same? any suggestions?', u'responses': [u'I had a similar issue and found that I was calculating the responsibilities incorrectly. I was using the log probability for the numerator and realized I need to to do np.exp() to bring it to a normal probability. ', u'What Benny says seems to be the answer - you will get negative values if you use logs instead of e^log in the formula.']}, {u'text': u'In GaussianMixtureModel, is the likelihood() function always suppose to return negative value in range (-inf, 0]? 
when called after train_model(), my likelihood() will return positive values like 4000. Is that an expected behavior?
I actually passed Bonnie test for part 2, but have error in BIC_likelihood_model_test(). I suspect it may caused by some hidden error in my likelihood() function.
', u'responses': [u'I believe Likelihood is a log probability function so it should be returning a log of a value between zero and 1 which should be a negative value.', u'I also think the same way, thanks for confirm. I think my problem is in my train_model. My likelihood increased 6000+ after one iteration of EM, which can't be right.', u'To avoid confuse anyone, I passed all Bonnie test from Part I to Part 4, my likelihood after train_model for the party_spock.png are large numbers >0']}, {u'text': u'In train_model, after we converge, should our means be exactly equal to the actual means of the unit test?', u'responses': [u'Not necessarily. They should get reasonably close though.']}, {u'text': u'My log likelihood is increasing in every iteration. It's starting from ~1900 and ending at ~1700 with more than a 250 difference for 2 means. However, it's always failing for 4 means. I'm assuming my likelihood calculation is correct since it keeps increasing. Did anyone keep encountering a failure for 4 means mixture, and do you have any tips as to where I might be going wrong?', u'responses': [u'One test I did in my loglikelihood function (during testing) was to do a second calculation of the likelihood using a loop along the lines of:

test_likelihood = 0for i in range(num_pixels):    test_likelihood += self.joint_prob(pixel[i])
This should be the same value you calculate using the vector operations.  If not, you need to look at why.

Note that this will be too slow to pass bonnie, so it's only useful for testing/checking your local values.

If this gets the same values, then the problem is not in your likelihood, but in your calculations for means, variances and mixing_coefficients.   I had to throw away my train_model and start from scratch when I couldn't get them to converge even closely to correct on the spock image (though I was passing the basic train_model test).  ', u'This is a good tip. You should also check if all your calculations are in log space.']}, {u'text': u'I'm getting good gains for training like +1400 but this fails on the larger image because i'm having a hard time keeping the answer in log space. I can't seem to make np.exp(logsumexp()) replicate the results for converting the responsiblity matrix out of log space and then trying to sum it normally', u'responses': []}]",,,,1034,,Assignment 5 - Part 2 discussions,[a5]
5ad7d49b0d63974e20c3922b,"
Assignment 5 - Part 3 discussions go here.

",jc6w44hrp9v2ki,"[{u'text': u'My model with the new convergence performs the exact same as the regular GMM... any ideas? I checked that the right methods are being called and everything', u'responses': [u'what do you mean by exactly the same? To the same clusters (means, variances, mixing coeff)? It is also taking similar time to converge (check the number of iterations to converge)?', u'Everything comes out to be the same - almost same means, variances, coeffs and the same number of runs. There is a 0.06 difference in their likelihoods', u'Logically speaking, if the new variables are within 10% of the previous variables, wouldn't they also produce similar likelihoods? What is the difference in convergence conditions?', u'To answer only the last question, similar variables may imply similar likelihoods, but not the other way around. There is the possibility that early on, in two successive iterations you have radically different Gaussians but similar likelihoods. These should not be counted towards convergence, but they may be in the default case.', u'That makes sense, but in our case, we look for similar likelihood 10 times in a row, so is that possible without similar variables as well?', u'They may not be wildly different, but it is possible to achieve a likelihood within 10% with variables that are more than 10% away from each other. The new condition is simply a bit stricter, and our local test only asks for a small improvement over your previous convergence condition.

Try printing out your means, variances and mixing coefficients when your convergence counter is more than 3 or 4? You should see them change by more than 10% with the default convergence condition, and the condition will only be reached a bit later in the training process with the new one.', u'I did try that and they are exactly the same, so of course the likelihood is the same as well and no where near 82k difference like the threshold requires. I did implement the equations from the pdf straight without using log space, so maybe that is why. I did not find the instructions in the readme sufficient to implement the whole algorithm in log space (it only explains how to transform the gaussian) and it didn't work when I tried to guess at the gaps, so I stayed true to the reference material.

However, reading your comment ""You should see them change by more than 10% with the default convergence condition"" makes me think I am using the convergence condition in the wrong way altogether. The way my implementation works is that it does the E step, the M step and then checks for convergence and decides whether to go again - in this way, the convergence condition has no bearing on how the variables change, it only checks if they changed enough. If this is the wrong way to use the convergence condition, can you point me in the right direction?', u'We did feel that conversion of the multiplications and divisions into log space was a fairly simple operation, which is why we have not explicitly provided those formulae for you. Using log space should help.

Your understanding of convergence is correct. The convergence condition has no bearing on how the variables change. What I meant is, with the default convergence condition, your algorithm might converge even though the variables are changing by more than 10% (since convergence is based purely on likelihood). You can test this by printing the variables in the final few iterations.']}, {u'text': u'I'm stumped on the grader for both parts (a) and (b).  I'm getting zero points for this section - but everything works as expected locally. 

For part (a), I'm using a certain clustering algorithm to initialize the means.  That's it, right?  When I hard-code the 3-segment means of Party Spock for the non-improved version of the algorithm, the improved version converges on a log-likelihood of ~97810 (vs ~84108 for the non-improved version).  If I don't hard-code the means for the non-improved version, the improved version still beats it most of the time.  That's to be expected, though, right?  ...since the non-improved version picks random initial means - and sometimes those values could be better than what clustering gives us.

For part(b), I'm doing exactly what the readme says: algorithm is considered converged when all means, variances and coeffs are within 10% of their last value for 10 consecutive iterations.  When I hard-code the initial means, the improved version does better than the non-improved.  As expected, it takes longer to converge since it represents a higher bar for the model to pass - and it's always better.  But what if the initial values are just bad?  Just because the terminating condition is stricter doesn't mean that it will climb a better hill than the non-improved version of the algorithm.

Am I just getting unlucky with the grader?  I don't want to burn another attempt if that's all.  I must be missing something basic.  Can I just make the non-improved version of gmm worse?  Thanks!', u'responses': [u'For part(a) yes, the improved version is expected to do better. DO NOT hard code the means, we have different image at Bonnie. 

For part(b) again, DO NOT hardcode. 
For this, you are allowed to initialize your means the way you are doing in Part(a) and use the improved convergence function on top of it.', u'Thanks for the response.  I am not hard-coding the means outside of tests.  I am still confused what the tests are looking for.  The non-improved version can still do better than parts (a) and (b) if it randomly gets initialized to a good mean, right? 

I was under the impression that part 3 was pretty easy compared to part 2.  Part (a) consists of using clustering to choose good means and part (b) just checks that the model params converge to within 10%.  These are both pretty straight-forward (I thought).  Everything works as expected locally.  Do you have any advice on debugging the grader? 

Thanks!', u'Matthew, you understand it correctly - ""the non-improved version can still do better than parts (a) and (b) if it randomly gets initialized to a good means"". But as far as testing on Bonnie is concerned - we have the thresholds calculated  for a particular set of starting means - so the output becomes deterministic. It's similar to how the local tests are implemented. ', u'Hi Richa. Quick followup on your point: ""so the output becomes deterministic"". I was just wondering if generating the deterministic output on Bonnie also involves setting a random seed? I was setting a random seed locally for reproducibility and seeing very consistent results (even when varying it) but have failed twice now on Bonnie - I'm wondering if my seed might be over-writing Bonnie's expectation?

Thanks!', u'The stochasticity in the algorithm comes from choosing random initial means and doing your training/clustering.

However, to test your train function we provide a fixed set of means on Bonnie, so there is no randomness.']}, {u'text': u'I've implemented the convergence function a handful of different ways and none pass on Bonnie (despite passing the local test). Can you please clarify what the convergence test is looking for? If the latest parameters must be +/-10% of the previous parameters, does that mean you check the latest ones against previous_parameters[-1], then the latest vs previous_parameters[-2], etc? Or are we checking latest vs previous_parameters[-1] and then previous_parameters[-1] vs previous_parameters[-2], etc?

Is Bonnie checking for an improved likelihood more than a certain threshold or for a specific value? Thanks!', u'responses': [u'same here, i'm passing all the unit tests for this case, but none of them are passing on bonnie. Are the thresholds on bonnie different from the local thresholds?', u'Did either of you not convert everything to log space? I am having this same problem and I think this might be the issue. I am going to try and convert everything to log space and try again tonight. I only have 2 attempts left so I will be watching the terminal spin with sheer anxiety.

Part 3b is the only failure I have on bonnie.', u'I had the same thought, but then again I thought logspace was only necessary for the probabilities because they became vanishingly small. Also, the instructions don't mention converging the log of the parameters, it says to converge based on the parameters, but maybe that is something they left out. What would you be converging between? For example, on the low side, 0.9 * ln(x) or ln(0.9 * x) = ln(0.9) + ln(x). Either way (and for all the methods I've tried), mine tends to converge to a log likelihood value that is clearly above the threshold, but not by a massive amount.', u'I'm not sure. I think calculate everything into log space and then convert it back for convergence test? At this point I don't have much else to go on.', u'Make sure you are not hardcoding your initial means in any case. We have different images on Bonnie.', u'And please use log for calculations wherever possible. Any multiplication can result in underflow in this assignment. That may be the issue in this case.

To clarify, you check your parameters after the M step against the parameters before the M step for the 10% threshold.', u'Hey Wade I don't know if you ever figured out your problem, but here is what fixed it for me. I changed all of my calculations (means, variances, gamma, mixing coefficients) to log-space and passed all of the Bonnie tests. Locally everything looked pretty close with or without log space. The biggest difference was probably the variances. There had to be some underflow going on there. It is also worth realizing that scipy's logsumexp handles the underflow pretty well. So even though functions might be mathematically equivalent on paper between the log and not log versions, using the logsumexp provides the benefit of improved underflow handling despite the fact that it seems redundant to convert numbers from log to normal, sum them up, and convert back to log (rather than never messing with logs and just summing).

Just so I don't confuse, the convergence test still checked using the non-logspace means, variances, and mixing coefficients. I just converted back with np.exp where necessary.', u'Thanks for the replies!']}]",,,,1035,,Assignment 5 - Part 3 discussions,[a5]
5ad7d49b0d63974e20c3922c,"
Assignment 5 - Part 4 discussions go here.

",jc6w44hrp9v2ki,"[{u'text': u'The question I had on BIC was answered here: @1050', u'responses': []}, {u'text': u'is the max_likelihood calculated from an initialized model, or a trained model?', u'responses': [u'The trained model.', u'I had assumed BIC should be calculated before training the model since that is what was done for the test case, is this not true? The BIC should also be with the trained model?', u'Yup', u'I am confused (again, this assignment..sigh..) So I had first assumed BIC should be calculated on the trained model. However, the unit tests run on the untrained model so I added training iterations to the bayes_info_criterion() call to do the training. But all following tries failed the unit test.

So finally (without anything better to try..) I tried not training and the unit test passed the very first time. So good it passed but now I'm confused by Ravi's comment that BIC should be calculated on the trained model. Anyone able to able to clear up this confusion for me?
', u'Seconded - I wasn't getting 0.0 but I was getting the wrong answer with the trained model']}, {u'text': u'I'm using the formula outlined in @1050, but the rounded BIC is always 0.0. What am I doing incorrectly?', u'responses': [u'Hard to tell unless we know how exactly you're interpreting the formula and coding it up. Are you sure you aren't taking a log where you shouldn't be?', u'ok thanks, that does make sense. I will give that a try tonight. Thank you for the tip.', u'Nick, for what its worth I was also getting 0.0 but I was calculating on the trained model. When I removed training it came right straight away.. (see my related discussion above..)', u'Seconded - I wasn't getting 0.0 but I was getting the wrong answer with the trained model', u'Lily, did you get the correct answer on Bonnie using an untrained model?']}, {u'text': u'I got 4a and my likelihood calculation correct on Bonnie. However, my 4b was wrong regardless of what model  (initialized or trained) I used. I tried different implementation approaches as well, but the results stayed the same. Does anyone have any thoughts on how I should troubleshoot? ', u'responses': [u'are you returning the best num_components value or the BIC and likelihood values?', u'I turned in a number from 2-7', u'Based on the problem statement, the likelihood should at least show some increasing trend as k increases, but that's not the case for me. ', u'Be sure to check that you are returning the num_components for which you got the min BIC and the num_components for which you got the max-likelihood. 

And yes, you are right you should see an increasing trend for likelihoods. ']}, {u'text': u'My part 4a is correct but in part b the BIC likelihood model test found the num_component maximizes likelihood and minimizes BIC, this shouldn't be happening right? ', u'responses': [u'It's not a rule that a clustering that maximizes likelihood cannot minimize BIC. ', u'Since bic is calculated based on likelihood, shouldn't it be common for the min bic to coincide with the max likelihood?', u'BIC is meant to account for the number of free variables and thus should help prevent overfitting. While there are a lot of cases where maximizing likelihood can be shown to minimize BIC, this ceases to be the case when you're overfitting to your data.']}, {u'text': u'What should the input to bonus function look like, could someone give an example please?
Thanks!', u'responses': [u'Two arrays with the same number of columns but different number of rows - so the points array is X-by-n and the means array is Y-by-n. For example:

points = [[1, 1], [2, 1], [3, 1]]
means = [[2, 2], [3, 2]]']}, {u'text': u'Readme shows BIC_model_test() the method to be implemented whereas in the misture_models.py the method signature is BIC_likelihood_model_test( ).Please confirm which one to will be checked by bonnie?', u'responses': [u'The function signature in mixture_models.py is correct. Thanks for letting us know!']}, {u'text': u'Just to verify I have it correct for part 4b, all we are doing is training the gmm for k values 2 until 7. At each iteration, check both BIC and max likelihood values and then return the K for where max likelihood is greatest (largest positive value) and min likelihood is smallest (largest negative value)?', u'responses': [u'Yes, that is correct.', u'Well now I am confused. Return K, or return the GMM's?The code says the following:

def BIC_likelihood_model_test():    """"""Test to compare the    models with the lowest BIC    and the highest likelihood.    returns:
    min_BIC_model = GaussianMixtureModel
    max_likelihood_model = GaussianMixtureModel
', u'I think you return the models in this function and then fill in the k values in BIC_likelihood_question']}, {u'text': u'hey guys, 

you can use the following test case for memory profiling for bonus ques

if platform.system() != 'Windows':
    import resource

class GMMTests(unittest.TestCase):
    # ...

    def test_bonus(self):
        n = 3
        num_points = 9990
        num_means = 990
        points = np.random.random(size=num_points * n).reshape((num_points, n))
        means = np.random.random(size=num_means * n).reshape((num_means, n))
        distances = bonus(points, means)

        if platform.system() != 'Windows':
            peak_mem = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            max_mem = 250* 1024
            if platform.system() == 'Darwin':
                max_mem *= 1024
            self.assertLess(peak_mem, max_mem)
            print('peak mem: {:,}'.format(peak_mem))

        for i in range(num_means):
            exp_dist = np.sqrt(np.square(points - means[i]).sum(axis=1))
            np.testing.assert_almost_equal(exp_dist, distances[:, i])', u'responses': [u'Thank you for the test case! Do we also need to consider the cases when the last dimension(n) could be different for both the arrays?', u'please could you post applicable code for Windows to test memory? My test case passes locally for correct values, but fails Bonnie due to memory issues. Due to the submission limit it would be helpful to see how different refactorings perform before submitting. Thanks!', u'', u'import psutil
p = psutil.Process()
peak_mem = p.memory_info().peak_wset
max_mem = 250 * 1024 * 1000
self.assertLess(peak_mem, max_mem)
Use the above script for Windows. ', u'many thanks!', u'I passed this test case, but still fails on Bonnie. Bonnie gives no clue of why it failed, but simply

      ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_pifcwmvd/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 90, in test_bonus\n    self.assertTrue(test_flag, \""Part 6: Bonus test\"")\nAssertionError: Part 6: Bonus test\n"",

Has anyone seen the same error?', u'I got the same error even after comment out the whole ""bonus()"" part. Is there anybody figured this out?', u'To whom this(memory issue above) might matter.

In my case, the problem was k-means.
In k-means, I used ""np.meshgrid"" to calculate euclidean distances for all  x's by means pairs.
To reduce the memory required for the huge-memoried variables, I assigned ""None"" to the huge-memoried variables to clear them as quickly as possible.
For me, this worked fine and I got the expected points right after applying this strategy.

Hope this helps~!', u'jungho870, are you saying that another unrelated function (your k-means implementation) caused your bonus to fail? That seems like a bug in the autograder. ', u'I mean it’s not only the bonus that causes the memory error but others also can. In my case the memory issue was from k-means and I overcame it like what I said above.', u'Out of curiosity, why does Darwin get an extra *1024 over other platforms?']}, {u'text': u'In part 4.B, how is Bonnie passing the image to the GaussianMixtureModel model object when it gets instantiated within the BIC_likelihood_model_test() method?  Does it pass the raw image, or an array?  What is it's name?', u'responses': [u'Is it just 'image_matrix"", as it is in the local tests?', u'You have to create the image matrix from party_spock.png. Look at test_bayes_info test for insight.', u'I see. So the path on Bonnie to the image is just ""party_spock.png"", that is, it is in the active directory on Bonnie where our program is being run?  Don't want to waste any submissions on not finding the image.', u'Bonnie will be testing on a different image.
It is passed the same way as it is being passed in the local tests.', u'Thank you!', u'Sorry, I think I missed something here. @Richa, how is Bonnie going to test a different image if we are hardcoding it to ""party_spock.png"" inside the BIC_likelihood_model_test() method? Is it a different image but with the same name as party_spock.png?

', u'I figured it out. Bonnie using an image with the same name.']}, {u'text': u'Are we allowed to use scipy, or are we restricted to only numpy for the bonus task', u'responses': [u'numpy should be enough for bonus.']}, {u'text': u'for the BIC equation, wiki says that ""L-hat"" in the equation is the maximized likelihood, is this determined in a similar way to the ""best segment"" where we are just iterating and calculating the likelihood multiple times and taking the best?', u'responses': [u'Hey Erik,
just use the likelihood of the GMM that is passed to the function.']}, {u'text': u'For part b,

1) Does Bonnie run BIC_likelihood_model_test()?  
2) Or, are we supposed to run that locally, get an answer and place it in BIC_likelihood_question()?
3) Or, is BIC_likelihood_question() supposed to call BIC_likelihood_model_test()?

', u'responses': [u'I've the same doubt.', u'I'm stuck here too. Richa states above that Bonnie will test BIC_likelihood_model_test() on a different image (not Spock), but the readme makes it seem like we are hard-coding the answer to BIC_likelihood_question() based on the Spock image and provided means.', u'1) and 2)!', u'Thanks.', u'Thank you. I was not returning the GMM in BIC_likelihood_model_test() -- I didn't think it was being used. Perhaps that is why I was failing part 4b.', u'Steven you are right, you have to return both the gmm that produces the max likelihood and the one with the minimum bic.', u'Does this mean that my failure on Bonnie for part 4b could be either entering the wrong integers in BIC_likelihood_question() AND/OR a problem with the gmm that I am returning?', u'What format do we use when returning the gmm's?  Like this?

return  min_BIC_model, max_likelihood_model', u'To Theodore,

If Bonnie is running ""BIC_likelihood_model_test()"", how do we know the path to the ""Spock.png""?
Just assume the same path('images/party_spock.png') in unit tests??

And Richa said that Bonnie is testing on a different image(s) too but I don't understand how ""BIC_likelihood_model_test()"" can access to the image(it doesn't have any argument places).', u'Part 4b is unnecessarily confusing.  The instructions need to be clearer.']}, {u'text': u'While submitting on Bonnie, I encountered an error below.
I  want to know how to cope with this one~!!!


Submission includes the following files:
    mixture_models.py

Uploading submission...
[=========================== 100% ===========================] 25425/25425

Waiting for results...Done!

Results:
--------
{
    ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_ybejrsco bash -c \\\""cd /home/vmuser_ybejrsco; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""FF\"", \""stderr\"": \""bash: line 1:    29 Killed                  python run.py assignment_5 > run_stdout.txt 2> run_stderr.txt\\n\""}""', u'responses': [u'Memory issue, which I am also having even though I've profiled my code for the unit tests and everything is pretty minimal. I think I've tracked my down to train_model by burning a submission using NotImplementedError()', u'@jungho870, this is a memory error.  
']}, {u'text': u'Hello,

Sumeet: Thanks for the test_bonus(). 

Here's the output of the mem_profiler with my unit test run locally.
Filename: mixture_models.py
Line # Mem usage Increment Line Contents
================================================
 765 49.582 MiB 49.582 MiB @profile 

When I run it on Bonnie, this is what i get
{
  ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_xthndifa bash -c \\\""cd /home/vmuser_xthndifa; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""\"", \""stderr\"": \""bash: line 1:    30 Killed                  python run.py assignment_5 > run_stdout.txt 2> run_stderr.txt\\n\""}""
}

When I comment out the bonus() implementation, the bonnie tests goes through, and I can see a score.

Q1. Is the bonnie test relating to bonus() testing only the bonus() working well under mem constraint/ expects all functions to work well under mem constraints?

Q2. Is the data used in the unit test a good proxy (size wise) of the image used for testing on bonnie? My assumption is that the local unit test is a good representation of the load one can expect on Bonnie, and hence the mem profile would be similar; consequently, if it goes thru locally (i.e. passes within mem limits), it would pass on Bonnie as well.

Can you please advise? 


Thanks & regards,




', u'responses': [u'1. Bonnie test relating to bonus, is only testing for the Bonus question, but the entire submission is expected to run in 3600 seconds.

2. Yes, the image sizes are comparable - on local and Bonnie. 

But due the weekend before deadline, Bonnie load might be higher than usual. If you are confident of your Bonus implementation, you can try submitting to Bonnie again - submission killed due to memory error on Bonnie should not count against your submission count. (Did the above submission count against your quota of 5?)', u'I can see it in the list versions on Bonnie. So I guess it must be counted.

Let me try again!
', u'You must also be able to see your remaining submissions on Bonnie.', u'1]  Bombed once again with the same error.  Should I just keep retrying? Can you please advise? 

2] Is there a way to differentiate if it really failed due to mem violation/ due to Bonnie being loaded? This will help me decide if/where I should put in more efforts on the code/ just keep retrying.

3] I assume I do not need to resubmit to get my best score before the last failed attempt(s). 

Thanks & regards,
', u'Yeah, only your best submission counts. 

But, make sure that you are generating a huge dataset to test your bonus function on. The numbers given in the test shared by Sumeet are only place holders. And it is not an official test that we released.', u'Thanks Richa.

Re:
> But, make sure that you are generating a huge dataset to test your bonus function on
Based on an earlier response on this thread ""2. Yes, the image sizes are comparable - on local and Bonnie. "", I am assuming test_bonus is a good comparison. Is this assumption correct?

Can you please also respond to #2?
> 2] Is there a way to differentiate if it really failed due to mem violation/ due to Bonnie being loaded? 
> This will help me decide if/where I should put in more efforts on the code/ just keep retrying.

Thanks & regards,

', u'The images are comparable. That is all I said. We are not releasing the input sizes to the bonus questions.', u'I'd suggest - put in more effort on the code. ', u'Thanks Richa.', u'The bonus is not run on images. test_bonus as provided by Sumeet may be comparable since it uses thousands of points and hundreds of means, but we are not releasing the input sizes.

Bonnie load can result in your code taking long to run, but if it was killed it is most probably due to a MemoryError. I would advise you to keep an eye on your submissions anyway and be smart about it.

That being said, the output you have provided above does not seem correct. 49.582 MB seems too small for Sumeet's test case. Are you sure you are looking at the right values? Using 9990 points and 990 means for example?', u'Thanks for pointing that out. I was looking at the line-by-line memory usage, that too at the entry point of the function. This instead of looking at full memory usage. My bad. 

Thanks again.']}, {u'text': u'Are the ""comp_means"" in BIC_likelihood_model_test() provided

1) so we can see if our means convergence toward these values?
2) provided for initial means for our GMM?', u'responses': [u'for initial means.', u'Thanks. I am now getting consistent answers for the optimal number of components-though Bonnie still dislikes my values.']}, {u'text': u'It is a bit unclear from README and comments, what should BIC_likelihood_model_test() return?
1) Dictionary, where keys are ""min_BIC_model"" and ""max_likelihood_model"" and values are models (type GaussianMixtureModel)
2) Tuple of two models', u'responses': [u'Tuple.', u'Thank you']}, {u'text': u'', u'responses': []}, {u'text': u'Does 4b require us to create a new convergence criteria function for our GaussianMixtureModel? The instructions tell us to use the original GaussianMixtureModel, but this is based on a convergence in likelihood, not bic.', u'responses': [u'Steve, I used the default convergence function for this and it worked. You should calculate BIC for each k value (after training). That way you have both a likelihood and BIC value for each k.
', u'Thanks. These are the only points I’m missing on the whole assignment and I can’t figure out why. ']}, {u'text': u'I got the following output on Bonnie for bonus implementation, not sure why points_awarded is 0:
{
    ""output"": {
        ""points_available"": 5,
        ""points_awarded"": 0,
        ""autograder_comments"": ""Bonus results.\nUser implementation produced the correct distance.""
    },
    ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_lfcgqaep/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 90, in test_bonus\n    self.assertTrue(test_flag, \""Part 6: Bonus test\"")\nAssertionError: Part 6: Bonus test\n"",
    ""description"": ""Test the Bonus implementation""
},', u'responses': [u'Hey, I am getting the same result. It states my implementation produced the correct distances and yet points awarded is 0.', u'Leonid, I resubmitted without changing anything and it awarded me the points.', u'@Philip: That's weird.

@both: This error usually means you produced the correct distance but exceeded the time limit for the submission, which means your code needs to run faster.']}, {u'text': u'Has anyone found unusual formatting requirements on part 4b? These are the only points I am missing on the whole assignment—which I believe implies my bic, likelihood, and gmm are all working fine. I get consistent and reasonable answers but Bonnie hates them.  If anyone found peculiarities in the submission format, please share—I’m on my last attempt. ', u'responses': [u'Make sure in the BIC question method, return the correspondong K value, not the likelihood/bic', u'What Willie said might just be the answer to your issue.', u'I’ve entered integers between 2-7 for each. I guess I have something else I’m overlooking. ']}]",,,,1036,,Assignment 5 - Part 4 discussions,[a5]
5ad7d49b0d63974e20c3922d,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


DYNAMIC TIME WARPING

You intercept a Morse Code message: 110111110011.
You know that the message uses the International Morse Code shown in the figure below, and that it can represent one of two words: ST or IS. Unfortunately the channel you used to intercept the message has a lot of noise, so the signal you received is distorted. 


a. Calculate the distance via Dynamic Time Warping with 10% signal length Sakoe-Chiba bounds (i.e. 1), between the given signal and each of the two messages (“ST” and“IS”). Use the Euclidean distance metric.

b. Is the intercepted message more likely to be 'ST' or 'IS'?

c. For dynamic time warping, what effect does the following band has compared to normal Sakoe-Chiba Band?





Solution - @1157 

",jc6w44hrp9v2ki,"[{u'text': u'If I got the Morse code right:
ST = [1010100011]
IS =  [10100010101]
O =   [110111110011]
then,
a. Using Sakoe-Chiba bounds i.e. |i(k) - j(k)| <= 1, I got the Euclidean distance between ST and O, and between IS and O, is 13 and 18, respectively. 
b. Thus the intercepted message is more likely to be ST
c. the adaptive band allows the central part of the signal have less variability and the more variability for the beginning and ending of the time series. ', u'responses': [u'Hi Junwei, ST is [10101000111]. 
c is correct!', u'Thanks Theodore. I still got the same answer for (a) and (b). Here is how following Sakoe & Chiba 1978's paper. Which part I got wrong?
ST = [10101000111]
IS =  [10100010101]
O =   [110111110011]
time normalised distance using symmetric weighting coefficient w(k) = (i(k)-i(k-1)) + (j(k) - j(k-1)) with w(1) = 2.

D(O,ST)=(0*2+0*1+0*2+0*2+1*2+1*2+2*2+3*2+1*2+2*2+1*2+1*2)/N=24/23=1.043, the bold digit shows the warping function F under the constraint |i(k)-j(k)|<=1. 

12

1
33120123111
11

1
32110122111
10

0
31201111234
9

0
21101111233
8

1
12011234222
7

1
12011234222
6

1
12011234222
5

1
12011234222
4

1
11011233222
3

0
10112222345
2

1
01122345555
1

1
01122345555
^
I
O/ST
1

0

1

0

1

0

0

0

1

1

1
J->
1

2

3

4

5

6

7

8

9

10

11


D(O,IS)=(0*2+0*1+0*2+0*2+1*1+2*1+3*2+1*2+1*1+1*1+1*2+2*2+2*2+2*2)/N=27/23=1.217
121331222011221113211110112210031200012223902110001122381120123122337112012312233611201231223351120123122334111012212233301011112233421011234455661101123445566
^
I
O/IS10100010101J->1234567891011', u'Hey Junwei, nice work!
I think there might be some calculation error somewhere in there ^^. I'll post the answers soon and you can take a look. Also the distance is calculated as the sqrt of the final digit in the path (1 and 2) in your case ;)', u'a) D(IS) = sqrt(5), D(ST) = 2
b) ST

ST should be [10101000111]', u'Solution is out! Check the solution and give your thoughts ;)']}]",,,,1037,,Challenge Question 23 - Pattern Recognition Through Time,"[lesson8, challengeqtns]"
5ad7d49c0d63974e20c3922e,"I referred this : schedule
And matched Expectation Maximization due, and found that we are running late by a week.

We are on the schedule :)

Since, I have something that has come up in April. I want to ask the following questions.

1) What is the endterm week ( release and due dates)?
2) If I say, Expectation Maximization is the  Assignment  no: 5,  how many would be more?
    Can I get the dates of those (release and due)",jc6w44hrp9v2ki,[],"I'm not sure how you say we are late by a week. In fact, we are a week ahead in terms of the videos, and as per the Week 1 Assignment in @7, we have released A5 on time as well - on the Wednesday of the week of March 19.

All your questions are answered in the schedule. Final is from April 23-29, and A6 from Week of April 2, due on April 22.",,,1040,,Schedule related query,[other]
5ad7d49c0d63974e20c3922f,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


HIDDEN MARKOV MODELS

Consider the following
I:                 -6 -4 -2 0  2  6  2  0 -4 -6
Thank you: 6 6 5 3 0 -3 -6 -6 -6 -6

a. Give a three stage HMM transformation for I.
One possible division:  6 -4 -2 0 | 2  6  2 | 0 -4 -6. You can follow this division to create the HMM.
(In real world, you can decide the bound to better fit in a data-drive approach, taking human biases out of the equation.)
 

 

b. Give a three stage HMM transformation for Thank You.





Solution - @1163",jc6w44hrp9v2ki,"[{u'text': u'
a) s1  - mean=-3, stdev=2.58, P(s2)=0.25, P(s1)=0.75
    s2  - mean=3.33, stdev=2.31 P(s3)=0.33, P(s2)=0.67
    s3  - mean=-3.33, stdev=3.06, P(out)=0.33, P(s3)=0.67

b) s1  - mean=5, stdev=1.41, P(s2)=0.25, P(s1)=0.75
    s2  - mean=-1.5, stdev=2.12 P(s3)=0.5, P(s2)=0.5
    s3  - mean=-6, stdev=0, P(out)=0.25, P(s3)=0.75', u'responses': [u'Hey, check the solutions above! ^^']}]",,,,1043,,Challenge Question 24 - Pattern Recognition Through Time,"[lesson8, challengeqtns]"
5ad7d49c0d63974e20c39230,"Date: 23rd March

Time: 8pm Eastern
Link: https://www.youtube.com/watch?v=zZzdu2FJ8Dk
 
We'll be going over a run down of Assignment 5, walking through the git repo, talking about some common issues people run into, and taking questions. As with all other sessions, this will also be recorded. 

It'd help to have read through the assignment once before this session. In any case, please download the folder and have the following documents in front of you - README.txt, em.pdf and mixture_models.py. We'll be referring to them multiple times throughout the session. 


",jc6w44hrp9v2ki,[],,,,1044,,"Youtube Live Event, Assignment 5",[a5]
5ad7d49c0d63974e20c39231,"In case you've been musing – or drooling! – over Thad's glasses, a reasonably up-to-date listing of the alternatives & price points is at https://www.tomsguide.com/us/best-ar-glasses,review-2804.html

I found myself musing how useful they would be as a HUD to let me display lyrics while listening to music & driving, I think I'll wait until the price / feature balance is more favorable :-)

For the vehicle HUD, the better current / impending answer is apparently https://hudwaycast.com/",jc6w44hrp9v2ki,"[{u'text': u'Man AR is going to be so awesome.

That vehicle HUD look interesting, and the price point isn't too bad. Ships next month? Interesting. ', u'responses': []}]",,,,1046,,Augmented Reality,[announcements]
5ad7d49d0d63974e20c39232,"Got part 4b correct from Bonnie but ""Part 4a results. Calculated BIC doesn't match the expected BIC."". The wikipedia link shows two equations 
$$BIC=ln(n)k - 2ln(\widehat{L}) , BIC= -2ln(\widehat{L})+k(ln(n)-ln(2\pi )))$$
I tested both and neither is correct according to Bonnie's result. Did bonnie test every digit or as in mixture_test.py, only test the first few digits?

Anyone else has this problem?

",jc6w44hrp9v2ki,"[{u'text': u'so given the equation above,  is (Lˆ) just the max value given by the likelihood function we've already written?
 
', u'responses': [u'L in the equation is the likelihood. We calculate the logarithm of likelihood, ie. log(L). 
', u'wiki says it is the maximized likelihood, is this determined in a similar way to the ""best segment"" where we are just iterating and calculating the likelihood multiple times and taking the best?']}, {u'text': u'I am also facing this same problem.  The test_bayes_info test passes locally but not on bonnie', u'responses': [u'Just in case others have the same trouble.  I wasn't interpreting k incorrectly, my problem was 'n'.  I was not properly considering the shape of my matrix']}, {u'text': u'For part b,

1) Does Bonnie run BIC_likelihood_model_test()?  
2) Or, are we supposed to run that locally, get an answer and place it in BIC_likelihood_question()?
3) Or, is BIC_likelihood_question() supposed to call BIC_likelihood_model_test()?

', u'responses': [u'answered in @1036']}]","The first one:  $$BIC=ln(n)k - 2ln(\widehat{L})$$  should work fine. 

Be careful of the k that you are using. 
 

",,,1050,I am also facing the same problem.,BIC formula used in Bonnie,[a5]
5ad7d49d0d63974e20c39233,"Hopefully this isn't too obvious of a question, also please forgive my rusty math skills.

I'm working on the joint probability function.  I am getting from the unit test:
Incorrect joint log probability
-0.982 != -0.9826

I completed the initialization function first which stated the following:
Initialize the training process by setting each component mean to a random pixel's value (without replacement), each component variance to 1, and each component mixing coefficient to a uniform value (e.g. 4 components -> [0.25,0.25,0.25,0.25]).

From the pdf, this is the formula to be used (section 9.2)

I understand this as: for each component, sum the multiplication of its mixing co-efficient with the probability resulting from the normal distribution function.

In order to prevent underflow errors, we are to use log probabilities.  The log probability of Gaussian is defined the readme as:


Lastly, we are to use  logsumexp(a, b) for summing the resulting logs.

By plugging in these parts in to the first formula, we should have:
 SUM for 1 to k: logsumexp( ln(mix coefficient k), ln(N())
Now, my unit test result is close, but still is an error.  I noticed that I was originally doing the following:
SUM( mix coefficient k * ln(N())

Is it just coincidence that it is close to the correct answer?  Has anyone encountered something similar and found a solution?  If I merely plugin ln(mix coefficient k) my answer is quite a bit off.

Thanks.
",jc6w44hrp9v2ki,"[{u'text': u'Eric - did you ever figure this out? I have the exact same result and off by one decimal place:-

mine: -0.9826  but unit test expects -0.982

but the only way I can even get this close is SUM ( logN * mix) which is different to the formula given which is SUM(N * mix)', u'responses': [u'Hope the explanation above helps. ', u'I was summing the logs instead of taking a log of the sum.  IDK if it is correct or not, but it passed the unit test.
', u'I'm actually getting the correct answer on using logsumexp(ln(mix_coefficient)+ln(N())), not with replacing logsumexp by sum. But I do see logsumexp is undoing the log we've taken so I don't understand how this equation is working.', u'Just Kruti said i get this correct answer as she is getting using logsumexp() but i dont know why']}, {u'text': u'Shouldn't you be apply log on the entire sum of the first equation? not to the individual terms inside the sum.', u'responses': [u'I'd like to know this as well', u'The N(x|u,sigma) function tells you the probability that a point was generated by the given Gaussian.
The joint is based on the mixture, so you want to use N for each Gaussian in the proportion of the mixing coefficients. Hence, sum (mix coeff * N for each cluster)
Now convert this into log, and work it out on paper. Let me know if it makes sense!']}, {u'text': u'I must be doing something really wrong because I'm not even close to the expected value for the joint distribution.
By applying:
ln(mix coefficient k) + ln(N())
I get the weighted probabilities values whose sum produces a number that is very far from the expected.
This calculation seems pretty obvious but I'm struggling with it and don't know what I'm doing wrong.
I initialized the mixing coefficients with equal values according to the number of components so their sum is equal to 1.
The variances are 1 initially for every component and the means are given by the test.
', u'responses': [u'Do I need to recalculate the variances based on the new means provided by test?', u'Nevermind I figure it out scipy.misc.logsumexp() helped a lot. It was key to me to transform the whole formula into a sum of exponentials.']}, {u'text': u'From the instructor answer:
ln(mix coefficient k) + ln(N())
""You already know how to calculate ln(N()). Sum over all clusters.""


ln(N()) is given by the log probability gaussian equation in the paper, correct?  I'm not quite sure what ln(N()) is representing in this part... but I'm assuming it's this equation:


as for ln(mix coefficient k)... this is just the natural log for each of the mixture coefficients right?


And given that we have the equation above, the joint probability is simply the following:
sum{ln(mix coefficient k) + ln(N())}  

It isn't clear to me where logsumexp fits into all of this...', u'responses': [u'Hi Eric,

Thanks for all your posts on this assignment. Several of them helped me out a ton. Where you have ""sum"" in the above equation, you can swap that out for the logsumexp function. I can't honestly say I fully understand why or what that does, but I can say from experience that if you follow your previous posts (@1082) to calculate the inner pieces of this:

sum{ln(mix coefficient k) + ln(N())}  

And then wrap logsumexp around it, you pass the unit test.

logsumexp{ln(mix coefficient k) + ln(N())}  ', u'logsumexp(val) is equivalent to np.log(np.sum(np.exp(val))) if I understand correctly', u'But this is confusing. logsumexp(ln(mix_coefficient_k) + ln(N())) is essentially,

log(mix_coefficient_k + N())But this isn't what we have to calculate. How is this giving the correct answer?
', u'The assignment README has a description of exactly what logsumexp does.', u'The reason why you are getting the correct answer with logsumexp is that you can't add logs together when they are in logspace (addition in logspace is a multiplication operation equivalent in normal space).  So logsumexp takes them out of logspace (with the exp operation) does the sum in normal space and then logs the sum to put it back in logspace.']}, {u'text': u'This might be a stupid question, but I'll ask anyways.
Why is the joint probability a sum of all the probabilities?
Shouldn't it be multiplication of all the probabilities?', u'responses': [u'I had the same doubt', u'I think it's an addition because it's adding together the probability that it comes from each curve (like when we added the probability that an event was true given another event was false plus the probability that the event  was true given the other event was true).  ']}]","What Conor says is correct. Apply Log(AB) = Log A + Log B on equation 9.7 above. You'll get Conor's first equation 
 

ln(mix coefficient k) + ln(N())
You already know how to calculate ln(N()). Sum over all clusters. ",,,1053,"I did not use logsumexp for the joint probability calculation.  That's essentially undoing the ln operations and putting the answer back in normal (non logarithmic) space.

The 2nd SUM that you have is incorrect because your mixing coefficients are not in logarithmic space.  So you need to do one of the following:

LOGSUMEXP( ln(mix coefficient k) + ln(N()) )
or:

SUM( ln(mix coefficient k * N()) )",part 2 joint probability question,[a5]
5ad7d49d0d63974e20c39234,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


VITERBI TRELLIS

Considering the following HMM:

You receive this signal: 4 0 5 -2 -1 5 4

Calculate the probability that this signal was generated by the above HMM.
Draw out the Viterbi Trellis and find the optimal path.






Solution: @1168",jc6w44hrp9v2ki,"[{u'text': u'Hi, why is it that outgoing probabilities of S3 do not sum to 1?', u'responses': [u'Sorry, my mistake, consider the probability from S3 -> End to be 0.75', u'Alright, thanks!
']}, {u'text': u'
Optimal path: S1 -> S2 -> S1 -> S2 -> S2 -> S3 -> S3 -> end.
$$P(signal | model) = 8.162 \times 10^{-7}.$$', u'responses': [u'Hey Le Van, nice work, but are you sure about those .242? ^^', u'To be honest I was iffy about these output probabilities. Since the distribution is continuous, it doesn't make a lot of sense to just plug the numbers into the pdf to get the probabilities. How about this:

$$P(4 | \text{state 1}) = F(5)-F(3), \text{where } F(t)=\int_{-\infty}^{t}f(x|\mu=5;\sigma=1)\text{d}x = 0.477$$?', u'Le Van what did you use to draw that graphical model?', u'I second Tasuku's question! 
Le Van: P(4 | S1) = F( 4 | μ = 5, σ2 = 1) ', u'Ok I'll try again:

$$P(\text{signal}|\text{model}) = 2.97 \times 10^7.$$

I used an online editor at www.matcha.io. Here's the link to the page where I draw the trellis in case anyone needs it: https://www.mathcha.io/editor/Ge27iE5SOVh5PFYB.', u'Which solution is correct? I got the same result as Le Van's first solution 8.162e-7

Shouldn't P(4 | S1) = F( 4 | μ = 5, σ2 = 1) = exp(-0.5)/sqrt(2*pi) = 0.242?', u'Ok LeVan, Junwei- I had it wrong. Sorry about that. LeVan's first solution is correct with 0.242. Will be posting the solutions soon.', u'@Le Van Thank you for sharing mathcha.io.']}]",,,,1054,,Challenge Question 25 - Pattern Recognition Through Time,"[lesson8, challengeqtns]"
5ad7d49e0d63974e20c39235,"Hello everyone,

We are currently ahead of the schedule since we have a gap for Spring Break. Over the next two weeks, you should finish Lesson 8, Pattern Rec Through Time and read Chapter 22 in Russell & Norvig.  Additional readings can be found on the course schedule. We encourage you to go through these, as Assignment 6 will deal with this chapter and is on Prof. Starner’s favourite topic!

We also encourage you to engage in discussion on the challenge questions for this chapter as they are particularly interesting; please check @1037, @1043 and @1054.  

Assignment 5:  Gaussian Mixture Models
Due:  April 1 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 5 is currently running and is due this coming Sunday! This is not an April Fool’s joke. Details in @1032.

Office Hours:
Here is the OH calendar, the syllabus and the schedule.  

",jc6w44hrp9v2ki,"[{u'text': u'Hey should week 12 readings be chapter 15 and not chapter 22?', u'responses': [u'Chapter 15 was the prescribed reading for last week.']}, {u'text': u'The hidden Markov Model stuff is fascinating. I've been doing some digging around on my own, but if anyone has good links to material that explains state of the art Sentiment analysis, I'd be grateful. I can leverage the Stanford Core NLP library, but I'd be interested in building my own.
', u'responses': []}, {u'text': u'With respect to Assignment 6; do we really have three weeks? It's creating anxiety because I'm thinking it's going to be 50% more work than the other assignments.', u'responses': [u'We give three weeks for Assignment 6 because it's the one we anticipate to modify the most from semester to semester, so the difficulty may swing. However, we don't anticipate it being that much more difficult than other assignments this time, so you really need not worry.']}]",,,,1058,,Week 12 Announcement,[announcements]
5ad7d49e0d63974e20c39236,"I cannot seem to install SciPy. It appears that the 0.18.1 version is not available for 64 bit OS. It looks like only versions 1.0 and later are supported by 64 bit.

1.0.1 installed fine. Can we use that?
The code compiles using 1.0.1",jc6w44hrp9v2ki,"[{u'text': u'May just be because I am using windows x64.I get the following output:
pip install scipy-0.18.1-cp27-cp27m-manylinux1_x86_64.whl
scipy-0.18.1-cp27-cp27m-manylinux1_x86_64.whl is not a supported wheel on this platform.

I also tried:
pip install scipy==0.18.1
', u'responses': [u'I will try anaconda', u'I would second using Anaconda. It's very easy to setup and manage different environments. I am also using windows 64 bit.

https://www.anaconda.com/download/ 

Managing environments
https://conda.io/docs/user-guide/tasks/manage-environments.html 

Installing packages
https://conda.io/docs/user-guide/tasks/manage-pkgs.html#installing-packages ', u'Got it working thanks!

Anyone having the same problem, make sure you have the latest conda and the run 
conda install numpy=1.12.0
conda install scipy=0.18.1
', u'If you're downloading a wheel, which is what I did, make sure you have the right wheel for your OS. It looks like you were trying to install a linux wheel on a windows machine.', u'Jake Gilbert,

Did you have any issues with Atlas or Blas files not being found when installing with conda?

EDIT: Figured it out']}]","I see a lot referring to x86 64 bit installs on this page: https://pypi.python.org/pypi/scipy/0.18.1. Are you sure?Regardless, have you tried installing it with Anaconda? I went years without using it (due to both a lack of exposure and dumb stubbornness). I would highly recommend that.",,,1064,,Cannot install SciPy,[a5]
5ad7d49f0d63974e20c39237,"Hi,

I was talking with someone recently about defining AI, and I thought I remembered hearing/reading that Prof. Starner had a definition that was something like ""any NP-hard problem that hasn't been solved yet."" I liked that because it encapsulates that AI is sort of a moving target. But, now I can't find the evidence that he ever said anything like that. Am I confusing this with someone else's line? Or does anyone know where I might have heard something like this?

Thanks!",jc6w44hrp9v2ki,"[{u'text': u'You’re not imagining things, that line stuck with me as well. It’s somewhere in the earlier lectures, but I can’t say which one. I’d start hunting in the first or second week. ', u'responses': [u'Perfect. Thanks! Yes, it was in the early lectures (Video 1.42: Thad's Asides):

""Many problems in artificial intelligence are exponential in time or space, or both.
In fact, NP hard problems are so common in AI that researchers joke half seriously that AI is the study of finding clever hacks to exponential problems.

Often when a clever hack is finally found, when computers finally get fast enough to address that particular problem successfully, the world no longer thinks of the problem as one belonging to artificial intelligence.

How many people think about the system that helps consumers choose plane flights as an AI? Or the system that helps determine when to deploy an airbag on an SUV. Yet at one point, these types of problems were considered to be part of AI.

That idea leads me to another joke definition of AI. Artificial intelligence consists of all the NP-hard problems that have not yet been solved.

What matters to me are the problems that the field of AI tackles. On the way here, I was practicing this lecture with my taxi driver Dilber, when I realized he was using AI while we were talking. To get me to Udacity headquarters, the navigation program on his smartphone had plotted a path that was better than the one I would have told him. And was communicating with him in a way that he was getting the information as he needed it.

That's what is exciting about AI. You get a chance to work on everyday problems that can improve people's lives.""']}]",It was in the initial Game Playing lectures. :)marking resolved for housekeeping.,,,1070,,Thad&#39;s Definition of AI,[other]
5ad7d49f0d63974e20c39238,"I was going through various resources for understanding EM, and I found this video on youtube - https://www.youtube.com/watch?v=REypj2sy_5UIt was really helpful for me, so I thought of sharing it with the class. All the best!",jc6w44hrp9v2ki,"[{u'text': u'Victor Lavrenko's videos are great. I looked him up and he doesn't currently teach anymore, but his channel is loaded full of great content.', u'responses': []}, {u'text': u'+1

Victor's series of videos on EM really helped me get a decent grasp on this subject.

Highly recommended!', u'responses': []}, {u'text': u'This was great and extremely helpful. I googled and there were many that came up, and I watched many. I think this was the best high-level explanation. Thanks again!', u'responses': []}]",,,,1077,,Helpful video on EM,[a5]
5ad7d4a00d63974e20c39239,"I've read the other scipy install thread, but I am having a different problem. I have been using an anaconda environment on Windows 7 since project 1 without any problems. Attempting to install scipy results in a list of all the packages not found. numpy 1.12.0 is already installed.

The last line of the error is as follows:

File ""scipy\linalg\setup.py"", line 20, in configuration
        raise NotFoundError('no lapack/blas resources found')
    numpy.distutils.system_info.NotFoundError: no lapack/blas resources found


I am troubleshooting across the web but haven't found a clear solution yet.

Please advise and thanks for any help offered.

",jc6w44hrp9v2ki,"[{u'text': u'Thanks Chenxi. Pip was the issue.', u'responses': []}]",,,,1078,"Make sure you have not messed up numpy+mkl was how it turned my world back.Probably that was the reason,because I found when I executed pip install -r requirement, it seemed numpy+mkl disappeared and wasted 4 hrs of mine and so on....

I ended up getting things back one by one and used conda or pycharm to set things up.
Good luck,by the way.",Scipy Install issue on Anaconda: Unable to find Atlas and Blas packages,[a5]
5ad7d4a00d63974e20c3923a,"Has anyone else seen this error when submitting?

{
  ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_dbhwgazy bash -c \\\""cd /home/vmuser_dbhwgazy; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""F\"", \""stderr\"": \""bash: line 1:    32 Killed                  python run.py assignment_5 > run_stdout.txt 2> run_stderr.txt\\n\""}""
} ",jc6w44hrp9v2ki,"[{u'text': u'yes, I had the bonus enabled.  I commented it out and it workded.  I just saw a similar post in the Assignment 5 released thread.', u'responses': []}, {u'text': u'Anyone know if that counts as a submission?', u'responses': [u'Nevermind. I see now in the readme where it says it does.']}]",,,,1079,Probably out of memory - is your bonus enabled by any chance?,Assignmnet 5 submit error,[a5]
5ad7d4a00d63974e20c3923b,"I'm having a really hard time following the equations for assignment 5...

I've been over the book chapter multiple times, and the PDF given with the assignment.

I understand the intuition behind EM just fine, but I was hoping to find a better breakdown of the equations as I'm just not grasping how to even begin coding them...

I'm specifically struggling with joint probability, likelihood, and BIC.  Can anyone recommend any good resources for this material?  The book and PDF do not explain most of the variables well... I was hoping to find a walkthrough actually showing the formulas in use (not code, just the formulas), but there doesn't seem to be anything...",jc6w44hrp9v2ki,"[{u'text': u'What about the equations are you having trouble understanding?

@1077 has a link to a video by Victor Lavrenko where he goes through the theory of E/M and that really helped me.

This class has really forced me to level up my ability to read formal algorithms. Do you feel that you are lacking in understanding of what the various symbols mean in the formulas? It can help to do some research on how to break those down and what each symbol represents. I think you'll find doing so will really unlock what the formulas are trying to say.', u'responses': [u'yeah, I watched that video... again, he just discusses the intuition behind it... he doesn't really get into the details of the equations... it's not quite clear to me what to plug into various parts of the equation based on what we're given, so I was hoping to find an example of someone actually writing out the math for this', u'Well, let's start with the log form of the Gaussian probability of the scalar value x.

$$ln(N(x|\mu,\sigma)) = -0.5ln(2\pi\sigma^2)- \frac{(x - \mu)^2}{(2\sigma^2)}$$

$$\mu = mean$$
$$\sigma^2 = variance$$

We are looking for the logged form of the gaussian for x.

The initialize_training method tells you what to set the means, variances, and mixing coefficients to.

mean starts out being equal to a random pixel value.
variance to 1
mixing coefficients to a uniform value based on k.', u'Are the values in self.variances already squared? Or do you have to square them in the equation?', u'each self.variances is
σ2=variance. 
', u'Nick, you've gone above and beyond to try and break it down.  I really appreciate it as that was highly unexpected.

This equation itself isn't really my issue.  I understand what I need to plug into the individual parts for this equation, but relating it back to the joint probability equation given in the assignment is where I am really struggling.

As you noted above, the equation above gives the natural log of the normal gaussian distribution.  Following what's given in the assignment, the above equation plugs into this one to get the joint probability.


So... my understanding is that the joint probability is the sum of the mixture coefficients * the normal distribution for each coefficient?

In pseudo-code:  f(x) = sum(mixture_coeff_k * N())... that gives the joint probability but not the joint log probability... so would joint log probability be f(x) = sum(ln(mixture_coeff_k) * ln(N())) ?

There is discussion in the assignment about using logexpsum() from scipy as an easier way to sum these, but other students have mentioned that using this function effectively reverses the natural log, which is not what we want... so I'm confused as to why the assignment even mentions that function...', u'The one other issue I'm having is with likelihood given what is in the assignment:

ln(Pr(X | mixing, mean, stdev)) = sum((n=1 to N), ln(sum((k=1 to K),mixing_k * N(x_n | mean_k,stdev_k))))

in this equation, what does n represent?  I get that each k are the mixture coefficients, but what is n?
(n=1 to N)

The last part of the equation just looks like the log probability we have already discussed:
ln(sum((k=1 to K),mixing_k * N(x_n | mean_k,stdev_k)))
This is the same as the log probability equation we've already been talking about correct?


So what is the point of the first sum in the equation?  I get that the first sum is done over each mixture coefficient value, but what is the N value that we are summing over a second time?
sum((n=1 to N),
', u'Look at how they are calculating the joint prob in @1053, that gives you the answer to your first question.

If you are taking the log of the distribution, then you shouldn't be multiplying the coefficients, but adding the log of the coefficients.
You can safely multiply the coefficients if you are taking the log of the product of those.

If it means anything, I had goodluck returning the result of the logsumexp equation for the joint probability.

The likelihood you'll find look strikingly similar to the equation we just calculated in the joint probability. Notice that the joint_prob test is passing in a single value for ""val"", or our x.
X appears to be a single value, or point here.

The equation says to sum n=1 to N and it defines X in that equation as $$X_n$$

Also, you're welcome! It's not easy to understand this stuff. This project has been a real struggle for me this last week. I was in the same position as you asking the same questions, so I know what you're going through. The best advice I can offer is to just try different things. Try coding up the algorithms the best you can. When it doesn't work, look at the definition again and try to see where you are going wrong. Try different things. It's what I did. 

This is really a cool algorithm once you see it in action.
', u'Thanks Nick for all of the insights on this thread. For others who find this and are moving on from joint probability to likelihood. There is a section on this in @1034 (David Murphy's question) where a course instructor confirms that likelihood is the sum of all the join probabilities for each pixel (although writing a naive loop to calculate this wouldn't be efficient enough). Just putting this here to save others the time of looking that up if the question comes to mind.', u'Yep that is correct Nathan. ', u'Thank you Nick, I have been posting questions in that thread as well, haha.  I think all this talking through everything has finally helped me make some sense of it.  I sure was banging my head against a wall for a few days with these formulas.  Thanks!', u'Glad to have helped! ']}]","marking resolved for housekeeping. ( as per the comments below) 
Also, refer to Hangouts Live video where the equations in em.pdf are discussed. ",,,1082,,EM examples?,[a5]
5ad7d4a00d63974e20c3923c,"When I started this project, I separated the unit tests out so that I was testing k-means individually and not as a loop (ie: def test_kmeans_k2(), def test_kmeans_k3(), etc).  My implementation passes those tests.

I submitted to bonnie and it failed on k > 2.  I checked out the unit tests, if I run the provided unit tests, sure again, it fails on k > 2.

The unit test loop begins as this:
for k in range(k_min, k_max + 1):
If my thinking is correct, I should be able to swap k_min and k_max if I wanted to try 1 version of k, say for k=3
for k in range(3, 3 + 1):
I tried for 2 <= k <= 6 and all pass.  Has anyone encountered this issue and if so what helped to fix it?",jc6w44hrp9v2ki,"[{u'text': u'Thanks, that was the issue.  I was changing image_values in place instead of working on a copy.
', u'responses': []}]",,,,1085,If you're modifying the image array inside your kmeans you're modifying it globally and thus on the second run it's no longer the original values. What is passed in is a reference to the array not a copy.,k means unit &amp; bonnie tests,[a5]
5ad7d4a10d63974e20c3923d,"Hi,
Are we going to have OH today?
It looks like Xuewen didn't show up today and we are waiting for Sumeet.
Thanks,
",jc6w44hrp9v2ki,"[{u'text': u'I am online, are you not able to see me?', u'responses': [u'Hi Sumeet, I am online and can see you but not sure if you can hear me or see my messages.', u'I dont see you, can you join again?', u'
if platform.system() != 'Windows':
    import resource

class GMMTests(unittest.TestCase):
    # ...

    def test_bonus(self):
        n = 3
        num_points = 9990
        num_means = 990
        points = np.random.random(size=num_points * n).reshape((num_points, n))
        means = np.random.random(size=num_means * n).reshape((num_means, n))
        distances = bonus(points, means)

        if platform.system() != 'Windows':
            peak_mem = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            max_mem = 250* 1024
            if platform.system() == 'Darwin':
                max_mem *= 1024
            self.assertLess(peak_mem, max_mem)
            print('peak mem: {:,}'.format(peak_mem))

        for i in range(num_means):
            exp_dist = np.sqrt(np.square(points - means[i]).sum(axis=1))
            np.testing.assert_almost_equal(exp_dist, distances[:, i])']}, {u'text': u'I'm passing the above test locally but get the following when I submit to Bonnie:
    ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_fjcynubo bash -c \\\""cd /home/vmuser_fjcynubo; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""\"", \""stderr\"": \""bash: line 1:    29 Killed                  python run.py assignment_5 > run_stdout.txt 2> run_stderr.txt\\n\""}""
Any ideas what I could be doing wrong', u'responses': [u'Oh, looks like this test has it set to 500MB max memory rather than Bonnie's requirement (250)?', u'+1 I don't know whats happening', u'It is a memory error because you're exceeding the limit for your overall submission', u'Yes, I copied the code from my last year's test case. That time the memory limit was 500MB. I have updated the code now. Please be aware this does not show memory consumed on Bonnie, this shows memory consumed on your system. Use it to test your different versions of the solutions and select the best one. Bonnie does not have the same test case as the one I shared, so I recommend that do not compare if your test passes locally, but not on Bonnie.']}]",Sorry about today. I will have a make up session tomorrow 6:30 - 8 pm EST.,,,1089,,Sumeet OH,[a5]
5ad7d4a10d63974e20c3923e,"I had some personal business today so I missed today's OH. Very sorry about that.

The make up session is tomorrow 6:30 - 8 pm EST



",jc6w44hrp9v2ki,"[{u'text': u'How can I attend the office hour?', u'responses': [u'https://hangouts.google.com/hangouts/_/calendar/N2Y1YWdoNzRyZTRsZHBrZGRvcWE5MWNlNHNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ.00hlfta2qoehuppnq38a915clt?authuser=0', u'Is the link working for you? I can't see you in the OH.', u'Yes']}]",,,,1090,,Xuewen&#39;s OH moves to tomorrow,[office_hours]
5ad7d4a10d63974e20c3923f,"height, width, depth = image_values.shape
np.all(image_values.flatten().reshape((height*width, depth)) == flatten_image_matrix(image_values))



Thought this might help.

Now, who can figure out how to unflatten in a similar fashion? ",jc6w44hrp9v2ki,"[{u'text': u'Why flatten before reshaping? Wouldn't image_values.reshape((height * width, depth)) be equivalent?', u'responses': [u'Wow, thanks for exposing my stupidity ! ']}, {u'text': u'I just used .flatten and .reshape. I had no time issues.', u'responses': []}]",,,,1091,,A faster way to flatten/unflatten the image,[a5]
5ad7d4a20d63974e20c39240,"Is anyone facing  the below error in Bonnie?  I did not get any other logs other than the below. My code is fully vectorized and it takes less than 90s to pass all tests locally.

{
  ""error"": ""{\""msg\"": \""The command $(sudo -H -u vmuser_amvpqbjz bash -c \\\""cd /home/vmuser_amvpqbjz; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\"") exceeded the timeout of 3600 seconds.\""}""
} ",jc6w44hrp9v2ki,[],"are you submitting the bonus section as well? It could be timing out, if your other parts are tested locally.",,,1100,,Bonnie Timeout Exception,[a5]
5ad7d4a20d63974e20c39241,"I found below paper helpful in understanding initial value and convergence function of EM algorithms.

http://www2.stat-athens.aueb.gr/~exek/papers/Xekalaki-CompStatDataAnal2003(577-590)ft.pdf",jc6w44hrp9v2ki,[],,,,1104,,Good read about Choosing initial values for EM algorithms,[a5]
5ad7d4a20d63974e20c39242,"Hi all, 

Can anyone suggest some good books for learning Numpy. 

Thanks",jc6w44hrp9v2ki,[],,,,1105,https://www.safaribooksonline.com/library/view/python-for-data/9781449323592/ch04.html,Good Books/Resources for learning Numpy,[python]
5ad7d4a30d63974e20c39243,"so I'm understanding that likelihood is the sum of the joint_probabilities and if I run a loop to perform the joint_prob function on each pixel value and then sum them this gives me the correct result... however, this could obviously take a long time for large images...

is there a simple way to vectorize a function call?  or do I essentially have to rewrite my joint_prob function in a way that functions over all values at once?

any tips on how to think about this?",jc6w44hrp9v2ki,"[{u'text': u'I personally went with the latter approach (""rewrite the joint_prob function in a way that functions over all values at once"") rather than the former (""vectorize a function call""). I looked around for ways to vectorize the call but didn't seem to find any, so figured the rewrite would be simpler to implement.', u'responses': [u'An additional warning: most the numpy ""vectorize"" decorator doesn't actually vectorize the execution, it's just a convenience that allows you to use a particular function as if its vectorized. Outcome: no performance gains.

Unfortunately writing slightly-harder-to-read code seems to be the way forward.']}]",,,,1107,"You can write the joint probabilities function in such a way that it calculates the values over all pixels at once using the magic of vectorization. The statement is simple, but it does result in some added complication to your code. Think back to the previous assignment and how we vectorized loops. That should help give you some additional insight.",likelihood vectorization,[a5]
5ad7d4a30d63974e20c39244,"Hello All,

I posted some of this in https://piazza.com/class/jc6w44hrp9v2ki?cid=1035, but I not sure it's getting much of an audience.

I was under the impression that part 3 was pretty easy compared to part 2.  (a) consists of using clustering to choose good means and part (b) just checks that the model params converge to within 10%.  These are both pretty straight-forward (I thought).  Everything works as expected for me locally.  

Based on bonnie's feedback (""Improved initialization achieved a likelihood which was not far greater than the original likelihood""), I am assuming that bonnie is simply doing a before and after comparison (vs calling the init and convergence function as if it were a unit test).  What if the before just happens to be good?  Will bonnie be happy if I just give my non-improved algorithm a handicap?  

I'm close to throwing in the towel on this assignment, which is a shame since it was a bunch of work and everything seems to work as it should.  Does anyone have any suggestions?  Additional unit tests to run?  Much appreciated!",jc6w44hrp9v2ki,"[{u'text': u'If you see the unit tests, the initial means are provided for the standard GMM implementation, so as to set a common baseline. Hence, the output of the non-improved algorithm is completely deterministic. Also, for Part 3a, you are using the same train function in the improved GMM, as for the non-improved version, so there's really no way you can handicap just the non-improved version, keep the other one same.', u'responses': []}]","Hi Matthew, what Parth says below is correct. 
Your understanding of the concepts is accurate but during test time we are starting with a fixed set of means, for which we have pre-calculated thresholds. And we have expected likelihood values for non-improved version as well, so nope, Bonnie will not be happy if you give your non-improved version some sort of handicap.If your Part 3 is failing on BOnnie, I'd suggest instead of trying to degrade your performance of non-improved version, make sure you have implemented the new convergence function correctly.  ",,,1109,,understanding grader for part 3,[a5]
5ad7d4a40d63974e20c39245,"A poll to see how students felt about this assignment
 [o] Piece of cake
[o] Faced some difficulties, but it was not too hard
[o] Found it extremely difficult to understand the different equations and how they're working",jc6w44hrp9v2ki,"[{u'text': u'For me the main struggle was the tests not being strict enough. Very buggy implementations would pass so debugging became a bit of a wild goose chase.', u'responses': [u'+1, although i think allowing more Bonnie submissions might also have made things easier.', u'I'm sorry to say that the unit tests did a very poor job of testing for the Bonnie submission. My unit tests all passed just fine but then numerous Bonnie tests failed. It's clearly counterproductive to get a false positive from unit tests - it would be much better to let the students create their own unit tests.

I also waited till I'd coded all sections before submitting to Bonnie since submissions were limited to 5. When the unit tests all passed I assumed I was in pretty good shape but only discovered very late in the day that that was not the case.  In this assignment, if the basic gmm training does not work as expected then there is little point in completing sections after section 2. The unit tests needed to do a far better job of letting students know their gmm training was incorrect rather than implying that everything was in good shape.

As Chris noted above, debugging became a wild good chase. Ultimately a major goal of assignments should be to have students gain new knowledge but this goal was made much harder than necessary in this assignment for what could have been a very interesting topic.', u'David, I've created new unit tests for every single assignment...', u'@David - Interesting and good lesson learned. I will do that for assignment 6 for sure.
', u'+1The unit tests did little to help guide you towards a correct implementation. I got stuck because all of the unit tests passed up until `segment`. Even Bonnie scored my submission with 30 points for part 2, but, for some reason, every other test afterwards failed. My means always converged to the same number on the Spock image. Why? Who knows. Just stare at the equations longer.', u'I had an issue with passing local tests and not Bonnie on Part 2 best_segment. On Bonnie the error was ""can't multiply sequence by non-int of type 'float'"". It turned out that for best segment I was using a list for storing the best variances. Bonnie expected a numpy array. Apparently in some cases when a numpy array is expected and a list is provided that error message is generated, though it certainly isn't intuitive! Once I changed my variance list to an array it passed.  So agreed with others: 1) the local unit tests need to match Bonnie tests better. 2) error messages need to be easier to understand, where possible. And really if the unit tests match well then there shouldn't be too many new error messages to interpret on Bonnie.  Another suggestion is to break submission on Bonnie up into the four parts + bonus, then allow more submission attempts for some of the parts. This would remove some of the stress associated with chasing down errors. I really enjoyed the concepts in this assignment, and overall it is a solid project that had good TA support. Just very frustrating when you understand everything, it is passing locally, yet you aren't getting the points and have no idea why. It sounds like this happened to more people than usual on this one.', u'Yes. Writing your own tests helps a lot. But I strongly agree that the sample tests helped me a lot. I could easily replicated multiple scenarios using them.Also, the assignments that had unlimited number of submissions allowed, they made me lazy to write tests. I would shoot to Bonnie for even a small change in code.Few suggestions from my end:1) 5 is too low, there should be at lease 2x number of sections submissions allowed, at least.2) Unlimited submissions is a bad idea. There should be 20/30 or say 50 submissions. I hit Bonnie for around 100 times in 2nd assignment. 
', u'@Anil. I agree with your suggestions as well.  A submission number approx. 2x the number of sections would allow for checking with bonnie on average of twice before moving on to subsequent sections, whose result may depend on successfully completing the previous section.  That seems a reasonable balance between enabling lazily written code and genuinely needing to verify code that was carefully written and debugged.

As to the given unit tests, I view them as a welcome starting point, sometimes more and sometimes less helpful depending on the assignment.  Ideally, our job as students is to write code that we fully understand. However, given that errors inevitably arise as we write line after line, creating our own unit tests is a functional and practical alternative to being absolutely sure of every character that we write the first time we write it.', u'I guess that's why we get 1 dropped assignment. I have an A based on the rough calculations and it's the first assignment of my career that I felt was out of my control', u'In regards to the submission limit, I believe it was intended to prevent you from guessing on the last section (the one where you filled in values for k with min_BIC and max_likelihood). Obviously, with unlimited submissions, you could try every combination from 2 to 7...

However, it would have been nice to be able to test the earlier sections without losing a submission. Perhaps the submissions could be broken into parts, like Project 1. The earlier parts could be unlimited (or some other number like 20, 30, 50...), and the last part could be limited to 5. ']}, {u'text': u'It's completely unclear how to do EM in log space', u'responses': [u'There are a few rules around doing math with logarithms:

log(a/b) = log(a) - log(b)log(a*b) = log(a) + log(b)log(a^b) = log(a) * log(b) b * log(a)log(sqrt(a)) = 1/2 log(a)  (in other words log(nth_root(a)) = log(a) / n

Given those four translations, you take each equation and convert it to a logarithmic equivalent and do the basic equation and when done convert it all back into normal space (for those that we want in normal space like the means) with np.exp().

Note that log(a+b) cannot be split.  You need to do a+b in normal space and then take the log.  This is why logsumexp() is used to add together numbers that are in log space (it takes them out of logspace, adds them together and puts them back into logspace).   So

log(a+b) = logsumexp([log(a), log(b)])', u'Can't wait for the final where we'll have to do all this by hand or in an excel spreadsheet', u':-)   Or you can use python again...', u'It's unclear what works in Python. The numbers that make sense fail the unit test and some outrageous stuff passes the unit test like when mixture coefficients exceed 1.0', u'The coefficients should never exceed 1.  The formula for the coefficients is Nk/sum(Nk) so it should always be a fraction (unless you have all of your pixels associated exclusively with one cluster in which case it would be exactly 1.0 and all the others would be zero -- that should never happen).', u'I did not use any log space calculations other than where it was necessary(log likelihood). As mentioned in readme, the advantage of doing things in log space is to avoid underflow, but thankfully those cases did not come up in this assignment.
https://stackoverflow.com/questions/34930570/at-what-point-should-i-worry-about-underflow-in-numpy-values', u'Incidentally Conorlog(a^b) = log(a) * log(b) is wrong; $$\log(a^b) = b \log a$$
as you subsequently observe, $$\log(\sqrt{a}) = \log(a^{0.5}) = 0.5 \log a$$', u'Thanks Mark.   That was a test to see if you would find it and perk up :-)', u'I should have noticed the date you wrote that :-D', u'I went back to the assignment after cooling off for a few days since I can't stand losing in anything. Figured out what was wrong. When calculating the responsibility matrix I need to do numerator - denominator since they're in log space. Then np.exp them to normal space then I can calculate the means and variances in normal space with the equations in the book. No points for this work but at least this problem won't haunt me anymore', u'Late on this one, but this one pissed me off. As I finally got everything working locally everything done. Submit to BOnnie and get a 47% with no explanation of what is wrong. 6 hours later I push it up to 67%. If I had known the unit test were going to suck so bad I could have just skipped the whole assignment and taken it as my drop. ', u'Brett - exact same pattern with me. All unit tests were good so I started working on the bonus question. Then I think, well I better submit what I've done to Bonnie just to check.  Then low and behold lots of stuff failed. This was like Saturday evening before the deadline so then a mad panic to try to figure out what Bonnie was complaining about that the unit tests had all passed. Like I said above, if the basic gaussian training didn't work right then anything after section 2 would also not work right. So it was imperative that when the unit tests said section 2 was all good that we could trust that. But that's where the wheels fell off..', u'Yep the train had some bug which I never found. ']}]",,,,1117,,What are your thoughts about assignment 5 as compared to the other assignments?,"[a5, polls]"
5ad7d4a40d63974e20c39246,Is context training of an HMM simply training a larger HMM?,jc6w44hrp9v2ki,[],,,,1123,,HMM Context training,[lesson8]
5ad7d4a40d63974e20c39247,"Hi,I heavily used vectorization for the assignment.It passed all the local tests, but when I uploaded it I got error and it was crashed.Is it counted as upload? Is there any way to get stack trace? Without stack trace it is hard to trace it. And any thoughts and suggestions?
Thank youWaiting for results...Done! Results: -------- { ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_pykworfb bash -c \\\""cd /home/vmuser_pykworfb; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""FFF/home/vmuser_pykworfb/workspace/mixture_models.py:133: RuntimeWarning: invalid value encountered in true_divide\\n ln_prob = ln_prob / (2 * self.variances)\\n/home/vmuser_pykworfb/workspace/mixture_models.py:134: RuntimeWarning: divide by zero encountered in log\\n log_part = np.log(2 * np.pi * self.variances)\\n\"", \""stderr\"": \""bash: line 1: 29 Killed python run.py assignment_5 > run_stdout.txt 2> run_stderr.txt\\n\""}"" }",jc6w44hrp9v2ki,"[{u'text': u'I think there is at least some information there, no?

RuntimeWarning: invalid value encountered in true_divide\\n ln_prob = ln_prob / (2 * self.variances)
Seems like that might indicate that you have cases in which your variances are 0?', u'responses': []}]","As Zachary says below, you have a zero somewhere, meaning your calculations are incorrect - possibly with your variances.",,,1124,"I had the same issue. Then I submit one or two more times and it passed.

Instructor Edit: This information seems incorrect.",error from bonnie,[a5]
5ad7d4a50d63974e20c39248,"Hello everyone,

I just received the following error from Bonnie, and can't make any sense of it. Does anyone else have an idea of what this may mean? Any help is much appreciated.

{
    ""error"": ""{\""stdout\"": \""\"", \""run_stdout\"": \""\"", \""cmd\"": \""sudo -H -u vmuser_wesductp bash -c \\\""cd /home/vmuser_wesductp; ulimit -f 160000 ; ulimit -c 10000 ; python run.py assignment_5 1> run_stdout.txt 2> run_stderr.txt\\\""\"", \""return_code\"": 137, \""run_stderr\"": \""F\"", \""stderr\"": \""bash: line 1:    31 Killed                  python run.py assignment_5 > run_stdout.txt 2> run_stderr.txt\\n\""}""
}
",jc6w44hrp9v2ki,[],,,,1127,It looks like from other threads that this error is caused by going over the Bonnie memory limit of 500 MB.,Unknown Bonnie Error,[a5]
5ad7d4a50d63974e20c39249,"Getting following error trying to submit and yes I entered the right password! What is wrong!? Note, I did switch to two factor recently but was able to submit the last assignment.

GT Login required.Username :myerger3Password :Traceback (most recent call last): File ""submit.py"", line 46, in <module> main() File ""submit.py"", line 42, in main submit('cs6601', 'assignment_5', filenames) File ""/usr/local/lib/python2.7/site-packages/nelson/gtomscs.py"", line 36, in submit session = build_session(environment, id_provider, jwt_path) File ""/usr/local/lib/python2.7/site-packages/nelson/gtomscs.py"", line 25, in build_session jwt_path).new() File ""/usr/local/lib/python2.7/site-packages/nelson/sessionbuilder.py"", line 47, in new jwt = self.login_for_jwt() File ""/usr/local/lib/python2.7/site-packages/nelson/sessionbuilder.py"", line 122, in login_for_jwt gt_login(session, self.root_url, username, password) File ""/usr/local/lib/python2.7/site-packages/nelson/sessionbuilder.py"", line 172, in gt_login raise ValueError(""Username and password failed (Do you use two-factor?)"")ValueError: Username and password failed (Do you use two-factor?)",jc6w44hrp9v2ki,"[{u'text': u'Did you follow the jwt token instructions?', u'responses': [u'I got a new laptop this week probably why it stopped working.', u'Please mark resolved.', u'Thanks for the update. Funnily enough, saw the instructions on a followup to one of your comments about being apprehensive to switch to two-factor: https://piazza.com/class/jc6w44hrp9v2ki?cid=584 :)']}]",Marking as resolved.,,,1128,"Thanks to Connor off slack...
https://bonnie.udacity.com/auth_tokens/two_factor
",Help cannot submit to Bonnie,[a5]
5ad7d4a50d63974e20c3924a,Is there someone who can check?  I just had two submissions in a row time-out after an hour.  I submitted the first with the bonus. After Bonnie-timed out I resubmitted without the bonus.  The second timed-out as well.   My code is fully vectorized and  I pass the local unit tests with a few additions of my own in under 10 minutes.  Bonnie didn't take away from my quota for the submissions so maybe my code was just sitting in queue for an hour?  I'll try again in a few hours.  ,jc6w44hrp9v2ki,"[{u'text': u'how long does it take you to run all the given tests?', u'responses': [u'Less than 10 minutes.', u'Ha!  I just submitted and it finished in 2 minutes.  The server must have been swamped.', u'Because mine takes a little over 1 min. So i dont know what additional tests you've added. If its not much, then 10 mins seem a little long. You might wanna double check while waiting for confirmation from the TAs. ', u'Ok cool. Glad it worked out', u'Probably has something to do with my five your old processor.  An upgrade is incoming.']}, {u'text': u'I also had this problem ~2 hours ago. The timed-out run didn't take away from my submission count, but it did leave me sweating for a full hour. Resubmitting the same code ran successfully (including the bonus) in 57 seconds.

Not sure what happened there—maybe it had an hour's worth of code ahead of me in the queue and just never got to my code? I sure wish Udacity/Bonnie had effective horizontal scaling. Would cut a lot of unnecessary stress from OMSCS. ', u'responses': []}, {u'text': u'mine keep getting time out error. i've been awake and tried several times... really not what to do now.
I have submit a backup through t-square. if the last try also time out on bonnie can the back up been checked?
', u'responses': []}]",Marking as resolved!,,,1131,,Is Bonnie overloaded?,[a5]
5ad7d4a50d63974e20c3924b,"Carrying on from our previous announcement (@1058), by the end of this week you should finish Lesson 8, Pattern Rec Through Time and read Chapter 22 in Russell & Norvig. Additional readings can be found on the course schedule.  

Assignment 5:  Gaussian Mixture Models
Due: April 1 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 5 is due tonight! Details in @1032.
As always, here are the OH calendar, the syllabus and the schedule.  

",jc6w44hrp9v2ki,"[{u'text': u'Chapter 22 in Russell & Norvig is Natural Language Processing. Perhaps Chapter 15 (specifically 15.1 - 15.2) is more relevant as mentioned in one of the slides in lectures', u'responses': [u'Chapter 15 was the required reading for Week 11 (@1012). Chapter 22 contains topics that build upon those discussed in Chapter 15, and need not necessarily be completely covered in the videos. It contains a number of topics we would like students to know but could not cover in the videos.']}]",,,,1133,,Week 13 Announcement,[announcements]
5ad7d4a60d63974e20c3924c,"Is our kaggle extra credit based on the private leader board which uses 50% of test data or will it be (public_score + private_score)/2 in order to capture all test data results?

Edit: I misinterpreted the Kaggle text: 

The private leaderboard is calculated with approximately 50% of the test data.
This competition has completed. This leaderboard reflects the final standings.

The first sentence confused me.",jc6w44hrp9v2ki,"[{u'text': u'From Assignment 4 Bonus Kaggle competition note on Piazza, it states ""After you make a submission you will see your accuracy for approximately 50% of the test data. The other half will be hidden until the end of the competition and will be used as the final result of the competition."" It seems to me like the private half will be used for the final result.', u'responses': []}]",,,,1137,I think the private leaderboard uses all test data available.,Kaggle Results,[a4]
5ad7d4a60d63974e20c3924d,"Hi,

Sorry for my ignorance, this is my first class in the OMSCS. I'm hiring a couple of data scientist positions at Wells Fargo, and I would like to share information about the postings to OMSCS students in case anyone is interested in applying, but I don't want to violate any written/unwritten rules on recruiting. Does anyone know where the appropriate place would be to post something like this? Is it fair game to post details here or is that frowned upon?

Thanks!",jc6w44hrp9v2ki,"[{u'text': u'I'm sure it's ok to post here. In my other/past courses, there's usually one collective thread for job postings. Sometimes even the professor creates it.', u'responses': []}, {u'text': u'There is a section called ""other"". I think it would be appropriate to post there.', u'responses': []}, {u'text': u'Note, I have done similar in the past in the Google group under jobs for OMCS. So, go for it.', u'responses': []}]",I don't see any issues with it; if we have an issue we'll let you know!,,,1140,,Appropriate Place for Job Postings?,[other]
5ad7d4a60d63974e20c3924e,I need to know so I can request some days off if I have to. Thank you.,jc6w44hrp9v2ki,"[{u'text': u'Thank you, Sasha, but I would also like to know time it would be released and time it would be due. Also, I would like a confirmation from the instructors, if possible. Thank you.', u'responses': []}]","It will be released at midnight AoE on April 23 and the deadline will be at 11:59:59 PM AoE on April 29, just like the midterm.
",,,1141,"The dates are in the course schedule, which is included in the weekly email they sent out this morning/last night.",What date/time will final exam be released and what date/time it will be due?,[final]
5ad7d4a60d63974e20c3924f,"In the DTW section it seems to take for granted that you have discrete times series to compute the distance between. I've seen the paper by Keogh about clustering on sub-sequences using a sliding window never providing meaningful clusters,(http://www.cs.ucr.edu/~eamonn/meaningless.pdf) and the seems like it would encompass streaming data. I'm wondering what approaches the instructors (or students) suggest to segment times series data streams before trying to cluster them? They don't necessarily need to be online approaches.",jc6w44hrp9v2ki,[],,,,1144,,DTW for Continuous Data Streams,[lesson8]
5ad7d4a70d63974e20c39250,"Hi,

Hope this OK to post here (@1140). But, I'm hiring two data scientists at Wells Fargo (jobs just posted) and I think a lot of people in the OMSCS would be ideal candidates.

If you are interested, you can look at the job descriptions at WellsFargo.com/careers and search for job opening IDs 5398649 (for a senior data scientist position) or 5398760 (for a mid-level data scientist position). Both jobs are open for any location (including remote / work from home), and are on my team, which is a centralized Natural Language Processing and Machine Learning group at Wells.

I'm looking for people who are strong Python coders and have some NLP / ML background and big data experience. There are lots of similarities to things we work on in this class, such as tree models (although not from scratch! ... we use scit-kit learn or Spark MLLib), usupervised learning methods (lots of similarities between something like LDA for topic modeling and things like GMMs), as well as some other methods (word2vec, recurrent neural networks, etc.).

The best thing to do if you're interested is apply and include OMSCS somewhere on your resume. If anyone wants to reach out to me directly with questions, LinkedIn is probably the best way. Thanks! https://www.linkedin.com/in/nathan-susanj-35856824/ ",jc6w44hrp9v2ki,[],,,,1145,,Hiring Two Data Scientists at Wells Fargo in NLP / ML group,[other]
5ad7d4a70d63974e20c39251,"Hello everyone,

Assignment 4 grades have been released to T-Square. Please note that Extra Credit has not been graded yet, and will be added to T-Square as a separate Gradebook item when done.

The stats are as follows:

Mean92.62Median100St. Dev.16.48

Your score should be the same as your last submission on Bonnie before the deadline. Please comment here with your name and T-Square ID if there is a discrepancy.

#pin",jc6w44hrp9v2ki,"[{u'text': u'Median a freaking 100. This class is to smart! Congrats to all you super stars. To have a 100 median and a 92.62 mean and a 16.48 Std implies the people like me who struggle grades drop down really quick.', u'responses': []}, {u'text': u'Is bonus points already included?', u'responses': [u'ignore this.']}, {u'text': u'Do you have to have kaggle codes through t-square for them to count? just realized I didn't do that - i only submitted them to Kaggle. Looks like I got a pretty good score though, so hoping it actually counts!', u'responses': [u'Any guidance on the above? Thx!', u'I'll leave this unresolved for the time being. I don't think we require you to submit to T-Square, but I'll still need to check with the other TAs. We will be taking some time to get back to grading A4 extra credit though, so I request you to be patient - we will get back to you in a week or so.', u'Thank you!']}, {u'text': u'Ravi, I dont see the bonus points yet. Does it show as a separate entry?

thanks
rshetty35', u'responses': [u'From the post: ""Please note that Extra Credit has not been graded yet, and will be added to T-Square as a separate Gradebook item when done.""', u'Ack, thx.']}]",,,,1146,,Assignment 4 Grades Released,"[a4, grades]"
5ad7d4a70d63974e20c39252,"Hi everyone.
 
Assignment 6 is now released and active on Bonnie. The git repo is here.
 
Please read the README carefully.
 
The assignment is due on Bonnie and T-Square by April 22nd 2018, 11:59pm UTC-12 (Anywhere on earth). The submission on T-Square is a backup just in case, and the submission to Bonnie will be officially used for grading.
 
Important: There is a TOTAL submission limit of 10 on Bonnie. Please be careful to not use your LAST submission for any debugging.
 
Your LAST submission will be counted towards the assignment grade. 
 
There will be a separate post soon about a Youtube live event going over Assignment 6.
 

BONUS

Extra Credit is mentioned at the end of README.
For those who want to participate in Extra Credit, please fill Assignment 6 Extra Credit Form before the deadline.
 
Append two functions: decoder and extra_credit at the end of hmm_submission.py and submit it to T-square. You don’t need to submit to Bonnie for this.
 
The extra credit points are awarded as follows:
1. First place: 15 bonus points
2. Second place: 12 bonus points
3. Third place: 10 bonus points
4. Fourth to tenth place: 7 bonus points


Good luck!

#pin",jc6w44hrp9v2ki,"[{u'text': u'Will there be a separate submission point in T-Square for the extra credit?', u'responses': [u'No you can submit to the same t-square entry.']}, {u'text': u'Suggestion: Modify the bonnie output so that we are told what sequences are failing but not the probabilities.  Not getting ANY helpful output from the bonnie report is frustrating and feels like an unproductive learning environment.', u'responses': [u'+1. I just know from the Bonnie output that I fail 2 test cases, but why I don't know as there is no feedback. Locally all the sequences seem to work, maybe I am still missing something but don't know even what to try next :( ', u'+1', u'We cannot release test cases as people hardcode answers. We'll try to improve the feedback! ']}, {u'text': u'In case anyone else likes to draw out their Viterbi Trellises, I've been printing these.  I've included a PDF as well as the Microsoft Visio file so you can remove the unnecessary state transitions and add extra columns for longer input.

Viterbi_Trellis.pdf

Viterbi_Trellis.vsdx', u'responses': [u'This is helpful. Thumbs up', u'Thanks John
']}, {u'text': u'Hi,

How do we submit the bonus question? Do we put the provided code and our solution both in the hmm_submission.py and submit it to bonnie again? Which function is going to be called when it is tested on your end? And where do we include the string and morse code? (""Besides the decoder, you also need to submit a string (only alphabets and spaces) and its morse code equivalent as performed by a human (in 0s and 1s)."")

Thanks,', u'responses': [u'You need to submit your final hmm_submission.py on t-square . You don't need to submit to Bonnie again. Also fill in the form mentioned. 

You include the string and morse code in the function extra_credit() as mentioned in the README at the end.', u'ok, thanks!']}, {u'text': u'For the bonus problem, I understand the dot can be one of 1, 11, 111, and the dash can be one of 11111, 111111, 1111111. but do we assume the letter pause is exactly 000 and word pause is exactly 0000000? If not, what is the temporal variability for letter pause and word pause? What about the silence? Is it one of 0, 00, 000? Thanks. ', u'responses': [u'Pauses may also vary.', u'Thanks. and silence varies too?', u'yes']}, {u'text': u'Was there a Youtube session about this assignment? I can't seem to find one mentioned anywhere on Piazza. ', u'responses': [u'There will be one by next week. Sorry for the delay!', u'Has the video been posted yet?', u'Also curious about this - I have not seen a link anywhere ? Did the office hours happen? ']}, {u'text': u'Where do we submit our bonus submission? I don't see the decoder and extra credit functions - should we just make a new file with them in it?', u'responses': [u'nevermind, just saw it in the description above :facepalm:']}]",,,,1149,,Assignment 6 Released,[a6]
5ad7d4a70d63974e20c39253,"Assignment 6 - part 2 discussions go in this folder. (@1149)

#pin
",jc6w44hrp9v2ki,"[{u'text': u'I'm a little confused by 2b. The test setup for part 2 indicates that the return value for 2a will be a big tuple. But in the clarifications on the readme it says `You are free to define 2a in any way you want as long as it works for your own 2b.`. I'm assuming our 2a is used in testing our 2b. Is this correct? If so, I'm guessing that means we are free to change the return value of 2a so it will work for multi-letter evidence vectors like we will need in 2b? (This is even more confusing because the test in 2b is just for a single letter.)', u'responses': [u'The final variable returned from 2a needs to be a big tuple, so it can work with 2b. Check the part2 tests in hmm_submission_tests.py for how it should work.', u'Thanks! I thought maybe there was something else going on since the test for part 2b is only for a single letter, but that's not the case. I'll try another route then. :)', u'I can not reconcile the return tuple form part 2 a with the signature of part 2 b. The example in test uses one letter, but the readme says part 2 b should include A, Y, Z, L and W . Should we assume the grader will provide prior_probs and so on that contain all states and all transitions between states?', u'+1 do we need to combine them in part_2b or the passed in arguments already have them combined?', u'The test is just an example for A. You need to merge all the information and pass it as an argument to 2b if you want to test for all states.', u'so, what argument is the autograder in bonnie passing to part2b for prior_probs and so on? Is it passing the prior probs of a single letter or of all letters and word and letter space?

Athira: the code for part2_b in the commented section says ""Expect the same type of combinations for all probability and state input arguments"", if that is the case, then it seems we don;t have to combine it ourselves for Bonnie (but yes for local testing)
Is this interpretation correct?

thanks
', u'Correct', u'Hi all,
 
I got ""part_2_a runs Fail"". Want to check what's the return from your part_2_a? Are you maintain the original ""return (a_states, a_prior_probs, a_transition_prob... ...) or did you changed to other format? I'm merging each part and returned "" return(states, prior_probs, transition_probs, emission_probs)"" but clearly its wrong...', u'found it, return the same as the template. do not combine, bonnie will combine itself.']}, {u'text': u'Delete', u'responses': [u'If it runs successfully the program has no errors, but the answers are wrong so points are deducted.']}, {u'text': u'According to the instruction for part_2_a
If no sequence can be found, the probability of 0 also needs to appear in the return. ""no sequence can be found"" means the probability reaches 0 midway. If you find an incomplete sequence with some probability, output that sequence with the probability. Aend, Yend, .... don't appear in the answer for 1b. 
My questions are:
1. When ""no sequence can be found"", should part_2_b output a tuple with the incomplete sequence and probability zero, or return probability zero only? Under what condition, absolutely no sequence can be found? I thought due to the presence of noise, the first state either A1, Y1, or Z1 will be in the sequence, no matter what. Did I misundertand anything?
2. For incomplete sequence, should part_2_b output the state sequence or letter sequence. According to hmm_submission_tests.py, if a sequence can be found it should work like this:
self.evidence_vector = [1, 0, 1, 1, 1]self.correct_letter = 'A'
So does it means, for incomplete sequence, output state sequence e.g., A1, A2, A3, A3. If it is considered as a complete sequence, output A only?
', u'responses': [u'I'm unclear on your (1) as well, especially given this from the readme: ""If the observation is somehow shorter than the sequence, like it ends at A2 but with some probability, then the sequence should be output with that probability."" It seems to me that the only way to be shorter than the evidence vector is for the probability to hit 0 midway. But maybe I'm wrong about that?', u'This is another confusing point to me as well, ""the observation is somehow shorter than the sequence"". I can't think of an evidence vector that produces a state sequence longer than the evidence vector. If it ends at A2 with zero probability to any other state including A2 itself, then the sequence is shorter than the observation, not the other way around. In addition, with noise, the self-transition prob is non-zero. Therefore it can stay on A2 till the end of the evidence vector. In this case the state sequence is always the same length as the evidence vector. Hope TAs can provide some hints. ', u'When no sequence is found i.e. probability reaches 0 midway in the Viterbi trellis, return None as the sequence. If there is any non-zero probability, then return that sequence.Incomplete sequence means that it does not need to have Aend & you need to output only A for part_2_b.', u'Thanks Athira. Another question on the incomplete sequence is how to break a tie. For example, evidence vector = [1, 1, 1] can give an incomplete state sequence of either [Y1, Y1, Y1], or [Z1, Z1, Z1] with identical probability. Thus the sequence of letter is either Y or Z, so which one bonnie would consider correct?', u'Return the first occurrence.']}, {u'text': u'delete me', u'responses': []}, {u'text': u'Hi,  

Found this line in the readme: ""For 2a, all priors should sum to one"". How is this possible after rounding? Let's say I have 7 letters with equal priors: each will have prior probability 1/7 = 0.1428... If I enter the value as 0.143 (3 decimals, as requested), then the sum is 1.001 != 1.

', u'responses': [u'I found it is fine for that case to not have it sum to one.', u'Yes that is fine']}, {u'text': u'The instructions state ""A letter pause or word space can transition to any letter with equal probability. When it reaches the end state, it stays at the end state."" 
I am having trouble understanding what the ""its"" refer to in the sentence ""When it reaches the end state, it stays at the end state"". 
My understanding right now is that any letter can go from its final sequence state (A3, Y7, Z7) to either an end state for that letter, a letter pause, or a word space with equal probability. If any of the letter end states (Aend, Yend, Zend) are reached this signals us that we have reached the end of the entire sequence. Is this a correct assumption? If not please help me understand how to interpret the instruction above. Thanks!', u'responses': [u'Correct']}, {u'text': u'Can we have clarification for part 2 b please? Readme says ""Use your output in part 2a "" , but the signature for part 2b does not take the tuple, output of part 2a. The example of the test file uses a single letter as input. What is the input that the autograder in bonnie will use?', u'responses': [u'Check part2 tests in hmm_submission_tests.py. That should be sufficient.', u'I do not understand what that means. The only test I see, is calling self.a_prior_probs and so on . Could you please give a direct answer?', u'You can check the setUp function in the tests to see how the return value from 2a is used for 2b.', u'but how do you check if the sequence belongs to which letter if you only pass in a_states and a_prior and so on? the unittest contradicts to what 2b is trying to do here. are we expected to combine them together ourselves within the part_2b function?', u'I am also confused on this. Assuming we have to decode a combination of letters/spaces we will need the information for all possible letters/spaces in order to correctly calculate probabilities along the trellis. 
Athira, can you confirm that we are supposed to decode a combination of letters/spaces in 2b? If so, are we supposed to be merging all the information from our call to 2a into the call to 2b? If not how will 2b know all the information needed to calculate correct probabilities? Thanks!', u'Yes you need to decode a combination of letters/spaces in 2b. The test is just an example for A. You need to merge all the information if you want to test 2b for all letters/spaces.', u'One thing is sure we cant use the ""pass"" in local tests as a sign that we will pass bonnie. The local test code  does not handle anything but single letter and that too  A.

IMHO we need to create a new test for testing.

looks like heavy typing job. Now I am balking at the idea, if we have to join the challenge (26 letters X no of states) + letter pause + word_pause the combinations that we need to write will make the code a monster.

May be we have to think out of box to find a better solution.

The assignment looked deceptively simple till one tries to submit to bonnie.', u'I suggest first pass part_2_b locally and then make changes in part_2_a

the Hint following part_2_a is very important. especially ""Hmm, (<-- see the pun), looks like our example above will need a few more updates...

We can safely assume that bonnie will correctly merge the probabilities and states that we create in part_2_a. 

we can also change the local test for part_2_b word checking accordingly with multiple sequence of words , letter_pause and word_spaces

I am yet to handle the fringe cases got 91 in bonnie.

All the best. 

Come to think of it after 72 hrs of head banging, we have to read in between the readme and see through the hints', u'My lesson learned from assignment #5 was 1) the unit tests were not really sufficient to ensure a decent Bonnie grade and 2) they sometimes allowed incorrect implementations to pass as correct. I think 1) appears to be true for assignment #6 but hoping 2) is not. Specifically, it looks like we need to write our own unit tests for the main part of this assignment.', u'@Srirangam it's probably too late for this to be helpful, but maybe it will be for a future assignment: I wrote little functions that take a letter like ['dot', 'dash'] and outputs the states and probabilities. It was more work up front but was less work to add a 'noise' parameter for the second part of the assignment. I've done this for a few assignments and it's generally been worth it. ']}, {u'text': u'Can we know how long the evidence vectors are for part 2b?', u'responses': [u'If bonnie crashes because it runs out of memory, does it count as submission? My quota on bonnie.udacity.com doesn't seem to count those', u'It does not count if it runs out of memory']}, {u'text': u'Should the unit test for part 2b pass? [A1 A2 A3 WS1 ...] is a valid transition, but you can't look at where to go from WS1 because the unit tests only takes the transition probabilities from A.', u'responses': [u' The local test is just an example for A. You need to merge all the information and pass it as an argument to 2b if you want to test for all states.
', u'thanks']}, {u'text': u'Can we assume that the transition probability table passed by bonnie to part 2b will be complete?
ie. if we have both A and Z in the table, transition probabilities from A1, A2, A3 will be defined going to Z1, Z2, ... with zero probability

Or will the transitions from A only be defined to other A states and the word/letter separators?', u'responses': [u'Yes Bonnie will take care of all states', u'delete', u'Nevermind.  I see that bonnie passes the merged dictionaries to part_2_b, with complete and explicit transition probabilities for every state to every other state.']}, {u'text': u'Since each sequence will always start with a letter as specified by the readme, should the prior probabilities of the letter pause and word space be 0 instead of 1 as they are listed in the readme?', u'responses': [u'Yes']}, {u'text': u'Will the Letters L and W be used to test part 2b at all? If so, how will we differentiate between L and a letter separator, or W and a word separator?', u'responses': [u'Yes. They are distinguished by their transition probabilities.', u'How will they be distinguished in the state list and keys for the transition dictionary and emission dictionary?Working backward from random transitions to try to find each letter’s state assignments seems excessive.In future versions of this assignment I would recommend giving the separators more unique identifying keys than another letter of the alphabet to reduce confusion.', u'Jacob ask a great question which isn't being addressed by TA's in the manner in which he's asking it. Allow me to be more explicit. Since a letter space and the letter L share an identical state key, L1, how are you supposed to distinguish between them? In other words, if given a dictionary of transition probabilities, what does a key of L1 represent? Is it the key for the letter space or is it the key for the letter L?

{ 
  'L1': { 
    # ... is this the beginning of the transition probabilities for the letter space or the letter L?
  }
}', u'Where is the letter L being used? It is mentioned in the README that L1 is for letter pause.

Updated: My apologies. I misread the statement 'Will the Letters L and W be used to test part 2b at all?'. L1 stands for letter pause and W1 for word pause. The only letters that will be tested are A , Y and Z', u'Okay, it appears there is some confusion. So, the letters L and W won't be given as inputs. This was Jacob's original question.', u'Thank you for the clarification Athira.', u'Thank you for the clarification.Using non-alphabetic characters as the state keys for letter pause and word pause in future iterations of the assignment would definitely help reduce confusion here.']}, {u'text': u'For part 2 b in bonnie I am getting a ""
""part_2_a runs successfully\nFail to run part_2_b\nfail test case 1...
"" message. My code passes tests locally (single and multiple letters), so I believe the method signature and return values are formatted properly. I have no way of knowing what the problem is. Is there a possibility to get better feedback from the autograder?', u'responses': [u'It means you're returning an incorrect sequence or probability. We cannot release the test cases since people can hardcode answers.', u'Athira, it says ""fail to run part 2b"", it makes me think i snot just incorrect sequence.', u'Checking', u'Hi Athira, would you be able to check the error thrown in my submission as well? Getting all points through 2a and passing all local tests including 2b plus local tests I coded myself. But I've gotten 0/40 on 2b over a few submissions, and the Bonnie feedback just says that 2b failed to run. Thanks very much. ', u'Hi William, I had the exact same failure state for a couple of submissions. The problem was that I was not accounting for how Bonnie would merge the part 2 a outputs before passing it into 2b. Essentially, my 2b code was throwing exceptions because it was assuming the inputs made sense. Bonnie's merge operation does not ensure this, while my home made local tests were correctly merging the 2a outputs.
', u'Thanks Jon! That did the trick. Nice job on figuring that out. Thought it might be something along those lines but didn't want to keep burning submissions. ', u'Aritha, did you have any guidance on this? I know you can't tell what the answers are, but it seems fair to ask about the format that bonnie is expecting. I have the same problem: passing all local tests (plus ones i coded) and Bonnie telling me 'part_2_a runs successfully' yet 'Fail to run part_2_b""


Jonathon, can you say more about what you determined regarding how bonnie merges the outputs of 2a?

Update: the problem was all in the parser I used to return the sequence. I think the wording in the error message is misleading.', u'Hi all,

I got ""part_2_a runs Fail"". Want to check what's the return from your part_2_a? Are you maintain the original ""return (a_states, a_prior_probs, a_transition_prob... ...) or did you changed to other format? I'm merging each part and returned "" return(states, prior_probs, transition_probs, emission_probs)"" but clearly its wrong...', u'found it, return the same as the template. do not combine, bonnie will combine itself.', u'Any update on this? Even I'm getting Fail to run part_2_b']}, {u'text': u'Hello, 

I am getting the below message for 2_b: 

""message"": ""part_2_a runs successfully\npart_2_b runs successfully\npart_2_b runs successfully\nfail test case 2\npart_2_b runs successfully\nfail test case 3\npart_2_b runs successfully\n""
It looks I am failing 2 test cases, but not sure which ones. I have tried combinations of 'A,Y, Z', letter pause and word spaces (with/without noise). Could you please share a few examples (input-output pairs), for which we can verify if our code is working as expected on Bonnie? Examples like if input is 

[1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1]
the output should be : A Z Y A etc. Or maybe guide to what we might be missing while testing. I am not able to make any progress, whatever I try. 

Thanks
', u'responses': [u'It means you're returning an incorrect sequence or probability. We cannot release the test cases since people can hardcode answers.', u'Hi Athira, just to chime in. I'm also stuck with one test case (test case 2) and without any kind of context it is difficult to debug. Are there other ways you can help us without giving the test case outright? For example, does it deal with certain edge cases, or does it deal with a vector whose possible outcomes are a small delta apart from each other, etc. Any bit to help us moving along helps. ', u'To avoid the hardcoding problem though is it not possible to release some test cases that are not used in the auto-grader? Even some simpler cases beyond the single letter test in the unit tests would help a lot since otherwise the unit tests don't appear to really test the main part of the assignment.', u'+1 to David's recommendation', u'Alternatively, randomise the bonnie tests and release a couple of samples from a different random seed. That way the tests are realistic / representative but hardcoding is impossible. ', u'Please provide some more test case that is not used in Bonnie for us to debug. The provided test case is just too simple for any kind of debug.', u'Yes, can we please have some additional test case to help with debugging? The error log messages are not helpful. ', u'I was pretty much feeling around in the dark, but I passed the last couple of test cases when I considered that, because of noise, A1A2A3A3A3 is not the only state vector that can be translated to A', u'I think Giacomo has it right, you may not see an exact match for a letter’s nominal state sequence given noisy input.', u'Hi all,

I got ""part_2_a runs Fail"". Want to check what's the return from your part_2_a? Are you maintain the original ""return (a_states, a_prior_probs, a_transition_prob... ...) or did you changed to other format? I'm merging each part and returned "" return(states, prior_probs, transition_probs, emission_probs)"" but clearly its wrong...']}, {u'text': u'For part 2b the return type is stated as "" an evidence vector of [1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1] would return the String 'AA' with it's probability"".

Just want to confirm that Bonnie is really expecting 'AA' as opposed to ['A1','A2','A3','A3','A3','L1','L1','L1','A1','A2','A3','A3','A3'] which would be consistent with part 1b.

If 'AA' is truly expected, is it correct to say that we will need to implement a parser that would map the vector to a human readable string?

', u'responses': [u'Yes. Also remember what you should output if it is letter pause or word pause']}, {u'text': u'Hi, can someone confirm?
I am only losing points for part 2_b - does the deduction in 2_b implies incorrect implementation of only 2_b or I need to debug other parts as well? (provided my 2_b code is independent of all parts except 2_a - where only probabilities are set and 2_a runs successfully).', u'responses': [u'Check implementation of 2b unless it depends on any other function within the programme', u'ok thanks
']}, {u'text': u'Can anyone provide a hint on `fail test case 2` in part 2b means?
I have more than 20 local tests passing, and tried all edge cases I could think of, and I am still failing.
Thanks.', u'responses': [u'I had a problem in my parser, which was causing test cases 2 and 3 on fail on Bonnie, despite passing more than 35 test cases locally. Fixing the bug in how I convert from states to sequence helped.', u'Thank you!']}, {u'text': u'Can we use scipy for the bonus section?', u'responses': [u'No']}, {u'text': u'What's the time limit for the bonus section? Approximate how long will the signal string be?', u'responses': [u'There's no time limit, as long as it works. String should be of normal sentence length in English.']}, {u'text': u'Am I correct in assuming the priors for letter_pause and word_pause need to be changed from the sample code, since the message cannot start with a letter or word pause?', u'responses': [u'Yes. See Jacob's question above.']}, {u'text': u'If we see an input that translates just to ['A1'], would we output that as 'A'?', u'responses': [u'Ideally you should output A if you encounter A1 until the last state (A3) or Aend & if your trellis works correctly there shouldn't be any partial sequences encountered.', u'How are we supposed to enforce sequences ending in an end state?']}, {u'text': u'When we evaluate sequences, should we prioritize low probability full sequences that end over high probability partial sequences?

For example, if we are given [1, 1, 1, 0, 1] in 2b, this could be a low probability ['A1', 'A2', 'A3', 'A3', 'A3'], which then could lead to a Aend or a high probability ['Y1', 'Y1', 'Y1', 'Y2', 'Y3'], which does not lead to Yend.  In this case, should we go with the high probability choice (Y) or the lower probability choice that is a full sequence (A)?', u'responses': [u'Return one with highest probability is the general rule.']}, {u'text': u'Hi,
 
I got ""part_2_a runs Fail"" from my bonnie test for part_2_b. Want to check what's the return from your part_2_a? Are you maintain the original ""return (a_states, a_prior_probs, a_transition_prob... ...) or did you changed to other format? I'm merging each part and returned "" return(states, prior_probs, transition_probs, emission_probs)"" but clearly its wrong...', u'responses': [u'found it, return the same as the template. do not combine, bonnie will combine itself.']}, {u'text': u'""part_2_b runs successfully fail test case 1""  everything else works fine but test case 1 on 2b--this is my last piece. Any insights? Is this testing weird cases, like empty or incomplete sequences?', u'responses': [u'Same here.

Update: I resolved the issue, which was a bug in my code.', u'I'm stuck in same spot. Have 95 in bonnie with only failure is test case 1 part 2b', u'update... I had a bug in part 2a. resolved the issue', u'Yep--that was it. Thanks.']}, {u'text': u'I'm getting what seems to be a common issue on 2b.

Fail to run part_2_b

It's working OK on my local tests where I do the conversions myself but it appears it doesn't work at all on bonnie. I cannot tell if there is an issue with it throwing an exception inside the test case or it just spits out the wrong answer/probability. I'm using my same viterbi function as part 1b if that changes anything.

EDIT:It look like I made a bad assumption about how part 2a is combined and given to 2b. When writing my own unit tests I had write a combining function anyway. So I just ignore the passed in values and build my own from 2a. Try that if you're failing to even run 2b.
 ', u'responses': []}, {u'text': u'The sequence 'A1, A2, A3, A3, A1, A2, A3, A3' should be impossible because a letter or word space must occur before another letter, correct? ', u'responses': [u'Correct, Based on the transition probabilities, it is impossible.', u'It is possible. With noise, It would mean an 'A', I guess.', u'Even with noise that is impossible because A3 can never transition to A1 in one step.']}, {u'text': u'I realized that Bonnie is not merging part 2a output well for my implementation. I have failed a few times for 2b with 0/40 although my local tests are good. Just now I tried to merge the output of 2a at the beginning of my part 2b, then I got 40/40. 

This tells me that my part 2a output is different from the ""standard"" one. But I did not do anything special. I simply followed the format and style given. 

I am just curious about how Bonnie merged data or what format of 2a output Bonnie expects.

I saw someone on slack talked about flattened dictionary. I think the transition prob is easier to be written as a dic of dics. ', u'responses': [u'Even I've gotten 0/40 a few times now. Were you also seeing ""failed to run part_2_b""?', u'I did not merge the output from 2a in my 2b (my 2b just uses the passed in parameters).   I did add additional tests that combined the outputs from 2a and fed them to 2b to test different sequences of characters.  In order to combine them correctly,

states must be a list of states and are joined together by simple list addition (using the elements in the part 2 tests: self.a_states + self.y_states...priors, transitions and emissions must be dictionaries and are joined together by creating a new dictionary out of the items of the dictionaries:  dict( self.a_prior_probs.items() + self.y_prior_probs.items() )  -- at least that's how I combined them and then passed them to 2b for it to work (there are very likely other python mechanisms to join dictionaries together).

If you are having an issue that is solved by you doing the joining inside of 2b, it's likely the output format from your 2a is not correct (e.g. one of the thing's that's supposed to be a dict is a list or vice versa).  Take a close look at your letter and word space entries -- I *suspect* that is the likely place where something may be different.']}, {u'text': u'My application computes the right answers but takes way too long to compute.  I keep hitting timeout in Bonnie. 

My implementation uses a recursive function that calculates probability of a node by adding the emission probability of the current node with the best probability from its the previous nodes.  It computes until it reaches the first node (length of evidence vector) and then returns an answer.  This method essentially searches every possible path from possible end states to the beginning of the sequence.

Any hints on how i can prune this search to a be more cost efficient? Are we supposed to implement a stochastic beam search?

From the lecture when discussing how to eliminate paths, Kelly states:  ""Keep paths randomly in proportion to their probability"".  I'm a little confused on what this means or how to implement it.  Can somebody explain this?

Any help would be much appreciated.  Thank you', u'responses': [u'If you use numpy and matrix I don't think you'll need to prune anything. ', u'Thank you Irene.  My approach has been wrong and I've been wasting time trying to optimize/prune my bad approach.  Looks like i'll be re-writing from scratch.']}, {u'text': u'So I think I understand the final piece of translating the sequence into the expected letters... basically if I see A1->A2->A3(x3) then that equals ""A""... that part makes sense to me... but I don't quite understand how we calculate the probability in this case...  I mean, I would think the probability should be 1 since A is exactly what was output... the probability returned from the viterbi function is 0.09... but it says the expected is 0.03... which is the 0.09 x 1/3... is the 1/3 because there were 3 states found?  Or is there something more to this I'm not seeing?', u'responses': [u'Hi Eric, I'm not sure if you've figured this out yet but review your prior probs. This confused me a bit but all priors needs to add up to 1. Ignore the docstring/comments. This may or may not solve it. Good luck.', u'Thanks for the comment, my priors do add up to 1 already, but I'm still seeing this issue.  I get the right sequence output, and all of my probabilities are reported as good for the test cases given, but I am failing on the expected probability for part 2b.... why would all my other probabilities be good but this one is wrong?', u'in the cases where we add L and W as possible transitions (in addition to Aend, for example)... would the probability not be equally divided into thirds amongst the ""end"", ""W"", and ""L"" transitions?  I'm just missing a few points on this assignment and trying to figure out what I'm missing at this point', u'First you figure out the self vs next transition probabilities, then you take the next probabilities and divide them evenly amongst the possible next states.  At least that's how I did it.', u'Hey Eric, yes, divide into thirds. For the few points, what's the Bonnie msg? I have one as well (test_case_2). Bonnie won't tell you much but at least she'll let you know if it's a runtime error.']}, {u'text': u'Part 2a is pretty straightforward, but I'm having a hard time understanding how to properly split the evidence list in 2b...

From everyone else's conversations it sounds like states, probabilities, transitions, etc... will be combined in this part?  If I combine them for a local test and run my viterbi algorithm as I have it I just keep getting key errors... since it makes sense that the states don't all exist...

Does anyone have any hints on how to go about parsing the string into the various letters?  It makes perfect sense for a single letter such as ""A"", but with multiple letters how do you avoid having dictionary key errors?  I could try partitioning the data beforehand and seeing if a letter fits the partition, but that seems really inefficient...', u'responses': [u'Once you get the complete sequence, you need to find the various letter pauses and word spaces and form your string based on that. I didn't understand what you mean by dictionary key errors.', u'I got this working, I was looping over all possible transition states in my viterbi algorithm and this was causing a missing key error when checking a transition that isn't possible... such as L1 -> A2... I added a check for that and fixed it', u'I addressed this by just making sure there was a transition probability for every state to every other state (filling in the missing ones with zeros).']}, {u'text': u'Do we need to compute the probability in log space for this and return that? I made own test case combining all the data and I'm passing the local test, but I keep getting ""Failed to run part_2_b"" on Bonnie. Any insights?', u'responses': [u'I just passed bonnie without log probabilities.', u'I found that failed to run means you raise an exception or the function returns the wrong types and maybe wrong return count too. ie. It couldn't compare the result sent back. If you return ('', 0.0) it's will say it ran but failed the test.
I did some test on log vs. non-log probabilities. For 5 character sequences it was too close to tell most of the time, and no where close to the 3 sig fig needed.', u'Like Anthony, I had no problems passing without using log probabilities.', u'No logs for me as well (though I'm still failing one test). Like Piers mentioned, your Bonnie error msg is a runtime error. Try creating your own multi-letter, multi-word evidence vector and see what happens locally. Checking for ""legal"" transitions was one thing I had to do to get everything running smoothly.']}, {u'text': u'""fail test case 2"", from our beautiful Bonnie (this is my last test case)

I've been trying to debug this one for a long while now. Very little information to work on, but I know everyone here's struggling this as well. And insights on this failed test_case_2?

Thank you in advance!', u'responses': [u'Create your own tests cases, in the documentation it reads:

For example:    an evidence vector of [1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1]    would return the String 'AA' with it's probability

but that test is not provided in tests, you need to add it by yourself, that helped me.', u'Thanks, Carlos!

I've tested both ""A"" and ""AA"" and passed. It definitely helped me get from to 95, but now I'm stuck on this last hurdle.

Thank you for the reply!', u'I added tests that tested combinations of letters (e.g. ""AZ"" and ""YA"") as well as words like ""AZA YYA"".  You have to combine the states/priors/transitions/emissions in your testing function before submitting the mixed tests, but that's what they are going to do on bonny anyway.']}]",,,,1150,,Assignment 6 - Part 2 discussions,[a6]
5ad7d4a70d63974e20c39254,"Assignment 6 - part 1 discussions go in this folder. (@1149)

#pin",jc6w44hrp9v2ki,"[{u'text': u'For part 1b, I can't avoid this failure on bonnie: ""part_1_b runs successfully fail test case 3"". I followed the instruction
If no sequence can be found, the algorithm should return one of the following: None (null) [] (empty list) ['A1', 'A1', ...'A1'] (Or all being the first state)
and return a tuple like (['A1', 'A1', 'A1'], 0.0) or (['A1', 'A2', 'A3'], 1.0). Any edge scenarios I missed, such as evidence vector is zero in length, has character other than 1 and 0, etc? I don't want to test all likely scenarios with limited submission. Anyone else has this issue? Any suggestions? Thanks. 
', u'responses': [u'I used None and it worked. I also recommend creating a separate unit test from the ones given that causes a None-result and verify your code works correctly if you haven't already.', u'Thanks Jacob. return (None, 0.0) when probability is zero makes my code fail case 1, 2 and 3. That's quite puzzling. ', u'Jacob, did you return None, or None, 0.0?', u'None, 0.0 since it requires a 2-tuple as the return', u'Junwei, did you solve the problem with returning (None, 0.0)?']}, {u'text': u'Can anyone provide some more test cases for 1b? Having some trouble fully understand 1b, though could get the provided test case correct.... Thanks!', u'responses': [u'Unfortunately, I think that is part of the assignment for this one.  Try working out a test case or two by hand and test them out with your program. That’s what helped me find my error. ', u'I tried. My 2b could get full credit, while my 1b could always get partial credit.

Just to confirm, 1b only tests single letter, not words, right?', u'Yeah, I am calculating y and z manually and then sending one for it and make sure it works cleanly.', u'I tried with A,Y,Z and all seem to work correctly on local. But i'm getting only 25/45 on Bonnie, and with the following error:

""message"": ""part_1_a runs successfully\npart_1_b runs successfully \npart_1_b runs successfully \npart_1_b runs successfully \nfail test case 1\nfail test case 1\npart_1_b runs successfully \npart_1_b runs successfully \npart_1_b runs successfully \nfail test case 2\nfail test case 2\nfail test case 2\nfail test case 2\npart_1_b runs successfully \npart_1_b runs successfully \npart_1_b runs successfully \nfail test case 3\nfail test case 3\n"",', u'Parth, I'm seeing the same thing, did you get what the problem was?']}, {u'text': u'How should we compute the second returned value ""probability"" of part 1-b?
The description ""probability this state sequence fits the evidence as a float"" is kinda vague.', u'responses': [u'Hello TAs,

Docstring for viterbi need to be corrected.
Returns:
        ( A list of states the most likely explains the evidence,
          probability this state sequence fits the evidence as a float )

        Example:
            ( ['A1', 'A2', 'A3', 'A3', 'A3'],
              1.0 )
The second return value should be 0.444889 instead of 1.0.', u'Thanks will fix this in future versions.']}, {u'text': u'I'm finding the output from the autograder to be very vague for this project. I've tested my trellis locally on A, Y, and Z and I'm pretty sure it's working correctly on them, but I'm getting 20/45 from Bonnie with this message: 

""part_1_a runs successfully\nFail to run part_1_b\nFail to run part_1_b\nFail to run part_1_b \nfail test case 1\nfail test case 1\nfail test case 1\nfail test case 1\nfail test case 1\nfail test case 1\nFail to run part_1_b\npart_1_b runs successfully \npart_1_b runs successfully \nfail test case 2\nfail test case 2\npart_1_b runs successfully \nFail to run part_1_b\npart_1_b runs successfully \nfail test case 3\nfail test case 3\n""
Any idea what's tripping it up?', u'responses': [u'I follow  this pseudo code https://en.wikipedia.org/wiki/Viterbi_algorithm. I had similar output when I incorrectly decoded final path from the table.', u'Sounds like we're not going to get any helpful feedback from the grader or the TAs on this. 

I wonder if it's underflow error since I'm not logging my probabilities. ', u'I converted all of my calculations to log space and I got the same results, so, I don't think underflow is the issue.', u'One of the comments in the ""Part 2 Discussion"" mentioned getting the ""Fail to run part_2_b"" message and finding that their code was raising exceptions in certain circumstances.  Perhaps the ""Fail to run part_1_b"" part of the message is indicating that here as well?', u'Thanks Brett, that's helpful, although I'll probably need to go into logspace for the longer sequences at some point. 

And thanks, Chris. I was able to trigger an exception by passing the evidence vector for A into the function with all other quantities from Y, and I wasn't catching that exception properly. I'm going to wait to submit to Bonnie until I have more of the project done but I suspect that was my issue! ', u'That took care of test cases 2 and 3, but I'm still failing case 1. ']}, {u'text': u'Same here - I see the following on bonnie, no idea how to look further, the local tests pass for 1a 1b -

 ""tests"": [    {      ""output"": {        ""points_available"": 10,        ""message"": ""part_1_a runs successfully\n"",        ""points_awarded"": 6      },      ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_slmdzncw/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 320, in test_part_1_a\n    self.assertEqual(score, 10, \""Part_1a\"")\nAssertionError: Part_1a\n"",      ""description"": ""Test part_1_a""    },    {      ""output"": {        ""points_available"": 45,        ""message"": ""part_1_a runs successfully\npart_1_b runs successfully \nFail to run part_1_b\nFail to run part_1_b \nfail test case 1\nfail test case 1\nfail test case 1\nfail test case 1\npart_1_b runs successfully \nFail to run part_1_b\nFail to run part_1_b \nfail test case 2\nfail test case 2\nfail test case 2\nfail test case 2\npart_1_b runs successfully \nFail to run part_1_b\nFail to run part_1_b \nfail test case 3\nfail test case 3\nfail test case 3\nfail test case 3\n"",        ""points_awarded"": 15      },      ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_slmdzncw/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 704, in test_part_1_b\n    self.assertEqual(score, 45, \""Viterbi\"")\nAssertionError: Viterbi\n"",      ""description"": ""Test part_1_b""    },', u'responses': [u'i had fat fingered something, now I have interesting results -
1b passes 45/45
1a fails 8/10

{
  ""tests"": [
    {
      ""output"": {
        ""points_available"": 10,
        ""message"": ""part_1_a runs successfully\n"",
        ""points_awarded"": 8
      },
      ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_boyrcket/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 320, in test_part_1_a\n    self.assertEqual(score, 10, \""Part_1a\"")\nAssertionError: Part_1a\n"",
      ""description"": ""Test part_1_a""
    },', u'I had 8/10 in 1_a as well and found out that I has a probability incorrect.']}, {u'text': u'Does the total probability of the Viterbi path through the trellis include the exit probability from the last state? In the video ""Viterbi path"" it does include that last 0.2 in the calculation, but in the unit test for A for part 1b it doesn't. It asserts that the probability should be 0.444889, but with the last 0.333 for the exit probability from A3 it should be .148148 to be consistent. 

Which should we be using for this course?', u'responses': [u'In my implementation I ignored the transition probabilities to the end state once the trellis was fully constructed. For example, in 1b you would ignore the transition probability from A3 to Aend', u'Since there are partial sequences possible, we do not consider the exit probability for this assignment.
', u'What do you mean by partial sequences possible? I don't follow.', u'If your algorithm finds an incomplete sequence then it is not certain if it will exit that state or not, so to avoid any confusion we just ask you to find probability until that state.']}, {u'text': u'For the test case of part 1b, the sequence is A1', 'A2', 'A3', 'A3', 'A3'
I wonder why the probability is 0.667 * 0.667, rather than 0.667 * 0.667 * 0.333.
In other words, why we don't need to take A3 -> End transition probability into account?

Thanks.', u'responses': [u'Since there are partial sequences possible, we do not consider the exit probability for this assignment.']}, {u'text': u'I got below error for 1_b,  anyone encounter this before?  Not sure what's going on..

""tests"": [    {      ""output"": {        ""points_available"": 45,        ""points_awarded"": null      },      ""traceback"": ""Traceback (most recent call last):\n  File \""/home/vmuser_zewclvmr/AIResult.py\"", line 26, in func_wrapper\n    ans = func(self)\n  File \""run.py\"", line 444, in test_part_1_b\n    if isclose(a_probability, correct_a_probability, rel_tolerance):\n  File \""run.py\"", line 16, in isclose\n    return abs(a - b) <= rel_tol\nTypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n"",      ""description"": ""Test part_1_b""    },    {

', u'responses': [u'You are likely returning None for probability when you should return 0.']}, {u'text': u'Do we have to round to 3 digits when we define probabilities?

I would prefer to just use fractions. For example, instead of writing 0.333, it would be nice to simply write 1.0/3.0.
example: 	     {'A1'  : {'A1'  : 0.0,
                               'A2'  : 1.0,
                               'A3'  : 0.0,
                               'Aend': 0.0},
                      'A2'  : {'A1'  : 0.0,
                               'A2'  : 0.0,
                               'A3'  : 1.0,
                               'Aend': 0.0},
                      'A3'  : {'A1'  : 0.0,
                               'A2'  : 0.0,
                               'A3'  : 2.0/3.0,  #instead of .667
                               'Aend': 1.0/3.0}, #instead of .333
                      'Aend': {'A1'  : 0.0,
                               'A2'  : 0.0,
                               'A3'  : 0.0,
                               'Aend': 1.0}}
', u'responses': [u'Yes it's advisable to round.']}, {u'text': u'I am trying to reconcile this content form the README for part 1b:

If no sequence can be found, the algorithm should return one of the following: None (null) [] (empty list) ['A1', 'A1', ...'A1'] (Or all being the first state)

with the information on this thread that ""there are partial sequences possible"".

I understand that if the probability of an evidence vector hits 0 midway, I should return (None, 0.0). My question is:
What is required to be returned for 1b if a partial sequence is encountered?:
1) the partial sequence with its non-zero probability -or- 
2) (None, 0.0)

Maybe I am confused because Part 2b explicitly requires ""If you find an incomplete sequence with some probability, output that sequence with the probability"". But Part 1 README does is not as clear. Do ""partial sequence"" and ""incomplete sequence"" mean the same thing?', u'responses': [u'If any sequence had non-zero probability (“complete” or not), I found the highest probability sequence and returned that sequence with its probability', u'If i'm understanding you correctly, then and evidence vector of [1] for part 1b will always return a probability of 1, right?']}, {u'text': u'For the autograder tests for 1b, is it safe to assume that the inputs will always be for Morse code, such that state 1 has the only nonzero prior?', u'responses': [u'yes']}, {u'text': u'Hopefully this helps someone not make the stupid mistake I did.I did not follow the instructions well enough and instead of using the state name ""Zend"" I wrote ""ZEND"" in all caps. This led me to losing over 30 points. Both 1_a and 1_b were failing because of this but not locally. After fixing it I am almost 100% clear in both parts', u'responses': [u'Awesome. Thanks for taking the time to help us avoid the same pitfall.']}, {u'text': u'For this part, I feel like I'm just fighting with the autograder. Are there any special cases that should be considered? 

I've been coding with the assumption that the letter will always start at the beginning, but can complete at the end or anywhere in the middle. Is there more to this that needs to be considered? ', u'responses': [u'I'm also totally stuck on test case 1 for part 1b. Everything else works but I can't figure out what corner case Bonnie is testing. Locally everything works great and I've thrown just about every evidence vector I can think of at my code and it does fine. Any tips or other ideas welcome. ', u'Have you tried when prob is zero? You need to return a special output in that case.']}]",,,,1151,,Assignment 6 - Part 1 discussions,[a6]
5ad7d4a70d63974e20c39255,"Hi,
I have worked on section 27
in lesson 8 for quite a while and could not get the answer indicated by the instructor.And I wonder how it is calculated.


According to the lecture,the logic should be laid down as below thus requiring the determination of ""a"",""b"" and ""c"" in the posted image.

I have plugged in a=0.005, b =.4,c = 0.005
And the product of those numbers is far from the indicated answer.

So I wonder how I should do it right if I get it wrong.Please point out. Thanks",jc6w44hrp9v2ki,"[{u'text': u'I also worked this one out, here is the full trellis view if it helps.
IMG_20180405_124137757.jpg', u'responses': [u'Precisely.']}]",,,,1153,"For calculating the total probability, we need to draw out the full Viterbi Trellis as shown in lecture 21. If you refer to that trellis, we need to insert 3 states for -1 (before 0) with probabilities x=0.005, y=0.4, z=0.015 and 3 states for 1 (after 0) with probabilities a=0.015, b=0.4, c=0.005. [x, y, z being the probabilities P(-1|state 1or 2 or 3) respectively and a, b, c being the probabilities P(1|state 1 or 2 or 3) respectively].

In the shared image, the probabilities for sequence values 0 need to be the same as in lecture 21, P(0|state 1) =0.01, P(0|state 2) =0.9 and P(0|state 3) =0.01. Then if you calculate path with maximum likelihood, you'll get the same answer. 

Hope the following screenshot helps:
1.jpg",explanation needed for section27 in lesson8,[lesson8]
5ad7d4a80d63974e20c39256,"I was really struck by a project out of MIT that used Machine Learning to read subvocal muscle movements, allowing you to think commands to a computer. If you're like me and you enjoy having class topics connected to actual cutting-edge research, then you'll probably find this article interesting. Also, Professor Starner was interviewed at the end of the article, and offers some insightful intuition about how this research could be applied.

http://news.mit.edu/2018/computer-system-transcribes-words-users-speak-silently-0404

That article is light on technical detail, so if you're interested in the machine learning model architecture and cross validation details, check out their paper.

https://dl.acm.org/citation.cfm?id=3172977
",jc6w44hrp9v2ki,"[{u'text': u'Thanks for sharing. I would be interested in knowing what research areas in this space Professor Starner believes requires more attention.

', u'responses': []}, {u'text': u'That is super cool!', u'responses': []}]",,,,1154,,Machine Learning Enables a New Computer Interface,[other]
5ad7d4a80d63974e20c39257,"Hello everyone,
 
Assignment 5 grades have been released to T-Square. The Bonus score has been added to T-Square as a separate Gradebook item.
 
The stats are as follows:
 
Mean91.62Median100St. Dev.19.10
 
Your score should be the same as your best submission on Bonnie before the deadline. Please comment here with your name and T-Square ID if there is a discrepancy.
 
#pin",jc6w44hrp9v2ki,"[{u'text': u'Hi, my t-square id is ""mzhang406"".


My latest 5 submissions on bonnie are all failed with either timeout or unknown reason. I checked out all the thread regarding bonnie submit error, some of them are random, and I don't see matching errors like mine so I just keep trying. I submitted a backup in T-square, can TA help check my T-square submission for the assignment 5 score?

Thanks,
Mengyun', u'responses': [u'Just had a look at your code. You're using np.apply_along_axis, which is NOT vectorization. It simply runs the function on every element individually, similar to a loop. Your code takes too long to run, which is why it was timing out.
I'm sorry, there will be no change to your score.', u'Hi Ravi, I see, but if ""np.apply_along_axis"" is not vectorization, which function should I use to apply certain function for all the points in an array?
Also, for np functions, in general how do we find out if one function is vectize or not?
', u'For your specific case, you have applied apply_along_axis to get the probabilities. Instead, you could have just used the array directly instead of val and it might have worked.

There were a number of posts where students had discussed runtimes for their functions, and we have some guidelines in the readme. Using those, you could have spotted that your code was running too slowly. The numpy documentation itself says that apply_along_axis is similar to using a loop, which is what we warned against doing.

In general, any complex function would probably not be vectorized. On the other hand, simple operations such as addition, subtraction, multiplication, powers/log, min/max etc. can be vectorized. We did not ask for any more complex functions in this assignment.']}]",,,,1156,,Assignment 5 Grades Released,"[announcements, a5, grades]"
5ad7d4a80d63974e20c39258,"This is a solution for Challenge Question 23- @1037

DYNAMIC TIME WARPING
a. 
ST:
['-', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1']
['1', '0', '0', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
['0', '1', '1', '0', '-', '-', '-', '-', '-', '-', '-', '-', '-']
['1', '-', '1', '1', '0', '-', '-', '-', '-', '-', '-', '-', '-']
['0', '-', '-', '1', '1', '1', '-', '-', '-', '-', '-', '-', '-']
['1', '-', '-', '-', '1', '1', '1', '-', '-', '-', '-', '-', '-']
['0', '-', '-', '-', '-', '2', '2', '2', '-', '-', '-', '-', '-']
['0', '-', '-', '-', '-', '-', '3', '3', '3', '-', '-', '-', '-']
['0', '-', '-', '-', '-', '-', '-', '4', '4', '3', '-', '-', '-']
['1', '-', '-', '-', '-', '-', '-', '-', '4', '4', '4', '-', '-']
['1', '-', '-', '-', '-', '-', '-', '-', '-', '5', '5', '4', '-']
['1', '-', '-', '-', '-', '-', '-', '-', '-', '-', '6', '4', '4']
Distance = sqrt(4) = 2
 
IS:
['-', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1']
['1', '0', '0', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
['0', '1', '1', '0', '-', '-', '-', '-', '-', '-', '-', '-', '-']
['1', '-', '1', '1', '0', '-', '-', '-', '-', '-', '-', '-', '-']
['0', '-', '-', '1', '1', '1', '-', '-', '-', '-', '-', '-', '-']
['0', '-', '-', '-', '2', '2', '2', '-', '-', '-', '-', '-', '-']
['0', '-', '-', '-', '-', '3', '3', '3', '-', '-', '-', '-', '-']
['1', '-', '-', '-', '-', '-', '3', '3', '3', '-', '-', '-', '-']
['0', '-', '-', '-', '-', '-', '-', '4', '4', '3', '-', '-', '-']
['1', '-', '-', '-', '-', '-', '-', '-', '4', '4', '4', '-', '-']
['0', '-', '-', '-', '-', '-', '-', '-', '-', '4', '4', '5', '-']
['1', '-', '-', '-', '-', '-', '-', '-', '-', '-', '5', '4', '4']
Distance = sqrt(4) = 2

b. Both ST and IS are equally likely.

c. It will allow more variances and the beginning and the end. You may find it to be helpful in some situations. For example, people may have bigger variance when doing sign languages in the beginning and end of words, but more consistent in the middle.",jc6w44hrp9v2ki,"[{u'text': u'Can you please show the equation you used for the distance? Is it Distance = 2*sqrt(the distance between the last digits)? The lecture used distance = sqrt(sum(d*d)).   If I followed the original paper by Sakoe and Chiba 1978, the ""Time-normalized distance"" is used. So would be good to know what equation to use for this course. 

', u'responses': [u'Distance  = sqrt(X), where X is the last digit in the diagonal. 

The values in the array are cumulative so you only need the value of the last cell.', u'Thanks Theodore. why there is a 2 times sqrt(X) as shown in the solution?', u'Oh I'm sorry if it was unclear but I meant: d = sqrt(4) = 2. I edited it for clarity.']}, {u'text': u'I have some questions regarding a).
for ""10% signal length Sakoe-Chiba bounds (i.e. 1)"", I'm not quite sure how 10% -> 1, is that because the total signal length for my intercept morse code is 12 and ST/SI are 11, so we get 11/12*0.1 ~= 1?

Also based on my understanding of what's answer posted, looks like you are calculating maximum 3 numbers each time along with time wrapping, the diagonal line, upper bound (diagonal+1),  and lower bound. Then how did this moving forward through time? For example, if we treat along x-axis, for first point we calculate along diagonal it's 0, and upper bound is 1, shouldn't we choose the smallest in this calculation and use that value to go to next point's calculation? why we have each time all 3 points calculated, how did you do the accumulate through time?
', u'responses': []}, {u'text': u'Can you explain how you constructed your matrix? It doesn’t seem to follow what was done in the video lecture. ', u'responses': []}]",,,,1157,,[Solution] Challenge Question 23 - Pattern Recognition Through Time,"[lesson8, challengeqtns]"
5ad7d4a80d63974e20c39259,"Hello everyone,

This week you should do Lesson 9, Logic & Planning, and read Chapters 7-10 in Russell & Norvig.  Additional readings can be found on the course schedule.  

Assignment 6:  Hidden Markov Models
Due:  April 22 at 11:59PM UTC-12 (Anywhere on Earth time)
Assignment 6 is out, hope you’re all enjoying it! Details in @1149.
As always, here are the OH calendar, the syllabus and the schedule.  

",jc6w44hrp9v2ki,[],,,,1161,,Week 14 Announcement,[announcements]
5ad7d4a90d63974e20c3925a,"This is a solution for Challenge Question 24, @1043.


HIDDEN MARKOV MODELS

",jc6w44hrp9v2ki,"[{u'text': u'Using only the mean (-3), how do we get the probability of as 3/4 and 1/4 for 'I' in first state?', u'responses': [u'Hi Anil, the transition probabilities are not calculated based on the probability distributions. They are calculated based on the number of samples that correspond to each state! Four samples mean that there is 1/4 chance to moving on. Three -> 1/3 and so on..']}, {u'text': u'Can you show the work or explain how you arrived at the divisions / bounds for thank you?', u'responses': [u'Hi Aron!
So in the beginning you decide how many states you want to use in order to encode your training data into an HMM. For this question we are using 3 states.

Once you know the number of states of the HMM, you can go ahead and divide your observation data. You have 10 observations and 3 states so your data is split into 3, 3 and 4.

Step 1:
For each state you then measure the mean and variance for the emission probabilities, and also calculate the transition probabilities (n observations for the state give a 1/n transition probability and a (n-1)/n probability to stay in the same state.) 

Step 2:
Once you have the emission and transition probabilities you can measure if some observation belongs to a different state. So, for example, is '3' (observation no. 4) closer to state 1 or 2? You measure the emission probability of state 1, then the same for state 2 and find the most probable one. You re-assign all observations to their new states and go back to Step 1. 
You terminate when you have no new changes. ', u'Thanks for the detailed explanation!']}]",,,,1163,,[Solution] Challenge Question 24 - Pattern Recognition Through Time,"[challengeqtns, lesson8]"
5ad7d4a90d63974e20c3925b,"For assignment 5, I never could get mine to consistently run without underflow. I tried to implement everything in logspace but obviously missed something. Now that the assignment is returned is there a reference implementation or something I could check out? I'd really like to understand where I went wrong.",jc6w44hrp9v2ki,"[{u'text': u'I remember changing the image data type to float32 resolved underflow issue.', u'responses': []}]",,,,1165,,Underflow,[a5]
5ad7d4a90d63974e20c3925c,"Hello everyone,

Apologies for the short notice. I won't be able to make it to my office hours at the usual time tomorrow, and have had to postpone it to the same time (10:30 AM Eastern) on Thursday.

I'll be back to my usual schedule from next week.

",jc6w44hrp9v2ki,[],,,,1166,,Ravi OH postponed to Thursday,[office_hours]
5ad7d4a90d63974e20c3925d,"This post is a solution for Challenge Question 25, @1054.


VITERBI TRELLIS


The optimal path is S1 - S2 - S1 - S2 - S2 - S3 - S3, with a total probability of 1.089 * 10-6",jc6w44hrp9v2ki,"[{u'text': u'Hope this isn't a stupid question.  how did you get .15 for state 1 at time 1?  I got .242.  Just want to make sure I have this all figured out cause I'm guessing this would make an excellent question on the final exam.', u'responses': [u'Hey Eric, not stupid at all! That was a mistake. I corrected it, should be good now.']}]",,,,1168,,[Solution] Challenge Question 25 - Pattern Recognition Through Time,"[lesson8, challengeqtns]"
5ad7d4a90d63974e20c3925e,"Hi all,

I have a graduation party tonight so my OH is moved to tomorrow 6:30 - 8 pm ET.

Xuewen

#pin",jc6w44hrp9v2ki,[],,,,1170,,Xuewen OH postponed to Friday,[office_hours]
5ad7d4a90d63974e20c3925f,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


LOGIC MAPS

You are given a function MapColor and predicates In(x, y), Borders(x, y), and Country(x), whose arguments are geographical regions, along with constant symbols for various regions.
In each of the following we give an English sentence and a number of candidate logical expressions. For each of the logical expressions, state whether it:
(1) correctly expresses the English sentence;
(2) is syntactically invalid and therefore meaningless; or
(3) is syntactically valid but does not express the meaning of the English sentence.
 
(In the blank after each expression, write the number 1, 2, or 3 as your answer, given the meaning as described above)
 
a. Paris and Marseilles are both in France.
(i) In(Paris ∧ Marseilles, France). ________
(ii) In(Paris, France) ∧ In(Marseilles, France). ________
(iii) In(Paris, France) ∨ In(Marseilles, France). ________
 b. All countries that border Ecuador are in South America.
(i) ∀ c Country(c) ∧ Border(c, Ecuador) ⇒ In(c, SouthAmerica). ________
(ii) ∀ c Country(c) ⇒ [Border(c, Ecuador) ⇒ In(c, SouthAmerica)]. ________
(iii) ∀ c [Country(c) ⇒ Border(c, Ecuador)] ⇒ In(c, SouthAmerica). ________
(iv) ∀ c Country(c) ∧ Border(c, Ecuador) ∧ In(c, SouthAmerica). ________
 
c. No region in South America borders any region in Europe.
(i) ¬[∃ c, d In(c, SouthAmerica) ∧ In(d, Europe) ∧ Borders(c, d)]. ________
(ii) ∀ c, d [In(c, SouthAmerica) ∧ In(d, Europe)] ⇒ ¬Borders(c, d). ________
(iii) ¬∀ c In(c, SouthAmerica) ⇒ ∃ d In(d, Europe) ∧ ¬Borders(c, d). ________
(iv) ∀ c In(c, SouthAmerica) ⇒ ∀ d In(d, Europe) ⇒ ¬Borders(c, d). ________
 
d. No two adjacent countries have the same map color.
(i) ∀ x, y ¬Country(x) ∨ ¬Country(y) ∨ ¬Borders(x, y) ∨ ¬(MapColor(x) = MapColor(y)). ________
(ii) ∀ x, y (Country(x) ∧ Country(y) ∧ Borders(x, y) ∧ ¬(x = y)) ⇒ ¬(MapColor(x) = MapColor(y)). ________
(iii) ∀ x, y Country(x) ∧ Country(y) ∧ Borders(x, y) ∧ ¬(MapColor(x) = MapColor(y)). ________
(iv) ∀ x, y (Country(x) ∧ Country(y) ∧ Borders(x, y)) ⇒ MapColor(x = y). ________
 
 
 

Solution by Thad:  https://youtu.be/sXsI0Wsam_I?t=6m14s - Please attempt to solve it first on your own!
  
",jc6w44hrp9v2ki,"[{u'text': u'I'll give it a shot.

a. Paris and Marseilles are both in France.
(i) In(Paris ∧ Marseilles, France). 
2, invalid since it can only be one object in the function

(ii) In(Paris, France) ∧ In(Marseilles, France).
1, correct

(iii) In(Paris, France) ∨ In(Marseilles, France). 
3, valid but says Paris is in France or Marseilles is in France
 b. All countries that border Ecuador are in South America.
(i) ∀ c Country(c) ∧ Border(c, Ecuador) ⇒ In(c, SouthAmerica).
1, Correct

(ii) ∀ c Country(c) ⇒ [Border(c, Ecuador) ⇒ In(c, SouthAmerica)]. 
3, valid but i think it says, for all C, if C is a country, then it is true that C borders ecuador which implies c is in south america

(iii) ∀ c [Country(c) ⇒ Border(c, Ecuador)] ⇒ In(c, SouthAmerica).
3, valid but says for all C, if C is a country, then c borders ecuador which then implies that c is in south america

(iv) ∀ c Country(c) ∧ Border(c, Ecuador) ∧ In(c, SouthAmerica).
3, I think it is valid but is incorrect (not 100% sure though). It states that for all C, c is a country and c borders ecuador and c is in southamerica.  
 
c. No region in South America borders any region in Europe.
(i) ¬[∃ c, d In(c, SouthAmerica) ∧ In(d, Europe) ∧ Borders(c, d)].
3, valid but states It is not the case that there is a c and d such that c is in south america and d is in europe and c borders d.

(ii) ∀ c, d [In(c, SouthAmerica) ∧ In(d, Europe)] ⇒ ¬Borders(c, d).
1 Correct

(iii) ¬∀ c In(c, SouthAmerica) ⇒ ∃ d In(d, Europe) ∧ ¬Borders(c, d).
2, invalid since the negation operator needs to be adjacent to a function

(iv) ∀ c In(c, SouthAmerica) ⇒ ∀ d In(d, Europe) ⇒ ¬Borders(c, d).
3, valid but states, for all c, if c is in south america, then for all d, d is in europe which implies that c does not border d
 
d. No two adjacent countries have the same map color.
(i) ∀ x, y ¬Country(x) ∨ ¬Country(y) ∨ ¬Borders(x, y) ∨ ¬(MapColor(x) = MapColor(y)).
3, states for all x,y if x is not a country or y is not a country or x does not border y or it is not the case that the mapcolor of x is the same as the map color of y

(ii) ∀ x, y (Country(x) ∧ Country(y) ∧ Borders(x, y) ∧ ¬(x = y)) ⇒ ¬(MapColor(x) = MapColor(y)). 
1, correct, key being that x is not equal to y (assuming a country can border itself)

(iii) ∀ x, y Country(x) ∧ Country(y) ∧ Borders(x, y) ∧ ¬(MapColor(x) = MapColor(y)).
3, close to (ii) but x could equal y

(iv) ∀ x, y (Country(x) ∧ Country(y) ∧ Borders(x, y)) ⇒ MapColor(x = y).
3, if x is a country, y is a country and x borders y, then the map colors of x and y are equivalent', u'responses': [u'Hi Erik, posted Thad's solutions. Take a look and tell me if you have any questions! ;)']}, {u'text': u'Posting it here so that I can verify when the solution is out.a. Paris and Marseilles are both in France.(i) - 2 , invalid as P and M is is true, ln(true, F) = ?(ii) - 1 , looks fine(iii) - 3 , or is incorrect b. All countries that border Ecuador are in South America.(i) - 1 , seems okay - All country cond. And Border cond. implies continent condition (ii) - 3 , seems okay but border condition is not for all countryuntry (iii) - 3 , country -> country,Border not correct as sentence(iv) - 3 , No implication just gives set of countries satisfying 2 condtions c. No region in South America borders any region in Europe.(i) - 1 , effectivly it looks like it will work. (ii) - 1 , seems good as implication works well(iii) - 2 , couldn't understand , last and with what?(iv) - 3 , implication in first part is not valid d. No two adjacent countries have the same map color.(i) - 3 , no condition on being a country(ii) - 1 , covers everything (iii) - 3 , after reading (ii), i miss the -(x=y) here(iv) - 3 , Valid but doesn't go with the givne statement', u'responses': [u'I think d - iv should be invalid... as all arguments need to be regions.... MapColor(x=y) has a boolean argument.', u'Hey guys, posted Thad's solutions. Take a look and tell me if you disagree with something.', u'@Saalis : Yes, you are correct!. I missed to consider the syntax part and considered  MapColor(x = y) same as MapColor(x) = MapColor(y).']}, {u'text': u'Hi Theodore, 

I have a confusion on sentence b:

I am not 100% sure on how to solve such problems but in i) ∀ c Country(c) ∧ Border(c, Ecuador) ⇒ In(c, SouthAmerica). Suppose Border(c, Ecuador) is false, then the premise is false but the entire expression will always evaluate to true (irrespective of the conclusion). Should we not consider such case? Because of the same reasoning I got ii) incorrect too.

Could you please guide?
Thanks!', u'responses': [u'Hi Rupal,

That's an interesting question. You're correct in your assessment that statement: "" F ⇒ F/T "" is always true.
Such a statement however makes no sense because it is never going to produce any additional information; you will never derive anything from it.

So it really depends on the question at hand. If the question read 'evaluate these sentences as True or False' then the answer would be true. You were correct to use it on b (ii), as the statement was isolated in brackets which meant that if country(c) is true, then everything within the brackets should also be true; which is what we want.']}]",,,,1171,,Challenge Question 26 - Logic and Planning,"[lesson9, challengeqtns]"
5ad7d4aa0d63974e20c39260,"Hi, 

I am having trouble understanding the example given in Chapter 9 in AIMA under section 9.5 Resolution. In order to explain how to get a CNF from First Order Logic(FOL), there is an example ""Everyone who loves all animals is loved by someone"" and its FOL expression is stated as: 
∀x [∀y Animal(y) => Loves(x, y)] =>  [∃y Loves(y, x)]      - exp A

My questions are: 
1). When I read that sentence, I naturally thought its FOL would be:
∀x ∀y Animal(x) ∧ Loves(x, y) =>  ∃z Loves(y, z)      - exp B
Is this an incorrect interpretation?

2). In exp A above, 'y' on the conclusion side creates confusion with 'y' in antecedent. Is it fine to use the same variable 'y' here, where it refers to animal on LHS but 'someone' on RHS?

3). In step 1: Eliminate Implications (mentioned in book), there are 2 implications to be eliminated, but it looks like only the inner implication has been eliminated. After eliminating implication, the expression shown is: 
∀x [¬∀y ¬Animal(y) ∨ Loves(x, y)] ∨ [∃y Loves(y, x)] 

As per my understanding, this should have been evaluated to:
¬∀x [¬∀y ¬Animal(y) ∨ Loves(x, y)] ∨ [∃y Loves(y, x)]
The first ¬ to eliminate the implication between antecedent and conclusion. Am I missing something here?

Could someone please share some insights?

Thanks
",jc6w44hrp9v2ki,"[{u'text': u'Thanks Junwei for the truth table perspective. From what you explained, its quite clear I did not consider every possibility.

Thanks Ravikiran for the elaborate answer. I never knew the details mentioned in part3. Its definitely clear now! ', u'responses': []}]","In Exp A, Loves(y, x) implies y loves x. In Exp B, it appears to be the other way around. I'll first correct that before proceeding:
∀x ∀y Animal(x) ∧ Loves(y, x) =>  ∃z Loves(z, y)

Now, I would say it is an incorrect implementation. Allow me to explain.

Exp A
∀y Animal(y) => Loves(x, y) says ""For all Y, Y is an animal implies X loves Y."" In other words, ""If Y is an animal, X loves Y."" 
This is the same as saying X is someone who loves all animals.
X loves all animals => [∃y Loves(y, x)] This means, if X loves all animals, there exists someone who loves X.
Since this applies for all X, it is the same as the sentence ""Everyone who loves all animals is loved by someone.""

Exp B
Assuming the expression you meant to convey was the following:
∀x ∀y Animal(x) ∧ Loves(y, x) =>  ∃z Loves(z, y)
Let's take the LHS:
∀x ∀y Animal(x) ∧ Loves(y, x)
Here, you are saying ""All X are animals and are loved by all Y."" which is clearly not true. 
Maybe one could interpret this as saying ""If X is an animal and is loved by Y, Y is loved by someone.""
Which means the same as ""Everyone who loves an animal is loved by someone."" You're not accounting for the person having to love ALL animals. Hence it's still incorrect.

2) You're right, it can get a bit confusing. Best to always use different variables wherever possible.

3) When eliminating implication, A => B is changed to ¬A ∨ B. 
Thus, ∀x A => B which is the same as ∀x (A => B) gets changed to ∀x ¬A ∨ B.
Please note: The negation is NOT applied to ""for all"" or ""there exists"", it is only applied to the inner condition.

In the textbook example,
∀x [∀y Animal(y) => Loves(x, y)] =>  [∃y Loves(y, x)] 

Let us say this is ∀x C => D
where
C is ∀y Animal(y) => Loves(x, y)
D is ∃y Loves(y, x)

Now, we eliminate the implication from C.
C is ∀y ¬ Animal(y) ∨ Loves(x, y)

Now, we wish to eliminate the implication from ∀x C => D
It becomes ∀x ¬C ∨ D
Now, we wish to negate C.
Please remember that negating ""<expression> is true for all X"" IS NOT ""<expression> is false for all X""
For example, if I say ""Everyone in the class got an A"", the negation of that is not ""Everyone in the class failed to get an A"", it is ""Not everyone in the class got an A.""
Essentially, we are simply negating the ""for every"".
Thus, the negation of ∀y ¬ Animal(y) ∨ Loves(x, y) is ¬∀y ¬ Animal(y) ∨ Loves(x, y)

Which means after eliminating both implications, we get ∀x ¬∀y ¬ Animal(y) ∨ Loves(x, y) ∨ ∃y Loves(y, x)

I hope this is clear!",,,1173,"This is a very good question. I understand part (1) as follows:

For the LHS ""Everyone who loves all animals"", my understanding is
exp1 LHS: ∀x ∀y Animal(y) => Loves(x, y) says ""For each Y, if Y is an animal, then every X loves Y."". 
exp2 LHS: ∀x ∀y Animal(y) ∧ Loves(x, y) says ""For each Y that is animal and each X loves Y."" 

I think the difference between these two is the difference between a=>b and a∧b. To see the difference, I used truth table
aba=>ba∧bFFTFFTTFTFFFTTTT

Based on the table, LHS of exp1 and exp2 is identical only when a is True, i.e Y is indeed animal. When a is False, ie Y is not animal, exp1 differs from exp2. So in English, exp1 full expression includes the following statements 
""For each robot, if it is animal, then everyone loves it, and then everyone is loved by an entity""
""For each tree, if it is animal, then everyone loves it, and then everyone is loved by an entity""
""For each paper, if it is animal, then everyone loves it, and then everyone is loved by an entity""
... You get the idea. All the above statement depends on if everyone is loved by an entity. If everyone is loved by an entity is true, then the statement is true, otherwise false. 

For exp2 full expression, it becomes""If each robot is animal, and everyone loves it, then everyone is loved by an entity""
""If each tree is animal, and everyone loves it, and then everyone is loved by an entity""
""If each paper is animal, and everyone loves it, and then everyone is loved by an entity""
...
and all the above statement is true, regardless if everyone is loved by an entity or not. 

In summary, I think exp1 is closer to the English statement than exp2. ",Doubt in Resolution Section Chapter 9,[lesson9]
5ad7d4aa0d63974e20c39261,"This may seem a very basic question, but I don't understand how the state probabilities are calculated in the Viterbi Trellis.
In the quiz in video 20, how were the probabilities filled?

",jc6w44hrp9v2ki,[],,,,1174,"This is as described in the previous section.

We use the observation sequence. At time step 5, we see a delta y of -5. By looking at the output distribution at the three states, we can see how probable it is to get a -5 from them.

Based on the mean and stddev of each, we can estimate the probabilities of getting a -5 from them.
Considering the mean of state 1 is at 5, and the distance between the mean and the observed value is 9. Also, it has a (relatively) larger stddev. Hence, the probability is quite low.Considering the mean of state 2 is at 0, the distance between the mean and the observed value is 5. But it has a (relatively) smaller stddev. Hence the probability is even lower.Considering the mean of state 3 is at -5, and the observed value -5, the distance is zero. This has a high probability.
In terms of values,
For state 1, the situation is similar to the one for evaluating the prob of being in state 3 at time step 2 (observed val 4); the distribution has a similar stddev, and the distance between the mean and the observed value is 9, and the distance we see is 10. Hence, assign a similar value 10^-4, (d)For state 2, the situation is somewhere in between step 2 (observed val 7, assigned prob 10^-5) and step 3 (observed val 4, assigned prob 10^-7). This was assigned a value of 10^-4. Out of the choices, pick 10^-6, (e)For state 3, the situation is similar the one for evaluating the prob of being in state 1 at time step 3 (observed val 4). This was at a distance of 1. In this case, the distribution has a similar stddev, and the distance from the mean is even smaller, hence the assigned probability has to be higher then the one assigned (was .6); we choose 0.8 (b)

edit: switched from E-notation to representation from the slide
",How are probabilities calculated in Viterbi Trellis?,[lesson8]
5ad7d4aa0d63974e20c39262,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


LOGIC SPIES
In the near future, the Democratic Republic of Starneria is at war with the Autocratic Dictatorship of Isbelland. As an agent working for Starneria’s intelligence agency AI-6, your mission is simple: go behind enemy lines and take down the dictatorship by finding evidence linking Isbelland’s ML-4 to human rights violations. However, if there is a person who needs to be rescued, they are more important than your mission.
In order to help you, AI-6 has collected the following intelligence about the people in Isbelland: If a person is a spy, their life is in danger. Else, he/she is a commoner and their life is safe. If a person is a commoner or their life is in danger, they need to be rescued. Moreover, spies in Isbelland get some great perks: every spy drives a fast car, and only spies are allowed to use smartphones and smartwatches.
For the first three questions, one or more options are correct. 
 
Question 1:
You step out of the airport in Isbelland City and find that the hotel is only ten minutes away on foot. You decide to walk. A car suddenly speeds past you, and you realize it’s very very fast. What can you say about the driver?

The driver is a spy


The driver uses a smartphone

The driver needs to be rescued

 

Question 2:
On your way to your hotel, you meet a woman on the street. What can you say about her for sure?

She is a spy


She is more important than the mission

She needs to be rescued

 

Question 3:
You walk into the hotel and are greeted by the receptionist. He offers to take your bags to your room, and you notice that he is wearing an old analog watch. Which of the following can be true about the receptionist?

He is a spy

His life is safe

The mission is more important than the receptionist


Question 4 :
After reaching your room, you check in with your handler. She tells you that one (logical) sentence in the intelligence you received was actually added by an Isbellan spy purely to make you help ML-4. Which sentence is it?
 

If a person is a spy, their life is in danger.

If a person is not a spy, he/she is a commoner and their life is safe.

If a person is a commoner or their life is in danger, they need to be rescued.

Every spy drives a fast car.

Only spies are allowed to use smartphones.

Only spies are allowed to use smartwatches.


Question 5 :
After removing the above sentence, using the following symbols:C: Person is a commonerD: Person’s life is in dangerF: Person drives a fast carI: Person is more important than the missionP: Person uses a smartphoneR: Person needs to be rescuedS: Person is a spyW: Person uses a smartwatch
Prove using resolution that if a person doesn’t drive a fast car, they are a commoner.

Question 6 :
You are given the following predicates:

Commoner(x)

Danger(x)

FastCar(x)

Smartwatch(x)

Smartphone(x)

User(x, y)

Spy(x)

Rescue(x)

For each of the following logical expressions, state whether it

Exactly expresses one of the sentences given in the intelligence

Does not exactly express a sentence, but can be inferred from the intelligence

Is syntactically valid, but cannot be inferred from the intelligence

Is syntactically invalid, and therefore meaningless

You may assume that the arguments are always of the correct type

∀ x , y [ FastCar(x) ∧ User(x, y) ] ⇒ Spy (y) __________________

 

∀ x Spy(x) ⇒ [ ∃ y Smartwatch(y) ∧ User(x, y) ] __________________

 

∃ x ¬Commoner(x) ∨ Spy(x) ∨ Rescue(x) __________________

 

∃ x [ Commoner ∨ Danger(x) ] ⇒ Rescue(x) __________________

 

∀ x , y ¬Smartphone(x) ∨ ¬User (x, y) ∨ Spy(y) __________________

 

∀ x ¬Spy(x) ⇒ [ Commoner(x) ∧ ¬Danger(x) ] __________________

 

∀ x , y [ FastCar(x) ∧ User(x, y) ] ∨ Commoner(y) __________________

∀ x ∧ Spy(x) ∧ FastCar(x) ⇒ ¬Commoner(x) __________________

 
 

Solution: @1211 - Please first try it on your own before looking at the solutions.",jc6w44hrp9v2ki,"[{u'text': u'I'll give it a shot. 

Initial knowledge base:
1:  If a person who needs to be rescued, they are more important than your mission.
2.  If a person is a spy, their life is in danger.
3.  If a person is not a spy, then he/she is a commoner and their life is safe
4.  If a person is a commoner or their life is in danger, they need to be rescued
5.  If a person is a spy, that person drives a fast car.
6.  If a person is a spy and not a commoner, that person uses a smart phone.
7.  If a person is a spy and not a commoner, that person uses a smart watch.


Question 1:
You step out of the airport in Isbelland City and find that the hotel is only ten minutes away on foot. You decide to walk. A car suddenly speeds past you, and you realize it’s very very fast. What can you say about the driver?

The driver is a spy


The driver uses a smartphone

The driver needs to be rescued

 
Driver needs to be rescued.  Spies or commoners can drive fast cars, both need to be rescued.
 
Question 2:
On your way to your hotel, you meet a woman on the street. What can you say about her for sure?

She is a spy


She is more important than the mission

She needs to be rescued

 
More important than the mission & need to be rescued.  Since spies are in danger, commoners and those in danger need to be rescued, rescues are more important than the mission.
 
Question 3:
You walk into the hotel and are greeted by the receptionist. He offers to take your bags to your room, and you notice that he is wearing an old analog watch. Which of the following can be true about the receptionist?

He is a spy

His life is safe

The mission is more important than the receptionist


1st and 2nd can be true but not be known to be necessarily true.  The 3rd is not true since commoners and spies need rescuing, which means everyone needs rescuing.
Question 4 :
After reaching your room, you check in with your handler. She tells you that one (logical) sentence in the intelligence you received was actually added by an Isbellan spy purely to make you help ML-4. Which sentence is it?
 

If a person is a spy, their life is in danger.

If a person is not a spy, he/she is a commoner and their life is safe.

If a person is a commoner or their life is in danger, they need to be rescued.

Every spy drives a fast car.

Only spies are allowed to use smartphones.

Only spies are allowed to use smartwatches.

 
#2, since if the ML-4 is accused of humanitarian crimes, this would make the most sense, that all commoners' lives are safe.
Question 5 :
After removing the above sentence, using the following symbols:C: Person is a commonerD: Person’s life is in dangerF: Person drives a fast carI: Person is more important than the missionP: Person uses a smartphoneR: Person needs to be rescuedS: Person is a spyW: Person uses a smartwatch
Prove using resolution that if a person doesn’t drive a fast car, they are a commoner.
 
I am stuck on this one and would appreciate help.

Knowledge base:
S => D (if the person is a spy, life is in danger)
[C v D] => R (if a commoner or in danger, then needs rescuing)
S => F (if a spy, that person drives a fast car)
P => S (only a spy can use a smart phone)
W => S (only a spy can use a smart watch)

Proof by resolution is a proof by contradiction.  What we need to prove is !F => C.  I got the knowledge base in to conjunctive normal form but was unable to cancel out all the terms, so I either am wrong or misunderstand something.
Question 6 :
You are given the following predicates:

Commoner(x)

Danger(x)

FastCar(x)

Smartwatch(x)

Smartphone(x)

User(x, y)

Spy(x)

Rescue(x)

For each of the following logical expressions, state whether it

Exactly expresses one of the sentences given in the intelligence

Does not exactly express a sentence, but can be inferred from the intelligence

Is syntactically valid, but cannot be inferred from the intelligence

Is syntactically invalid, and therefore meaningless

You may assume that the arguments are always of the correct type


∀ x , y [ FastCar(x) ∧ User(x, y) ] ⇒ Spy (y) :  #4

 

∀ x Spy(x) ⇒ [ ∃ y Smartwatch(y) ∧ User(x, y) ]  #1

 

∃ x ¬Commoner(x) ∨ Spy(x) ∨ Rescue(x)  #3

 

∃ x [ Commoner ∨ Danger(x) ] ⇒ Rescue(x) #4

 

∀ x , y ¬Smartphone(x) ∨ ¬User (x, y) ∨ Spy(y) #3

 

∀ x ¬Spy(x) ⇒ [ Commoner(x) ∧ ¬Danger(x) ] #1

 

∀ x , y [ FastCar(x) ∧ User(x, y) ] ∨ Commoner(y) #2

∀ x ∧ Spy(x) ∧ FastCar(x) ⇒ ¬Commoner(x) #4
', u'responses': [u'∀ x , y [ FastCar(x) ∧ User(x, y) ] ⇒ Spy (y) :  #4Why is it syntactially invalid?∀ x , y [ FastCar(x) ∧ User(x, y) ] ∨ Commoner(y) #2What does this sentence infer?', u'Nice try! 1-3 are stellar, I would give 4-6 a second look. :)', u'Oops, i think i copied off of my notes wrong in a few spots.  I'll have to look again later.', u'Hopefully, y'all are having fun with this one!', u'In the case of 
∀ x , y [ FastCar(x) ∧ User(x, y) ] ∨ Commoner(y) 
I don't think is true because this implies that a Commoner can not drive a fast car, which can not be inferred from the intelligence.
', u'@Eric Wickstrom I think there should be another clause in your knowledge baseYour knowledge base:1- S => D (if the person is a spy, life is in danger)2 - [C v D] => R (if a commoner or in danger, then needs rescuing)3 - S => F (if a spy, that person drives a fast car)4 - P => S (only a spy can use a smart phone)5 - W => S (only a spy can use a smart watch)6  - !S => C (if not spy then commoner)

Proof:
S => F (3)
!F => !S (Modus Tollens on 3)
!F => C ( !F => !S , !S => C)
', u'Solution's up, take a look :)']}]",,,,1176,,Challenge Question 27 - Logic and Planning,"[lesson9, challengeqtns]"
5ad7d4aa0d63974e20c39263,"The segment ""Situation Calculus 3"" in lesson 9 seems to be in the wrong place? It seems to be referencing things covered later in the lesson. Is it supposed to be after ""Situation Calculus 3""?",jc6w44hrp9v2ki,[],"After Situation Calculus 2, yes. Thanks for bringing that to our notice. Not sure why it's this way, but we'll get it fixed ASAP.",,,1180,,&#34;Situation Caclulus 3&#34; in wrong place,[lesson9]
5ad7d4aa0d63974e20c39264,"This week you should finish Lesson 10, Planning Under Uncertainty, and read Chapters 17 & 21 in Russell & Norvig.

CIOS opens tomorrow! You should receive an email with the link. Please provide your feedback if you wish. As we have said before, this course is constantly evolving and we need your honest feedback to improve it further. 

Assignment 6: Hidden Markov Models
Due: April 22 at 11:59PM UTC-12 (Anywhere on Earth time)
Details in @1149.

Final Exam: April 23 - 29, 2018
Here is the list of topics that may be covered on the exam.
Just as with the midterm, the final exam will be posted on T-Square on Monday, April 23, as a PDF form. You can type directly into the form, or print, hand-write, & scan (or some combination of these). Submission will be through Gradescope, and the rules and guidelines will be the same as with the midterm.

As always, here are the OH calendar, the syllabus and the schedule.  

#pin",jc6w44hrp9v2ki,[],,,,1181,,Week 15 Announcement,[announcements]
5ad7d4ab0d63974e20c39265,"What is the policy on using the pseudo-code and/or the python code shown on the Wikipedia page?: https://en.wikipedia.org/wiki/Viterbi_algorithm

I assume most students know about this link and are already using it to some extent. So, I think it makes sense to have an official policy clarification if this is fair-use for this project.

Thank you",jc6w44hrp9v2ki,"[{u'text': u'So only code directly derived from the pseudo-code is allowed. Make sense, thanks!', u'responses': []}]",,,,1182,"From what I saw from the Syllabus, pseudo code should be fine (this is what we use from the textbook), but looking at python code directly applicable to the problem is cheating and not allowed. ",Viterbi Algorithm on Wikipedia,[a6]
5adcb42d1331be8fe9423b32,"Apologizes if this has already been posted.  R&N chapter 17 slides need to be reposted as content is cut off.  I tried flipping the layout in my viewer, which did not fix it.

EDIT:  Link to slides in the course schedule: https://www.cc.gatech.edu/~thad/6601-gradAI-fall2015/chapter17.pdf
",jc6w44hrp9v2ki,"[{u'text': u'I ended up finding all the slides from AIMA website http://aima.eecs.berkeley.edu/. (Slides at  http://aima.eecs.berkeley.edu/slides-pdf/ ) but chapter 17 is not there. I also found an edx course (which is linked from AIMA website) as well which follows the book more closely.
https://www.edx.org/course/artificial-intelligence-ai-columbiax-csmm-101x-0', u'responses': []}]",,,,1195,I could find the working link in the Final Course Topics List:  https://people.eecs.berkeley.edu/~russell/classes/cs188/f05/slides/chapter17.pdf,"R &amp; N slides, ch17",[lesson10]
5adcb42e1331be8fe9423b33,"Conference info: https://conferences.oreilly.com/artificial-intelligence/ai-ny?cmp=kn-data-confreg-home-ainy18_adw_branded

I'm attending and figured some of the other people in this class might be there. If so, would love to meet up. Let me know!",jc6w44hrp9v2ki,"[{u'text': u'Unfortunately not, I am closer to the one in Beijing which seems to have seariously impressive set of speakers - http://beijing.thegmic.com/speakers/. Please do share your experiences if you can.', u'responses': []}]",,,,1200,,Anyone Else Going to O&#39;Reilly&#39;s AI Conference in NYC (Apr 29 - May 2)?,[other]
5adcb42e1331be8fe9423b34,"Can someone explain in more detail the difference between Relations (Predicate) and Functions?
I am having a hard time understanding the examples from the book, since both are quite similar.
Thanks.",jc6w44hrp9v2ki,[],"Hi Andres,
you can imagine that Relations return a boolean value whereas Functions return a new object.

isFather(x, y) would be a relation and would return true or false, depending on whether x is the father of y.
FatherOf(x) would be a function returning the father of x.",,,1204,,First Order Logic clarification,[lesson9]
5adcb42e1331be8fe9423b35,"These questions are aimed at encouraging peer learning, and making sure that you understand the material better. Check out more Challenge Questions here @283.
We want students to first solve these on their own, before scrolling down for answers. Since it is tempting to look at other students' comments, we request students to NOT post any comments until this post is open for discussion.

This post is now OPEN FOR DISCUSSION.


VALUE ITERATION

Consider the grid-world given below and a bot who is trying to learn the optimal policy. If an action results in landing on one of the reward states, the corresponding reward is awarded during that transition. All states with rewards are terminal states. The other states have the North, East, South, West actions available. Assume this is a deterministic environment. The discount factor γ = 0.5. The bot starts at (1,2).
 

What is the optimal utility value at each position after convergence?



Solution: @1212 - Please try it first on your own, before looking at the answers.
#pin",jc6w44hrp9v2ki,"[{u'text': u'', u'responses': []}]",,,,1205,,Challenge Question 28 - Planning under Uncertainty,"[lesson10, challengeqtns]"
